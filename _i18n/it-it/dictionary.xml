<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Note legali</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Le note legali forniscono l'accesso a dichiarazioni di copyright, marchi, brevetti e altro ancora.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marchi</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, il logo NETAPP e i marchi elencati nella pagina dei marchi NetApp sono marchi di NetApp, Inc. Altri nomi di società e prodotti potrebbero essere marchi dei rispettivi proprietari.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevetti</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Un elenco aggiornato dei brevetti di proprietà di NetApp è disponibile all'indirizzo:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Direttiva sulla privacy</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Open source</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">I file di avviso forniscono informazioni sul copyright e sulle licenze di terze parti utilizzate nel software NetApp.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Avviso per ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Avviso per ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Avviso per ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Avviso per ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Avviso per ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Avviso per ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Avviso per ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Avviso per ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Avviso per ONTAP 9,7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Avviso per ONTAP 9,6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Avviso per ONTAP 9,5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Avviso per ONTAP 9,4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Avviso per ONTAP 9,3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Avviso per ONTAP 9,2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Avviso per ONTAP 9,1</block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Policy</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Ciò è comune con i database. Anche i database che contengono blocchi inattivi sono candidati per il tiering FabricPool. Ad esempio, un database di gestione della catena logistica potrebbe contenere informazioni cronologiche che devono essere disponibili se necessario ma non accessibili durante le normali operazioni. La funzione FabricPool può essere utilizzata per spostare selettivamente i blocchi inattivi.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Ad esempio, i file di dati in esecuzione su un volume FabricPool con un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il periodo di 90 giorni conserva i blocchi a cui si accede nei 90 giorni precedenti nel tier di performance. Tuttavia, qualsiasi elemento a cui non si accede per 90 giorni viene ricollocato nel Tier di capacità. In altri casi, la normale attività applicativa preserva i blocchi corretti sul livello corretto. Ad esempio, se un database viene normalmente utilizzato per elaborare regolarmente i 60 giorni precedenti di dati, è molto più basso<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il periodo può essere impostato perché l'attività naturale dell'applicazione garantisce che i blocchi non vengano spostati prematuramente.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> i criteri devono essere utilizzati con attenzione per i database. Numerosi database prevedono attività periodiche come la fine del quarter o la reindicizzazione delle operazioni. Se il periodo di queste operazioni è superiore a.<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> possono verificarsi problemi di prestazioni. Ad esempio, se l'elaborazione a fine quarter richiede 1TB TB di dati che non vengono intatti, è possibile che tali dati siano presenti nel Tier di capacità. Le letture dal Tier di capacità sono spesso estremamente veloci e potrebbero non causare problemi di performance, ma i risultati esatti dipendono dalla configurazione dell'archivio di oggetti.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il criterio deve essere impostato su un livello sufficientemente alto da conservare i file che potrebbero essere necessari nel livello di prestazioni. Ad esempio, un database in cui potrebbero essere necessari gli ultimi 60 giorni di dati con prestazioni ottimali giustificherebbe l'impostazione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo a 60 giorni. Risultati simili possono essere ottenuti anche in base ai modelli di accesso dei file. Ad esempio, se sono necessari gli ultimi 90 giorni di dati e l'applicazione sta accedendo a quell'arco di dati di 90 giorni, i dati resteranno sul Tier di performance. Impostazione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> un periodo di 2 giorni eseguirebbe il tiering dei dati non appena i dati diventano meno attivi.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy è necessaria per gestire il tiering di questi blocchi perché solo l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio influisce sui blocchi che si trovano nel file system attivo.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Qualsiasi tipo di accesso ai dati ripristina i dati della mappa termica. Pertanto, le scansioni delle tabelle complete dei database e persino le attività di backup in grado di leggere i file di origine impediscono il tiering perché necessario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la soglia non viene mai raggiunta.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Sebbene il ridimensionamento delle LUN sia un'opzione per aumentare la capacità, in genere è preferibile utilizzare un LVM, incluso Oracle ASM. Uno dei motivi principali per cui esistono le LVM è evitare la necessità di ridimensionare le LUN. Con un LVM, più LUN sono unite in un pool virtuale di storage. I volumi logici scavati da questo pool sono gestiti da LVM e possono essere facilmente ridimensionati. Un ulteriore vantaggio è l'eliminazione degli hotspot su una determinata unità distribuendo un determinato volume logico su tutte le LUN disponibili. Di solito, la migrazione trasparente può essere eseguita utilizzando il volume manager per spostare le estensioni sottostanti di un volume logico su nuovi LUN.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL forzato manualmente</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">Questa sezione espande la spiegazione di ONTAP NVFAIL di base per affrontare argomenti specifici di MetroCluster.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Con MetroCluster, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight Se si verifica un guasto nella NVRAM locale o nella connettività ad altri nodi, i dati non verranno più mirrorati.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Se la NVRAM locale riporta un errore, il nodo si arresta. Questo arresto determina il failover su un partner controller quando vengono utilizzate coppie ha. Con MetroCluster, il comportamento dipende dalla configurazione complessiva scelta, ma può portare al failover automatico della nota remota. In ogni caso, nessun dato viene perso perché il controller che subisce l'errore non ha confermato l'operazione di scrittura.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Un guasto di connettività site-to-site che blocca la replica NVRAM ai nodi remoti è una situazione più complicata. Le scritture non vengono più replicate sui nodi remoti, con la possibilità di perdita di dati in caso di errore catastrofico su un controller. Cosa più importante, il tentativo di failover su un nodo diverso in queste condizioni comporta una perdita di dati.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">Il fattore di controllo è se la NVRAM è sincronizzata. Se la NVRAM è sincronizzata, il failover da nodo a nodo può procedere in tutta sicurezza senza il rischio di perdita di dati. In una configurazione MetroCluster, se la NVRAM e i plessi degli aggregati sottostanti sono sincronizzati, è possibile effettuare lo switchover senza correre il rischio di perdita di dati.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP non consente alcun failover o switchover quando i dati non sono sincronizzati, a meno che non sia forzato il failover o lo switchover. La forzatura di una modifica delle condizioni in questo modo riconosce che i dati potrebbero essere lasciati indietro nel controllore originale e che la perdita di dati è accettabile.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">I database sono particolarmente vulnerabili al danneggiamento se un failover o uno switchover è forzato, perché mantengono cache interne di dati su disco di dimensioni maggiori. In caso di failover o switchover forzato, le modifiche riconosciute in precedenza vengono eliminate del tutto. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Per proteggere le applicazioni da questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro gli errori della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano l'arresto di un'applicazione in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché eventuali scritture riconosciute sono ancora presenti nel sistema di storage e, nel caso dei database, tutti i dati delle transazioni con commit devono essere presenti nei registri.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Solitamente, gli amministratori dovranno arrestare completamente gli host prima di riportare manualmente LUN e volumi in linea. Sebbene queste fasi possano comportare un certo lavoro, questo approccio è il modo più sicuro per garantire l'integrità dei dati. Non tutti i dati richiedono questa protezione, motivo per cui il comportamento di NVFAIL può essere configurato in base al volume.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">L'opzione più sicura per forzare uno switchover con un cluster di applicazioni (inclusi VMware, Oracle RAC e altri) distribuito tra i siti dipende da come specificato<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> alla riga di comando. Questa opzione è disponibile come misura di emergenza per assicurarsi che tutti i dati memorizzati nella cache vengano eliminati. Se un host utilizza risorse di storage situate originariamente nel sito colpito da disastro, riceve errori di i/o o un handle di file obsoleto <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>). I database Oracle si arrestano in modo anomalo e i file system possono andare completamente offline o passare alla modalità di sola lettura.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Al termine dello switchover, il<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Il flag deve essere cancellato e i LUN devono essere messi online. Al termine di questa attività, è possibile riavviare il database. È possibile automatizzare queste attività per ridurre l'RTO.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">Come misura di sicurezza generale, impostare<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> contrassegnare tutti i volumi a cui è possibile accedere da un sito remoto durante le normali operazioni, ovvero si tratta di attività utilizzate prima del failover. Il risultato di questa impostazione è che i volumi remoti selezionati diventano non disponibili quando vengono immessi<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> durante uno switchover. Al termine dello switchover, il<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Il flag deve essere cancellato e i LUN devono essere messi online. Al termine di queste attività, è possibile riavviare le applicazioni. È possibile automatizzare queste attività per ridurre l'RTO.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">Il risultato è come usare l'<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> flag per commutatori manuali. Tuttavia, il numero di volumi interessati può essere limitato solo a quei volumi che devono essere protetti da applicazioni o sistemi operativi con cache obsolete.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Ci sono due requisiti critici per un ambiente che non utilizza<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> su volumi applicativi:</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Uno switchover forzato non deve avvenire più di 30 secondi dopo la perdita del sito primario.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Lo switchover non deve essere eseguito durante le attività di manutenzione o in altre condizioni in cui i plex SyncMirror o la replica della NVRAM non sono sincronizzati. Il primo requisito può essere soddisfatto con il software tiebreaker configurato per eseguire uno switchover entro 30 secondi da un guasto del sito. Questo requisito non significa che lo switchover debba essere eseguito entro 30 secondi dal rilevamento di un guasto del sito. Ciò significa che non è più sicuro forzare uno switchover se sono trascorsi 30 secondi da quando un sito è stato confermato operativo.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">Il secondo requisito può essere parzialmente soddisfatto disattivando tutte le funzionalità di switchover automatico quando la configurazione di MetroCluster non è sincronizzata. Un'opzione migliore è quella di disporre di una soluzione di tiebreaker in grado di monitorare lo stato di salute della replica NVRAM e dei plessi SyncMirror. Se il cluster non è completamente sincronizzato, il tiebreaker non deve attivare uno switchover.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">Il software NetApp MCTB non è in grado di monitorare lo stato di sincronizzazione, pertanto deve essere disattivato quando MetroCluster non è sincronizzato per alcun motivo. ClusterLion include funzionalità di monitoraggio NVRAM e plex e può essere configurato in modo da non attivare lo switchover a meno che il sistema MetroCluster non sia confermato completamente sincronizzato.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">Numero di LUN</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Un LUN è un oggetto virtualizzato in ONTAP presente in tutti i dischi dell'aggregato di hosting. Di conseguenza, le performance della LUN non sono influenzate dalle sue dimensioni, perché la LUN sfrutta al massimo il potenziale in termini di performance dell'aggregato, indipendentemente dalle dimensioni scelte.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">Per comodità, i clienti potrebbero desiderare di utilizzare un LUN di particolari dimensioni. Ad esempio, se un database è costruito su un gruppo di dischi LVM o Oracle ASM composto da due LUN da 1TB GB ciascuno, tale gruppo di dischi deve essere aumentato in incrementi di 1TB TB. Potrebbe essere preferibile costruire il gruppo di dischi da otto LUN da 500GB ciascuno in modo che il gruppo di dischi possa essere aumentato con incrementi più piccoli.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">La pratica di stabilire una dimensione LUN standard universale è scoraggiata perché ciò può complicare la gestibilità. Ad esempio, è possibile che una dimensione LUN standard di 100GB TB sia ottimale quando un database o un datastore è compreso nell'intervallo da 1TB a 2TB TB, ma un database o un datastore di 20TB GB richiederebbe 200 LUN. Ciò significa che i tempi di riavvio del server sono più lunghi, che vi sono più oggetti da gestire nelle varie interfacce utente e che prodotti come SnapCenter devono eseguire la ricerca su molti oggetti. Utilizzando un numero inferiore di LUN di dimensioni maggiori è possibile evitare questi problemi.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">Il numero di LUN è più importante delle dimensioni delle LUN.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">Le dimensioni dei LUN sono principalmente controllate dai requisiti di numero di LUN.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Evitare di creare più LUN del necessario.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">A differenza delle dimensioni delle LUN, il numero di LUN influisce sulle performance. Spesso le prestazioni delle applicazioni dipendono dalla capacità di eseguire i/o paralleli attraverso il livello SCSI. Di conseguenza, due LUN offrono performance migliori rispetto a una singola LUN. Utilizzare un LVM come Veritas VxVM, Linux LVM2 o Oracle ASM è il metodo più semplice per aumentare il parallelismo.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">I clienti di NetApp hanno in genere ottenuto il minimo beneficio dall'aumento del numero di LUN oltre i sedici, sebbene i test degli ambienti con dischi a stato solido al 100% con i/o casuali molto intensi abbiano dimostrato un ulteriore miglioramento fino a 64 LUN.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp consiglia* quanto segue:</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">In generale, da quattro a sedici LUN sono sufficienti per supportare le esigenze di i/o di qualsiasi carico di lavoro del database. Meno di quattro LUN potrebbero creare limiti di performance a causa delle limitazioni nelle implementazioni SCSI host.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Impostazioni del sistema operativo host</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">La maggior parte della documentazione del fornitore di applicazioni include impostazioni TCP ed ethernet specifiche per garantire il funzionamento ottimale dell'applicazione. Queste stesse impostazioni sono in genere sufficienti per fornire anche prestazioni ottimali dello storage basato su IP.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Controllo di flusso Ethernet</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Questa tecnologia consente a un client di richiedere che un mittente interrompa temporaneamente la trasmissione dei dati. Questa operazione viene solitamente eseguita perché il ricevitore non è in grado di elaborare i dati in ingresso abbastanza rapidamente. Una volta, la richiesta che un mittente cessi la trasmissione era meno disgregativa di avere pacchetti di scarto del destinatario perché i buffer erano pieni. Questo non è più il caso degli stack TCP utilizzati oggi nei sistemi operativi. Infatti, il controllo di flusso causa più problemi di quanti ne risolva.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Negli ultimi anni sono aumentati i problemi di prestazioni causati dal controllo di flusso Ethernet. Questo perché il controllo di flusso Ethernet opera al livello fisico. Se una configurazione di rete consente a qualsiasi sistema operativo host di inviare una richiesta di controllo di flusso Ethernet a un sistema di storage, il risultato è una pausa in i/o per tutti i client connessi. Poiché un numero crescente di client viene servito da un singolo storage controller, aumenta la probabilità che uno o più client inviino richieste di controllo di flusso. Il problema è stato riscontrato frequentemente presso le sedi dei clienti con un'ampia virtualizzazione del sistema operativo.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Una scheda NIC su un sistema NetApp non dovrebbe ricevere richieste di controllo di flusso. Il metodo utilizzato per ottenere questo risultato varia in base al produttore dello switch di rete. Nella maggior parte dei casi, il controllo di flusso su uno switch Ethernet può essere impostato su<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> oppure<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, il che significa che una richiesta di controllo di flusso non viene inoltrata al controller di memorizzazione. In altri casi, la connessione di rete sul controller di storage potrebbe non consentire la disattivazione del controllo di flusso. In questi casi, i client devono essere configurati in modo da non inviare mai richieste di controllo di flusso, modificando la configurazione NIC sul server host stesso o le porte switch a cui è connesso il server host.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp consiglia* assicurarsi che i controller di archiviazione NetApp non ricevano pacchetti di controllo di flusso Ethernet. In genere, è possibile eseguire questa operazione impostando le porte dello switch a cui è collegato il controller, ma alcuni hardware dello switch presentano dei limiti che potrebbero richiedere modifiche sul lato client.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">Dimensioni MTU</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">È stato dimostrato che l'utilizzo dei frame jumbo offre un certo miglioramento delle performance nelle reti 1Gb, riducendo l'overhead della CPU e della rete, ma i benefici non sono solitamente significativi.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp consiglia* l'implementazione di frame jumbo quando possibile, sia per ottenere potenziali vantaggi in termini di prestazioni sia per rendere la soluzione a prova di futuro.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">L'utilizzo di frame jumbo in una rete 10Gb è quasi obbligatorio. Questo perché la maggior parte delle implementazioni 10Gb raggiungono un limite di pacchetti al secondo senza frame jumbo prima che raggiungano il contrassegno 10Gb. L'utilizzo di frame jumbo migliora l'efficienza dell'elaborazione TCP/IP, poiché consente a sistema operativo, server, schede di rete e sistema di storage di elaborare un numero inferiore di pacchetti, anche se di dimensioni maggiori. Il miglioramento delle prestazioni varia da scheda di rete a scheda di rete, ma è significativo.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">Per le implementazioni jumbo-frame, esiste la convinzione comune, ma non corretta, che tutti i dispositivi connessi debbano supportare frame jumbo e che le dimensioni MTU debbano corrispondere end-to-end Al contrario, i due endpoint di rete negoziano la dimensione del frame più elevata reciprocamente accettabile quando si stabilisce una connessione. In un ambiente tipico, uno switch di rete è impostato su una dimensione MTU di 9216, il controller NetApp è impostato su 9000 e i client sono impostati su una combinazione di 9000 e 1514. I client in grado di supportare un valore MTU di 9000 possono utilizzare frame jumbo, mentre i client in grado di supportare solo 1514 possono negoziare un valore inferiore.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">I problemi con questa disposizione sono rari in un ambiente completamente commutato. Tuttavia, in un ambiente con routing occorre assicurarsi che nessun router intermedio sia costretto a frammentare frame jumbo.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp consiglia* di configurare quanto segue:</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">I frame jumbo sono desiderabili ma non necessari con 1Gb Ethernet (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">I frame jumbo sono necessari per ottenere le massime prestazioni con 10GbE e velocità.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">Parametri TCP</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">Tre impostazioni spesso non sono configurate correttamente: Timestamp TCP, riconoscimento selettivo (SACK) e ridimensionamento finestra TCP. Molti documenti obsoleti su Internet consigliano di disabilitare uno o più di questi parametri per migliorare le prestazioni. Molti anni fa, questa raccomandazione ha avuto un certo merito quando le capacità della CPU erano molto inferiori e, quando possibile, vi era un vantaggio nel ridurre il sovraccarico sull'elaborazione TCP.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Tuttavia, con i sistemi operativi moderni, la disattivazione di una qualsiasi di queste funzioni TCP in genere non comporta alcun vantaggio rilevabile e, allo stesso tempo, può danneggiare le prestazioni. In ambienti di rete virtualizzati, i danni alle prestazioni sono particolarmente probabili, poiché queste funzioni sono necessarie per gestire in modo efficiente la perdita di pacchetti e le modifiche della qualità della rete.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp consiglia* di abilitare timestamp TCP, SACCO e ridimensionamento finestra TCP sull'host, e tutti e tre questi parametri dovrebbero essere attivi per impostazione predefinita in qualsiasi sistema operativo corrente.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Errore: Immagine grafica mancante</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Replica sincrona</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Hardware per lo storage</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">Mediatore ONTAP</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Data Protection con SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">Al livello più semplice, la replica sincrona significa che qualsiasi modifica deve essere apportata a entrambi i lati dello storage con mirroring prima che venga riconosciuta. Ad esempio, se un database sta scrivendo un registro o un guest VMware viene aggiornato, non deve mai andare persa una scrittura. Come livello di protocollo, il sistema di storage non deve riconoscere la scrittura fino a quando non è stato assegnato a un supporto non volatile in entrambi i siti. Solo allora è sicuro procedere senza il rischio di perdita dei dati.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">L'utilizzo di una tecnologia di replica sincrona è il primo passo nella progettazione e nella gestione di una soluzione di replica sincrona. La considerazione più importante è capire cosa potrebbe accadere durante i vari scenari di guasto pianificati e non pianificati. Non tutte le soluzioni di replica sincrona offrono le stesse funzionalità. Se hai bisogno di una soluzione che offra un recovery point objective (RPO) pari a zero, ovvero zero data loss, devi prendere in considerazione tutti gli scenari di guasto. In particolare, qual è il risultato previsto quando la replica è impossibile a causa della perdita di connettività tra i siti?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">Disponibilità dei dati SyncMirror</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">Non solo SyncMirror può passare alla modalità sincrona senza problemi se il sito remoto non è raggiungibile, ma può anche risincronizzare rapidamente uno stato RPO = 0 al ripristino della connettività. La copia obsoleta dei dati nel sito remoto può anche essere preservata in uno stato utilizzabile durante la risincronizzazione, garantendo l'esistenza in ogni momento di copie locali e remote dei dati.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Solo snapshot</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">Il<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> si applica solo ai blocchi non condivisi con il file system attivo. Essenzialmente si traduce in tiering dei backup del database. I blocchi diventano candidati per il tiering dopo la creazione di uno snapshot e il blocco viene quindi sovrascritto, generando un blocco presente solo all'interno dello snapshot. Il ritardo prima di un<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> il blocco è considerato freddo e controllato da<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> impostazione del volume. L'intervallo a partire da ONTAP 9,8 è compreso tra 2 e 183 giorni.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">Molti set di dati hanno tassi di cambiamento bassi, con conseguenti risparmi minimi derivanti da questa policy. Ad esempio, un database tipico osservato con ONTAP ha un tasso di variazione inferiore al 5% alla settimana. I log di archivio dei database possono occupare spazio esteso, ma in genere continuano a esistere nel file system attivo e pertanto non possono essere candidati per il tiering in base a questa policy.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Automatico</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy di tiering estende il tiering sia a blocchi specifici di snapshot che a blocchi nel file system attivo. Il ritardo prima che un blocco venga considerato freddo è controllato dall'<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> impostazione del volume. L'intervallo a partire da ONTAP 9,8 è compreso tra 2 e 183 giorni.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Questo approccio abilita opzioni di tiering che non sono disponibili con<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> policy. Ad esempio, un criterio di protezione dei dati potrebbe richiedere la conservazione di 90 giorni di determinati file di registro. L'impostazione di un periodo di raffreddamento di 3 giorni comporta il tiering di tutti i file di registro precedenti a 3 giorni dal livello delle prestazioni. Questa azione libera spazio sostanziale sul Tier delle performance, consentendoti comunque di visualizzare e gestire tutti e 90 i giorni di dati.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Nessuno</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">Il<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la policy di tiering impedisce il tiering di blocchi aggiuntivi dal layer di storage, ma i dati ancora presenti nel tier di capacità rimangono nel tier di capacità fino a quando non vengono letti. Se quindi il blocco viene letto, viene tirato indietro e posizionato nel Tier di performance.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">Il motivo principale per cui si utilizza<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la policy di tiering impedisce il tiering dei blocchi, ma nel tempo potrebbe risultare utile modificarli. Ad esempio, supponiamo che un set di dati specifico venga suddiviso in Tier per il livello di capacità, ma sorge un'esigenza inaspettata di funzionalità di performance complete. La policy può essere modificata per impedire qualsiasi tiering aggiuntivo e per confermare che i blocchi letti nuovamente quando l'io aumenta rimangono nel Tier di performance.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Tutto</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">Il<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la policy di tiering sostituisce<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Policy in data ONTAP 9,6. Il<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Policy applicata solo ai volumi di data Protection, che significa destinazione SnapMirror o NetApp SnapVault. Il<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> le funzioni dei criteri sono identiche, ma non si limitano ai volumi di protezione dei dati.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Grazie a questa policy, i blocchi vengono immediatamente considerati COOL e possono essere immediatamente suddivisi in Tier nel livello di capacità.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Questo criterio è particolarmente appropriato per i backup a lungo termine. Può anche essere utilizzato come forma di gestione gerarchica dello storage (HSM, Hierarchical Storage Management). In passato, HSM veniva comunemente utilizzato per eseguire il tiering dei blocchi di dati di un file su nastro, mantenendo il file stesso visibile nel file system. Un volume FabricPool con<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> il criterio consente di archiviare i file in un archivio visibile e gestibile pur non occupando quasi nessuno spazio nel livello di storage locale.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">Suddivisione in zone</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Una zona FC non deve mai contenere più di un iniziatore. Una tale disposizione potrebbe sembrare funzionare inizialmente, ma la diafonia tra gli iniziatori interferisce eventualmente con le prestazioni e la stabilità.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Le zone MultiTarget sono generalmente considerate sicure, anche se in rare circostanze il comportamento delle porte target FC di fornitori diversi ha causato problemi. Ad esempio, evita di includere nella stessa zona le porte di destinazione di uno storage array NetApp e non NetApp. Inoltre, l'inserimento di un sistema di storage NetApp e di un dispositivo a nastro nella stessa zona è ancora più probabile che causino problemi.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Una SVM, nota come vserver nell'interfaccia a riga di comando di ONTAP, è un'unità funzionale di base dello storage ed è utile confrontare una SVM con un guest su un server VMware ESX.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">Come per altri aspetti dell'architettura dello storage, le migliori opzioni per il design di SVM e interfaccia logica (LIF) dipendono in gran parte dai requisiti di scalabilità e dalle esigenze di business.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">Non esistono Best practice ufficiali per il provisioning di SVM per ONTAP. Il giusto approccio dipende dai requisiti di gestione e sicurezza.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">La maggior parte dei clienti utilizza una SVM primaria per la maggior parte delle loro esigenze quotidiane, quindi crea un piccolo numero di SVM per esigenze speciali. Ad esempio, è possibile creare:</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">Una SVM per un database aziendale critico gestita da un team di specialisti</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">Una SVM per un gruppo di sviluppo al quale è stato assegnato un controllo amministrativo completo in modo da poter gestire il proprio storage in maniera indipendente</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">Una SVM per i dati di business sensibili, come le risorse umane o i dati di reporting finanziario, per cui il team di amministrazione deve essere limitato</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">Aggregati SSD, inclusi i sistemi AFF</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">Lo spazio libero viene definito come lo spazio non utilizzato per i dati effettivi e include lo spazio non allocato dell'aggregato e lo spazio non utilizzato all'interno dei volumi costituenti. È importante prendere in considerazione anche il thin provisioning. Ad esempio, un volume potrebbe contenere un LUN da 1TB GB, di cui solo il 50% viene utilizzato dai dati reali. In un ambiente con thin provisioning, questo sembra consumare correttamente 500GB GB di spazio. Tuttavia, in un ambiente con provisioning completo, la capacità completa di 1TB TB sembra essere in uso. I 500GB GB di spazio non allocato sono nascosti. Questo spazio non è utilizzato dai dati effettivi e deve quindi essere incluso nel calcolo dello spazio libero totale.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">Di seguito sono riportate le raccomandazioni NetApp per i sistemi storage utilizzati per le applicazioni aziendali:</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp consiglia* almeno il 10% di spazio libero. Ciò comprende tutto lo spazio inutilizzato, compreso lo spazio libero all'interno dell'aggregato o di un volume ed eventuale spazio libero allocato a causa dell'utilizzo del provisioning completo, ma non utilizzato dai dati effettivi. Lo spazio logico non è importante, la domanda è quanto spazio fisico libero effettivo è disponibile per lo storage dei dati.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">Il consiglio di liberare il 10% dello spazio è molto conservativo. Gli aggregati SSD possono supportare i carichi di lavoro a livelli di utilizzo ancora più elevati senza influire sulle performance. Tuttavia, con l'aumento dell'utilizzo dell'aggregato, aumenta anche il rischio di esaurimento dello spazio se l'utilizzo non viene monitorato con attenzione. Inoltre, mentre si utilizza un sistema al 99% della capacità potrebbe non verificarsi un peggioramento delle performance, tuttavia si verificherebbe un sforzo di gestione che impedirebbe il riempimento completo del sistema mentre si ordina hardware aggiuntivo e potrebbe essere necessario del tempo per l'acquisto e l'installazione di dischi aggiuntivi.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Aggregati HDD, compresi gli aggregati Flash Pool</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio è il criterio più appropriato per i dati di backup. In questo modo si garantisce un tiering rapido quando la soglia di raffreddamento è stata raggiunta, indipendentemente dal fatto che i file siano stati eliminati o continuino a esistere nel file system primario. Inoltre, l'archiviazione di tutti i file potenzialmente necessari in un'unica posizione nel file system attivo semplifica la gestione. Non c'è motivo di cercare tra gli snapshot per individuare un file che deve essere ripristinato.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">Il<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> i criteri potrebbero funzionare, ma si applicano solo ai blocchi che non si trovano più nel file system attivo. Pertanto, i file presenti in una condivisione NFS o SMB devono essere eliminati prima del tiering dei dati.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Questa policy risulterebbe ancora meno efficiente con la configurazione LUN, poiché l'eliminazione di un file da una LUN rimuove solo i riferimenti dei file dai metadati del file system. I blocchi effettivi sui LUN restano in posizione fino a quando non vengono sovrascritti. Questa situazione può creare un lungo ritardo tra il tempo di eliminazione di un file e il tempo in cui i blocchi vengono sovrascritti e candidati per il tiering. Lo spostamento dell' comporta alcuni vantaggi<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Dei blocchi nel Tier di capacità, ma, nel complesso, la gestione FabricPool dei dati di backup funziona meglio con l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> policy.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Questo approccio aiuta gli utenti a gestire lo spazio richiesto per i backup in modo più efficiente, ma FabricPool non è una tecnologia di backup. Il tiering dei file di backup nell'archivio di oggetti semplifica la gestione perché i file sono ancora visibili nel sistema di storage originale, ma i blocchi di dati nella destinazione dell'archivio di oggetti dipendono dal sistema di storage originale. Se il volume di origine viene perso, i dati dell'archivio di oggetti non sono più utilizzabili.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">Su un sistema ONTAP, lo storage è organizzato in 4KB unità. Un blocco 8KB di un database o di un file system deve corrispondere esattamente a due blocchi 4KB. Se un errore nella configurazione LUN sposta l'allineamento di 1KB:1 in entrambe le direzioni, ogni blocco 8KB esisterebbe su tre blocchi di storage 4KB diversi invece che due. Questa disposizione causerebbe un aumento della latenza e causerebbe l'esecuzione di ulteriori i/o all'interno del sistema di storage.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">L'allineamento influisce anche sulle architetture LVM. Se un volume fisico all'interno di un gruppo di volumi logici viene definito sull'intero dispositivo del disco (non vengono create partizioni), il primo blocco 4KB sul LUN si allinea con il primo blocco 4KB sul sistema di storage. Questo è un allineamento corretto. I problemi si verificano con le partizioni perché spostano la posizione iniziale in cui il sistema operativo utilizza il LUN. Finché l'offset viene spostato in intere unità di 4KB, il LUN viene allineato.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">Negli ambienti Linux, creare gruppi di volumi logici sull'intero dispositivo di unità. Quando è necessaria una partizione, controllare l'allineamento eseguendo<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> e verificare che l'inizio di ogni partizione sia un multiplo di otto. Ciò significa che la partizione inizia da un multiplo di otto settori a 512 byte, ovvero 4KB.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Protezione da errori del sito: NVRAM e MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster estende la protezione dei dati NVRAM nei seguenti modi:</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">In una configurazione a due nodi, i dati NVRAM vengono replicati attraverso i collegamenti Inter-Switch (ISL) al partner remoto.</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">In una configurazione ha-Pair, i dati NVRAM vengono replicati sia nel partner locale che in un partner remoto.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">Una scrittura non viene riconosciuta fino a quando non viene replicata a tutti i partner. Questa architettura protegge gli i/o in fase di trasferimento dai guasti del sito replicando i dati NVRAM a un partner remoto. Il processo non è coinvolto nella replica dei dati a livello di unità. Il controller proprietario degli aggregati si occupa della replica dei dati per iscritto a entrambi i plessi dell'aggregato, ma in caso di perdita del sito occorre comunque proteggere dalle perdite di i/o in fase di trasferimento. I dati NVRAM replicati sono utilizzati solo se un partner controller deve subentrare a un controller guasto.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Protezione dai guasti di shelf e siti: SyncMirror e plessi</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror è una tecnologia di mirroring che migliora, ma non sostituisce, RAID DP o RAID-TEC. Esegue il mirroring del contenuto di due gruppi RAID indipendenti. La configurazione logica è la seguente:</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">I dischi sono configurati in due pool in base alla posizione. Un pool è composto da tutti i dischi sul sito A, mentre il secondo è composto da tutti i dischi sul sito B.</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">Viene quindi creato un pool di storage comune, detto aggregato, in base a set di gruppi RAID con mirroring. Viene ottenuto lo stesso numero di unità per ciascun sito. Ad esempio, un aggregato SyncMirror da 20 dischi sarebbe composto da 10 dischi del sito A e 10 dischi del sito B.</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Ogni set di unità su un dato sito viene configurato automaticamente come uno o più gruppi RAID DP o RAID-TEC completamente ridondanti, indipendentemente dall'utilizzo del mirroring. Questo utilizzo di RAID sottostante il mirroring garantisce la protezione dei dati anche dopo la perdita di un sito.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">La figura precedente illustra una configurazione SyncMirror di esempio. È stato creato un aggregato di 24 dischi sul controller con 12 dischi da uno shelf allocato sul sito A e 12 dischi da uno shelf allocato sul sito B. I dischi sono stati raggruppati in due gruppi RAID con mirroring. Il gruppo RAID 0 include un plesso A 6 dischi sul sito A con mirroring su un plesso A 6 dischi sul sito B. Analogamente, il gruppo RAID 1 include un plesso A 6 dischi sul sito A con mirroring su un plesso A 6 dischi sul sito B.</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">Di norma, SyncMirror viene utilizzato per fornire il mirroring remoto con i sistemi MetroCluster, con una copia dei dati in ciascun sito. A volte, è stato utilizzato per fornire un livello di ridondanza extra in un unico sistema. In particolare, fornisce ridondanza a livello di shelf. Uno shelf di dischi contiene già doppi controller e alimentatori e nel complesso è poco più di una lamiera, ma in alcuni casi è consigliabile garantire una protezione extra. Ad esempio, un cliente NetApp ha implementato SyncMirror per una piattaforma mobile di analytics in tempo reale utilizzata durante i test nel settore automobilistico. Il sistema è stato separato in due rack fisici forniti con alimentatori indipendenti e sistemi UPS indipendenti.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Errore di ridondanza: NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Come discusso in precedenza, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight Se si verifica un guasto nella NVRAM locale o nella connettività ad altri nodi, i dati non verranno più mirrorati.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">Il fattore di controllo è se la NVRAM è sincronizzata. Se la NVRAM è sincronizzata, il failover da nodo a nodo può procedere in tutta sicurezza senza rischio di perdita di dati. In una configurazione MetroCluster, se la NVRAM e i plessi degli aggregati sottostanti sono sincronizzati, è possibile procedere con lo switchover senza rischio di perdita di dati.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">I database e altre applicazioni sono particolarmente vulnerabili al danneggiamento se un failover o uno switchover è forzato perché mantengono cache interne di dati su disco di dimensioni maggiori. In caso di failover o switchover forzato, le modifiche riconosciute in precedenza vengono eliminate del tutto. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache non riflette più lo stato dei dati su disco.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Per evitare questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro i guasti della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano un crash dell'applicazione. Questo blocco causa l'arresto delle applicazioni in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché i dati delle transazioni devono essere presenti nei registri. Solitamente, gli amministratori dovranno arrestare completamente gli host prima di riportare manualmente LUN e volumi in linea. Sebbene queste fasi possano comportare un certo lavoro, questo approccio è il modo più sicuro per garantire l'integrità dei dati. Non tutti i dati richiedono questa protezione, motivo per cui il comportamento di NVFAIL può essere configurato in base al volume.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">Coppie HA e MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster è disponibile in due configurazioni: Due nodi e coppia ha. La configurazione a due nodi si comporta come una coppia ha in relazione alla NVRAM. In caso di guasto improvviso, il nodo partner può riprodurre i dati della NVRAM per rendere i dischi coerenti e garantire che non vengano perse scritture riconosciute.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">La configurazione ha-Pair replica la NVRAM anche sul nodo partner locale. Un semplice guasto al controller porta a un replay della NVRAM sul nodo partner, come nel caso di una coppia ha standalone, senza MetroCluster. In caso di improvvisa perdita completa del sito, il sito remoto dispone anche della NVRAM necessaria per rendere i dischi coerenti e iniziare a fornire i dati.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Un aspetto importante di MetroCluster è che i nodi remoti non hanno accesso ai dati partner in normali condizioni operative. Ogni sito funziona essenzialmente come un sistema indipendente che può assumere la personalità del sito opposto. Questo processo, noto come switchover, include uno switchover pianificato, in cui le operazioni del sito vengono migrate senza interruzioni nel sito opposto. Include anche le situazioni non pianificate in cui si perde un sito ed è necessario uno switchover manuale o automatico come parte del disaster recovery.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Switchover e switchback</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">I termini switchover e switchback si riferiscono al processo di transizione dei volumi tra controller remoti in una configurazione MetroCluster. Questo processo si applica solo ai nodi remoti. Se viene utilizzato MetroCluster in una configurazione a quattro volumi, il failover di nodo locale utilizza il medesimo processo di takeover e giveback descritto in precedenza.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Switchover e switchback pianificati</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Uno switchover o uno switchback pianificato è simile a un takeover o un giveback tra i nodi. Il processo prevede diverse fasi e potrebbe richiedere alcuni minuti, ma in realtà si tratta di una transizione graduale delle risorse di storage e di rete. Il momento in cui il trasferimento del controllo avviene molto più rapidamente del tempo richiesto per l'esecuzione del comando completo.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">La differenza principale tra takeover/giveback e switchover/switchback influisce sulla connettività FC SAN. Grazie al takeover/giveback locale, un host subisce la perdita di tutti i percorsi FC nel nodo locale e si affida al proprio MPIO nativo per passare ai percorsi alternativi disponibili. Le porte non vengono ricollocate. Grazie a switchover e switchback, le porte di destinazione FC virtuali sui controller passano all'altro sito. Di fatto, smettono di esistere sulla SAN per un momento e ricompaiono su un controller alternativo.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">Timeout SyncMirror</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror è una tecnologia di mirroring ONTAP che fornisce protezione dai guasti agli shelf. Quando gli shelf sono separati su una distanza, il risultato è una data Protection remota.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror non fornisce mirroring sincrono universale. Il risultato è una maggiore disponibilità. Alcuni sistemi di archiviazione utilizzano un mirroring costante tutto o niente, talvolta chiamato modalità domino. Questa forma di mirroring è limitata nell'applicazione poiché tutte le attività di scrittura devono cessare se la connessione al sito remoto viene persa. Altrimenti, una scrittura esisterebbe in un sito ma non nell'altro. Generalmente, tali ambienti sono configurati per portare le LUN offline in caso di perdita della connettività sito-sito per più di un breve periodo (ad esempio 30 secondi).</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Questo comportamento è desiderabile per un piccolo sottoinsieme di ambienti. Tuttavia, la maggior parte delle applicazioni richiede una soluzione che offra una replica sincrona garantita in normali condizioni operative, ma con la possibilità di sospendere la replica. Una perdita completa della connettività da sito a sito viene spesso considerata una situazione quasi disastrosa. Generalmente, tali ambienti vengono mantenuti online e forniscono dati fino al ripristino della connettività o alla decisione formale di arrestare l'ambiente per proteggere i dati. Un requisito per l'arresto automatico dell'applicazione solo a causa di un errore di replica remota è insolito.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror supporta i requisiti di mirroring sincrono con la flessibilità di un timeout. Se la connettività al telecomando e/o al plex viene persa, inizia il conto alla rovescia un timer di 30 secondi. Quando il contatore raggiunge 0, l'elaborazione i/o in scrittura riprende a utilizzare i dati locali. La copia remota dei dati è utilizzabile, ma viene bloccata in tempo fino a quando non viene ripristinata la connettività. La risincronizzazione sfrutta le snapshot a livello di aggregato per riportare il sistema in modalità sincrona il più rapidamente possibile.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">In particolare, in molti casi, questo tipo di replica universale in modalità domino a tutto o niente è meglio implementato a livello di applicazione. Ad esempio, Oracle DataGuard include la modalità di protezione massima, che garantisce la replica a lunga istanza in tutte le circostanze. Se il collegamento di replica non riesce per un periodo superiore a un timeout configurabile, i database vengono arrestati.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Switchover automatico senza intervento dell'utente con MetroCluster fabric-attached</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">Lo switchover automatico non assistito (ASOLO) è una funzione MetroCluster collegata al fabric che offre un tipo di ha cross-site. Come indicato in precedenza, MetroCluster è disponibile in due tipi: Un singolo controller su ciascun sito o una coppia ha su ciascun sito. Il vantaggio principale dell'opzione ha è che l'arresto pianificato o non pianificato del controller consente comunque a tutti gli i/o di essere locali. Il vantaggio dell'opzione a nodo singolo consiste nella riduzione di costi, complessità e infrastruttura.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">Il valore primario di AUSO è migliorare le capacità ha dei sistemi MetroCluster fabric-attached. Ciascun sito esegue il monitoraggio dello stato di salute del sito opposto e, se non sono ancora presenti nodi che forniscono dati, AUDO esegue un rapido switchover. Questo approccio è particolarmente utile nelle configurazioni MetroCluster con un solo nodo per sito, perché consente di avvicinare la configurazione a una coppia ha in termini di disponibilità.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO non è in grado di offrire un monitoraggio completo a livello di coppia ha. Una coppia ha può offrire una disponibilità estremamente elevata, perché include due cavi fisici ridondanti per la comunicazione diretta da nodo a nodo. Inoltre, entrambi i nodi di una coppia ha hanno accesso allo stesso set di dischi in loop ridondanti, offrendo un altro percorso a un nodo per monitorare la salute di un altro.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">I cluster MetroCluster esistono tra i siti per i quali le comunicazioni nodo-nodo e l'accesso al disco si basano sulla connettività di rete site-to-site. La capacità di monitorare il battito cardiaco del resto del cluster è limitata. AUSO deve discriminare tra una situazione in cui l'altro sito è effettivamente inattivo piuttosto che non disponibile a causa di un problema di rete.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">Di conseguenza, un controller in una coppia ha può richiedere un takeover se rileva un guasto del controller verificatosi per un motivo specifico, ad esempio un panico del sistema. Può anche richiedere un takeover in caso di perdita totale della connettività, talvolta nota come battito cardiaco perso.</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Un sistema MetroCluster può eseguire uno switchover automatico in modo sicuro solo quando viene rilevato un guasto specifico nel sito originale. Inoltre, il controller che prende la proprietà del sistema di storage deve essere in grado di garantire che i dati su disco e NVRAM siano sincronizzati. Il controller non è in grado di garantire la sicurezza di uno switchover solo perché ha perso il contatto con il sito di origine, cosa che potrebbe essere ancora operativa. Per ulteriori opzioni per automatizzare uno switchover, vedere le informazioni sulla soluzione MetroCluster Tiebreaker (MCTB) nella sezione successiva.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">Tiebreaker MetroCluster con MetroCluster fabric-attached</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">Tiebreaker NetApp MetroCluster</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">Sito di supporto NetApp</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">Il<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> È possibile eseguire il software su un terzo sito per monitorare lo stato dell'ambiente MetroCluster, inviare notifiche e, facoltativamente, imporre uno switchover in una situazione di emergenza. Una descrizione completa del rompighiaccio è disponibile sul<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>, Ma lo scopo principale di MetroCluster Tiebreaker è quello di rilevare la perdita del sito. Inoltre, deve discriminare tra la perdita del sito e la perdita della connettività. Ad esempio, lo switchover non deve essere eseguito perché il tiebreaker non è riuscito a raggiungere il sito primario; questo spiega perché il tiebreaker monitora anche la capacità del sito remoto di contattare il sito primario.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">Lo switchover automatico con AUSO è compatibile anche con l'MCTB. AUSO reagisce in modo molto rapido perché è progettato per rilevare eventi di errore specifici e quindi richiamare lo switchover solo quando i plex NVRAM e SyncMirror sono sincronizzati.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">Al contrario, il Tiebreaker è localizzato a distanza e quindi deve attendere che un temporizzatore trascorra prima di dichiarare un sito morto. Il tiebreaker alla fine rileva il tipo di guasto del controller coperto da AUSO, ma in generale AUSO ha già avviato lo switchover e, eventualmente, ha completato lo switchover prima che il tiebreaker agisca. Il secondo comando switchover risultante proveniente dal tiebreaker verrebbe rifiutato.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">*Attenzione: *Il software MCTB non verifica che la NVRAM sia e/o i plessi siano sincronizzati quando si forza uno switchover. Lo switchover automatico, se configurato, deve essere disattivato durante le attività di manutenzione che causano una perdita di sincronizzazione dei plessi NVRAM o SyncMirror.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">Inoltre, l'MCTB potrebbe non risolvere un disastro continuo che porta alla seguente sequenza di eventi:</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">La connettività tra i siti viene interrotta per più di 30 secondi.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">Timeout della replica SyncMirror e proseguimento delle operazioni sul sito primario, lasciando inattiva la replica remota.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Il sito primario viene perso. Il risultato è la presenza di modifiche non replicate sul sito primario. Uno switchover potrebbe quindi essere indesiderato per una serie di motivi, tra cui:</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">I dati critici potrebbero essere presenti sul sito primario e quindi ripristinabili. Uno switchover che ha permesso all'applicazione di continuare a funzionare eliminava efficacemente i dati critici.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Un'applicazione sul sito rimasto che stava utilizzando le risorse di storage sul sito primario al momento della perdita del sito potrebbe avere memorizzato nella cache i dati. Uno switchover introdurrebbe una versione obsoleta dei dati che non corrisponde alla cache.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Un sistema operativo del sito rimasto che utilizzava le risorse di storage del sito primario al momento della perdita del sito potrebbe avere memorizzato i dati nella cache. Uno switchover introdurrebbe una versione obsoleta dei dati che non corrisponde alla cache. L'opzione più sicura è configurare tiebreaker in modo da inviare un avviso se rileva un guasto del sito e chiedere a una persona di decidere se forzare uno switchover. Potrebbe essere necessario arrestare le applicazioni e/o i sistemi operativi per cancellare i dati memorizzati nella cache. Inoltre, è possibile utilizzare le impostazioni NVFAIL per aggiungere ulteriore protezione e semplificare il processo di failover.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">ONTAP Mediator con MetroCluster IP</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">ONTAP Mediator viene utilizzato con MetroCluster IP e con alcune altre soluzioni ONTAP. Funziona come un servizio di tiebreaker tradizionale, proprio come il software MetroCluster Tiebreaker descritto in precedenza, ma include anche una funzione critica che consente di eseguire uno switchover automatizzato e non assistito.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Un MetroCluster fabric-attached ha accesso diretto ai dispositivi di storage del sito opposto. Ciò consente a un controller MetroCluster di monitorare lo stato degli altri controller leggendo i dati heartbeat dalle unità. In questo modo, un controller riconosce il guasto di un altro controller ed esegue uno switchover.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">Al contrario, l'architettura IP di MetroCluster instrada tutti i/o esclusivamente attraverso la connessione controller-controller; non vi è accesso diretto ai dispositivi di storage sul sito remoto. Questo limita la possibilità per un controller di rilevare gli errori ed eseguire uno switchover. Pertanto, come dispositivo di tiebreaker occorre il ONTAP Mediator per rilevare la perdita di un sito ed eseguire automaticamente uno switchover.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Terzo sito virtuale con ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion è un'appliance di monitoraggio MetroCluster avanzata che funziona come un terzo sito virtuale. Questo approccio consente di implementare MetroCluster in maniera sicura in una configurazione a due siti con una funzionalità di switchover completamente automatizzata. Inoltre, ClusterLion può eseguire ulteriori operazioni di monitoraggio a livello di rete ed eseguire operazioni post-switchover. La documentazione completa è disponibile presso ProLion.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Gli appliance ClusterLion monitorano lo stato dei controller con cavi Ethernet e seriali collegati direttamente.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">I due dispositivi sono collegati tra loro mediante connessioni wireless 3G ridondanti.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">L'alimentazione alla centralina ONTAP viene instradata attraverso i relè interni. In caso di guasto a un sito, ClusterLion, che contiene un sistema UPS interno, interrompe i collegamenti di alimentazione prima di richiamare uno switchover. Questo processo assicura che non si verifichi alcuna condizione split-brain.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion esegue uno switchover entro il timeout SyncMirror di 30 secondi o non lo esegue affatto.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion non esegue uno switchover a meno che gli stati della NVRAM e dei plex SyncMirror non siano sincronizzati.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Poiché ClusterLion esegue uno switchover solo se MetroCluster è completamente sincronizzato, NVFAIL non è necessario. Questa configurazione consente ad ambienti che si estendono tra diversi siti, come un Oracle RAC esteso, di rimanere online anche durante uno switchover non pianificato.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">Il supporto include MetroCluster fabric-attached e MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Funzionamento normale</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">Durante il normale funzionamento, è possibile accedere a un LUN dalla replica locale o remota. La linea rossa indica il percorso ottimizzato come pubblicizzato da ALUA, e il risultato dovrebbe essere che io è preferenzialmente inviato lungo questo percorso.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Guasto</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Se la copia del mirror attivo non è più disponibile, a causa di un failover pianificato o non pianificato, ovviamente non sarà più utilizzabile. Tuttavia, il sistema remoto possiede una replica sincrona e i percorsi SAN verso il sito remoto esistono già. Il sistema remoto è in grado di gestire i/o per quel LUN.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Failover</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">Il failover fa sì che la copia remota diventi la copia attiva. I percorsi vengono modificati da Active a Active/Optimized e l'io continua a essere gestito senza perdita di dati.</block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Riparare</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Failback</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Se lo si desidera, un amministratore può eseguire un failback e riportare la copia attiva delle LUN nei controller originali.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">La registrazione di ripristino del database/transazioni genera di solito un i/o non allineato che può causare avvisi fuorvianti riguardo ai LUN disallineati su ONTAP.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">La registrazione esegue una scrittura sequenziale del file di registro con scritture di dimensioni variabili. Un'operazione di scrittura del registro che non si allinea ai limiti 4KB non causa normalmente problemi di prestazioni poiché l'operazione di scrittura del registro successiva completa il blocco. Il risultato è che ONTAP è in grado di elaborare quasi tutte le scritture come blocchi da 4KB KB completi, anche se i dati in alcuni blocchi da 4KB KB sono stati scritti in due operazioni separate.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Verifica dell'allineamento di WAFL</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Verificare l'allineamento utilizzando utilità come<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> oppure<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Che possono generare i/o a dimensioni dei blocchi definite. È possibile visualizzare le statistiche di allineamento di i/o del sistema di storage con<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> comando. Vedere <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">Molti set di dati delle applicazioni sono organizzati per data e tali dati hanno generalmente sempre meno probabilità di accedere man mano che invecchiano. Ad esempio, una banca potrebbe avere un archivio di file PDF che contengono cinque anni di dichiarazioni dei clienti, ma solo gli ultimi mesi sono attivi. FabricPool può essere utilizzato per spostare i file di dati meno recenti nel Tier di capacità. Un periodo di raffreddamento di 14 giorni garantirebbe che i 14 giorni più recenti di file PDF rimangano sul livello di prestazioni. Inoltre, i file letti almeno ogni 14 giorni resterebbero hot e quindi nel Tier di performance.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Per implementare un approccio di tiering basato su file, è necessario disporre di file scritti e non modificati successivamente. Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> i criteri devono essere impostati su un livello sufficientemente alto da mantenere i file di cui potresti aver bisogno nel tier di performance. Ad esempio, un set di dati per il quale sono necessari gli ultimi 60 giorni di dati con performance ottimali garantisce la definizione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo a 60. Risultati simili possono essere ottenuti anche in base ai modelli di accesso ai file. Ad esempio, se sono necessari gli ultimi 90 giorni di dati e l'applicazione sta accedendo a quell'arco di dati di 90 giorni, i dati resteranno sul Tier di performance. Impostando<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> a 2, si ottiene un tiering prompt dopo che i dati sono meno attivi.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Qualsiasi tipo di accesso ai dati ripristina i dati della mappa termica. La scansione virus, l'indicizzazione e persino le attività di backup in grado di leggere i file di origine impediscono il tiering perché è necessario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la soglia non viene mai raggiunta.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Predefinito</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Tutti i volumi FabricPool sono inizialmente impostati su<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, il che significa che il comportamento è controllato da `cloud-retrieval-policy. `il comportamento esatto dipende dal criterio di tiering utilizzato.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– consente di recuperare solo dati letti in modo casuale</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– consente di recuperare tutti i dati letti in modo sequenziale o casuale</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– consente di recuperare tutti i dati letti in modo sequenziale o casuale</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>– non recuperare i dati dal tier di capacità</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">A lettura</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Impostazione<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> in lettura sovrascrive il comportamento predefinito, in modo che una lettura di dati a livelli determini il ritorno dei dati al livello di prestazioni.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Ad esempio, un volume potrebbe essere stato leggermente utilizzato per un lungo periodo sotto il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy di tiering e la maggior parte dei blocchi ora vengono suddivisi in livelli.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Se una modifica imprevista delle esigenze aziendali richiedeva la scansione ripetuta di alcuni dati per preparare un determinato rapporto, potrebbe essere opportuno modificare<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> a.<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> per garantire che tutti i dati letti vengano restituiti al livello delle prestazioni, inclusi i dati letti in modo sequenziale e casuale. In questo modo si migliorano le prestazioni dell'i/o sequenziale rispetto al volume.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Promuovi</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">Il comportamento della policy di promozione dipende dalla policy di tiering. Se la policy di tiering è<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, quindi impostare<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> riporta tutti i blocchi dal tier di capacità nella successiva scansione del tiering.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Se la policy di tiering è<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, gli unici blocchi restituiti sono i blocchi associati al file system attivo. Normalmente questo non avrebbe alcun effetto perché gli unici blocchi suddivisi in livelli sotto<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la policy dovrebbe essere costituita da blocchi associati esclusivamente agli snapshot. Nel file system attivo non sono presenti blocchi a livelli.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Se, tuttavia, i dati di un volume sono stati ripristinati da un'operazione SnapRestore di volume o di file-clone da una snapshot, alcuni dei blocchi suddivisi in Tier perché associati solo a snapshot potrebbero ora essere richiesti dal file system attivo. Potrebbe essere opportuno modificare temporaneamente<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> policy to<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> per recuperare rapidamente tutti i blocchi richiesti localmente.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Mai</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">Non recuperare i blocchi dal Tier di capacità.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architettura</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool è una tecnologia di tiering che classifica i blocchi come "hot" o "cool" e li colloca nel Tier di storage più appropriato. Il Tier di performance è nella maggior parte dei casi collocato nello storage SSD e ospita i blocchi di dati "hot". Il Tier di capacità si trova in un archivio di oggetti e ospita i blocchi di dati "cool". Il supporto per lo storage a oggetti include NetApp StorageGRID, ONTAP S3, archiviazione BLOB di Microsoft Azure, il servizio di storage a oggetti Alibaba Cloud, archiviazione a oggetti IBM Cloud, archiviazione Google Cloud e Amazon AWS S3.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Sono disponibili più policy di tiering che controllano le modalità di classificazione dei blocchi come "hot" o "cool", che possono essere impostate in base al volume e modificate secondo necessità. Solo i blocchi di dati vengono spostati tra i Tier di performance e capacità. I metadati che definiscono la struttura LUN e del file system rimangono sempre sul Tier di performance. Di conseguenza, la gestione è centralizzata su ONTAP. I file e le LUN non appaiono diversi dai dati memorizzati in qualsiasi altra configurazione ONTAP. Il controller NetApp AFF o FAS applica le policy definite per spostare i dati nel Tier appropriato.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Provider di archivi di oggetti</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">I protocolli di storage a oggetti utilizzano semplici richieste HTTP o HTTPS per la memorizzazione di un grande numero di oggetti dati. L'accesso allo storage a oggetti deve essere affidabile, poiché l'accesso ai dati da parte di ONTAP dipende dalla puntuale manutenzione delle richieste. Le opzioni includono le opzioni Amazon S3 Standard e accesso poco frequente, Microsoft Azure Hot e Cool Blob Storage, IBM Cloud e Google Cloud. Le opzioni di archiviazione come Amazon Glacier e Amazon Archive non sono supportate, perché il tempo necessario per recuperare i dati può superare le tolleranze dei sistemi operativi e delle applicazioni host.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">NetApp StorageGRID è anche supportato e rappresenta una soluzione di livello Enterprise ottimale. Si tratta di un sistema storage a oggetti dalle performance elevate, scalabile e altamente sicuro, in grado di fornire ridondanza geografica per i dati FabricPool nonché per altre applicazioni di archivi di oggetti che hanno sempre più probabilità di far parte di ambienti applicativi Enterprise.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID può anche ridurre i costi evitando le spese di uscita imposte da molti provider di cloud pubblici per la lettura dei dati di nuovo dai propri servizi.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Dati e metadati</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Si noti che il termine "dati" si applica in questo caso ai blocchi di dati effettivi, non ai metadati. Viene eseguito il tiering solo dei blocchi di dati, mentre i metadati rimangono nel Tier di performance. Inoltre, lo stato di un blocco come caldo o freddo è influenzato solo dalla lettura del blocco di dati effettivo. La semplice lettura del nome, dell'indicatore data e ora o dei metadati di proprietà di un file non influisce sulla posizione dei blocchi di dati sottostanti.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Backup</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Anche se FabricPool può ridurre significativamente l'impatto dello storage, non rappresenta di per sé una soluzione di backup. I metadati NetApp WAFL rimangono sempre nel Tier di performance. Se un disastro catastrofico distrugge il Tier di performance, non è possibile creare un nuovo ambiente utilizzando i dati sul Tier di capacità perché non contiene metadati WAFL.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">FabricPool, tuttavia, può entrare a far parte di una strategia di backup. Ad esempio, FabricPool può essere configurato con la tecnologia di replica NetApp SnapMirror. Ciascuna metà del mirror può avere la propria connessione a una destinazione dello storage a oggetti. Il risultato sono due copie indipendenti dei dati. La copia primaria è costituita dai blocchi sul Tier di performance e dai blocchi associati nel Tier di capacità, mentre la replica è un secondo set di blocchi di performance e capacità.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Compressione</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Le funzionalità di efficienza in termini di spazio, come compressione, compaction e deduplica, sono progettate per aumentare la quantità di dati logici applicabili a una determinata quantità di storage fisico. Il risultato è una riduzione dei costi e dell'overhead di gestione.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">Ad un livello elevato, la compressione è un processo matematico in cui gli schemi nei dati vengono rilevati e codificati in modo da ridurre i requisiti di spazio. La deduplica, invece, rileva i blocchi di dati effettivi e ripetuti e rimuove le copie estranee. La tecnologia di compaction consente a più blocchi logici di dati di condividere lo stesso blocco fisico sui supporti.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Prima della disponibilità dei sistemi storage all-flash, la compressione basata su array aveva un valore limitato, perché la maggior parte dei carichi di lavoro con i/o-intensive richiedeva un numero molto elevato di spindle per fornire performance accettabili. I sistemi storage contenevano invariabilmente una capacità superiore rispetto a quella richiesta come effetto collaterale dell'elevato numero di dischi. La situazione è cambiata con l'ascesa dello storage a stato solido. Non è più necessario effettuare un provisioning in eccesso significativo dei dischi solo per ottenere buone prestazioni. Lo spazio su disco di un sistema di storage può essere adattato alle effettive esigenze di capacità.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">L'aumento della capacità degli IOPS dei dischi a stato solido (SSD) offre quasi sempre risparmi sui costi rispetto ai dischi rotanti, ma la compressione può ottenere ulteriori risparmi aumentando la capacità effettiva dei supporti a stato solido.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Compressione adattiva</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">La compressione adattiva è stata testata accuratamente con carichi di lavoro Enterprise senza effetti osservati sulle performance, anche in un ambiente all-flash in cui la latenza viene misurata in microsecondi. Alcuni clienti hanno anche segnalato un aumento delle performance con l'utilizzo della compressione, perché i dati rimangono compressi nella cache, aumentando di fatto la quantità di cache disponibile in un controller.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP gestisce i blocchi fisici in 4KB unità. La compressione adattiva utilizza dimensioni predefinite dei blocchi di compressione di 8KB KB, il che significa che i dati sono compressi in unità da 8KB KB. Corrisponde alle dimensioni dei blocchi di 8KB KB utilizzate più spesso dai database relazionali. Gli algoritmi di compressione diventano più efficienti con la compressione di un numero maggiore di dati come una singola unità. Una dimensione dei blocchi di compressione da 32KB KB sarebbe più efficiente in termini di spazio rispetto a un'unità dei blocchi di compressione da 8KB KB. Ciò significa che la compressione adattiva che utilizza le dimensioni predefinite dei blocchi di 8KB KB produce tassi di efficienza leggermente inferiori, ma esiste anche un vantaggio significativo nell'utilizzo di dimensioni inferiori dei blocchi di compressione. I carichi di lavoro dei database includono un'elevata attività di sovrascrittura. La sovrascrittura di un 8KB di un blocco di dati 32KB compresso richiede la lettura dell'intero 32KB di dati logici, la decompressione, l'aggiornamento della regione 8KB richiesta, la ricompressione e quindi la riscrittura dell'intero 32KB sui dischi. Si tratta di un'operazione molto costosa per un sistema storage ed è il motivo per cui alcuni storage array concorrenti basati su dimensioni dei blocchi di compressione più grandi implicano anche una significativa penalizzazione delle performance con i carichi di lavoro dei database.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Efficienza di conservazione sensibile alla temperatura</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Allineamento delle compressioni</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">La compressione adattiva in un ambiente di database richiede alcune considerazioni sull'allineamento dei blocchi di compressione. Ciò rappresenta solo una preoccupazione per i dati che sono soggetti a sovrascritture casuali di blocchi molto specifici. Questo approccio è simile in teoria all'allineamento complessivo del file system, dove l'inizio di un file system deve essere allineato al limite di un dispositivo 4K e la dimensione di blocco di un file system deve essere un multiplo di 4K.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">SAN</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Compaction dei dati</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">La data compaction opera consentendo di memorizzare più blocchi logici all'interno dei blocchi fisici. Ad esempio, un database con dati altamente comprimibili come testo o blocchi parzialmente completi può comprimere da 8KB a 1KB. Senza la compaction, quei 1KB PB di dati continuerebbero ad occupare un intero blocco da 4KB KB. Inline data compaction per memorizzare 1KB TB di dati compressi in sole 1KB:1 di spazio fisico insieme ad altri dati compressi. Non si tratta di una tecnologia di compressione, ma semplicemente di un metodo più efficiente per allocare spazio sulle unità e quindi non dovrebbe creare alcun effetto rilevabile sulle prestazioni.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Deduplica</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">La deduplica consiste nella rimozione di dimensioni dei blocchi duplicate da un set di dati. Ad esempio, se lo stesso blocco 4KB esistesse in 10 file diversi, la deduplica reindirizzerebbe quel blocco 4KB in tutti i file 10 allo stesso blocco fisico da 4KB KB. Il risultato sarebbe un miglioramento di 10:1 volte in efficienza per quei dati.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Dati come i LUN di avvio guest di VMware si deduplicano in genere in modo estremamente efficace poiché sono costituiti da più copie degli stessi file del sistema operativo. Sono state osservate un'efficienza pari o superiore a 100:1.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">In pochi casi, sono stati osservati risparmi di spazio fino al 15% nei database con blocchi di dimensioni grandi e 16KB. Il 4KB iniziale di ciascun blocco contiene la testata unica a livello globale, mentre il 4KB finale contiene il rimorchio quasi unico. I blocchi interni sono candidati per la deduplica, sebbene in pratica ciò sia quasi interamente attribuito alla deduplica di dati azzerati.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Efficienza e thin provisioning</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Le funzionalità di efficienza sono forme di thin provisioning. Ad esempio, una LUN da 100GB GB che occupa un volume da 100GB GB potrebbe comprimere fino a 50GB GB. Non ci sono risparmi effettivi ancora realizzati perché il volume è ancora 100GB. Le dimensioni del volume devono essere innanzitutto ridotte in modo che lo spazio salvato possa essere utilizzato in un'altra posizione del sistema. Se successivamente le modifiche apportate al LUN da 100GB GB rendono i dati meno comprimibili, il LUN aumenta le dimensioni e il volume potrebbe riempirsi.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Alcuni clienti preferiscono utilizzare il thick provisioning, per carichi di lavoro specifici o generalmente basato su pratiche operative e di approvvigionamento consolidate.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">*Attenzione:* se un volume viene sottoposto a thick provisioning, è necessario fare attenzione a disattivare completamente tutte le funzioni di efficienza per quel volume, inclusa la decompressione e la rimozione della deduplica tramite<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> comando. Il volume non dovrebbe essere visualizzato in<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> output. In tal caso, il volume è ancora parzialmente configurato per le funzioni di efficienza. Di conseguenza, la sovrascrittura garantisce un funzionamento diverso, aumentando le possibilità che le sovrascritture causino l'esaurimento inaspettato dello spazio del volume, con conseguenti errori di i/o del database.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Best practice di efficienza</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">Valori predefiniti AFF</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Raccomandazioni generali</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Se i volumi e/o le LUN non sono dotati di thin provisioning, è necessario disabilitare tutte le impostazioni di efficienza perché queste funzioni non offrono risparmi e la combinazione del thick provisioning con l'efficienza dello spazio può causare comportamenti imprevisti, inclusi errori di spazio esaurito.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Se i dati non sono soggetti a sovrascritture, ad esempio con i backup o i log delle transazioni dei database, puoi ottenere una maggiore efficienza abilitando TSSE con un periodo di raffreddamento ridotto.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Alcuni file potrebbero contenere una quantità significativa di dati non comprimibili, ad esempio quando la compressione è già abilitata a livello di applicazione dei file sono crittografati. Se uno di questi scenari è vero, considerare la possibilità di disattivare la compressione per consentire un funzionamento più efficiente su altri volumi che contengono dati comprimibili.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Criteri - istantanee locali</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">La release iniziale di FabricPool era rivolta a un caso di utilizzo di backup. L'unico tipo di blocchi che è possibile eseguire il tiering era costituito da blocchi che non erano più associati a dati nel file system attivo. Pertanto, solo i blocchi di dati Snapshot possono essere spostati nel Tier di capacità. Questa rimane una delle opzioni di tiering più sicure quando occorre, in modo da garantire che le performance non subiscano alcun impatto.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Esistono due opzioni per il tiering di blocchi di snapshot inattivi nel Tier di capacità. Innanzitutto, la<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la politica riguarda solo i blocchi di snapshot. Anche se il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio include<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> ed esegue il tiering dei blocchi dal file system attivo. Ciò potrebbe non essere desiderabile.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valore deve essere impostato su un periodo di tempo in cui i dati che potrebbero essere necessari durante un ripristino sono disponibili sul livello di prestazioni. Ad esempio, la maggior parte degli scenari di ripristino di un database di produzione critico include un punto di ripristino in un determinato momento dei giorni precedenti. Impostazione a.<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il valore 3 garantisce che qualsiasi ripristino del file porti a un file che offre immediatamente le massime prestazioni. Tutti i blocchi dei file attivi sono ancora presenti sullo storage veloce senza dover ripristinarli dal livello di capacità.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Criteri - istantanee replicate</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Di norma, uno snapshot replicato con SnapMirror o SnapVault utilizzato solo per il ripristino deve utilizzare FabricPool<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> policy. Con questa policy, i metadati vengono replicati, ma tutti i blocchi di dati vengono inviati immediatamente al Tier di capacità, ottenendo il massimo delle performance. La maggior parte dei processi di recovery implica un i/o sequenziale, che è intrinsecamente efficiente. È necessario valutare il tempo di ripristino dalla destinazione dell'archivio oggetti, ma in un'architettura ben progettata questo processo di ripristino non deve essere significativamente più lento del ripristino da dati locali.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Se per il cloning è prevista anche l'utilizzo dei dati replicati, l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politica è più appropriata, con un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valore che comprende i dati che si prevede vengano utilizzati regolarmente in un ambiente di clonazione. Ad esempio, il working set attivo di un database potrebbe includere dati letti o scritti nei tre giorni precedenti, ma potrebbe includere anche altri 6 mesi di dati storici. In tal caso, il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> La policy nella destinazione di SnapMirror rende disponibile il working set nel Tier di performance.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">QoS (IOPS)</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">Nello specifico, la maggiore adozione dello storage all-flash ha permesso il consolidamento dei carichi di lavoro. Gli storage array che si affidano a supporti rotanti tendevano a supportare solo un numero limitato di workload i/o-intensive a causa delle limitate funzionalità IOPS della tecnologia delle unità rotazionali meno recente. Uno o due database altamente attivi saturerebbero i dischi sottostanti molto prima che gli storage controller raggiungano i loro limiti. Questo è cambiato. La capacità di performance di un numero relativamente contenuto di dischi SSD è in grado di saturare anche gli storage controller più potenti. Ciò significa che è possibile sfruttare tutte le funzionalità dei controller senza la paura di un improvviso crollo delle performance con picchi di latenza dei supporti rotanti.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">Come esempio di riferimento, un semplice sistema ha AFF A800 a due nodi è in grado di fornire fino a un milione di IOPS casuali prima che la latenza superi un millisecondo. Ci si aspetta che pochissimi carichi di lavoro singoli raggiungano tali livelli. L'utilizzo completo di questo array di sistema AFF A800 implicherà l'hosting di più carichi di lavoro, per questo motivo in modo sicuro, garantendo al contempo la prevedibilità dei requisiti di qualità del servizio.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">Esistono due tipi di qualità del servizio (QoS) in ONTAP: IOPS e larghezza di banda. È possibile applicare controlli di qualità del servizio a SVM, volumi, LUN e file.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Un controllo della qualità del servizio IOPS si basa ovviamente sugli IOPS totali di una data risorsa, ma esistono alcuni aspetti della qualità del servizio IOPS che potrebbero non essere intuitivi. Alcuni clienti sono rimasti colpiti dall'apparente aumento della latenza al raggiungimento di una soglia IOPS. L'aumento della latenza è il risultato naturale della limitazione degli IOPS. Logicamente, funziona in modo simile a un sistema token. Ad esempio, se un dato volume contenente file di dati ha un limite di 10K IOPS, ogni i/o che arriva deve prima ricevere un token per continuare l'elaborazione. Fino a quando non sono stati consumati più di 10K gettoni in un dato secondo, non sono presenti ritardi. Se le operazioni io devono attendere per ricevere il token, questa attesa viene visualizzata come latenza aggiuntiva. Più un carico di lavoro supera il limite di qualità del servizio, più a lungo ogni i/o deve attendere in coda per l'elaborazione del proprio turno, che appare all'utente come una latenza più elevata.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Prestare attenzione nell'applicazione dei controlli QoS ai dati dei log di transazione/ripristino del database. Mentre le richieste di performance del logging di redo sono in genere molto, molto più basse dei data afiles, l'attività del log di redo è molto bursty. L'io avviene in brevi impulsi e un limite QoS che appare appropriato per i livelli di io di redo medi potrebbe essere troppo basso per i requisiti effettivi. Il risultato può essere una serie di limitazioni delle performance, mentre la qualità del servizio viene associata a ogni burst dei log di ripristino. In generale, il redo e la registrazione dell'archivio non devono essere limitati dalla QoS.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">QoS della larghezza di banda</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">Non tutte le dimensioni i/o sono uguali. Ad esempio, un database potrebbe eseguire un elevato numero di piccoli blocchi di lettura con il raggiungimento della soglia IOPS, tuttavia, è possibile che i database eseguano anche un'operazione di scansione completa della tabella, che consisterebbe in un numero molto ridotto di letture di blocchi di grandi dimensioni, consumando una grande quantità di larghezza di banda ma con un numero relativamente basso di IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">Allo stesso modo, un ambiente VMware potrebbe gestire un numero molto elevato di IOPS casuali durante l'avvio, ma eseguirebbe un numero minore di io, ma più grande, durante un backup esterno.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">Una gestione efficace delle performance a volte richiede limiti di qualità del servizio (QoS) IOPS o larghezza di banda, o anche entrambi.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">Qualità del servizio minima/garantita</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">Molti clienti cercano una soluzione che includa QoS garantita, che sia più difficile da raggiungere di quanto possa sembrare e che sia potenzialmente abbastanza dispendiosa. Ad esempio, collocare 10 database con una garanzia di 10K IOPS richiede il dimensionamento di un sistema per uno scenario in cui tutti i 10 database vengono eseguiti contemporaneamente a 10K IOPS, per un totale di 100K.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">L'utilizzo ottimale per i controlli minimi della qualità del servizio è la protezione dei carichi di lavoro critici. Ad esempio, prendi in considerazione un controller ONTAP con un numero massimo di IOPS possibile di 500K e un mix di workload di produzione e sviluppo. È consigliabile applicare policy QoS massime ai carichi di lavoro di sviluppo per impedire a qualsiasi database di monopolizzare il controller. Quindi, ai carichi di lavoro di produzione si applicano policy minime di qualità del servizio per assicurarsi che dispongano sempre degli IOPS richiesti, quando necessario.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">QoS adattiva</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">La qualità del servizio adattiva fa riferimento alla funzionalità ONTAP, in cui il limite della qualità del servizio si basa sulla capacità dell'oggetto storage. Viene utilizzata raramente con i database perché di solito non esiste alcun collegamento tra le dimensioni di un database e i relativi requisiti prestazionali. I database di grandi dimensioni possono essere quasi inerti, mentre quelli di dimensioni inferiori possono utilizzare un numero elevato di IOPS.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">La qualità del servizio adattiva può rivelarsi molto utile con i datastore di virtualizzazione, perché i requisiti di IOPS di tali set di dati tendono a correlare le dimensioni totali del database. Un datastore più recente, che contiene 1TB TB di file VMDK, avrà probabilmente bisogno di circa la metà delle performance rispetto a un datastore da 2TB TB. La qualità del servizio adattiva ti consente di aumentare automaticamente i limiti della qualità del servizio, man mano che il datastore viene popolato con i dati.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">Il tiering di un set di dati con FabricPool determina una dipendenza tra lo storage array primario e il Tier dell'archivio di oggetti. Sono disponibili molte opzioni di storage a oggetti che offrono livelli di disponibilità variabili. È importante comprendere l'impatto di una possibile perdita di connettività tra lo storage array primario e il Tier dello storage a oggetti.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Se un i/o emesso a ONTAP richiede dati dal Tier di capacità e ONTAP non riesce a raggiungere il Tier di capacità per recuperare i blocchi, l'i/o finisce il time-out. L'effetto di questo timeout dipende dal protocollo utilizzato. In un ambiente NFS, ONTAP risponde con una risposta EJUKEBOX o EDELAY, a seconda del protocollo. Alcuni sistemi operativi meno recenti potrebbero interpretare questo come un errore, ma i sistemi operativi attuali e i livelli di patch correnti del client Oracle Direct NFS considerano questo come un errore recuperabile e continuano ad attendere il completamento dell'i/O.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Un timeout più breve si applica agli ambienti SAN. Se un blocco nell'ambiente dell'archivio oggetti è necessario e rimane irraggiungibile per due minuti, viene restituito un errore di lettura all'host. Il volume e i LUN di ONTAP rimangono online, ma il sistema operativo host potrebbe segnalare il file system come in uno stato di errore.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Problemi di connettività dello storage a oggetti<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> i criteri sono meno preoccupanti, perché vengono suddivisi in livelli solo i dati di backup. I problemi di comunicazione rallenterebbero il recupero dei dati, ma non influenzerebbero altrimenti l'utilizzo attivo dei dati. Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> e.<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Le policy consentono il tiering dei dati cold dal LUN attivo, il che significa che un errore durante il recupero dei dati dell'archivio oggetti può influire sulla disponibilità del database. Un'implementazione SAN con queste policy deve essere utilizzata solo con storage a oggetti di classe Enterprise e connessioni di rete progettate per l'alta disponibilità. NetApp StorageGRID è l'opzione superiore.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">La maggior parte dei database relazionali opera in modalità di archiviazione dei log delle transazioni per fornire un ripristino point-in-time. Le modifiche apportate ai database vengono salvate registrando le modifiche nei registri delle transazioni e il registro delle transazioni viene conservato senza essere sovrascritto. Il risultato può essere la necessità di conservare un enorme volume di registri delle transazioni archiviati. Esempi simili esistono con molti altri flussi di lavoro delle applicazioni che generano dati che devono essere conservati, ma con molte probabilità di accesso.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">FabricPool risolve questi problemi offrendo una singola soluzione con tiering integrato. I file vengono memorizzati e rimangono accessibili nella loro posizione abituale, ma non occupano praticamente spazio nell'array primario.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Utilizzare un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la policy di pochi giorni comporta la conservazione dei blocchi nei file creati di recente (che sono i file più probabilmente necessari a breve termine) nel tier di performance. I blocchi di dati dei file meno recenti vengono quindi spostati nel Tier di capacità.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> applica il tiering prompt quando viene raggiunta la soglia di raffreddamento, indipendentemente dal fatto che i log siano stati eliminati o continuino a esistere nel file system primario. Inoltre, l'archiviazione di tutti i log potenzialmente necessari in un'unica posizione nel file system attivo semplifica la gestione. Non c'è motivo di cercare tra gli snapshot per individuare un file che deve essere ripristinato.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Alcune applicazioni, come Microsoft SQL Server, troncano i file di log delle transazioni durante le operazioni di backup in modo che i log non si trovino più nel file system attivo. È possibile risparmiare capacità utilizzando<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> tiering delle policy, ma<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio non è utile per i dati di log perché raramente dovrebbero essere raffreddati i dati di log nel file system attivo.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster è disponibile in 3 diverse configurazioni</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">Coppie HA con connettività IP</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">Coppie HA con connettività FC</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Controller singolo con connettività FC</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">IP MetroCluster</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">La configurazione MetroCluster IP ha-Pair utilizza due o quattro nodi per sito. Questa opzione di configurazione aumenta la complessità e i costi rispetto all'opzione a due nodi, ma offre un vantaggio importante: La ridondanza intrasite. Un semplice errore del controller non richiede l'accesso ai dati nella WAN. L'accesso ai dati rimane locale attraverso il controller locale alternativo.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">La maggior parte dei clienti sceglie la connettività IP perché i requisiti dell'infrastruttura sono più semplici. In passato, la connettività cross-site ad alta velocità era generalmente più semplice da fornire utilizzando gli switch FC e in fibra scura, ma oggi i circuiti IP ad alta velocità e a bassa latenza sono più prontamente disponibili.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">L'architettura è anche più semplice perché le uniche connessioni cross-site sono per i controller. Nei MetroClusters collegati a FC SAN, un controller scrive direttamente sulle unità del sito opposto e quindi richiede connessioni SAN, switch e bridge aggiuntivi. Al contrario, un controller in una configurazione IP scrive sulle unità opposte tramite il controller.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Architettura e progettazione della soluzione IP di MetroCluster</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Per ulteriori informazioni, consultare la documentazione ufficiale di ONTAP e.<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">MetroCluster HA-Pair FC SAN-Attached</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">La configurazione ha-Pair MetroCluster FC utilizza due o quattro nodi per sito. Questa opzione di configurazione aumenta la complessità e i costi rispetto all'opzione a due nodi, ma offre un vantaggio importante: La ridondanza intrasite. Un semplice errore del controller non richiede l'accesso ai dati nella WAN. L'accesso ai dati rimane locale attraverso il controller locale alternativo.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Alcune infrastrutture multisito non sono progettate per le operazioni Active-Active, ma vengono utilizzate maggiormente come sito primario e sito di disaster recovery. In questa situazione, è generalmente preferibile un'opzione ha-Pair MetroCluster per i seguenti motivi:</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Anche se un cluster MetroCluster a due nodi è un sistema ha, un guasto imprevisto di un controller o una manutenzione pianificata richiedono che i servizi dati vengano online sul sito opposto. Se la connettività di rete tra i siti non supporta la larghezza di banda richiesta, le prestazioni ne risentono. L'unica opzione sarebbe anche eseguire il failover dei vari sistemi operativi host e dei servizi associati al sito alternativo. Il cluster MetroCluster ha-Pair elimina questo problema grazie alla perdita di un controller che consente di eseguire un semplice failover all'interno dello stesso sito.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Alcune topologie di rete non sono progettate per l'accesso tra siti, ma utilizzano sottoreti o SAN FC isolate. In questi casi, il cluster MetroCluster a due nodi non funziona più come sistema ha, perché il controller alternativo non può fornire dati ai server del sito opposto. L'opzione ha-Pair MetroCluster è necessaria per garantire ridondanza completa.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Se un'infrastruttura a due siti viene vista come una singola infrastruttura ad alta disponibilità, la configurazione MetroCluster a due nodi è adatta. Tuttavia, se il sistema deve funzionare per un periodo di tempo prolungato dopo il guasto del sito, è preferibile una coppia ha perché continua a fornire ha all'interno di un singolo sito.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">MetroCluster FC SAN-attached a due nodi</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">La configurazione MetroCluster a due nodi utilizza un solo nodo per sito. Questo design è più semplice rispetto all'opzione ha-Pair perché richiede meno componenti da configurare e gestire. Inoltre, ha ridotto le richieste di infrastruttura in termini di cablaggio e switch FC. Infine, riduce i costi.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">L'evidente impatto di questa progettazione è che un guasto del controller su un singolo sito implica che i dati sono disponibili dal sito opposto. Questa restrizione non è necessariamente un problema. Molte aziende hanno operazioni di data center multisito con reti estese, ad alta velocità e a bassa latenza che funzionano essenzialmente come una singola infrastruttura. In questi casi, la configurazione preferita è la versione a due nodi di MetroCluster. Diversi service provider utilizzano attualmente sistemi a due nodi con scalabilità di petabyte.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Funzionalità di resilienza di MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">Non esistono single point of failure in una soluzione MetroCluster:</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Ogni controller dispone di due percorsi indipendenti verso gli shelf di dischi sul sito locale.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Ogni controller dispone di due percorsi indipendenti verso gli shelf di dischi sul sito remoto.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Ciascun controller dispone di due percorsi indipendenti verso i controller sul sito opposto.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">Nella configurazione ha-Pair, ogni controller ha due percorsi verso il partner locale.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">Riassumendo, qualsiasi componente della configurazione può essere rimosso senza compromettere la capacità di MetroCluster di fornire dati. L'unica differenza in termini di resilienza tra le due opzioni è che la versione ha-Pair è ancora un sistema storage ha generale dopo un guasto del sito.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Gestione dello spazio</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">Il thin provisioning è disponibile in molte forme e rappresenta parte integrante di molte funzionalità offerte da ONTAP a un ambiente applicativo aziendale. Il thin provisioning è inoltre strettamente correlato alle tecnologie di efficienza per lo stesso motivo: Le funzionalità di efficienza consentono di memorizzare dati più logici rispetto a quanto tecnicamente esistente nel sistema storage.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">Quasi tutti gli utilizzi delle snapshot implicano il thin provisioning. Ad esempio, un tipico database da 10TB TB su storage NetApp include circa 30 giorni di snapshot. Questa disposizione risulta in circa 10TB di dati visibili nel file system attivo e 300TB dedicati agli snapshot. In genere, il 310TB GB di storage totale risiede su un totale di circa 12TB - 15TB GB di spazio. Il database attivo consuma 10TB e i restanti 300TB di dati richiedono solo da 2TB a 5TB di spazio, in quanto vengono memorizzate solo le modifiche apportate ai dati originali.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">Anche il cloning è un esempio di thin provisioning. Un importante cliente NetApp ha creato 40 cloni di un database da 80TB TB per l'utilizzo da parte dello sviluppo. Se tutti i 40 sviluppatori che utilizzano questi cloni sovrascrivono ogni blocco in ogni file dati, sarebbero necessari oltre 3,2PB TB di storage. In pratica, il turnover è basso e il requisito di spazio collettivo è più vicino a 40TB, perché solo le modifiche sono memorizzate sui drive.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">È necessario prestare particolare attenzione al thin provisioning di un ambiente applicativo, perché la velocità di modifica dei dati può aumentare inaspettatamente. Ad esempio, il consumo di spazio dovuto agli snapshot può crescere rapidamente se le tabelle di database vengono riindicizzate o se viene applicata una patch su larga scala ai guest VMware. Un backup posizionato in modo errato può scrivere una grande quantità di dati in un tempo molto breve. Infine, può essere difficile recuperare alcune applicazioni se un file system esaurisce inaspettatamente lo spazio libero.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Fortunatamente, questi rischi possono essere risolti con un'attenta configurazione di<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> criteri: Come indicato dai nomi, queste opzioni consentono a un utente di creare policy in grado di liberare automaticamente lo spazio occupato dalle snapshot o di far crescere un volume per ospitare dati aggiuntivi. Sono disponibili molte opzioni e le esigenze variano in base al cliente.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">documentazione per la gestione logica dello storage</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Vedere <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> per una discussione completa di queste funzioni.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Un'attenta pianificazione della configurazione LVM può migliorare l'efficienza e ridurre al minimo la necessità di provisioning dello storage e di ridimensionamento delle LUN. Quando si utilizza un LVM come Veritas VxVM o Oracle ASM, le LUN sottostanti vengono suddivise in estensioni che vengono utilizzate solo quando necessario. Ad esempio, se un set di dati inizia a 2TB TB ma potrebbe crescere fino a 10TB TB con il passare del tempo, è possibile inserire il set di dati in 10TB LUN con thin provisioning organizzati in un gruppo di dischi LVM. Occupa solo 2TB GB di spazio al momento della creazione e richiederebbe spazio aggiuntivo solo se le estensioni sono allocate per ospitare la crescita dei dati. Questo processo è sicuro finché lo spazio è monitorato.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Prenotazioni frazionarie</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">Riserva frazionaria si riferisce al comportamento di un LUN in un volume rispetto all'efficienza dello spazio. Quando l'opzione<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> è impostato al 100%, tutti i dati nel volume possono subire un turnover del 100% con qualsiasi modello di dati senza esaurire lo spazio sul volume.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Ad esempio, si consideri un database su una singola LUN da 250GB GB in un volume da 1TB GB. La creazione di uno snapshot comporterebbe immediatamente la riserva di ulteriori 250GB GB di spazio nel volume per garantire che il volume non esaurisca lo spazio per alcun motivo. L'utilizzo di riserve frazionarie comporta in genere uno spreco di risorse poiché è estremamente improbabile che ogni byte nel volume del database debba essere sovrascritto. Non c'è motivo di riservare spazio per un evento che non si verifica mai. Tuttavia, se un cliente non è in grado di monitorare il consumo di spazio in un sistema di storage e deve essere certo che lo spazio non si esaurisce mai, sarebbero necessarie prenotazioni frazionarie del 100% per utilizzare gli snapshot.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Compressione e deduplica</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">Compressione e deduplica sono entrambe forme di thin provisioning. Ad esempio, un impatto dei dati di 50TB:1 potrebbe comprimere fino a 30TB:1, ottenendo un risparmio di 20TB:1. Affinché la compressione possa produrre vantaggi, alcuni di questi 20TB TB devono essere utilizzati per altri dati, altrimenti il sistema storage deve essere acquistato con meno di 50TB TB. In questo modo è possibile memorizzare una quantità di dati superiore rispetto a quella tecnicamente disponibile sul sistema storage. Dal punto di vista dei dati, i dati sono 50TB, anche se occupano solo 30TB sulle unità.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Esiste sempre la possibilità che la compressibilità di un set di dati cambi, con conseguente aumento del consumo di spazio reale. Questo aumento dei consumi implica che la compressione deve essere gestita come con altre forme di thin provisioning in termini di monitoraggio e utilizzo<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">Compressione e deduplica sono descritte in dettaglio nella sezione link:efficiency.html</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Compressioni e prenotazioni frazionarie</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">La compressione è una forma di thin provisioning. Le prenotazioni frazionarie influiscono sull'utilizzo della compressione, con una nota importante; lo spazio viene riservato prima della creazione dell'istantanea. Normalmente, la riserva frazionaria è importante solo se esiste uno snapshot. Se non è presente uno snapshot, la riserva frazionaria non è importante. Questo non è il caso della compressione. Se viene creata una LUN su un volume con compressione, ONTAP preserva lo spazio per ospitare uno snapshot. Questo comportamento può creare confusione durante la configurazione, ma è previsto.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Ad esempio, consideriamo un volume da 10GB GB con una LUN da 5GB GB compressa a 2,5GB GB senza snapshot. Considerare questi due scenari:</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">Riserva frazionaria = 100 risultati in 7,5GB utilizzo</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">Riserva frazionaria = 0 risultati in 2,5GB utilizzo</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">Il primo scenario include 2,5GB di consumo di spazio per i dati attuali e 5GB di spazio per rappresentare il 100% di fatturato della fonte in previsione dell'utilizzo di snapshot. Il secondo scenario non riserva spazio aggiuntivo.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Sebbene questa situazione possa sembrare confusa, è improbabile che si verifichi nella pratica. La compressione implica thin provisioning e il thin provisioning in un ambiente LUN richiede prenotazioni frazionarie. È sempre possibile sovrascrivere i dati compressi con qualcosa di non comprimibile, il che significa che un volume deve essere sottoposto a thin provisioning per la compressione per consentire qualsiasi risparmio.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp consiglia* le seguenti configurazioni riservate:</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Impostare<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 0 quando è in atto il monitoraggio della capacità di base con<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Impostare<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 100 se non vi è alcuna capacità di monitoraggio o se è impossibile scaricare lo spazio in qualsiasi circostanza.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">Tipi di LIF</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Documentazione di gestione della rete ONTAP</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">Questa sezione offre una panoramica dei principali principi di progettazione della LIF. Per una documentazione più completa, vedere <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Come per altri aspetti dell'architettura dei database, le migliori opzioni per la progettazione di una Storage Virtual Machine (SVM, nota come vserver all'interfaccia della CLI) e di un'interfaccia logica (LIF) dipendono in gran parte dai requisiti di scalabilità e dalle esigenze di business.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Durante la creazione di una strategia LIF, prendi in considerazione i seguenti argomenti principali:</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Performance.* la larghezza di banda della rete è sufficiente?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Resilienza.* ci sono singoli punti di guasto nel progetto?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Gestibilità.* la rete può essere scalata senza interruzioni?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Gli argomenti trattati sono relativi alla soluzione end-to-end, dall'host fino agli switch fino al sistema storage.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">Documentazione ONTAP sui tipi di LIF</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Esistono diversi tipi di LIF. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Fornisci informazioni più complete su questo argomento, ma da un punto di vista funzionale le LIF possono essere divise in gruppi:</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*LIF di gestione cluster e nodi.* LIF utilizzati per gestire il cluster storage.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*LIF di gestione SVM.* interfacce che consentono l'accesso a una SVM tramite l'API REST o ONTAPI (nota anche come ZAPI) per funzioni come la creazione di snapshot o il ridimensionamento del volume. Prodotti come SnapManager for Oracle (SMO) devono avere accesso a una LIF di gestione SVM.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*Interfacce LIF dati* per FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, o dati SMB/CIFS.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">Una LIF dati utilizzata per il traffico NFS può anche essere utilizzata per la gestione cambiando la policy del firewall da<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> a.<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> O un'altra policy che consente HTTP, HTTPS o SSH. Questa modifica può semplificare la configurazione di rete evitando la configurazione di ciascun host per l'accesso sia alla LIF dati NFS che a una LIF di gestione separata. Non è possibile configurare un'interfaccia sia per iSCSI che per il traffico di gestione, nonostante entrambi utilizzino un protocollo IP. Negli ambienti iSCSI è necessaria una LIF di gestione separata.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Progettazione della SAN LIF</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">Il design di LIF in un ambiente SAN è relativamente semplice per un motivo: Il multipathing. Tutte le moderne implementazioni SAN consentono a un client di accedere ai dati su più percorsi di rete indipendenti e di selezionare i percorsi migliori per l'accesso. Di conseguenza, le performance rispetto alla progettazione LIF sono più semplici da gestire, perché i client SAN bilanciano automaticamente il carico dell'i/o nei migliori percorsi disponibili.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Se un percorso non è disponibile, il client seleziona automaticamente un percorso diverso. Grazie alla sua semplicità di progettazione, le LIF SAN sono generalmente più gestibili. Ciò non significa che un ambiente SAN sia sempre più facile da gestire, poiché vi sono molti altri aspetti dello storage SAN che sono molto più complicati di NFS. Significa semplicemente che la progettazione della SAN LIF è più semplice.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">La considerazione più importante riguardo le performance di una LIF in un ambiente SAN è la larghezza di banda. Ad esempio, un cluster ONTAP AFF a due nodi con due porte FC da 16GB GB per nodo offre fino a 32GB Gbps di larghezza di banda da/per ciascun nodo.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Resilienza</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">Le LIF SAN non eseguono il failover su un sistema storage AFF. In caso di guasto di una LIF SAN a causa del failover del controller, il software multipath del client rileva la perdita di un percorso e reindirizza l'i/o a una diversa LIF. Con i sistemi storage ASA, il failover delle LIF dopo un breve ritardo, ma ciò non interrompe l'io perché ci sono percorsi già attivi sull'altro controller. Il processo di failover viene eseguito per ripristinare l'accesso dell'host su tutte le porte definite.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Gestibilità</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">La migrazione LIF è un task molto più comune in un ambiente NFS, perché la migrazione LIF è spesso associata alla riallocazione dei volumi nel cluster. Non è necessario migrare una LIF in un ambiente SAN quando i volumi vengono ricollocati nella coppia ha. Questo perché, una volta completato lo spostamento del volume, ONTAP invia una notifica alla SAN in merito a una modifica dei percorsi e i client SAN vengono automaticamente risottimizzati. La migrazione LIF con SAN è associata principalmente a importanti modifiche hardware fisiche. Ad esempio, per eseguire un upgrade senza interruzioni dei controller, viene eseguita la migrazione di una SAN LIF nel nuovo hardware. Se una porta FC è guasta, una LIF può essere migrata a una porta inutilizzata.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Raccomandazioni di progettazione</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp formula i seguenti consigli:</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">Non creare più percorsi di quelli richiesti. Un numero eccessivo di percorsi complica la gestione complessiva e può causare problemi con il failover del percorso su alcuni host. Inoltre, alcuni host hanno limitazioni inattese del percorso per configurazioni come l'avvio SAN.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Un numero molto ridotto di configurazioni deve richiedere più di quattro percorsi a un LUN. Il valore di avere più di due nodi che pubblicizzano i percorsi delle LUN è limitato perché l'aggregato che ospita un LUN è inaccessibile in caso di guasto del nodo proprietario del LUN e del partner ha. In una situazione del genere, la creazione di percorsi su nodi diversi dalla coppia ha primaria non è d'aiuto.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Sebbene il numero di percorsi LUN visibili possa essere gestito selezionando le porte incluse nelle zone FC, in genere è più semplice includere tutti i potenziali punti di destinazione nella zona FC e controllare la visibilità delle LUN a livello ONTAP.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">In ONTAP 8,3 e versioni successive, la funzione SLM (Selective LUN mapping) è quella predefinita. Con SLM, ogni nuova LUN viene automaticamente pubblicizzata dal nodo proprietario dell'aggregato sottostante e del partner ha del nodo. Questa disposizione evita la necessità di creare set di porte o configurare la suddivisione in zone per limitare l'accessibilità delle porte. Ogni LUN è disponibile sul numero minimo di nodi necessari per performance e resilienza ottimali.
*Nel caso in cui sia necessario migrare un LUN all'esterno dei due controller, è possibile aggiungere i nodi aggiuntivi con<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> In modo che le LUN vengano pubblicizzate sui nuovi nodi. In questo modo si creano ulteriori percorsi SAN alle LUN per la migrazione delle LUN. Tuttavia, l'host deve eseguire un'operazione di rilevamento per utilizzare i nuovi percorsi.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">Non preoccupatevi eccessivamente del traffico indiretto. Si consiglia di evitare il traffico indiretto in un ambiente i/o-intensive per il quale è critico ogni microsecondo di latenza, ma l'effetto visibile delle performance è trascurabile per i workload tipici.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">Progettazione della LIF NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">A differenza dei protocolli SAN, NFS ha una capacità limitata di definire percorsi multipli ai dati. Le estensioni Parallel NFS (pNFS) a NFSv4 risolvono questo limite, ma poiché le velocità ethernet hanno raggiunto 100GB Mbps e oltre, raramente è utile aggiungere altri percorsi.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Performance e resilienza</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Sebbene la misurazione delle performance SAN LIF si debba principalmente calcolare la larghezza di banda totale da tutti i percorsi primari, la determinazione delle performance NFS LIF richiede un'analisi più approfondita dell'esatta configurazione di rete. Ad esempio, è possibile configurare due porte 10Gb come porte fisiche grezze oppure come gruppo di interfacce LACP (link Aggregation Control Protocol). Se sono configurati come gruppo di interfacce, sono disponibili più criteri di bilanciamento del carico che funzionano in modo diverso a seconda che il traffico sia commutato o instradato. Infine, Oracle Direct NFS (DNFS) offre configurazioni di bilanciamento del carico attualmente inesistenti in nessun client NFS del sistema operativo.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">A differenza dei protocolli SAN, i file system NFS richiedono resilienza al livello del protocollo. Ad esempio, un LUN è sempre configurato con il multipathing attivato, ovvero sono disponibili più canali ridondanti per il sistema storage, ciascuno dei quali utilizza il protocollo FC. Un file system NFS, invece, dipende dalla disponibilità di un unico canale TCP/IP che può essere protetto solo a livello fisico. Questa disposizione è il motivo per cui esistono opzioni quali il failover della porta e l'aggregazione della porta LACP.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">In un ambiente NFS, performance e resilienza sono fornite a livello del protocollo di rete. Di conseguenza, entrambi gli argomenti sono intrecciati e devono essere discussi insieme.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Associare le LIF ai gruppi di porte</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Per associare una LIF a un gruppo di porte, associare l'indirizzo IP della LIF a un gruppo di porte fisiche. Il metodo principale per aggregare insieme le porte fisiche è LACP. La capacità di fault tolerance di LACP è abbastanza semplice; ogni porta di un gruppo LACP viene monitorata e rimossa dal gruppo di porte in caso di malfunzionamento. Esistono, tuttavia, molte idee sbagliate sul funzionamento di LACP in relazione alle prestazioni:</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP non richiede che la configurazione sullo switch corrisponda all'endpoint. Ad esempio, ONTAP può essere configurato con il bilanciamento del carico basato su IP, mentre uno switch può utilizzare il bilanciamento del carico basato su MAC.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Ogni endpoint che utilizza una connessione LACP può scegliere indipendentemente la porta di trasmissione del pacchetto, ma non può scegliere la porta utilizzata per la ricezione. Ciò significa che il traffico da ONTAP a una destinazione specifica è legato a una porta specifica e il traffico di ritorno potrebbe arrivare su un'interfaccia diversa. Ciò non causa tuttavia problemi.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP non distribuisce uniformemente il traffico in ogni momento. In un ambiente di grandi dimensioni con molti client NFS, il risultato è generalmente l'utilizzo di tutte le porte in un'aggregazione LACP. Tuttavia, qualsiasi file system NFS nell'ambiente è limitato alla larghezza di banda di una sola porta, non all'intera aggregazione.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Sebbene i criteri LACP di robin-robin siano disponibili su ONTAP, questi criteri non indirizzano la connessione da uno switch a un host. Ad esempio, una configurazione con un trunk LACP a quattro porte su un host e un trunk LACP a quattro porte su ONTAP è ancora in grado di leggere un file system utilizzando una sola porta. Sebbene ONTAP sia in grado di trasmettere dati attraverso tutte e quattro le porte, non sono attualmente disponibili tecnologie di switch che inviano dallo switch all'host attraverso tutte e quattro le porte. Ne viene utilizzato uno solo.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">L'approccio più comune in ambienti di grandi dimensioni costituiti da molti host di database è quello di creare un aggregato LACP di un numero appropriato di interfacce 10Gb (o più veloce) utilizzando il bilanciamento del carico IP. Questo approccio consente a ONTAP di garantire l'uso uniforme di tutte le porte, purché esistano un numero sufficiente di client. Il bilanciamento del carico si interrompe quando nella configurazione sono presenti meno client, poiché il trunking LACP non ridistribuisce dinamicamente il carico.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Quando viene stabilita una connessione, il traffico in una determinata direzione viene posizionato su una sola porta. Ad esempio, un database che esegue una scansione completa della tabella su un file system NFS collegato tramite un trunk LACP a quattro porte legge i dati tramite una sola scheda di interfaccia di rete (NIC). Se in un tale ambiente sono presenti solo tre server di database, è possibile che tutti e tre stiano leggendo dalla stessa porta, mentre le altre tre porte sono inattive.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Lega le LIF alle porte fisiche</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">L'associazione di una LIF a una porta fisica dà come risultato un controllo più granulare della configurazione di rete, in quanto un dato indirizzo IP su un sistema ONTAP è associato a una sola porta di rete alla volta. La resilienza viene quindi ottenuta tramite la configurazione di gruppi di failover e policy di failover.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Criteri di failover e gruppi di failover</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">Documentazione sulla gestione della rete di ONTAP per gruppi e policy di failover</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">Il comportamento delle LIF durante un'interruzione di rete è controllato da policy di failover e gruppi di failover. Le opzioni di configurazione sono state modificate con le diverse versioni di ONTAP. Consultare <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Per informazioni specifiche sulla versione di ONTAP distribuita.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">ONTAP 8,3 (e versioni successive) consente la gestione del failover LIF in base ai domini di broadcast. Pertanto, un amministratore può definire tutte le porte che hanno accesso a una data subnet e consentire a ONTAP di selezionare una LIF di failover appropriata. Questo approccio può essere utilizzato da alcuni clienti, ma presenta limitazioni in un ambiente di rete di storage ad alta velocità a causa della mancanza di prevedibilità. Ad esempio, un ambiente può includere sia porte 1Gb GbE per l'accesso di routine al file system sia porte 10Gb GbE per l'i/o del file dati Se nello stesso dominio di broadcast sono presenti entrambi i tipi di porte, il failover LIF può spostare l'i/o del file dati da una porta 10Gb a una porta 1Gb.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">In sintesi, prendere in considerazione le seguenti pratiche:</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Configurare un gruppo di failover come definito dall'utente.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Popola il gruppo di failover con le porte sul partner controller di failover dello storage (SFO), in modo che le LIF seguano gli aggregati durante un failover dello storage. In questo modo si evita di creare traffico indiretto.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Utilizza porte di failover con caratteristiche di performance corrispondenti alla LIF originale. Ad esempio, una LIF su una singola porta fisica di 10Gb deve includere un gruppo di failover con una singola porta 10Gb. Un LIF LACP a quattro porte deve eseguire il failover in un altro LIF LACP a quattro porte. Queste porte sono un sottoinsieme delle porte definite nel dominio di broadcast.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Impostare la policy di failover solo su partner SFO. Questo assicura che la LIF segua l'aggregato durante il failover.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Ripristino automatico</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Impostare<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> parametro come desiderato. La maggior parte dei clienti preferisce impostare questo parametro su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Di ripristinare la porta home della LIF. Tuttavia, in alcuni casi, i clienti hanno impostato questo valore su `false' per poter esaminare un failover imprevisto prima di restituire una LIF alla porta home.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">Rapporto LIF-volume</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">Un equivoco comune consiste nella necessità di una relazione 1:1:1 tra volumi e LIF NFS. Sebbene questa configurazione sia necessaria per spostare un volume ovunque in un cluster senza creare mai traffico di interconnessione aggiuntivo, non si tratta di un requisito categoricamente importante. Occorre considerare il traffico intercluster, ma la semplice presenza di traffico intercluster non crea problemi. Molti dei benchmark pubblicati per ONTAP includono principalmente l'i/o indiretto</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Ad esempio, un progetto di database contenente un numero relativamente contenuto di database critici per le performance, che richiedevano solo un totale di 40 volumi, potrebbe giustificare un volume da 1:1 GB per la strategia LIF, una disposizione che richiederebbe 40 indirizzi IP. Quindi, è possibile spostare un qualsiasi volume nel cluster insieme alla LIF associata e il traffico sarebbe sempre diretto, minimizzando ogni origine di latenza anche a livelli di microsecondi.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Ad esempio, è possibile gestire più facilmente un ambiente di grandi dimensioni in hosting con una relazione di 1:1:1 tra clienti e LIF. Con il passare del tempo, potrebbe essere necessario migrare un volume su un nodo diverso, causando traffico indiretto. Tuttavia, l'effetto sulle prestazioni non dovrebbe essere rilevabile a meno che le porte di rete sullo switch di interconnessione non siano saturanti. In caso di problemi, è possibile stabilire una nuova LIF sui nodi aggiuntivi e l'host può essere aggiornato nella successiva finestra di manutenzione per rimuovere il traffico indiretto dalla configurazione.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster e aggregati multipli</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">In condizioni normali, le scritture in arrivo su un dato controller vengono mirrorate in modo sincrono per il partner. In un ambiente NetApp MetroCluster, le scritture vengono anche mirrorate su un controller remoto. Fino a quando non viene memorizzata in un supporto non volatile in tutte le posizioni, la scrittura non viene riconosciuta all'applicazione host.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">Il supporto che memorizza i dati di scrittura è chiamato memoria non volatile o NVMEM. Viene anche talvolta indicata come memoria non volatile ad accesso casuale (NVRAM, nonvolatile Random Access Memory), e può essere considerata come una cache di scrittura anche se funziona come un journal. In condizioni normali, i dati provenienti da NVMEM non vengono letti; vengono utilizzati solo per proteggere i dati in caso di guasti software o hardware. Quando i dati vengono scritti sulle unità disco rigido, i dati vengono trasferiti dalla RAM nel sistema, non da NVMEM.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Durante un'operazione di takeover, un nodo di una coppia ha (high Availability) assume il controllo delle operazioni dal partner. Lo switchover è praticamente identico, ma si applica alle configurazioni MetroCluster in cui un nodo remoto assume le funzioni di un nodo locale.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Durante le normali operazioni di manutenzione, un'operazione di takeover o switchover dello storage deve essere trasparente, ad eccezione di una potenziale breve pausa nelle operazioni in base al cambiamento dei percorsi di rete. Il networking può rivelarsi complesso, tuttavia, ed è facile commettere errori, pertanto NetApp consiglia vivamente di eseguire accuratamente le operazioni di takeover e switchover prima di mettere in produzione un sistema storage. In questo modo, è possibile verificare che tutti i percorsi di rete siano configurati correttamente. In un ambiente SAN, controllare attentamente l'output del comando<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> per assicurarsi che tutti i percorsi primario e secondario previsti siano disponibili.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Occorre prestare attenzione quando si rilascia un'acquisizione forzata o uno switchover. Imporre una modifica alla configurazione dello storage con queste opzioni significa che lo stato del controller proprietario delle unità non viene preso in considerazione e il nodo alternativo assume forzatamente il controllo delle unità. Una forzatura non corretta di un takeover può causare la perdita o il danneggiamento dei dati. Questo perché un takeover o uno switchover forzato può scartare il contenuto di NVMEM. Una volta completato il takeover o lo switchover, la perdita dei dati potrebbe riportare i dati memorizzati nelle unità a uno stato leggermente più vecchio dal punto di vista del database.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">Raramente dovrebbe essere necessario un takeover forzato con una normale coppia ha. In quasi tutti gli scenari di errore, un nodo si arresta e informa il partner in modo che si verifichi un failover automatico. In alcuni casi, ad esempio in caso di guasto permanente che causa la perdita dell'interconnessione tra i nodi e la perdita di un controller, è necessario eseguire un takeover forzato. In una situazione del genere, il mirroring tra i nodi viene perso prima del guasto del controller, il che significa che il controller rimasto non avrebbe più una copia delle scritture in corso. Il takeover deve quindi essere forzato, il che significa che potenzialmente i dati vengono persi.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">La stessa logica si applica a uno switchover MetroCluster. In condizioni normali, lo switchover è quasi trasparente. Tuttavia, un disastro può causare una perdita di connettività tra il sito rimasto e il sito disastroso. Dal punto di vista del sito sopravvissuto, il problema potrebbe essere nient'altro che un'interruzione della connettività tra i siti, e il sito originale potrebbe ancora elaborare i dati. Se un nodo non è in grado di verificare lo stato del controller primario, è possibile solo uno switchover forzato.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp raccomanda* adottare le seguenti precauzioni:</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Prestare molta attenzione a non forzare accidentalmente un'acquisizione o uno switchover. In genere, non è necessario forzare e forzare la modifica può causare la perdita di dati.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Se è necessario un takeover o uno switchover forzato, assicurarsi che le applicazioni vengano arrestate, che tutti i file system vengano dismontati e che i gruppi di volumi LVM (Logical Volume Manager) siano diversi. I gruppi di dischi ASM devono essere smontati.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">In caso di switchover MetroCluster forzato, scollegare il nodo guasto da tutte le risorse di storage rimaste. Per ulteriori informazioni, consultare la Guida alla gestione e al ripristino di emergenza di MetroCluster per la versione pertinente di ONTAP.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster è una tecnologia di replica sincrona che passa alla modalità asincrona in caso di interruzione della connettività. Questa è la richiesta più comune da parte dei clienti, perché la replica sincrona garantita significa che l'interruzione della connettività del sito porta a uno stallo completo dell'i/o del database, mettendo il database fuori servizio.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Con MetroCluster, gli aggregati vengono sincronizzati rapidamente dopo il ripristino della connettività. A differenza di altre tecnologie di storage, MetroCluster non dovrebbe mai richiedere un reindirizzamento completo in seguito a un guasto del sito. È necessario spedire solo le modifiche delta.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">Nei set di dati estesi agli aggregati c'è solo un piccolo rischio che occorrano passaggi aggiuntivi di recovery dei dati in uno scenario di emergenza regolare. In particolare, se (a) la connettività tra siti viene interrotta, (b) la connettività viene ripristinata, (c) gli aggregati raggiungono uno stato in cui alcuni sono sincronizzati e alcuni non lo sono, quindi (d) il sito primario viene perso, il risultato è un sito sopravvissuto in cui gli aggregati non sono sincronizzati tra loro. In tal caso, parti del set di dati vengono sincronizzate tra loro e non è possibile ripristinare applicazioni, database o datastore senza un recovery. Se un set di dati si estende agli aggregati, NetApp consiglia vivamente di sfruttare i backup basati su snapshot con uno dei molti strumenti disponibili, per verificare la possibilità di recupero rapido in questo scenario insolito.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP e RAID-TEC utilizzano tutti la parità per garantire che il guasto al disco non determini una perdita di dati. Queste opzioni RAID offrono un utilizzo dello storage migliore rispetto al mirroring, ma la maggior parte delle implementazioni RAID presenta uno svantaggio che influisce sulle operazioni di scrittura. Il completamento di un'operazione di scrittura su altre implementazioni RAID potrebbe richiedere letture di più unità per rigenerare i dati di parità, un processo comunemente chiamato penalizzazione RAID.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">ONTAP, tuttavia, non subisce questa penalizzazione del RAID. Ciò è dovuto all'integrazione di NetApp WAFL (Write Anywhere file Layout) con il livello RAID. Le operazioni di scrittura vengono unite nella RAM e preparate come uno stripe RAID completo, inclusa la generazione della parità. ONTAP non ha bisogno di eseguire una lettura per completare una scrittura, il che significa che ONTAP e WAFL evitare la penalizzazione RAID. Le performance per le operazioni critiche in termini di latenza, come il logging di redo, vengono mantenute e le scritture random dei file di dati non comportano penalizzazioni RAID dovute alla necessità di rigenerare la parità.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">Per quanto riguarda l'affidabilità statistica, anche RAID DP offre una protezione migliore rispetto al mirroring RAID. Il problema principale è la richiesta fatta sui dischi durante una ricostruzione del RAID. Con un set RAID con mirroring, il rischio di perdita di dati causata da un guasto al disco e durante la ricostruzione nel partner nel set RAID è molto maggiore del rischio di un guasto a tre dischi in un set RAID DP.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Prima dell'era dei dischi flash, era stato utilizzato lo striping per superare i limiti di performance dei dischi rotanti. Ad esempio, se un sistema operativo deve eseguire un'operazione di lettura a 1MB bit, la lettura di 1MB GB di dati da un'unica unità richiederebbe un'ampia ricerca e lettura della testina dell'unità poiché il sistema 1MB viene trasferito lentamente. Se quei 1MB TB di dati sono stati suddivisi in 8 LUN, il sistema operativo potrebbe emettere otto operazioni di lettura 128K in parallelo, riducendo il tempo necessario per completare il trasferimento da 1MB GB.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">Lo striping con dischi rotanti era più difficile perché lo schema di i/o doveva essere noto in anticipo. Se lo striping non è stato regolato correttamente per i modelli i/o reali, le configurazioni con striping potrebbero danneggiare le prestazioni. Con i database Oracle, e in particolare con le configurazioni all-flash, lo striping è molto più semplice da configurare ed è stato dimostrato che le performance risultano notevolmente migliorate.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Per impostazione predefinita, i gestori di volume logici, come lo stripe di Oracle ASM, ma il sistema operativo LVM nativo non lo fanno. Alcune di esse collegano più LUN insieme come un dispositivo concatenato, il che comporta file di dati che esistono su un solo dispositivo LUN. Ciò causa punti caldi. Le altre implementazioni LVM sono impostate per impostazione predefinita su estensioni distribuite. Questo è simile allo striping, ma è più grossolano. I LUN nel gruppo di volumi vengono suddivisi in porzioni di grandi dimensioni, chiamate estensioni e generalmente misurati in molti megabyte, e i volumi logici vengono quindi distribuiti tra tali estensioni. Il risultato è un i/o casuale per un file dovrebbe essere ben distribuito tra i LUN, ma le operazioni i/o sequenziali non sono così efficienti come potrebbero essere.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">L'i/o delle applicazioni che richiedono elevate performance è quasi sempre (a) in unità delle dimensioni dei blocchi di base o (b) un megabyte.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">L'obiettivo principale di una configurazione con striping è quello di garantire che l'i/o a file singolo possa essere eseguito come una singola unità, mentre l'i/o a blocchi multipli, di dimensioni pari a 1MB GB, può essere parallelizzato in modo uniforme tra tutti i LUN del volume con striping. Ciò significa che la dimensione dello stripe non deve essere inferiore alla dimensione del blocco del database e che la dimensione dello stripe moltiplicata per il numero di LUN deve essere 1MB.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">La figura seguente mostra tre possibili opzioni per la regolazione delle dimensioni dello stripe e della larghezza. Il numero di LUN viene selezionato per soddisfare i requisiti di prestazioni come descritto sopra, ma in tutti i casi i dati totali all'interno di uno stripe singolo sono 1MB.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">Configurazione di ONTAP</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">qui.</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Tiering</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">Database PostgreSQL su ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Data Protection nativa</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">Uno degli aspetti principali della progettazione dello storage è la protezione dei volumi PostgreSQL. I clienti possono proteggere i database PostgreSQL utilizzando l'approccio dump o i backup del file system. In questa sezione vengono illustrati i diversi approcci per il backup di singoli database o dell'intero cluster.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Sono disponibili tre approcci per il backup dei dati PostgreSQL:</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">Dump di SQL Server</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Backup a livello di file system</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Archiviazione continua</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">L'idea alla base del metodo dump di SQL Server è generare un file con comandi di SQL Server che, quando viene restituito al server, può ricreare il database così come era al momento del dump. PostgreSQL fornisce i programmi di utilità<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> e.<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> per la creazione di backup singolo e a livello di cluster. Questi dump sono logici e non contengono informazioni sufficienti per essere utilizzati da WAL Replay.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Una strategia di backup alternativa consiste nell'utilizzare il backup a livello di file system, in cui gli amministratori copiano direttamente i file utilizzati da PostgreSQL per memorizzare i dati nel database. Questo metodo viene eseguito in modalità non in linea: Il database o il cluster devono essere chiusi. Un'altra alternativa è quella di utilizzare<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Per eseguire il backup hot streaming del database PostgreSQL.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">Database PostgreSQL su ONTAP</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Questa documentazione su ONTAP e il database PostgreSQL sostituisce il database _TR-4770: PostgreSQL precedentemente pubblicato sulle Best practice di ONTAP._</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshot</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">I backup basati su snapshot con PostgreSQL richiedono la configurazione di snapshot per file di dati, file WAL e file WAL archiviati per garantire un ripristino completo o point-in-time.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Per i database PostgreSQL, il tempo medio di backup con gli snapshot è compreso tra pochi secondi e pochi minuti. Questa velocità di backup è da 60 a 100 volte più veloce di<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> e altri approcci di backup basati sul file system.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Le snapshot sullo storage NetApp possono essere coerenti con il crash e con l'applicazione. Viene creato uno snapshot coerente con i crash sullo storage senza chiudere il database, mentre uno snapshot coerente con l'applicazione viene creato mentre il database è in modalità backup. NetApp garantisce inoltre che le snapshot successive siano backup incrementali perenni, per promuovere il risparmio dello storage e l'efficienza della rete.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Poiché le snapshot sono rapide e non influiscono sulle prestazioni del sistema, è possibile pianificare snapshot multiple ogni giorno invece di creare un unico backup giornaliero come avviene con l'altra tecnologia di backup in streaming. Quando è necessaria un'operazione di ripristino e ripristino, il downtime del sistema viene ridotto da due caratteristiche principali:</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">La tecnologia di recovery di dati NetApp SnapRestore consente di eseguire l'operazione di ripristino in pochi secondi.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Obiettivi di recovery point (RPO) aggressivi richiedono l'applicazione di un numero inferiore di log dei database e un'accelerazione del recovery in avanti.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Per eseguire il backup di PostgreSQL, è necessario assicurarsi che i volumi di dati siano protetti contemporaneamente con WAL (gruppo di coerenza) e i registri archiviati. Mentre si utilizza la tecnologia Snapshot per copiare i file WAL, assicurarsi di eseguire<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Per svuotare tutte le voci WAL che devono essere archiviate. Se si svuotano le voci WAL durante il ripristino, sarà sufficiente arrestare il database, smontare o eliminare la directory dei dati esistente ed eseguire un'operazione SnapRestore sull'archiviazione. Al termine del ripristino, è possibile montare il sistema e riportarlo allo stato corrente. Per il ripristino point-in-time, è anche possibile ripristinare i registri WAL e di archivio; quindi PostgreSQL decide il punto più coerente e lo recupera automaticamente.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">I gruppi di coerenza sono una funzionalità di ONTAP e sono consigliati quando ci sono più volumi montati su una singola istanza o su un database con tablespace multiple. Uno snapshot del gruppo di coerenza garantisce che tutti i volumi siano raggruppati e protetti. È possibile gestire in modo efficiente un gruppo di coerenza da ONTAP System Manager, clonandolo per creare una copia dell'istanza di un database a scopo di test o sviluppo.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Protezione dei dati</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Tablespace</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Due tablespace vengono create automaticamente al momento dell'inizializzazione del cluster di database.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">Il<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> tablespace viene utilizzato per i cataloghi di sistema condivisi. Il<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> tablespace è la tablespace predefinita dei database template1 e template0. Se la partizione o il volume su cui il cluster è stato inizializzato esaurisce lo spazio e non può essere esteso, è possibile creare uno spazio di tabella in un'altra partizione ed utilizzarlo fino a quando il sistema non può essere riconfigurato.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Un indice molto utilizzato può essere collocato su un disco veloce e altamente disponibile, come un dispositivo a stato solido. Inoltre, una tabella che memorizza i dati archiviati utilizzati raramente o non critici per le prestazioni può essere archiviata su un sistema su disco meno costoso e più lento, come le unità SAS o SATA.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Gli spazi di tabella fanno parte del cluster di database e non possono essere trattati come una raccolta autonoma di file di dati. Dipendono dai metadati contenuti nella directory dei dati principale e pertanto non possono essere collegati a un cluster di database diverso o sottoposti a backup individuale. Analogamente, se si perde uno spazio di tabella (a causa dell'eliminazione dei file, del guasto del disco e così via), il cluster del database potrebbe diventare illeggibile o non avviarsi. Posizionando una tablespace su un file system temporaneo come un disco RAM si rischia l'affidabilità dell'intero cluster.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Una volta creato, è possibile utilizzare un tablespace da qualsiasi database se l'utente richiedente dispone di privilegi sufficienti. PostgreSQL utilizza collegamenti simbolici per semplificare l'implementazione di tablespace. PostgreSQL aggiunge una riga al<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tabella (una tavola a livello di cluster) e assegna un nuovo identificatore di oggetto (OID) a quella riga. Infine, il server utilizza l'OID per creare un collegamento simbolico tra il cluster e la directory specificata. La directory<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> contiene collegamenti simbolici che puntano a ciascuno degli spazi di tabella non incorporati definiti nel cluster.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Configurazione del database</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Esistono diverse configurazioni di ottimizzazione PostgreSQL che possono migliorare le prestazioni.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">I parametri più comunemente utilizzati sono i seguenti:</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: Il numero massimo di connessioni al database da avere contemporaneamente. Utilizzare questo parametro per limitare lo scambio sul disco e l'interruzione delle prestazioni. A seconda delle esigenze dell'applicazione, è anche possibile regolare questo parametro per le impostazioni del pool di connessione.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: Il metodo più semplice per migliorare le prestazioni del server di database. Il valore predefinito è basso per la maggior parte dei componenti hardware moderni. Durante l'implementazione viene impostato su circa il 25% della RAM disponibile sul sistema. Questa impostazione di parametro varia in base al funzionamento con determinate istanze di database; potrebbe essere necessario aumentare e diminuire i valori per prova ed errore. Tuttavia, l'impostazione di un livello elevato potrebbe degradare le prestazioni.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Questo valore indica all'ottimizzatore di PostgreSQL la quantità di memoria disponibile per la memorizzazione nella cache dei dati e aiuta a determinare se utilizzare un indice. Un valore maggiore aumenta la probabilità di utilizzare un indice. Questo parametro deve essere impostato sulla quantità di memoria allocata a.<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> più la quantità di cache del sistema operativo disponibile. Spesso questo valore corrisponde a più del 50% della memoria di sistema totale.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Questo parametro controlla la quantità di memoria da utilizzare nelle operazioni di ordinamento e nelle tabelle hash. Se si esegue un ordinamento pesante nell'applicazione, potrebbe essere necessario aumentare la quantità di memoria, ma prestare attenzione. Non si tratta di un parametro a livello di sistema, ma di un parametro per operazione. Se una query complessa contiene diverse operazioni di ordinamento, utilizza più unità di memoria work_mem e più backend potrebbero farlo contemporaneamente. Questa query può spesso indurre il server di database a effettuare lo swap se il valore è troppo grande. Questa opzione era precedentemente chiamata sort_mem nelle versioni precedenti di PostgreSQL.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Questo parametro determina se tutte le pagine WAL devono essere sincronizzate su disco utilizzando fsync() prima che venga eseguito il commit di una transazione. Disattivandolo a volte si possono migliorare le prestazioni di scrittura e attivandolo si aumenta la protezione dal rischio di danneggiamento quando il sistema si blocca.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: Il processo del punto di verifica elimina i dati sottoposti a commit sul disco. Ciò comporta numerose operazioni di lettura/scrittura su disco. Il valore è impostato in secondi e valori inferiori riducono il tempo di recupero da crash e valori crescenti possono ridurre il carico sulle risorse di sistema riducendo le chiamate al punto di verifica. In base alla criticità dell'applicazione, all'utilizzo, alla disponibilità del database, impostare il valore di checkpoint_timeout.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> e.<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Queste opzioni vengono utilizzate insieme per migliorare le prestazioni scrivendo più transazioni che vengono effettuate contemporaneamente. Se ci sono diversi oggetti commit_siblings attivi nel momento in cui la transazione è in fase di commit, il server attende Commit_delay microsecondi per tentare di eseguire più transazioni contemporaneamente.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Configurare il numero ottimale di lavoratori per i processi. Max_Parallel_Workers corrisponde al numero di CPU disponibili. A seconda della progettazione dell'applicazione, le query potrebbero richiedere un numero minore di lavoratori per le operazioni parallele. È meglio mantenere lo stesso valore per entrambi i parametri, ma regolare il valore dopo la verifica.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Questo valore controlla il modo in cui PostgreSQL visualizza le letture del disco non sequenziali. Un valore più elevato indica che PostgreSQL è più probabile che utilizzi una scansione sequenziale invece di una scansione di indice, indicando che il server dispone di dischi veloci modificare questa impostazione dopo aver valutato altre opzioni come l'ottimizzazione basata su piano, l'aspirazione, l'indicizzazione per modificare query o schemi.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Questo parametro imposta il numero di operazioni di i/o su disco simultanee che PostgreSQL tenta di eseguire contemporaneamente. L'aumento di questo valore aumenta il numero di operazioni di i/o che una singola sessione PostgreSQL tenta di avviare in parallelo. L'intervallo consentito è compreso tra 1 e 1.000 o zero per disattivare l'emissione di richieste i/o asincrone. Attualmente, questa impostazione influisce solo sulle scansioni bitmap heap. I dischi a stato solido (SSD) e altro storage basato su memoria (NVMe) possono spesso elaborare molte richieste simultanee, cosicché il valore migliore può essere centinaia.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Consultare la documentazione di PostgreSQL per un elenco completo dei parametri di configurazione di PostgreSQL.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">TOAST</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST è l'acronimo di OVERSIZED-Attribute Storage Technique. PostgreSQL utilizza una dimensione di pagina fissa (in genere 8KB) e non consente alle tuple di occupare più pagine. Pertanto, non è possibile memorizzare direttamente valori di campo grandi. Quando si tenta di memorizzare una riga che supera queste dimensioni, TOAST suddivide i dati delle colonne di grandi dimensioni in "pezzi" più piccoli e li memorizza in una tabella TOAST.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">I valori elevati degli attributi tostati vengono estratti (se selezionati) solo quando il set di risultati viene inviato al client. La tabella stessa è molto più piccola e può contenere più righe nella cache buffer condivisa di quanto non possa fare senza alcuna archiviazione out-of-line (TOAST).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VUOTO</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">Nelle normali operazioni PostgreSQL, le tuple eliminate o rese obsolete da un aggiornamento non vengono fisicamente rimosse dalla tabella; rimangono presenti fino all'esecuzione di VACUUM. Pertanto, è necessario eseguire il VUOTO periodicamente, soprattutto nelle tabelle aggiornate di frequente. Lo spazio occupato deve quindi essere recuperato per essere riutilizzato da nuove righe, per evitare di esaurire lo spazio su disco. Tuttavia, non restituisce lo spazio al sistema operativo.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">Lo spazio libero all'interno di una pagina non è frammentato. L'ASPIRAPOLVERE riscrive l'intero blocco, comprimendo in modo efficiente le righe rimanenti e lasciando un singolo blocco contiguo di spazio libero in una pagina.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">Al contrario, VACUUM FULL comprime attivamente le tabelle scrivendo una versione completamente nuova del file di tabella senza spazio morto. Questa azione riduce al minimo le dimensioni della tabella, ma può richiedere molto tempo. Richiede inoltre ulteriore spazio su disco per la nuova copia della tabella fino al completamento dell'operazione. L'obiettivo del VUOTO DI routine è di evitare l'attività di VUOTO PIENO. Questo processo non solo mantiene le tabelle alla loro dimensione minima, ma mantiene anche l'utilizzo costante dello spazio su disco.</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Inizializzazione</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">È possibile creare un nuovo cluster di database utilizzando<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> programma. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script crea i file di dati, le tabelle di sistema e i database dei modelli (template0 e template1) che definiscono il cluster.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">Il database dei modelli rappresenta un database di stock. Contiene le definizioni per le tabelle di sistema, le viste standard, le funzioni e i tipi di dati.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> funge da argomento per il<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script che specifica la posizione del cluster di database.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Tutti gli oggetti di database in PostgreSQL sono gestiti internamente dai rispettivi OID. Le tabelle e gli indici sono inoltre gestiti da singoli OID. Le relazioni tra gli oggetti del database e i rispettivi OID vengono memorizzate in tabelle di cataloghi di sistema appropriate, a seconda del tipo di oggetto. Ad esempio, gli OID dei database e delle tabelle heap vengono memorizzati in<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> e `pg_class, rispettivamente. È possibile determinare gli OID eseguendo query sul client PostgreSQL.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Ogni database ha le proprie tabelle e i file di indice che sono limitati a 1GB. Ogni tabella ha due file associati, rispettivamente con il suffisso<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> e.<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Sono indicate come mappa dello spazio libero e mappa di visibilità. Questi file memorizzano le informazioni sulla capacità di spazio libero e hanno visibilità su ogni pagina del file di tabella. Gli indici hanno solo mappe di spazio libero individuali e non hanno mappe di visibilità.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">Il<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> la directory contiene i registri write-ahead. I registri write-ahead sono utilizzati per migliorare l'affidabilità e le performance del database. Ogni volta che si aggiorna una riga in una tabella, PostgreSQL scrive prima la modifica nel registro write-ahead e successivamente scrive le modifiche alle pagine di dati effettive su un disco. Il<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> la directory di solito contiene diversi file, ma initdb crea solo il primo. I file aggiuntivi vengono aggiunti in base alle necessità. Ciascun file xlog è lungo 16MB MB.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp consiglia* di utilizzare NFSv4,1 se sono necessarie funzionalità NFSv4. Sono stati apportati alcuni miglioramenti funzionali al protocollo NFSv4 di NFSv4,1 che migliorano la resilienza in alcuni casi edge.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">Dimensioni trasferimento NFS</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">SAN FC</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">Architettura PostgreSQL</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL è un RDBMS basato su architettura client e server. Un'istanza di PostgreSQL è nota come cluster di database, ovvero una raccolta di database anziché una raccolta di server.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Errore: Immagine non trovata</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">Un database PostgreSQL contiene tre elementi principali: Il postmaster, il front-end (client) e il back-end Il client invia richieste al postmaster con informazioni quali il protocollo IP e il database a cui connettersi. Il postmaster autentica la connessione e la passa al processo back-end per ulteriori comunicazioni. Il processo back-end esegue la query e invia i risultati direttamente al front-end (client).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Un'istanza PostgreSQL si basa su un modello multiprocesso anziché su un modello multithread. Genera più processi per diversi processi e ogni processo ha una propria funzionalità. I processi principali includono il processo client, il processo di scrittura WAL, il processo di scrittura in background e il processo di checkpointer:</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Quando un processo client (in primo piano) invia richieste di lettura o scrittura all'istanza PostgreSQL, non legge o scrive dati direttamente sul disco. Innanzitutto, memorizza i dati nei buffer condivisi e nei buffer WAL (Write-ahead logging).</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Un processo di scrittura WAL manipola il contenuto dei buffer condivisi e dei buffer WAL da scrivere nei registri WAL. I registri WAL sono in genere registri di transazioni di PostgreSQL e vengono scritti in sequenza. Pertanto, per migliorare i tempi di risposta dal database, PostgreSQL scrive prima nei registri delle transazioni e riconosce il client.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Per impostare il database in uno stato coerente, il processo di scrittura in background verifica periodicamente la presenza di pagine sporche nel buffer condiviso. Quindi, scarica i dati sui file di dati che sono memorizzati su volumi NetApp o LUN.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">Anche il processo checkpointer viene eseguito periodicamente (meno frequentemente del processo in background) e impedisce qualsiasi modifica ai buffer. Segnala al processo di scrittura WAL di scrivere e svuotare il record del punto di verifica alla fine dei registri WAL memorizzati sul disco NetApp. Segnala inoltre al processo di scrittura in background di scrivere e scaricare tutte le pagine sporche sul disco.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Software per la data Protection</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Il plug-in NetApp SnapCenter per i database PostgreSQL, combinato con le tecnologie Snapshot e NetApp FlexClone, offre diversi vantaggi, tra cui:</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Backup e ripristino rapidi.</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Cloni efficienti in termini di spazio.</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">La capacità di creare un sistema di disaster recovery rapido ed efficace.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Potresti preferire scegliere i partner di backup premium di NetApp come Veeam Software e CommVault nelle seguenti circostanze:</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Gestire i carichi di lavoro in un ambiente eterogeneo</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Memorizzazione dei backup su cloud o nastro per una conservazione a lungo termine</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Supporto per un'ampia gamma di versioni e tipi di sistema operativo</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">Il plug-in SnapCenter per PostgreSQL è un plugin supportato dalla comunità e la configurazione e la documentazione sono disponibili nell'archivio automazione di NetApp. Tramite SnapCenter, l'utente può eseguire il backup di database, clonare e ripristinare i dati in remoto.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Soluzioni per SAP HANA e AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA e SAP con AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Le Best practice per la configurazione, la gestione e l'automazione delle soluzioni SAP sono disponibili nella pagina soluzioni SAP di NetApp.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">qui</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Fare clic <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> per saperne di più.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server su ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Disaster recovery per Microsoft SQL Server</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Distribuire volumi che contengono dati SQL Server tra diversi nodi nel cluster per consentire a tutti i nodi del cluster di condividere l'attività di replica di SnapMirror. Questa distribuzione ottimizza l'utilizzo delle risorse dei nodi.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">TR-4015: Guida alle Best practice e alla configurazione di SnapMirror per ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Per ulteriori informazioni su SnapMirror, vedere <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">Configurazione CPU</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">Hyperthreading</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">Si noti che ogni versione di SQL Server presenta dei limiti specifici sulla potenza di calcolo che può utilizzare. Per ulteriori informazioni, vedere limiti di capacità di calcolo per edizione di SQL Server.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022: La tua moderna piattaforma per i dati</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Pertanto, per utilizzare tutte le CPU, è necessario utilizzare la licenza core per processore. Per informazioni dettagliate sulle licenze di SQL Server, vedere <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">Affinità della CPU</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server supporta l'affinità del processore mediante due opzioni:</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">Maschera di affinità della CPU</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Maschera i/o di affinità</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Massimo grado di parallelismo (MAXDOP)</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Numero massimo di thread di lavoro</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">L'opzione numero massimo di thread di lavoro consente di ottimizzare le prestazioni quando un numero elevato di client è connesso a SQL Server.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">Il valore predefinito è 0, che consente a SQL Server di configurare automaticamente il numero di thread di lavoro all'avvio. Funziona per la maggior parte dei sistemi. Max worker Threads è un'opzione avanzata e non deve essere alterata senza l'assistenza di un amministratore di database esperto (DBA).</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">Configurare l'opzione di configurazione del server numero massimo di thread di lavoro</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">Quando è necessario configurare SQL Server per utilizzare più thread di lavoro? Se la lunghezza media della coda di lavoro per ogni pianificatore è superiore a 1, si potrebbe trarre vantaggio dall'aggiunta di più thread al sistema, ma solo se il carico non è legato alla CPU o se si verificano altre attese pesanti. Se si verifica uno di questi due eventi, l'aggiunta di altri thread non aiuta perché sono in attesa di altri colli di bottiglia del sistema. Per ulteriori informazioni sui thread di lavoro max, vedere <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Configurazione di max worker threads con SQL Server Management Studio.</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Per &lt; o = a 8 core: File di dati tempdb = numero di core</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Per più di 8 core: 8 file di dati tempdb</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">A partire da SQL Server 2016, il numero di core di CPU visibili al sistema operativo viene rilevato automaticamente durante l'installazione e, in base a tale numero, SQL Server calcola e configura il numero di file tempdb necessari per ottenere prestazioni ottimali.</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter come software di backup, che include:</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Plug-in SnapCenter per Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">Plug-in di SnapCenter per SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Architettura e amministrazione di Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">Tool di matrice di interoperabilità NetApp (IMT)</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Considerazioni sullo storage per Microsoft SQL Server</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Progettazione dello storage dei dati</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Per i database SQL Server che non utilizzano SnapCenter per eseguire i backup, Microsoft consiglia di posizionare i file di dati e di log su dischi separati. Per le applicazioni che aggiornano e richiedono contemporaneamente i dati, il file di log è intensivo in scrittura e il file di dati (a seconda dell'applicazione) è intensivo in lettura/scrittura. Per il recupero dei dati, il file di log non è necessario. Pertanto, le richieste di dati possono essere soddisfatte dal file di dati posto sul proprio disco.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Posizionare i file di dati e di registro su unità separate</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Quando si crea un nuovo database, Microsoft consiglia di specificare unità separate per i dati e i registri. Per spostare i file dopo la creazione del database, il database deve essere portato offline. Per ulteriori consigli Microsoft, vedere <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">Aggregati</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Un grande aggregato consente l'utilizzo più efficiente dello spazio su disco.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Per l'high Availability (ha), posiziona la replica sincrona secondaria di SQL Server Always on Availability Group su una Storage Virtual Machine (SVM) separata nell'aggregato. Per scopi di disaster recovery, posizionare la replica asincrona in un aggregato che fa parte di un cluster di storage separato nel sito di disaster recovery, con contenuto replicato utilizzando la tecnologia NetApp SnapMirror. NetApp consiglia di disporre di almeno il 10% di spazio libero in un aggregato per ottenere performance dello storage ottimali.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volumi</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Considerazioni sulla progettazione dei volumi</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Prima di creare una progettazione di volumi di database, è importante comprendere in che modo il modello i/o di SQL Server e le relative caratteristiche variano in base al carico di lavoro e ai requisiti di backup e ripristino. Consulta i seguenti consigli NetApp per i volumi flessibili:</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Utilizzare i punti di montaggio NTFS invece delle lettere dell'unità per superare il limite di 26 lettere di unità in Windows. Quando si utilizzano punti di montaggio del volume, si consiglia di assegnare all'etichetta del volume lo stesso nome del punto di montaggio.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb è un database di sistema utilizzato da SQL Server come area di lavoro temporanea, in particolare per operazioni DBCC CHECKDB i/o intensive. Pertanto, collocare questo database su un volume dedicato con un set separato di spindle. In ambienti di grandi dimensioni in cui il numero di volumi rappresenta una sfida, è possibile consolidare il tempdb in un numero inferiore di volumi e memorizzarlo nello stesso volume degli altri database di sistema dopo un'attenta pianificazione. La protezione dei dati per tempdb non è una priorità elevata perché questo database viene ricreato ogni volta che SQL Server viene riavviato.</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Assicurarsi che i file del database utente e la directory di registro per l'archiviazione del backup del registro si trovino su volumi separati per evitare che il criterio di conservazione sovrascriva gli snapshot quando vengono utilizzati con la tecnologia SnapVault.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Se si creano LUN con DiskManager o altri strumenti, assicurarsi che la dimensione dell'unità di allocazione sia impostata su 64K per le partizioni durante la formattazione dei LUN.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows e MPIO nativo nelle Best practice ONTAP per le SAN moderne</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Vedere <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Per applicare il supporto multipathing in Windows ai dispositivi iSCSI nelle proprietà MPIO.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Directory di log</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">Le dimensioni della directory del registro host vengono calcolate come segue:
Dimensione della directory del log host = ( (dimensione massima LDF DB x velocità di modifica giornaliera del log %) x (conservazione snapshot) ÷ (1 - spazio di overhead LUN %)
La formula di dimensionamento della directory del registro host presuppone uno spazio di overhead LUN del 10%</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Posizionare la directory di registro su un volume o LUN dedicato. La quantità di dati nella directory del registro host dipende dalle dimensioni dei backup e dal numero di giorni in cui i backup vengono conservati. SnapCenter consente una sola directory di registro host per host SQL Server. È possibile configurare le directory del registro host in SnapCenter --&gt; host --&gt; Configura plug-in.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp consiglia* quanto segue per una directory del registro host:</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Assicurarsi che la directory del registro host non sia condivisa da altri tipi di dati che potrebbero danneggiare i dati dello snapshot di backup.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">Non posizionare database utente o database di sistema su un LUN che ospita punti di montaggio.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Utilizzare le procedure guidate SnapCenter per migrare i database nello storage NetApp in modo che i database vengano memorizzati in posizioni valide, consentendo operazioni di backup e ripristino SnapCenter corrette. Tenere presente che il processo di migrazione causa interruzioni e può causare la disconnessione dei database mentre è in corso la migrazione.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Per le istanze di cluster di failover (FCI) di SQL Server devono essere presenti le seguenti condizioni:</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Se si utilizza un'istanza del cluster di failover, il LUN della directory del log host deve essere una risorsa del disco del cluster nello stesso gruppo di cluster dell'istanza di SQL Server di cui viene eseguito il backup in SnapCenter.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Se si utilizza un'istanza cluster di failover, i database utente devono essere collocati su LUN condivisi che sono risorse cluster di dischi fisici assegnate al gruppo di cluster associato all'istanza di SQL Server.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Configurazione della memoria di Microsoft SQL Server</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Memoria massima del server</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">In un cluster SQL Server con diverse istanze SQL Server, ciascuna istanza potrebbe competere per le risorse. L'impostazione di un limite di memoria per ciascuna istanza di SQL Server può contribuire a garantire le migliori prestazioni per ciascuna istanza.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp consiglia* di lasciare almeno 4GB o 6GB GB di RAM per il sistema operativo per evitare problemi di prestazioni.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Regolazione della memoria minima e massima del server mediante SQL Server Management Studio.</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Accesso alla memoria non uniforme</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Indice creare memoria</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Controlla la quantità massima di RAM inizialmente allocata per la creazione degli indici. Il valore predefinito per questa opzione è 0, il che significa che è gestita automaticamente da SQL Server. Tuttavia, se si riscontrano difficoltà nella creazione degli indici, è consigliabile aumentare il valore di questa opzione.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Memoria minima per query</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Implementazione della compressione pagina</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">La compressione riga modifica il formato di memorizzazione dei dati. Ad esempio, cambia interi e decimali nel formato a lunghezza variabile invece del formato a lunghezza fissa nativo. Inoltre, le stringhe di caratteri a lunghezza fissa vengono modificate nel formato a lunghezza variabile eliminando gli spazi vuoti. La compressione della pagina implementa la compressione della riga e altre due strategie di compressione (compressione del prefisso e compressione del dizionario). Per ulteriori dettagli sulla compressione delle pagine, consultare <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">La compressione dei dati è attualmente supportata nelle edizioni Enterprise, Developer e Evaluation di SQL Server 2008 e versioni successive. Sebbene la compressione possa essere eseguita dal database stesso, ciò si verifica raramente in un ambiente SQL Server.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Di seguito sono riportati i suggerimenti per la gestione dello spazio per i file di dati di SQL Server</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Utilizzo del thin provisioning negli ambienti SQL Server per migliorare l'utilizzo dello spazio e ridurre i requisiti generali di storage quando viene utilizzata la funzionalità di garanzia di spazio.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Utilizza l'espansione automatica per la maggior parte delle configurazioni di implementazione più comuni, perché l'amministratore dello storage deve solo monitorare l'utilizzo dello spazio nell'aggregato.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Bonifica dello spazio</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">Il recupero di spazio può essere avviato periodicamente per recuperare spazio inutilizzato in un LUN. Con SnapCenter, puoi usare il seguente comando PowerShell per iniziare il recupero dello spazio.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Se è necessario eseguire il recupero di spazio, questo processo deve essere eseguito durante i periodi di attività bassa, poiché inizialmente consuma cicli sull'host.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">TR-4714: Guida alle Best practice per SQL Server con NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Per ulteriori informazioni sul plug-in di SQL Server per SnapCenter, vedere <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Protezione del database mediante snapshot T-SQL</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">Di seguito è riportato un esempio di flusso di lavoro di backup:</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Eseguire snapshot di più database sui volumi di storage contemporaneamente con il nuovo GRUPPO DI BACKUP e i comandi DEL SERVER DI BACKUP.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Eseguire backup COMPLETI o backup COMPLETI COPY_ONLY. Anche questi backup sono registrati in msdb.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Eseguire il recovery point-in-time utilizzando i backup di log eseguiti con il normale approccio di streaming dopo il backup COMPLETO delle snapshot. Se lo si desidera, sono supportati anche i backup differenziali in streaming.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Documentazione Microsoft per conoscere le istantanee T-SQL</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Per ulteriori informazioni, vedere <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Workload di Microsoft SQL Server</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">File di database e filegroup di Microsoft SQL Server</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">In teoria, SQL Server (a 64 bit) supporta 32.767 database per istanza e 524.272TB di dimensioni del database, sebbene l'installazione tipica abbia in genere diversi database. Tuttavia, il numero di database che SQL Server è in grado di gestire dipende dal carico e dall'hardware. Non è insolito vedere le istanze di SQL Server che ospitano decine, centinaia o persino migliaia di database di piccole dimensioni.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Ogni database è costituito da uno o più file di dati e da uno o più file di registro delle transazioni. Il registro delle transazioni memorizza le informazioni sulle transazioni del database e tutte le modifiche apportate ai dati da ciascuna sessione. Ogni volta che i dati vengono modificati, SQL Server memorizza informazioni sufficienti nel log delle transazioni per annullare (eseguire il rollback) o ripristinare (riprodurre nuovamente) l'azione. Un log delle transazioni di SQL Server è parte integrante della reputazione di SQL Server in termini di integrità e robustezza dei dati. Il log delle transazioni è fondamentale per le funzionalità di atomicità, coerenza, isolamento e durata (ACID) di SQL Server. SQL Server scrive nel registro delle transazioni non appena si verifica una modifica alla pagina dei dati. Ogni istruzione DML (Data Manipulation Language) (ad esempio, SELECT, INSERT, Update o DELETE) è una transazione completa e il log delle transazioni garantisce che l'intera operazione basata su set abbia luogo, assicurando l'atomicità della transazione.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Ogni database dispone di un file di dati primario che, per impostazione predefinita, ha l'estensione .mdf. Inoltre, ogni database può disporre di file di database secondari. Questi file, per impostazione predefinita, hanno estensioni .ndf.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Tutti i file di database sono raggruppati in filegroup. Un filegroup è l'unità logica, che semplifica l'amministrazione del database. Consentono la separazione tra il posizionamento degli oggetti logici e i file di database fisici. Quando si creano le tabelle degli oggetti del database, si specifica in quale filegroup devono essere posizionati senza preoccuparsi della configurazione del file di dati sottostante.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp recommended* evitare l'utilizzo del filegroup primario per oggetti diversi da quelli di sistema. La creazione di un filegroup separato o di un set di filegroup per gli oggetti utente semplifica l'amministrazione del database e il ripristino di emergenza, soprattutto nel caso di database di grandi dimensioni.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">È possibile specificare le dimensioni iniziali del file e i parametri di crescita automatica al momento della creazione del database o dell'aggiunta di nuovi file a un database esistente. SQL Server utilizza un algoritmo di riempimento proporzionale quando sceglie in quale file di dati scrivere i dati. Scrive una quantità di dati proporzionalmente allo spazio libero disponibile nei file. Maggiore è lo spazio libero nel file, maggiore è il numero di scritture gestite.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp consiglia* che tutti i file nel singolo filegroup abbiano le stesse dimensioni iniziali e parametri di crescita automatica, con la dimensione di crescita definita in megabyte piuttosto che in percentuali. Questo aiuta l'algoritmo di riempimento proporzionale a bilanciare uniformemente le attività di scrittura nei file di dati.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server azzera sempre il log delle transazioni e questo comportamento non può essere modificato. Tuttavia, è possibile controllare se i file di dati vengono azzerati attivando o disattivando l'inizializzazione istantanea dei file. L'attivazione dell'inizializzazione immediata dei file consente di velocizzare la crescita dei file di dati e di ridurre il tempo necessario per creare o ripristinare il database.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Un piccolo rischio per la sicurezza è associato all'inizializzazione immediata dei file. Quando questa opzione è attivata, le parti non allocate del file di dati possono contenere informazioni provenienti da file del sistema operativo eliminati in precedenza. Gli amministratori di database possono esaminare tali dati.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">È possibile attivare l'inizializzazione immediata dei file aggiungendo l'autorizzazione SA_MANAGE_VOLUME_NAME, nota anche come "Esegui attività di manutenzione del volume" all'account di avvio di SQL Server. È possibile eseguire questa operazione nell'applicazione di gestione dei criteri di protezione locale (secpol.msc), come illustrato nella figura seguente. Aprire le proprietà per l'autorizzazione "Esegui attività di manutenzione del volume" e aggiungere l'account di avvio di SQL Server all'elenco degli utenti.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Per verificare se l'autorizzazione è attivata, è possibile utilizzare il codice riportato nell'esempio seguente. Questo codice imposta due flag di traccia che obbligano SQL Server a scrivere informazioni aggiuntive nel registro degli errori, a creare un database di piccole dimensioni e a leggere il contenuto del registro.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Quando l'inizializzazione immediata del file non è attivata, il registro degli errori di SQL Server mostra che SQL Server sta azzerando il file di dati mdf oltre a azzerare il file di registro ldf, come illustrato nell'esempio seguente. Quando l'inizializzazione immediata del file è attivata, viene visualizzato solo l'azzeramento del file di registro.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Istanza condivisa Microsoft SQL Server rispetto a istanza dedicata</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">La risoluzione dei problemi di prestazioni può essere complicata, perché è necessario capire quale istanza è la causa principale. Questa domanda è valutata rispetto ai costi delle licenze del sistema operativo e delle licenze di SQL Server. Se le performance applicative sono fondamentali, si consiglia vivamente un'istanza dedicata.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft concede in licenza SQL Server per core a livello di server e non per istanza. Per questo motivo, gli amministratori di database sono tentati di installare tutte le istanze di SQL Server che il server è in grado di gestire per risparmiare sui costi di licenza, il che può portare a gravi problemi di performance in un secondo momento.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp consiglia* di scegliere istanze dedicate di SQL Server quando possibile per ottenere prestazioni ottimali.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP e applicazioni aziendali</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Argomenti di configurazione specifici di Solaris.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Opzioni di montaggio NFS Solaris</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio di Solaris NFS per una singola istanza.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Tipo di file</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Opzioni di montaggio</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">Pagina iniziale ADR</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">L'utilizzo di<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> è stato dimostrato di migliorare drasticamente le performance negli ambienti dei clienti rimuovendo la latenza associata all'acquisizione e al rilascio di blocchi sul sistema storage. Utilizzare questa opzione con attenzione negli ambienti in cui sono configurati numerosi server per montare gli stessi file system e Oracle è configurato per montare questi database. Sebbene si tratti di una configurazione molto insolita, viene utilizzata da un numero limitato di clienti. Se un'istanza viene avviata accidentalmente una seconda volta, i dati potrebbero danneggiarsi perché Oracle non è in grado di rilevare i file di blocco sul server esterno. I blocchi NFS non offrono altrimenti protezione; come nella versione 3 di NFS, sono solo di natura consultiva.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Perché il<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> i parametri si escludono a vicenda, è importante che<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> è presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file in modo che<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> viene utilizzato. Senza questo parametro, viene utilizzato il caching del buffer del sistema operativo host e le prestazioni possono essere compromesse.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio Solaris NFS RAC.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/votazione</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Dedicato<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">Il motivo<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password Oracle e file spfile. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è richiesto.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Opzioni di montaggio UFS di Solaris</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp consiglia vivamente di utilizzare l'opzione di montaggio della registrazione in modo che l'integrità dei dati venga preservata in caso di arresto anomalo dell'host Solaris o di interruzione della connettività FC. L'opzione di montaggio della registrazione preserva anche l'usabilità dei backup Snapshot.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">Solaris ZFS</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS deve essere installato e configurato con attenzione per garantire prestazioni ottimali.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">Se da questa modifica emergono problemi imprevisti, è possibile annullarli facilmente eseguendo il seguente comando come root:</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Kernel</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">Prestazioni ZFS affidabili richiedono un kernel Solaris con patch contro i problemi di allineamento LUN. La correzione è stata introdotta con la patch 147440-19 in Solaris 10 e con SRU 10,5 per Solaris 11. Utilizzare solo Solaris 10 e versioni successive con ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">Configurazione del LUN</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Per configurare un LUN, attenersi alla seguente procedura:</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Creare un LUN di tipo<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Installare l'host Utility Kit (HUK) appropriato specificato da <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">documentazione più recente</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Seguire esattamente le istruzioni nell'HUK come descritto. I passaggi di base sono descritti di seguito, ma fare riferimento a. <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> per la procedura corretta.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Eseguire<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> utilità per aggiornare<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> file. Questo consente alle unità SCSI di rilevare correttamente i LUN ONTAP.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Seguire le istruzioni fornite da<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Utility per abilitare l'input/output multipath (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Reboot (Riavvia). Questa fase è necessaria per consentire il riconoscimento di eventuali modifiche nel sistema.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Partizionare i LUN e verificare che siano allineati correttamente. Vedere "Appendice B: Verifica dell'allineamento WAFL" per istruzioni su come eseguire direttamente il test e confermare l'allineamento.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpool</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">Configurazione LUN</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">Il valore di<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> il valore predefinito è 9, ovvero 2^9 o 512 byte. Per prestazioni ottimali, la<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Il valore deve essere 12 (2^12=4K). Questo valore viene impostato al momento della creazione di zpool e non può essere modificato, il che significa che i dati in zpool con<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> oltre a 12 deve essere eseguita la migrazione copiando i dati in uno zpool appena creato.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Dopo aver creato uno zpool, verificare il valore di<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> prima di procedere. Se il valore non è 12, i LUN non sono stati rilevati correttamente. Distruggere lo zpool, verificare che tutti i passaggi indicati nella relativa documentazione delle utilità host siano stati eseguiti correttamente e ricreare lo zpool.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpool e LDOM Solaris</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Gli LDOM di Solaris creano un requisito aggiuntivo per assicurarsi che l'allineamento i/o sia corretto. Sebbene un LUN possa essere rilevato correttamente come un dispositivo 4K, un dispositivo vdsk virtuale su un LDOM non eredita la configurazione dal dominio i/O. Vdsk basato su tale LUN torna per impostazione predefinita a un blocco da 512 byte.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">È necessario un file di configurazione aggiuntivo. In primo luogo, i singoli LDOM devono essere aggiornati per Oracle bug 15824910 per abilitare le opzioni di configurazione aggiuntive. Questa patch è stata trasferita in tutte le versioni attualmente utilizzate di Solaris. Una volta installato il software LDOM, è pronto per la configurazione dei nuovi LUN correttamente allineati come segue:</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identificare il LUN o i LUN da utilizzare nel nuovo zpool. In questo esempio, si tratta del dispositivo c2d1.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Recuperare l'istanza vdc dei dispositivi da utilizzare per un pool ZFS:</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Modifica<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Ciò significa che all'istanza di dispositivo 1 viene assegnata una dimensione di blocco di 4096.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Come ulteriore esempio, si supponga che le istanze vdsk da 1 a 6 debbano essere configurate per una dimensione di blocco di 4K e.<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> recita:</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">La finale<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> il file deve contenere quanto segue:</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Attenzione</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">L'LDOM deve essere riavviato dopo la configurazione di vdc.conf e la creazione di vdsk. Questa fase non può essere evitata. La modifica delle dimensioni del blocco ha effetto solo dopo un riavvio. Procedere con la configurazione di zpool e accertarsi che l'ashift sia impostato correttamente su 12 come descritto in precedenza.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">ZFS Intent Log (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">In genere, non esiste alcun motivo per individuare ZFS Intent Log (ZIL) su un dispositivo diverso. Il registro può condividere lo spazio con il pool principale. L'uso principale di una ZIL separata è quando si utilizzano unità fisiche che non dispongono delle funzionalità di cache di scrittura nei moderni array di storage.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">logbias</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Impostare<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Parametro sui file system ZFS che ospitano dati Oracle.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">L'utilizzo di questo parametro riduce i livelli di scrittura complessivi. Per impostazione predefinita, i dati scritti vengono salvati prima nella ZIL e quindi nel pool di storage principale. Questo approccio è appropriato per una configurazione che utilizza una configurazione a disco normale, che include un dispositivo ZIL basato su SSD e supporti rotanti per il pool di storage principale. Questo perché consente l'esecuzione di un commit in una singola transazione i/o sul supporto con latenza più bassa disponibile.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Quando si utilizza un moderno storage array che include funzionalità di caching autonome, questo approccio generalmente non è necessario. In rare circostanze, potrebbe essere opportuno assegnare una scrittura con una singola transazione al registro, ad esempio un carico di lavoro costituito da scritture casuali altamente concentrate e sensibili alla latenza. Vi sono conseguenze sotto forma di amplificazione in scrittura poiché i dati registrati vengono infine scritti nel pool di archiviazione principale, con il risultato di raddoppiare l'attività di scrittura.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">I/o diretto</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">Molte applicazioni, inclusi i prodotti Oracle, possono bypassare la cache del buffer host attivando l'i/o diretto Questa strategia non funziona come previsto con i file system ZFS. Anche se la cache del buffer host viene ignorata, ZFS continua a memorizzare i dati nella cache. Questa azione può produrre risultati fuorvianti quando si utilizzano strumenti come fio o sio per eseguire test delle prestazioni perché è difficile prevedere se l'i/o raggiunge il sistema di storage o se viene memorizzato nella cache locale del sistema operativo. Questa azione rende inoltre molto difficile l'utilizzo di tali test sintetici per confrontare le prestazioni di ZFS con altri file system. In pratica, le performance del file system differiscono da poco a nulla per i carichi di lavoro degli utenti reali.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Diversi zpool</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Backup basati su snapshot, ripristini, cloni e archiviazione dei dati basati su ZFS devono essere eseguiti al livello di zpool e in genere richiedono più zpool. Uno zpool è analogo a un gruppo di dischi LVM e deve essere configurato utilizzando le stesse regole. Ad esempio, è probabilmente meglio disporre un database con i file di dati residenti su<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> e i log di archivio, i file di controllo e i log di ripristino che risiedono su<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Questo approccio consente un backup a caldo standard in cui il database viene posto in modalità hot backup, seguito da uno snapshot di<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. Il database viene quindi rimosso dalla modalità di backup a caldo, l'archivio di log viene forzato e viene creata una snapshot di<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> viene creato. Un'operazione di ripristino richiede lo smontaggio dei file system zfs e l'offlining completo di zpool, in seguito a un'operazione di ripristino di SnapRestore. Lo zpool può quindi essere portato nuovamente online e il database recuperato.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesystemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Parametro Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Funziona in modo diverso con ZFS. Se<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> oppure<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Viene utilizzato, le operazioni di scrittura sono sincrone e ignorano la cache del buffer del sistema operativo, ma le letture sono bufferizzate da ZFS. Questa azione causa difficoltà nell'analisi delle performance perché talvolta l'i/o viene intercettato e gestito dalla cache ZFS, rendendo la latenza dello storage e l'i/o totale inferiori a quanto pare.</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">Opzioni di montaggio NFS HP-UX</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS HP-UX per una singola istanza.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS HP-UX per RAC.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">Il motivo<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password Oracle e file spfile. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è richiesto.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">Opzioni di montaggio VxFS HP-UX</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i file system che ospitano file binari Oracle:</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i file system contenenti file di dati, log di ripristino, log di archivio e file di controllo in cui la versione di HP-UX non supporta i/o simultanei:</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Quando l'i/o simultaneo è supportato (VxFS 5.0.1 e versioni successive o con ServiceGuard Storage Management Suite), utilizzare queste opzioni di montaggio per i file system contenenti file di dati, log di ripristino, log di archivio e file di controllo:</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">Il parametro<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> È particolarmente critico negli ambienti VxFS. Oracle consiglia di non impostare questo parametro in Oracle 10g R1 e versioni successive, a meno che non sia diversamente specificato. L'impostazione predefinita con dimensioni blocco Oracle 8KB è 128 KB. Se il valore di questo parametro è forzato a 16 o inferiore, rimuovere l'<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Montare l'opzione perché può danneggiare le prestazioni i/o sequenziali. Questa operazione danneggia altri aspetti delle prestazioni e deve essere eseguita solo se il valore di<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> deve essere modificato dal valore predefinito.</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Argomenti di configurazione specifici per il sistema operativo Linux utilizzando AFD e ASMlib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">Dimensioni dei blocchi ASMlib</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib è una libreria di gestione ASM opzionale e le utilità associate. Il suo valore principale è la capacità di contrassegnare un LUN o un file basato su NFS come una risorsa ASM con un'etichetta leggibile da un utente.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Le versioni recenti di ASMlib rilevano un parametro LUN chiamato Logical Blocks per Physical Block Exponent (LBPPBE). Questo valore non è stato segnalato dal target SCSI ONTAP fino a poco tempo fa. Ora restituisce un valore che indica che è preferibile una dimensione blocco 4KB. Questa non è una definizione della dimensione del blocco, ma è un suggerimento per qualsiasi applicazione che utilizza LBPPBE che i/o di una certa dimensione potrebbero essere gestiti in modo più efficiente. ASMlib, tuttavia, interpreta LBPPBE come dimensione del blocco e contrassegna in modo permanente l'intestazione ASM quando viene creato il dispositivo ASM.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Questo processo può causare problemi di aggiornamento e migrazione in vari modi, tutti basati sull'impossibilità di combinare dispositivi ASMlib con dimensioni dei blocchi diverse nello stesso gruppo di dischi ASM.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Ad esempio, gli array meno recenti generalmente riportavano un valore LBPPBE pari a 0 o non riportavano affatto questo valore. ASMlib lo interpreta come una dimensione di blocco di 512 byte. Gli array più recenti dovrebbero essere interpretati come aventi una dimensione del blocco di 4KB KB. Non è possibile combinare dispositivi a 512 byte e 4KB nello stesso gruppo di dischi ASM. In questo modo, si impedirebbe a un utente di aumentare le dimensioni del gruppo di dischi ASM utilizzando LUN di due array o sfruttando ASM come strumento di migrazione. In altri casi, RMAN potrebbe non consentire la copia dei file tra un gruppo di dischi ASM con dimensioni del blocco di 512 byte e un gruppo di dischi ASM con dimensioni del blocco di 4KB KB.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">La soluzione preferita è quella di tamponare ASMlib. L'ID del bug di Oracle è 13999609 e la patch è presente in oracleasm-support-2,1.8-1 e versioni successive. Questo patch consente all'utente di impostare il parametro<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> a.<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> in<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> file di configurazione. In questo modo, ASMlib non utilizza il parametro LBPPBE, il che significa che i LUN del nuovo array sono ora riconosciuti come dispositivi a blocchi da 512 byte.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">L'opzione non modifica le dimensioni del blocco sui LUN precedentemente contrassegnati da ASMlib. Ad esempio, se un gruppo di dischi ASM con blocchi da 512 byte deve essere migrato in un nuovo sistema di storage che riporta un blocco da 4KB KB, è possibile scegliere questa opzione<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Deve essere impostato prima che i nuovi LUN siano contrassegnati con ASMlib.  Se i dispositivi sono già stati contrassegnati da oracleasm, è necessario riformattarli prima di essere contrassegnati con una nuova dimensione del blocco. Innanzitutto, deconfigurare il dispositivo con<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, E quindi cancellare i primi 1GB del dispositivo con<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Infine, se il dispositivo era stato precedentemente partizionato, utilizzare<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Per rimuovere le partizioni obsolete o semplicemente riavviare il sistema operativo.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Se ASMlib non può essere aggiornato, ASMlib può essere rimosso dalla configurazione. Questa modifica comporta un'interruzione e richiede la rimozione dello stampaggio dei dischi ASM e la verifica che<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> parametro impostato correttamente. Questa modifica, tuttavia, non richiede la migrazione dei dati.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Dimensioni blocco comando filtro ASM (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD è una libreria di gestione ASM opzionale che sta diventando il sostituto di ASMlib. Dal punto di vista dello storage, è molto simile ad ASMlib, ma include funzionalità aggiuntive come la capacità di bloccare i/o non Oracle per ridurre le possibilità di errori di utenti o applicazioni che potrebbero danneggiare i dati.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Dimensioni dei blocchi dei dispositivi</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Come ASMlib, anche AFD legge il parametro LUN Logical Blocks per Physical Block Exponent (LBPPBE) e per impostazione predefinita utilizza la dimensione fisica del blocco, non la dimensione logica del blocco.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Ciò potrebbe creare un problema se l'AFD viene aggiunto a una configurazione esistente in cui i dispositivi ASM sono già formattati come dispositivi a blocchi da 512 byte. Il driver AFD riconosce il LUN come un dispositivo 4K e la mancata corrispondenza tra l'etichetta ASM e il dispositivo fisico impedirebbe l'accesso. Allo stesso modo, le migrazioni sarebbero influenzate dal fatto che non è possibile combinare dispositivi a 512 byte e 4KB nello stesso gruppo di dischi ASM. In questo modo, si impedirebbe a un utente di aumentare le dimensioni del gruppo di dischi ASM utilizzando LUN di due array o sfruttando ASM come strumento di migrazione. In altri casi, RMAN potrebbe non consentire la copia dei file tra un gruppo di dischi ASM con dimensioni del blocco di 512 byte e un gruppo di dischi ASM con dimensioni del blocco di 4KB KB.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">La soluzione è semplice: AFD include un parametro per controllare se utilizza le dimensioni del blocco logico o fisico. Si tratta di un parametro globale che interessa tutti i dispositivi del sistema. Per forzare AFD a utilizzare le dimensioni del blocco logico, impostare<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> in<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> file.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Dimensioni di trasferimento multipath</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Le recenti modifiche al kernel linux impongono restrizioni delle dimensioni di i/o inviate ai dispositivi multipath e AFD non rispetta queste restrizioni. Gli i/o vengono quindi rifiutati, il che causa la disconnessione del percorso LUN. Il risultato è un'impossibilità di installare Oracle Grid, configurare ASM o creare un database.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">La soluzione consiste nel specificare manualmente la lunghezza massima di trasferimento nel file multipath.conf per i LUN ONTAP:</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Anche se attualmente non esistono problemi, questo parametro deve essere impostato se si utilizza AFD per garantire che un futuro aggiornamento linux non causi inaspettatamente problemi.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">I/o simultanei</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Per ottenere prestazioni ottimali su IBM AIX è necessario utilizzare l'i/o simultaneo Senza i/o simultaneo, è probabile che le limitazioni delle prestazioni siano dovute al fatto che AIX esegue i/o atomico serializzato, che comporta un overhead significativo.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">In origine, NetApp ha consigliato di utilizzare<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Opzione di montaggio per forzare l'uso di i/o simultanei sul file system, ma questo processo ha avuto degli inconvenienti e non è più necessario. Dall'introduzione di AIX 5,2 e Oracle 10gR1, Oracle su AIX può aprire singoli file per i/o simultanei, anziché forzare i/o simultanei sull'intero file system.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">Il metodo migliore per abilitare l'i/o simultaneo è impostare<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> a.<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. In questo modo, Oracle può aprire file specifici da utilizzare con i/o simultanei</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">Utilizzo di<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Come opzione di montaggio, l'utilizzo di i/o simultanei può avere conseguenze negative. Ad esempio, forzando i/o simultanei si disabilita la lettura dei file system, che può danneggiare le prestazioni dell'i/o al di fuori del software del database Oracle, come la copia dei file e l'esecuzione di backup su nastro. Inoltre, prodotti come Oracle GoldenGate e SAP BR*Tools non sono compatibili con l'uso di<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Montare l'opzione con alcune versioni di Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">Non utilizzare<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> opzione di montaggio a livello di file system. Abilitare invece l'i/o simultaneo tramite l'utilizzo di<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Utilizzare solo l'<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> l'opzione di montaggio dovrebbe essere impostata se non è possibile<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Opzioni di montaggio NFS AIX</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS AIX per i database Oracle a istanza singola.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS AIX per RAC.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare la cache del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">Anche se si utilizza il<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> montare l'opzione e.<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Implementazioni per facilitare la coerenza di file quali file di password Oracle e.<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> file di parametri. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è necessario.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Opzioni di montaggio di AIX jfs/JFS2</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio di AIX jfs/JFS2.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Valori predefiniti</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Prima di utilizzare AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> i dispositivi in qualsiasi ambiente, inclusi i database, controllano il parametro<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Questo parametro non è la profondità della coda HBA, bensì la profondità della coda SCSI dell'individuo<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> potrebbe essere troppo basso per garantire buone prestazioni. I test hanno dimostrato che il valore ottimale è 64.</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle supporta l'utilizzo di Microsoft Windows con il client NFS diretto. Questa funzionalità offre un percorso per i vantaggi di gestione di NFS, tra cui la possibilità di visualizzare i file tra più ambienti, ridimensionare dinamicamente i volumi e sfruttare un protocollo IP meno costoso. Consultare la documentazione ufficiale di Oracle per informazioni sull'installazione e la configurazione di un database in Microsoft Windows utilizzando DNFS. Non esistono Best practice speciali.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Per un'efficienza di compressione ottimale, assicurarsi che il file system NTFS utilizzi un'unità di allocazione di 8K GB o superiore. L'utilizzo di un'unità di allocazione 4K, generalmente predefinita, influisce negativamente sull'efficienza della compressione.</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Argomenti di configurazione specifici del sistema operativo Linux.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Tavoli con fessure</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Opzioni di montaggio NFS Linux</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS Linux per una singola istanza.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS Linux per RAC.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/votazione</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">Il motivo<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password e file spfile di Oracle. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è necessario.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">In genere, i file non di database devono essere montati con le stesse opzioni utilizzate per i file di dati a singola istanza, sebbene applicazioni specifiche possano avere requisiti diversi. Evitare le opzioni di montaggio<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> se possibile perché queste opzioni disabilitano la lettura e il buffering a livello di file system. Ciò può causare gravi problemi di prestazioni per processi quali l'estrazione, la traduzione e il caricamento.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESSO e GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Alcuni clienti hanno notato che un livello estremamente elevato di altri IOPS, come ACCESSO e GETATTR, può dominare i propri workload. In casi estremi, operazioni come letture e scritture possono arrivare fino al 10% del totale. Si tratta di un comportamento normale con qualsiasi database che include l'uso di<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> e/o.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Su Linux perché queste opzioni fanno sì che il sistema operativo Linux ricarichi costantemente i metadati dei file dal sistema di archiviazione. Operazioni quali ACCESS e GETATTR sono operazioni a basso impatto gestite dalla cache ONTAP in un ambiente di database. Non dovrebbero essere considerati IOPS autentici, come le letture e le scritture, che creano una vera domanda sui sistemi storage. Tuttavia, questi altri IOPS creano un certo carico, specialmente negli ambienti RAC. Per risolvere questo problema, abilitare DNFS, che ignora la cache buffer del sistema operativo ed evita queste operazioni non necessarie relative ai metadati.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">Linux Direct NFS</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Un'opzione di montaggio aggiuntiva, denominata<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, È necessario quando (a) DNFS è abilitato e (b) un volume sorgente è montato più di una volta su un singolo server (c) con un mount NFS nidificato. Questa configurazione si osserva principalmente in ambienti che supportano applicazioni SAP. Ad esempio, un singolo volume di un sistema NetApp può avere una directory situata in<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> e un secondo a.<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Se<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> è montato su<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> e.<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> è montato su<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, Il risultato sono montaggi NFS nidificati che hanno origine sulla stessa fonte.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS e Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">L'uso di DNFS offre speciali vantaggi in termini di prestazioni per Oracle RAC sul sistema operativo Linux, poiché Linux non dispone di un metodo per forzare l'i/o diretto, necessario con RAC per la coerenza tra i nodi. Come soluzione, Linux richiede l'uso di<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Opzione di montaggio, che fa sì che i dati dei file scadano immediatamente dalla cache del sistema operativo. Questa opzione a sua volta obbliga il client NFS Linux a rileggere costantemente i dati degli attributi, danneggiando la latenza e aumentando il carico sullo storage controller.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">Abilitando DNFS si ignora il client NFS dell'host ed evita questo danno. Diversi clienti hanno segnalato significativi miglioramenti delle performance sui cluster RAC e una significativa riduzione del carico ONTAP (soprattutto in relazione ad altri IOPS) quando si attiva DNFS.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS e file oranfstab</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Quando si utilizza DNFS su Linux con l'opzione multipathing, è necessario utilizzare più sottoreti. Su altri sistemi operativi, è possibile stabilire più canali DNFS utilizzando<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> e.<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Opzioni per configurare più canali DNFS su una singola subnet. Tuttavia, questo non funziona correttamente su Linux e possono verificarsi problemi di prestazioni imprevisti. Con Linux, ogni NIC utilizzata per il traffico DNFS deve trovarsi su una subnet diversa.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">Utilità di pianificazione i/O.</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Il kernel Linux permette un controllo di basso livello sul modo in cui l'i/o blocca i dispositivi è programmato. Le impostazioni predefinite su varie distribuzioni di Linux variano notevolmente. I test dimostrano che la scadenza di solito offre i migliori risultati, ma a volte NOOP è stato leggermente migliore. La differenza di prestazioni è minima, ma è necessario verificare entrambe le opzioni se è necessario estrarre le massime prestazioni possibili da una configurazione di database. CFQ è l'impostazione predefinita in molte configurazioni e ha dimostrato di avere problemi significativi di prestazioni con i carichi di lavoro del database.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Per istruzioni sulla configurazione dello scheduler i/o, consultare la documentazione del fornitore di Linux pertinente.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Multipathing</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Alcuni clienti hanno riscontrato arresti anomali durante l'interruzione della rete perché il daemon multipath non era in esecuzione sul proprio sistema. Nelle versioni recenti di Linux, il processo di installazione del sistema operativo e del demone multipathing potrebbero lasciare questi sistemi operativi vulnerabili a questo problema. I pacchetti sono installati correttamente, ma non sono configurati per l'avvio automatico dopo un riavvio.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Ad esempio, il valore predefinito per il daemon multipath su RHEL5,5 potrebbe essere il seguente:</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Questo può essere corretto con i seguenti comandi:</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">Mirroring ASM</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">Il mirroring ASM potrebbe richiedere modifiche alle impostazioni di multipath Linux per consentire ad ASM di riconoscere un problema e passare a un gruppo di errori alternativo. La maggior parte delle configurazioni ASM su ONTAP utilizza la ridondanza esterna, il che significa che la protezione dei dati è fornita dall'array esterno e ASM non esegue il mirroring dei dati. Alcuni siti utilizzano ASM con ridondanza normale per fornire il mirroring bidirezionale, in genere su siti diversi.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">Documentazione delle utilità host NetApp</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">Le impostazioni di Linux visualizzate nella <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Includi parametri multipath che determinano indefinite code di i/O. Ciò significa che un i/o su un dispositivo LUN senza percorsi attivi attende finché l'i/o non viene completato. Questo è solitamente consigliabile perché gli host Linux attendono il tempo necessario per il completamento delle modifiche al percorso SAN, per il riavvio degli switch FC o per il completamento di un failover da parte di un sistema di storage.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Questo comportamento di accodamento illimitato causa un problema con il mirroring ASM perché ASM deve ricevere un errore di i/o per consentire al reparto IT di riprovare l'i/o su un LUN alternativo.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Impostare i seguenti parametri in Linux<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> File per i LUN ASM utilizzati con il mirroring ASM:</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Queste impostazioni creano un timeout di 120 secondi per i dispositivi ASM. Il timeout viene calcolato come<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> in pochi secondi. In alcuni casi potrebbe essere necessario regolare il valore esatto, ma per la maggior parte degli utilizzi dovrebbe essere sufficiente un timeout di 120 secondi. In particolare, 120 secondi devono consentire il takeover o il giveback del controller senza produrre un errore di i/o che porterebbe il gruppo guasto a diventare offline.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">Un più basso<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> Il valore può ridurre il tempo richiesto per ASM per passare a un gruppo di errori alternativo, ma aumenta anche il rischio di un failover indesiderato durante attività di manutenzione come il takeover di un controller. Il rischio può essere mitigato tramite un attento monitoraggio dello stato di mirroring ASM. Se si verifica un failover indesiderato, è possibile risincronizzare rapidamente i mirror se la risincronizzazione viene eseguita in modo relativamente rapido. Per ulteriori informazioni, consultare la documentazione Oracle su ASM Fast Mirror Resync per la versione del software Oracle in uso.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Linux xfs, ext3, e ext4 opzioni di mount</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp recommended* usando le opzioni di mount predefinite.</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">Molti clienti di Oracle su ONTAP utilizzano ethernet, il protocollo di rete di NFS, iSCSI, NVMe/TCP e specialmente il cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Progettazione dell'interfaccia logica per i database Oracle</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">I database Oracle devono accedere allo storage. Le interfacce logiche (LIF) sono le tubazioni di rete che collegano una Storage Virtual Machine (SVM) alla rete e a loro volta al database. La corretta progettazione della LIF è necessaria per garantire una larghezza di banda sufficiente per ogni carico di lavoro del database e il failover non comporta una perdita dei servizi storage.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Configurazione di rete FC per database Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">La configurazione di FC SAN per database Oracle riguarda principalmente le seguenti Best practice quotidiane SAN.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Database Oracle su ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP è progettato per i database Oracle. Per decenni, ONTAP è stato ottimizzato per le esigenze uniche di i/o dei database relazionali e sono state create più funzionalità di ONTAP appositamente per soddisfare le esigenze dei database Oracle e persino su richiesta della stessa Oracle Inc.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-3633: Database Oracle su ONTAP; TR-4591: Protezione dei dati Oracle: Backup, recovery, replica; TR-4592: Oracle su MetroCluster; e TR-4534: Migrazione dei database Oracle su sistemi di storage NetApp_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Oltre ai numerosi modi possibili in cui ONTAP apporta valore all'ambiente di database, esiste anche una vasta gamma di requisiti utente, incluse le dimensioni del database, i requisiti di performance e le esigenze di protezione dei dati. Le distribuzioni note di storage NetApp includono tutto, da un ambiente virtualizzato di circa 6.000 database in esecuzione su VMware ESX a un data warehouse a singola istanza, di dimensioni attuali pari a 996TB TB e in crescita. Di conseguenza, sono disponibili alcune Best practice chiare per la configurazione di un database Oracle su storage NetApp.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">I requisiti per l'utilizzo di un database Oracle su storage NetApp vengono risolti in due modi. In primo luogo, quando esiste una buona pratica chiara, essa verrà richiamata in modo specifico. A un livello generale, verranno spiegate molte considerazioni di progettazione che i progettisti delle soluzioni di storage Oracle devono affrontare in base ai loro specifici requisiti di business.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Introduzione alla migrazione dello storage Oracle</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4534: Migrazione dei database Oracle in sistemi di storage NetApp_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">Nel caso di un nuovo progetto di database, questo non rappresenta un problema, poiché gli ambienti di database e applicazioni sono stati costruiti in sede. La migrazione, tuttavia, pone sfide speciali in relazione all'interruzione del business, al tempo necessario per il completamento della migrazione, alle competenze necessarie e alla minimizzazione del rischio.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Script</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">La presente documentazione contiene script di esempio. Questi script forniscono metodi di esempio per automatizzare vari aspetti della migrazione per ridurre la possibilità di errori da parte degli utenti. Gli script possono ridurre le richieste generali del personale IT responsabile della migrazione e accelerare il processo complessivo. Questi script sono ricavati da progetti di migrazione effettivi eseguiti dai servizi di assistenza professionale NetApp e dai partner NetApp. Nella presente documentazione sono riportati alcuni esempi del loro utilizzo.</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">Una parte delle interruzioni durante l'importazione di LUN esterne è inevitabile a causa della necessità di modificare la configurazione di rete FC. Tuttavia, l'interruzione non deve durare più a lungo del tempo necessario per riavviare l'ambiente di database e aggiornare lo zoning FC per passare dalla connettività FC dell'host al ONTAP.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Questo processo può essere riassunto come segue:</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Quiete di tutta l'attività LUN sui LUN esterni.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Reindirizzare le connessioni FC dell'host al nuovo sistema ONTAP.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Attivare il processo di importazione.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Rilevare nuovamente i LUN.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Riavviare il database.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">Non è necessario attendere il completamento del processo di migrazione. Non appena inizia la migrazione di un determinato LUN, questo è disponibile su ONTAP e può fornire dati durante il processo di copia dei dati. Tutte le letture vengono passate alla LUN esterna e tutte le scritture vengono scritte in modo sincrono su entrambi gli array. L'operazione di copia è molto veloce e l'overhead del reindirizzamento del traffico FC è minimo, per cui qualsiasi impatto sulle performance deve essere transitorio e minimo. In caso di problemi, è possibile ritardare il riavvio dell'ambiente fino al completamento del processo di migrazione e all'eliminazione delle relazioni di importazione.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Chiudere il database</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">Il primo passo per chiudere l'ambiente in questo esempio è arrestare il database.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Chiudere i servizi di rete</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">Uno dei file system basati su SAN oggetto della migrazione include anche i servizi Oracle ASM. La disattivazione dei LUN sottostanti richiede lo smontaggio dei file system, il che a sua volta significa l'arresto di tutti i processi con file aperti su questo file system.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Smontare i file system</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Se tutti i processi vengono arrestati, l'operazione umount ha esito positivo. Se l'autorizzazione viene negata, è necessario che sul file system sia presente un processo con blocco. Il<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> command può aiutare a identificare questi processi.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Disattivare i gruppi di volumi</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Una volta smontati tutti i file system di un dato gruppo di volumi, è possibile disattivare il gruppo di volumi.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Modifiche alla rete FC</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">È ora possibile aggiornare le zone FC per rimuovere tutti gli accessi dall'host all'array esterno e stabilire l'accesso a ONTAP.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Avviare il processo di importazione</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Per avviare i processi di importazione LUN, eseguire<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> comando.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Monitorare l'avanzamento dell'importazione</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">L'operazione di importazione può essere monitorata con<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> comando. Come illustrato di seguito, è in corso l'importazione di tutte le LUN da 20 GB, il che significa che i dati sono ora accessibili tramite ONTAP, anche se l'operazione di copia dei dati continua a proseguire.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Importazione di LUN esterne - completamento</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Se hai bisogno di una migrazione online, procedi con il rilevamento dei LUN nella nuova sede e attiva i servizi.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Eseguire la scansione delle modifiche al dispositivo SCSI</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">Nella maggior parte dei casi, l'opzione più semplice per ritrovare nuove LUN è riavviare l'host. In questo modo, si rimuovono automaticamente i vecchi dispositivi obsoleti, si rilevano correttamente tutti i nuovi LUN e si creano dispositivi associati come i dispositivi multipathing. L'esempio qui mostra una procedura completamente online a scopo dimostrativo.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Attenzione: Prima di riavviare un host, assicurarsi che tutte le voci in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Il riferimento alle risorse SAN migrate verrà commentato. Se questa operazione non viene eseguita e si verificano problemi con l'accesso LUN, il sistema operativo potrebbe non avviarsi. Questa situazione non danneggia i dati. Tuttavia, può essere molto scomodo avviare in modalità rescue o in una modalità simile e correggere<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> In modo che il sistema operativo possa essere avviato per consentire la risoluzione dei problemi.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">I LUN della versione di Linux utilizzata in questo esempio possono essere rianalizzati con<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> comando. Se il comando viene eseguito correttamente, nell'output viene visualizzato ogni percorso LUN. L'output può essere difficile da interpretare, ma, se la configurazione di zoning e igroup era corretta, molti LUN dovrebbero apparire che includono un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> stringa fornitore.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Verificare la presenza di dispositivi multipercorso</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">Il processo di rilevamento LUN attiva anche la ricreazione dei dispositivi multipath, ma è noto che il driver multipathing Linux presenta problemi occasionali. L'output di<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> dovrebbe essere controllato per verificare che l'output sia come previsto. Per esempio, l'uscita seguente mostra dispositivi multipercorso associati a A.<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> stringa fornitore. Ciascun dispositivo dispone di quattro percorsi, di cui due con priorità 50 e due con priorità 10. Anche se l'output esatto può variare con diverse versioni di Linux, questo risultato sembra come previsto.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Fare riferimento alla documentazione delle utilità host per la versione di Linux utilizzata per verificare che<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> le impostazioni sono corrette.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Riattivare il gruppo di volumi LVM</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Se i LUN LVM sono stati rilevati correttamente, l'<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> il comando dovrebbe riuscire. Questo è un buon esempio del valore di un volume manager logico. Una modifica del WWN di una LUN o anche di un numero di serie non è importante perché i metadati del gruppo di volumi vengono scritti sul LUN stesso.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">Il sistema operativo ha eseguito la scansione dei LUN e ha rilevato una piccola quantità di dati scritti sul LUN che lo identifica come volume fisico appartenente a.<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Successivamente, ha costruito tutti i dispositivi necessari. È sufficiente riattivare il gruppo di volumi.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Rimontare i file system</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Dopo la riattivazione del gruppo di volumi, i file system possono essere montati con tutti i dati originali intatti. Come indicato in precedenza, i file system sono completamente operativi anche se la replica dei dati è ancora attiva nel gruppo back.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Ripetere la scansione per i dispositivi ASM</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">I dispositivi ASMlib dovrebbero essere stati riselezionati al momento della nuova scansione dei dispositivi SCSI. La riscoperta può essere verificata online riavviando ASMlib e quindi eseguendo la scansione dei dischi.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Questa fase è pertinente solo alle configurazioni ASM in cui viene utilizzato ASMlib.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Attenzione: Se non viene utilizzato ASMlib, il<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> i dispositivi dovrebbero essere stati ricreati automaticamente. Tuttavia, le autorizzazioni potrebbero non essere corrette. È necessario impostare autorizzazioni speciali sui dispositivi sottostanti per ASM in assenza di ASMlib. Questa operazione viene solitamente eseguita tramite voci speciali in entrambi<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> oppure<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> o eventualmente in entrambi i set di regole. È possibile che questi file debbano essere aggiornati per riflettere le modifiche apportate all'ambiente in termini di numeri WWN o di serie per assicurarsi che i dispositivi ASM dispongano ancora delle autorizzazioni corrette.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">In questo esempio, il riavvio di ASMlib e la scansione dei dischi mostrano gli stessi 10 LUN ASM dell'ambiente originale.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Riavviare i servizi di rete</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Ora che i dispositivi LVM e ASM sono online e disponibili, è possibile riavviare i servizi grid.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Riavviare il database</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Dopo aver riavviato i servizi di griglia, è possibile avviare il database. Potrebbe essere necessario attendere alcuni minuti affinché i servizi ASM diventino completamente disponibili prima di provare ad avviare il database.</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Dal punto di vista dell'host, la migrazione è completa, ma l'i/o viene ancora servito dall'array esterno fino a quando le relazioni di importazione non vengono eliminate.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Prima di eliminare le relazioni, è necessario confermare che il processo di migrazione è completo per tutte le LUN.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Elimina relazioni di importazione</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Al termine del processo di migrazione, eliminare la relazione di migrazione. Dopo aver fatto ciò, l'i/o viene servito esclusivamente dalle unità su ONTAP.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Annullare la registrazione di LUN esterne</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Infine, modificare il disco per rimuovere<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> designazione.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Migrazione di Oracle tramite la distribuzione dei log</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Log shipping di Oracle</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">L'obiettivo di una migrazione utilizzando la distribuzione dei log è creare una copia dei file di dati originali in una nuova posizione e quindi stabilire un metodo per la distribuzione delle modifiche nel nuovo ambiente.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Una volta stabiliti, è possibile automatizzare la spedizione e la riproduzione dei log per mantenere il database di replica ampiamente sincronizzato con l'origine. Ad esempio, un job cron può essere programmato per (a) copiare i log più recenti nella nuova posizione e (b) riprodurli ogni 15 minuti. In questo modo si riduce al minimo l'interruzione al momento del cutover, in quanto è necessario riprodurre non più di 15 minuti dei registri di archivio.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">La procedura illustrata di seguito è essenzialmente un'operazione di clonazione del database. La logica illustrata è simile al motore all'interno di NetApp SnapManager per Oracle (SMO) e al plug-in NetApp SnapCenter per Oracle. Alcuni clienti utilizzano la procedura indicata negli script o nei workflow Wfa per le operazioni di cloning personalizzate. Sebbene questa procedura sia più manuale che non utilizzi SMO o SnapCenter, viene comunque rapidamente script e le API di gestione dei dati all'interno di ONTAP semplificano ulteriormente il processo.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Log shipping - dal file system al file system</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">In questo esempio viene illustrata la migrazione di un database denominato WAFFLE da un normale file system a un altro normale file system situato su un server diverso. Illustra anche l'utilizzo di SnapMirror per eseguire una copia rapida dei file di dati, ma questa non è parte integrante della procedura generale.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Creare il backup del database</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">Il primo passo consiste nel creare un backup del database. In particolare, questa procedura richiede una serie di file di dati che possono essere utilizzati per la riproduzione del log di archivio.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">Ambiente</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Ripristino in un nuovo ambiente</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">Ora il backup deve essere ripristinato nel nuovo ambiente. Questa operazione può essere eseguita in vari modi, tra cui Oracle RMAN, ripristino da un'applicazione di backup come NetBackup o semplice operazione di copia dei file di dati inseriti in modalità hot backup.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Creare un nuovo volume per ricevere i dati dello snapshot. Inizializzare il mirroring da<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> a.<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Una volta impostato lo stato da SnapMirror, a indicare che la sincronizzazione è completa, aggiornare il mirror in base allo snapshot desiderato,</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">La sincronizzazione può essere verificata visualizzando<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> sul volume speculare.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">Lo specchio può quindi essere rotto.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Montare il nuovo file system.con i file system basati su blocchi, le procedure precise variano in base al LVM in uso. È necessario configurare lo zoning FC o le connessioni iSCSI. Dopo aver stabilito la connettività ai LUN, comandi come Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Potrebbe essere necessario per rilevare quali gruppi di volumi o LUN devono essere configurati correttamente per essere rilevati da ASM.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">In questo esempio viene utilizzato un semplice file system NFS. Questo file system può essere montato direttamente.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Creare un modello di creazione controlfile</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">Successivamente, è necessario creare un modello controlfile. Il<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> comando crea comandi di testo per ricreare un controlfile. In alcuni casi, questa funzione può risultare utile per ripristinare un database da un backup e viene spesso utilizzata con script che eseguono attività come la clonazione dei database.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">L'output del comando seguente viene utilizzato per ricreare i file di controllo per il database migrato.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Una volta creati i file di controllo, copiarli nel nuovo server.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">File dei parametri di backup</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">Nel nuovo ambiente è necessario anche un file di parametri. Il metodo più semplice consiste nel creare un pfile dal file spfile o pfile corrente. In questo esempio, il database di origine utilizza un spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Crea voce oratab</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">La creazione di una voce oratab è necessaria per il corretto funzionamento di utility come oraenv. Per creare una voce oratab, completare il passaggio seguente.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Preparare la struttura delle directory</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Se le directory richieste non sono già presenti, è necessario crearle oppure la procedura di avvio del database non riesce. Per preparare la struttura di directory, completare i seguenti requisiti minimi.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Aggiornamenti del file dei parametri</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Per copiare il file dei parametri nel nuovo server, eseguire i seguenti comandi. La posizione predefinita è<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directory. In questo caso, il pfile può essere posizionato ovunque. Viene utilizzata solo come fase intermedia del processo di migrazione.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Modificare il file come richiesto. Ad esempio, se la posizione del log di archivio è stata modificata, il file pfile deve essere modificato per riflettere la nuova posizione. In questo esempio, vengono ricollocati solo i file di controllo, in parte per distribuirli tra i file system di log e di dati.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Al termine delle modifiche, creare un file spfile basato su questo file pfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Ricreare i file di controllo</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">In una fase precedente, l'output di<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> è stato copiato nel nuovo server. La parte specifica dell'uscita richiesta è la<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> comando. Queste informazioni si trovano nel file sotto la sezione contrassegnata<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Inizia con la linea<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> e dovrebbe includere la parola<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Termina con il punto e virgola (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">In questa procedura di esempio, il file viene letto come segue.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Modificare lo script come desiderato per riflettere la nuova posizione dei vari file. Ad esempio, alcuni file di dati noti per supportare un i/o elevato potrebbero essere reindirizzati a un file system su un Tier di storage dalle performance elevate. In altri casi, le modifiche possono essere apportate solo per motivi di amministrazione, ad esempio isolando i file di dati di un PDB in volumi dedicati.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">In questo esempio, il<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> stanza viene lasciata invariata, ma i log di redo vengono spostati in una nuova posizione in<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> piuttosto che condividere lo spazio con i log di archivio<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Se i file sono posizionati in modo errato o i parametri non sono configurati correttamente, vengono generati errori che indicano ciò che deve essere corretto. Il database è montato, ma non è ancora aperto e non può essere aperto perché i file di dati in uso sono ancora contrassegnati come in modalità di backup a caldo. Per rendere il database coerente, è necessario applicare prima i registri di archiviazione.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Replica iniziale del registro</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Per rendere coerenti i file di dati è necessaria almeno un'operazione di risposta del registro. Sono disponibili molte opzioni per la riproduzione dei registri. In alcuni casi, la posizione originale del log di archivio sul server originale può essere condivisa tramite NFS e la risposta del log può essere effettuata direttamente. In altri casi, è necessario copiare i registri di archivio.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Ad esempio, un semplice<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> l'operazione può copiare tutti i log correnti dal server di origine al server di migrazione:</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Riproduzione del registro iniziale</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Una volta che i file si trovano nella posizione del log di archivio, è possibile riprodurli inviando il comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguito dalla risposta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> per riprodurre automaticamente tutti i registri disponibili.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">La risposta finale del log di archivio riporta un errore, ma questo è normale. Il registro indica che<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> stava cercando un particolare file di registro e non lo ha trovato. Il motivo è, molto probabilmente, che il file di registro non esiste ancora.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Se il database di origine può essere arrestato prima di copiare i registri di archivio, questa operazione deve essere eseguita una sola volta. I log di archivio vengono copiati e riprodotti, quindi il processo può continuare direttamente con il processo di cutover che replica i log di ripristino critici.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Replica e riproduzione incrementale dei log</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">Nella maggior parte dei casi, la migrazione non viene eseguita immediatamente. Il completamento del processo di migrazione potrebbe richiedere alcuni giorni o addirittura settimane, pertanto i log devono essere inviati continuamente al database di replica e riprodotti. Pertanto, quando arriva il cutover, occorre trasferire e riprodurre minimi dati.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">In questo modo è possibile eseguire script in molti modi diversi, ma uno dei metodi più diffusi è l'utilizzo di rsync, un'utilità comune di replica dei file. Il modo più sicuro per usare questa utility è configurarla come demone. Ad esempio, il<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> file che segue mostra come creare una risorsa chiamata<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> A cui si accede con le credenziali utente Oracle e a cui è mappato<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Soprattutto, la risorsa è impostata su sola lettura, consentendo la lettura dei dati di produzione, ma non l'alterazione.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">Il seguente comando sincronizza la destinazione del log di archivio del nuovo server con la risorsa rsync<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> sul server originale. Il<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> argomento in<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> fa sì che l'elenco di file venga confrontato in base alla data e all'ora e che vengano copiati solo i nuovi file. Questo processo fornisce un aggiornamento incrementale del nuovo server. Questo comando può anche essere programmato in cron per essere eseguito regolarmente.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Riproduci i registri sul database</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Una volta ricevuti i registri, è necessario riprodurli. Gli esempi precedenti mostrano l'uso di sqlplus per l'esecuzione manuale<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, un processo che può essere facilmente automatizzato. Nell'esempio illustrato viene utilizzato lo script descritto nella <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Gli script accettano un argomento che specifica il database che richiede un'operazione di riproduzione. Ciò consente di utilizzare lo stesso script in una migrazione di più database.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Cutover</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Quando si è pronti per il passaggio al nuovo ambiente, è necessario eseguire una sincronizzazione finale che includa sia i registri di archivio che i registri di ripristino. Se la posizione originale del log di ripristino non è già nota, è possibile identificarla come segue:</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Arrestare il database di origine.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Eseguire una sincronizzazione finale dei registri di archivio sul nuovo server con il metodo desiderato.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">I log di ripristino di origine devono essere copiati nel nuovo server. In questo esempio, i log di ripristino sono stati spostati in una nuova directory all'indirizzo<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">In questa fase, il nuovo ambiente di database contiene tutti i file necessari per portarlo nello stesso stato dell'origine. I registri di archivio devono essere riprodotti una volta finale.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Al termine, i log di ripristino devono essere riprodotti. Se il messaggio<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> viene restituito, il processo è riuscito e i database sono sincronizzati e possono essere aperti.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Log shipping - da ASM a file system</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">In questo esempio viene illustrato l'utilizzo di Oracle RMAN per la migrazione di un database. È molto simile all'esempio precedente di distribuzione del log del file system, ma i file su ASM non sono visibili all'host. Le uniche opzioni per la migrazione dei dati presenti sui dispositivi ASM sono il riposizionamento del LUN ASM o l'utilizzo di Oracle RMAN per eseguire le operazioni di copia.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Sebbene RMAN sia un requisito per la copia dei file da Oracle ASM, l'utilizzo di RMAN non è limitato a ASM. RMAN può essere utilizzato per migrare da qualsiasi tipo di storage a qualsiasi altro tipo.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Questo esempio mostra il trasferimento di un database chiamato PANCAKE dallo storage ASM a un file system normale situato su un server diverso nei percorsi<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> e.<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">Il primo passo consiste nel creare un backup del database da migrare su un server alternativo. Poiché l'origine utilizza Oracle ASM, è necessario utilizzare RMAN. Un semplice backup RMAN può essere eseguito come segue. Questo metodo crea un backup con tag che può essere facilmente identificato da RMAN più avanti nella procedura.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">Il primo comando definisce il tipo di destinazione per il backup e la posizione da utilizzare. Il secondo avvia il backup dei soli file di dati.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Backup controlfile</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Un controlfile di backup è necessario più avanti nella procedura per<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> operazione.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">Nel nuovo ambiente è necessario anche un file di parametri. Il metodo più semplice consiste nel creare un pfile dal file spfile o pfile corrente. In questo esempio, il database di origine utilizza un spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Script di ridenominazione file ASM</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Diverse posizioni dei file attualmente definite nei file di controllo cambiano quando il database viene spostato. Lo script seguente crea uno script RMAN per semplificare il processo. Questo esempio mostra un database con un numero molto ridotto di file di dati, ma in genere i database contengono centinaia o addirittura migliaia di file di dati.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Conversione da ASM a nome file system</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Questo script si trova in <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> e fa due cose.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">In primo luogo, viene creato un parametro per ridefinire le posizioni del log di ripristino chiamate<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Si tratta essenzialmente di un elenco di campi alternati. Il primo campo rappresenta la posizione di un registro di ripristino corrente, mentre il secondo campo rappresenta la posizione sul nuovo server. Il modello viene quindi ripetuto.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">La seconda funzione consiste nel fornire un modello per la ridenominazione dei file di dati. Lo script esegue il ciclo dei file di dati, estrae le informazioni sul nome e sul numero del file e lo formatta come uno script RMAN. Quindi fa lo stesso con i file temporanei. Il risultato è un semplice script rman che può essere modificato come desiderato per assicurarsi che i file vengano ripristinati nella posizione desiderata.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Acquisire l'output di questa schermata. Il<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> il parametro viene inserito nel file pfile come descritto di seguito. Il file di dati RMAN rinominato e lo script duplicato devono essere modificati di conseguenza per posizionare i file di dati nelle posizioni desiderate. In questo esempio, sono tutti inseriti<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Gli script sono quasi pronti per l'esecuzione, ma prima la struttura di directory deve essere in posizione. Se le directory richieste non sono già presenti, è necessario crearle oppure la procedura di avvio del database non riesce. L'esempio riportato di seguito riflette i requisiti minimi.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">Il seguente comando è necessario per il corretto funzionamento di utility come oraenv.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Aggiornamenti dei parametri</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">Il file pfile salvato deve essere aggiornato per riflettere eventuali modifiche di percorso sul nuovo server. Le modifiche al percorso del file di dati vengono modificate dallo script di duplicazione RMAN e quasi tutti i database richiedono modifiche al<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> e.<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> parametri. Potrebbero inoltre essere presenti posizioni dei file di controllo che devono essere modificate e parametri quali<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Potrebbe non essere rilevante al di fuori di ASM. Prima di procedere, un DBA esperto deve esaminare attentamente le modifiche proposte.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">In questo esempio, le modifiche principali sono le posizioni controlfile, la destinazione di archivio del registro e l'aggiunta di<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Dopo la conferma dei nuovi parametri, i parametri devono essere applicati. Esistono diverse opzioni, ma la maggior parte dei clienti crea un file spfile basato sul file pfile di testo.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Nomount di avvio</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">Il passaggio finale prima della replica del database consiste nel visualizzare i processi del database ma non nel montare i file. In questa fase, potrebbero manifestarsi problemi con spfile. Se il<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> comando non riesce a causa di un errore di parametro, è semplice chiudere, correggere il modello pfile, ricaricarlo come spfile, e riprovare.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Duplicare il database</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">Il ripristino del backup RMAN precedente nella nuova posizione richiede più tempo rispetto ad altre fasi di questo processo. Il database deve essere duplicato senza modificare l'ID del database (DBID) o reimpostare i registri. Ciò impedisce l'applicazione dei registri, operazione necessaria per la sincronizzazione completa delle copie.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Connettersi al database con RMAN come aux ed eseguire il comando duplicato del database utilizzando lo script creato in un passaggio precedente.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">A questo punto è necessario inviare le modifiche dal database di origine a una nuova posizione. In tal caso, potrebbe essere necessario eseguire una combinazione di operazioni. Il metodo più semplice sarebbe fare in modo che RMAN nel database di origine scriva i log di archivio in una connessione di rete condivisa. Se una posizione condivisa non è disponibile, un metodo alternativo consiste nell'utilizzare RMAN per scrivere su un file system locale e quindi utilizzare rcp o rsync per copiare i file.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">In questo esempio, il<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Directory è una condivisione NFS disponibile sia per il database originale che per quello migrato.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">Una questione importante in questo caso è la<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> clausola. Il formato del disco del backup è<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Che significa che è necessario utilizzare il formato del numero di thread, il numero di sequenza e l'ID di attivazione per il database. Anche se le lettere sono diverse, questa corrisponde alla<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> parametro nel pfile. Questo parametro specifica inoltre i log di archivio nel formato di numero di thread, numero di sequenza e ID di attivazione. Il risultato finale è che i backup del file di registro sull'origine utilizzano una convenzione di denominazione prevista dal database. In questo modo, vengono eseguite operazioni come<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> molto più semplice perché sqlplus anticipa correttamente i nomi dei log di archivio da riprodurre.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Una volta che i file si trovano nella posizione del log di archivio, è possibile riprodurli inviando il comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguito dalla risposta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> per riprodurre automaticamente tutti i registri disponibili. Il file dei parametri sta attualmente indirizzando i log di archivio a.<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Ma non corrisponde alla posizione in cui RMAN è stato utilizzato per salvare i registri. La posizione può essere reindirizzata temporaneamente come segue prima di ripristinare il database.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">La risposta finale del log di archivio riporta un errore, ma questo è normale. L'errore indica che sqlplus stava cercando un particolare file di registro e non lo ha trovato. Il motivo è molto probabile che il file di registro non esista ancora.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">Nella maggior parte dei casi, la migrazione non viene eseguita immediatamente. Il completamento del processo di migrazione potrebbe richiedere alcuni giorni o addirittura settimane, pertanto i log devono essere inviati continuamente al database di replica e riprodotti. In questo modo si assicura che i dati minimi debbano essere trasferiti e riprodotti all'arrivo del cutover.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Questo processo può essere facilmente gestito tramite script. Ad esempio, è possibile pianificare il seguente comando nel database originale per assicurarsi che la posizione utilizzata per la spedizione dei log venga aggiornata continuamente.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Replay Logs on Standby Database</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Una volta ricevuti i registri, è necessario riprodurli. Gli esempi precedenti hanno mostrato l'uso di sqlplus per l'esecuzione manuale<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, che può essere facilmente automatizzato. Nell'esempio illustrato viene utilizzato lo script descritto nella <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. Lo script accetta un argomento che specifica il database che richiede un'operazione di riproduzione. Questo processo consente di utilizzare lo stesso script in una migrazione di più database.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Quando si è pronti a passare al nuovo ambiente, è necessario eseguire una sincronizzazione finale. Quando si lavora con i normali file system, è facile assicurarsi che il database migrato sia sincronizzato al 100% rispetto all'originale, poiché i log di ripristino originali vengono copiati e riprodotti. Con ASM non esiste un buon modo per farlo. È possibile recuperare facilmente solo i registri di archivio. Per assicurarsi che i dati non vadano persi, è necessario eseguire con attenzione l'arresto finale del database originale.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">In primo luogo, la base di dati deve essere chiusa, garantendo che non vengano apportate modifiche. Questa chiusura potrebbe includere la disattivazione delle operazioni pianificate, la chiusura dei listener e/o la chiusura delle applicazioni.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Una volta eseguita questa operazione, la maggior parte dei DBA crea una tabella fittizia da utilizzare come indicatore dell'arresto.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Forzare l'archiviazione di un registro per assicurarsi che la creazione della tabella fittizia sia registrata nei registri di archivio. A tale scopo, eseguire i seguenti comandi:</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Per copiare l'ultimo dei registri di archivio, eseguire i seguenti comandi. Il database deve essere disponibile ma non aperto.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Per copiare i log di archivio, eseguire i seguenti comandi:</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Infine, riprodurre i log di archivio rimanenti sul nuovo server.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">In questa fase, replicare tutti i dati. Il database è pronto per essere convertito da un database di standby a un database operativo attivo e quindi aperto.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Verificare la presenza della tabella fittizia e poi rilasciarla.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Migrazione dei log di ripristino senza interruzioni</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">A volte, un database è organizzato correttamente in generale, ad eccezione dei registri di ripristino. Questo può accadere per molte ragioni, la più comune delle quali è correlata agli snapshot. Prodotti come SnapManager per Oracle, SnapCenter e il framework di gestione dello storage NetApp Snap Creator consentono il ripristino quasi istantaneo di un database, ma solo se vengono ripristinati i volumi dei file di dati. Se i log di redo condividono lo spazio con i file di dati, non è possibile eseguire la reversione in modo sicuro, poiché causerebbe la distruzione dei log di redo, probabilmente la perdita di dati. Pertanto, i log di ripristino devono essere spostati.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Questa procedura è semplice e può essere eseguita senza interruzioni.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Configurazione corrente del log di ripristino</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Identificare il numero di gruppi di log di ripristino e i rispettivi numeri di gruppo.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Immettere le dimensioni dei registri di ripristino.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Creare nuovi registri</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo con dimensioni e numero di membri corrispondenti.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Verificare la nuova configurazione.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Rilasciare i vecchi registri</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Rilasciare i vecchi registri (gruppi 1, 2 e 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Se si verifica un errore che impedisce di rilasciare un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un checkpoint globale. Fare riferimento al seguente esempio di questo processo. Il tentativo di rilasciare il gruppo di file di registro 2, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Un'archiviazione dei log seguita da un punto di verifica consente di rilasciare il file di log.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">Quindi, eliminare i log dal file system. Questo processo deve essere eseguito con estrema attenzione.</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">La migrazione dei dati Oracle può avvenire a uno di tre livelli: Database, host o storage array.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Le differenze risiedono in quale componente della soluzione globale è responsabile dello spostamento dei dati: Il database, il sistema operativo host o il sistema di archiviazione.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">La figura riportata di seguito mostra un esempio dei livelli di migrazione e del flusso di dati. In caso di migrazione a livello di database, i dati vengono spostati dal sistema di storage originale ai livelli di host e database nel nuovo ambiente. La migrazione a livello di host è simile, ma i dati non passano attraverso il livello di applicazione e vengono invece scritti nella nuova posizione utilizzando i processi degli host. Infine, con la migrazione a livello di storage, un array come un sistema NetApp FAS si occupa dello spostamento dei dati.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Una migrazione a livello di database si riferisce generalmente all'utilizzo di Oracle log shipping attraverso un database di standby per completare una migrazione a livello di Oracle. Le migrazioni a livello di host vengono eseguite utilizzando le funzionalità native della configurazione del sistema operativo host. Questa configurazione include le operazioni di copia dei file utilizzando comandi quali cp, tar e Oracle Recovery Manager (RMAN) o un gestore del volume logico (LVM) per spostare i byte sottostanti di un file system. Oracle Automatic Storage Management (ASM) è classificato come capacità a livello di host perché viene eseguito al di sotto del livello dell'applicazione di database. ASM sostituisce il normale volume manager logico su un host. Infine, i dati possono essere migrati a livello di storage array, il che significa sotto il livello del sistema operativo.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Considerazioni sulla pianificazione</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">La scelta migliore per la migrazione dipende da una combinazione di fattori, inclusa la dimensione dell'ambiente da migrare, la necessità di evitare il downtime e lo sforzo complessivo necessario per eseguire la migrazione. Ovviamente, i database di grandi dimensioni richiedono più tempo e lavoro per la migrazione, ma la complessità di una migrazione di questo tipo è minima. I database di piccole dimensioni possono essere migrati rapidamente, ma se ne devono migrare migliaia, la portata dello sforzo può creare complicazioni. Infine, più grande è il database, più probabile è che l'IT sia business-critical, generando la necessità di ridurre al minimo i downtime mantenendo un percorso di back-out.</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Alcune considerazioni per la pianificazione di una strategia di migrazione sono discusse qui.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Dimensioni dei dati</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">Le dimensioni dei database da migrare influiscono ovviamente sulla pianificazione della migrazione, sebbene le dimensioni non influiscano necessariamente sul tempo di cutover. Quando è necessario migrare una grande quantità di dati, l'aspetto più importante è la larghezza di banda. Le operazioni di copia vengono in genere eseguite con un efficiente i/o sequenziale Come stima conservativa, si presuppone un utilizzo del 50% della larghezza di banda della rete disponibile per le operazioni di copia. Ad esempio, una porta FC da 8GB GB può trasferire in teoria circa 800Mbps GB. Ipotizzando un utilizzo del 50%, è possibile copiare un database a una velocità di circa 400Mbps KB. Pertanto, un database 10TB può essere copiato in circa sette ore a questa velocità.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Spostamento file dati online</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Numero di database</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">In molti casi, il problema dello spostamento di una grande quantità di dati non è la dimensione dei dati, ma piuttosto la complessità della configurazione che supporta il database. Semplicemente sapere che 50TB database devono essere migrati non è sufficiente. Può essere un singolo database mission-critical 50TB, una raccolta di 4 database legacy 000 o un mix di dati di produzione e non. In alcuni casi, gran parte dei dati è costituita da cloni di un database di origine. Non è necessario migrare questi cloni perché possono essere facilmente ricreati, specialmente quando la nuova architettura è progettata per sfruttare i volumi FlexClone di NetApp.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Per la pianificazione della migrazione, è necessario comprendere il numero dei database interessati e la priorità da assegnare. Con l'aumento del numero di database, l'opzione di migrazione preferita tende a essere più bassa e più bassa nello stack. Ad esempio, la copia di un singolo database può essere eseguita facilmente con RMAN e con una breve interruzione del servizio. Si tratta di una replica a livello di host.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">Se ci sono 50 database, potrebbe essere più facile evitare di impostare una nuova struttura del file system per ricevere una copia RMAN e spostare invece i dati sul posto. Questo processo può essere eseguito sfruttando la migrazione LVM basata su host per spostare i dati dalle vecchie LUN ai nuovi LUN. In tal modo, la responsabilità viene trasferita dal team di amministratori del database (DBA) al team del sistema operativo e, di conseguenza, i dati vengono migrati in modo trasparente rispetto al database. La configurazione del file system rimane invariata.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Infine, se occorre migrare 500 database su 200 server, è possibile utilizzare opzioni basate sullo storage come la funzionalità FLI (ONTAP Foreign LUN Import) per eseguire una migrazione diretta delle LUN.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Requisiti di riarchitettura</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">In genere, per sfruttare le funzionalità del nuovo storage array è necessario modificare il layout dei file del database; tuttavia, non sempre questo avviene. Ad esempio, le funzionalità degli array all-flash EF-Series sono rivolte principalmente alle performance e all'affidabilità della SAN. Nella maggior parte dei casi, i database possono essere migrati su un array EF-Series senza particolari considerazioni sul layout dei dati. Gli unici requisiti sono IOPS elevati, bassa latenza e solida affidabilità. Sebbene esistano Best practice correlate a fattori quali la configurazione RAID o Dynamic Disk Pools, i progetti EF-Series raramente richiedono modifiche significative all'architettura dello storage generale per sfruttare tali funzionalità.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">Al contrario, la migrazione a ONTAP richiede in genere una maggiore considerazione del layout del database per garantire che la configurazione finale fornisca il massimo valore. In sé, ONTAP offre molte funzionalità per un ambiente di database, anche senza interventi specifici sull'architettura. Soprattutto, offre la possibilità di migrare senza interruzioni al nuovo hardware quando l'hardware attuale termina la sua vita utile. In generale, la migrazione a ONTAP è l'ultima migrazione che è necessario eseguire. L'hardware successivo viene aggiornato e i dati vengono migrati senza interruzioni sui nuovi supporti.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Con una certa pianificazione, ancora più benefici sono disponibili. Le considerazioni più importanti riguardano l'uso delle istantanee. Le snapshot sono la base per l'esecuzione di backup, ripristini e operazioni di cloning quasi istantanei. Come esempio della potenza delle istantanee, il più grande utilizzo noto è con un singolo database di 996TB in esecuzione su circa 250 LUN su 6 controller. È possibile eseguire il backup di questo database in 2 minuti, ripristinarlo in 2 minuti e clonarlo in 15 minuti. Tra gli altri benefici, è inclusa la capacità di spostare i dati nel cluster in risposta alle variazioni del carico di lavoro e all'applicazione di controlli di qualità del servizio (QoS) per offrire performance buone e coerenti in un ambiente multi-database.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Panoramica delle procedure di migrazione Oracle</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Tecnologie come controlli della QoS, trasferimento dei dati, snapshot e cloning funzionano praticamente in ogni configurazione. Tuttavia, un certo pensiero è generalmente richiesto per elevare i benefici. In alcuni casi, i layout dello storage del database possono richiedere modifiche di progettazione per massimizzare l'investimento nel nuovo storage array. Tali modifiche di progettazione possono influire sulla strategia di migrazione perché le migrazioni basate su host o su storage replicano il layout dei dati originale. Per completare la migrazione e offrire un layout dei dati ottimizzato per ONTAP potrebbero essere necessari ulteriori passaggi. Le procedure illustrate nella <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> in seguito, dimostrare alcuni metodi non solo per migrare un database, ma anche per eseguirne la migrazione nel layout finale ottimale con il minimo sforzo.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Tempo di cutover</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Occorre determinare il disservizio massimo consentito del servizio durante il cutover. È un errore comune presumere che l'intero processo di migrazione causi interruzioni. È possibile eseguire numerose attività prima dell'inizio di qualsiasi interruzione del servizio e completare la migrazione senza interruzioni o black-out attraverso diverse opzioni. Anche quando è inevitabile un'interruzione, è comunque necessario definire il fuori servizio massimo consentito poiché la durata del tempo di cutover varia da procedura a procedura.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Percorso di ritorno</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Nessuna migrazione è completamente priva di rischi. Anche se la tecnologia funziona perfettamente, c'è sempre la possibilità di errori da parte dell'utente. Il rischio associato a un percorso di migrazione scelto deve essere preso in considerazione insieme alle conseguenze di una migrazione non riuscita. Ad esempio, la capacità di migrazione trasparente dello storage online di Oracle ASM è una delle sue caratteristiche principali e questo metodo è uno dei più affidabili. Tuttavia, i dati vengono copiati irreversibilmente con questo metodo. Nel caso altamente improbabile in cui si verifichi un problema con ASM, non esiste un facile percorso di back-out. L'unica opzione è ripristinare l'ambiente originale o utilizzare ASM per riportare la migrazione ai LUN originali. Il rischio può essere minimizzato, ma non eliminato, eseguendo un backup di tipo snapshot sul sistema di storage originale, supponendo che il sistema sia in grado di eseguire tale operazione.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Prova</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Alcune procedure di migrazione devono essere verificate completamente prima dell'esecuzione. La necessità di migrazione e verifica del processo di cutover è una richiesta comune con i database mission-critical per i quali la migrazione deve avere successo e il downtime deve essere ridotto al minimo. Inoltre, i test di accettazione da parte dell'utente sono spesso inclusi come parte del lavoro di post-migrazione e il sistema complessivo può essere riportato in produzione solo dopo il completamento di questi test.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">In caso di necessità di prove, diverse funzionalità di ONTAP possono rendere il processo molto più semplice. In particolare, le istantanee possono ripristinare un ambiente di test e creare rapidamente più copie di un ambiente di database efficienti in termini di spazio.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migrazione di singoli file di dati Oracle</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Spostamento del file dati</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">È possibile spostare singoli file di dati Oracle con un singolo comando.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Ad esempio, il comando seguente sposta il file dati IOPST.dbf dal filesystem<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> al filesystem<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Lo spostamento di un file dati con questo metodo può essere lento, ma in genere non dovrebbe produrre i/o sufficienti da interferire con i carichi di lavoro del database quotidiani. Al contrario, la migrazione tramite il ribilanciamento di ASM può essere eseguita molto più rapidamente, ma con il rischio di rallentare il database globale durante lo spostamento dei dati.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">È possibile misurare facilmente il tempo necessario per spostare i file di dati creando un file di dati di test e spostandolo. Il tempo trascorso per l'operazione viene registrato nei dati di v$session:</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">In questo esempio, il file spostato era datafile 8, della dimensione di 21GB GB e della durata di 6 minuti per la migrazione. Il tempo necessario dipende ovviamente dalle funzionalità del sistema di storage, della rete di storage e dall'attività complessiva del database che si verifica al momento della migrazione.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Migrazione di Oracle mediante lo stack di storage lato host</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">Come per la migrazione a livello di database, la migrazione nel layer host fornisce un approccio indipendente dal vendor di soluzioni di storage.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">In altre parole, talvolta "basta copiare i file" è l'opzione migliore.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Sebbene questo approccio a bassa tecnologia possa sembrare troppo semplice, offre comunque vantaggi significativi in quanto non è richiesto alcun software speciale e i dati originali rimangono intatti in tutta sicurezza durante il processo. Il limite principale è rappresentato dal fatto che la migrazione dei dati di una copia file causa interruzioni, poiché il database deve essere arrestato prima dell'inizio dell'operazione di copia. Non esiste un buon modo per sincronizzare le modifiche all'interno di un file, quindi i file devono essere completamente disattivati prima che la copia abbia inizio.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Se l'arresto richiesto da un'operazione di copia non è desiderabile, l'opzione successiva migliore basata su host è sfruttare un Logical Volume Manager (LVM). Esistono molte opzioni LVM, tra cui Oracle ASM, tutte con funzionalità simili, ma anche con alcune limitazioni che è necessario tenere in considerazione. Nella maggior parte dei casi, la migrazione può essere eseguita senza downtime e interruzioni.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Copia da filesystem a filesystem</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">L'utilità di una semplice operazione di copia non deve essere sottovalutata. Si tratta di un processo altamente affidabile che non richiede particolari competenze su sistemi operativi, database o sistemi storage. Inoltre, è molto sicuro perché non influisce sui dati originali. In genere, un amministratore di sistema modifica i file system di origine in modo che vengano montati in sola lettura e quindi riavvia un server per garantire che nessun elemento possa danneggiare i dati correnti. Il processo di copia può essere eseguito tramite script per garantire che venga eseguito il più rapidamente possibile senza il rischio di errori dell'utente. Poiché il tipo di i/o è un semplice trasferimento sequenziale dei dati, risulta estremamente efficiente in termini di larghezza di banda.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">Nell'esempio seguente viene illustrata un'opzione per una migrazione sicura e rapida.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">L'ambiente da migrare è il seguente:</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">File system attuali</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Nuovi file system</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Panoramica</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">Un DBA può migrare il database chiudendo semplicemente il database e copiando i file. Tuttavia, se occorre migrare molti database o ridurre al minimo il downtime, il processo può essere facilmente gestito tramite script. L'utilizzo di script riduce inoltre la possibilità di errori da parte dell'utente.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Gli script di esempio illustrati automatizzano le seguenti operazioni:</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Chiusura del database in corso</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Conversione dei file system esistenti in uno stato di sola lettura</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Copiare tutti i dati dai file system di origine a quelli di destinazione, mantenendo tutte le autorizzazioni dei file</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Smontaggio dei file system vecchi e nuovi</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Rimontaggio dei nuovi file system negli stessi percorsi dei file system precedenti</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Procedura</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Arrestare il database.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Convertire il file system in sola lettura</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Convertire i file system in sola lettura. Questa operazione può essere eseguita più rapidamente utilizzando uno script, come illustrato nella <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Verificare che i file system siano ora di sola lettura.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Sincronizzare il contenuto del file system con<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> comando.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Sostituire il file system</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Smontare i vecchi file system e riposizionare i dati copiati. Questa operazione può essere eseguita più rapidamente utilizzando uno script, come illustrato nella <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Verificare che i nuovi file system siano in posizione.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Avviare il database.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Cutover completamente automatizzato</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Questo script di esempio accetta argomenti del SID del database seguiti da coppie di file system delimitate in comune. Per l'esempio sopra illustrato, il comando viene inviato come segue:</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Quando viene eseguito, lo script di esempio tenta di eseguire la seguente sequenza. Termina se incontra un errore in qualsiasi fase:</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Convertire i file system correnti in stato di sola lettura.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Utilizzare ciascuna coppia di argomenti del file system delimitati da virgole e sincronizzare il primo file system con il secondo.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Smontare i file system precedenti.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Aggiornare<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archiviare come segue:</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Creare un backup in<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Annotare le voci precedenti per i file system precedenti e nuovi.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Creare una nuova voce per il nuovo file system che utilizza il vecchio punto di montaggio.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Montare i file system.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">Il testo seguente fornisce un esempio di esecuzione per questo script:</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Migrazione Oracle ASM spfile e passwd</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Una difficoltà nel completare la migrazione che coinvolge ASM è rappresentata dallo spfile specifico per ASM e dal file delle password. Per impostazione predefinita, questi file di metadati critici vengono creati nel primo gruppo di dischi ASM definito. Se un particolare gruppo di dischi ASM deve essere evacuato e rimosso, il file spfile e la password che governano l'istanza ASM deve essere riposizionato.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Un altro caso d'utilizzo in cui potrebbe essere necessario trasferire questi file è durante una distribuzione di software di gestione del database, come SnapManager per Oracle o il plug-in SnapCenter Oracle. Una delle funzionalità di questi prodotti è il ripristino rapido di un database ripristinando lo stato dei LUN ASM che ospitano i file di dati. Per eseguire questa operazione, è necessario portare il gruppo di dischi ASM offline prima di eseguire un ripristino. Questo non è un problema, purché i file di dati di un determinato database siano isolati in un gruppo di dischi ASM dedicato.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Quando il gruppo di dischi contiene anche il file ASM spfile/passwd, l'unico modo per mettere il gruppo di dischi in modalità non in linea è arrestare l'intera istanza ASM. Si tratta di un processo di interruzione, il che significa che il file spfile/passwd dovrebbe essere riposizionato.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">SID database = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">File di dati correnti su<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">File di log e file di controllo correnti attivati<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Nuovi gruppi di dischi ASM stabiliti come<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> e.<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Posizioni dei file spfile/passwd ASM</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">Il trasferimento di questi file può essere eseguito senza interruzione delle attività. Tuttavia, per motivi di sicurezza, NetApp consiglia di arrestare l'ambiente del database in modo da poter essere certi che i file siano stati spostati e che la configurazione sia stata aggiornata correttamente. Questa procedura deve essere ripetuta se su un server sono presenti più istanze ASM.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Identificare le istanze ASM</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Identificare le istanze ASM in base ai dati registrati in<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> file. Le istanze di ASM sono indicate dal simbolo +.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Su questo server è presente un'istanza ASM denominata +ASM.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Assicurarsi che tutti i database siano chiusi</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">L'unico processo di smon visibile dovrebbe essere quello per l'istanza ASM in uso. La presenza di un altro processo di smon indica che un database è ancora in esecuzione.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">L'unico processo di smon è l'istanza ASM stessa. Ciò significa che nessun altro database è in esecuzione ed è sicuro procedere senza il rischio di interrompere le operazioni del database.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Individuare i file</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Identificare la posizione corrente del file spfile e della password di ASM utilizzando<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> e.<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> comandi.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">I file si trovano entrambi alla base di<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> gruppo di dischi.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Copiare i file</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Copiare i file nel nuovo gruppo di dischi ASM con<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> e.<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> comandi. Se il nuovo gruppo di dischi è stato creato di recente ed è attualmente vuoto, potrebbe essere necessario montarlo per primo.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">I file sono stati copiati da<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> a.<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">Aggiornare l'istanza ASM</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">L'istanza ASM deve ora essere aggiornata per riflettere la modifica della posizione. Il<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> e.<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> I comandi aggiornano i metadati ASM richiesti per l'avvio del gruppo di dischi ASM.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Attivare ASM utilizzando i file aggiornati</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">A questo punto, l'istanza ASM utilizza ancora le posizioni precedenti di questi file. L'istanza deve essere riavviata per forzare una rilettura dei file dalle nuove posizioni e per rilasciare i blocchi sui file precedenti.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Rimuovere i vecchi file spfile e password</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Se la procedura è stata eseguita correttamente, i file precedenti non sono più bloccati e possono essere rimossi.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Copia da Oracle ASM a ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM è essenzialmente un volume manager e un file system combinati e leggeri. Poiché il file system non è facilmente visibile, è necessario utilizzare RMAN per eseguire operazioni di copia. Sebbene il processo di migrazione basato sulle copie sia sicuro e semplice, si traduce in un'interruzione. È possibile ridurre al minimo le interruzioni, ma non eliminarle completamente.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Se si desidera eseguire la migrazione senza interruzioni di un database basato su ASM, l'opzione migliore è sfruttare la capacità di ASM di riequilibrare le estensioni ASM nei nuovi LUN, eliminando al contempo i vecchi LUN. In genere, questo tipo di operazioni è sicuro e senza interruzioni, ma non offre alcun percorso di back-out. Se si riscontrano problemi di funzionamento o di prestazioni, l'unica opzione è quella di trasferire nuovamente i dati all'origine.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Questo rischio può essere evitato copiando il database nella nuova posizione piuttosto che spostare i dati, in modo che i dati originali non vengano toccati. Il database può essere completamente testato nella sua nuova posizione prima di entrare in funzione e il database originale è disponibile come opzione di fallback se vengono rilevati problemi.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Questa procedura è una delle numerose opzioni che interessano RMAN. È progettato per consentire un processo in due fasi in cui viene creato il backup iniziale e quindi sincronizzato successivamente tramite la riproduzione del registro. Questo processo è auspicabile per ridurre al minimo i tempi di inattività, in quanto consente al database di rimanere operativo e di distribuire i dati durante la copia di base iniziale.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Copia database</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN crea una copia di livello 0 (completa) del database di origine attualmente presente nel gruppo di dischi ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> alla nuova posizione su<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Forzare l'interruttore del registro di archiviazione</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">È necessario forzare un'opzione del log di archivio per assicurarsi che i log di archivio contengano tutti i dati necessari per rendere la copia completamente coerente. Senza questo comando, i dati chiave potrebbero essere ancora presenti nei log di ripristino.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Arrestare il database di origine</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">L'interruzione inizia in questa fase perché il database viene arrestato e inserito in una modalità di sola lettura ad accesso limitato. Per arrestare il database di origine, eseguire i seguenti comandi:</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Backup ControlFile</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">È necessario eseguire il backup di controlfile nel caso in cui sia necessario interrompere la migrazione e ripristinare la posizione di archiviazione originale. Una copia del controlfile di backup non è richiesta al 100%, ma rende più semplice il processo di ripristino delle posizioni dei file di database nella posizione originale.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">Il file spfile corrente contiene riferimenti ai file di controllo nelle posizioni correnti all'interno del vecchio gruppo di dischi ASM. Deve essere modificato, il che è fatto facilmente modificando una versione pfile intermedia.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Aggiornare pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Aggiornare tutti i parametri che fanno riferimento ai vecchi gruppi di dischi ASM per riflettere i nuovi nomi dei gruppi di dischi ASM. Quindi salvare il file pfile aggiornato. Assicurarsi che il<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> parametri presenti.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">Nell'esempio seguente, i riferimenti a.<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> che sono stati modificati in<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> sono evidenziati in giallo. Due parametri chiave sono<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> parametri che creano nuovi file nella posizione corretta.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Aggiorna il file init.ora</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">La maggior parte dei database basati su ASM utilizza un<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file che si trova in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Directory, che è un punto di spfile sul gruppo di dischi ASM. Questo file deve essere reindirizzato a una posizione sul nuovo gruppo di dischi ASM.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Modificare questo file come segue:</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Ricreazione del file dei parametri</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">spfile è ora pronto per essere popolato dai dati nel pfile modificato.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Avviare il database per iniziare a utilizzare il nuovo spfile</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Avviare il database per assicurarsi che utilizzi ora il nuovo spfile creato e che eventuali ulteriori modifiche ai parametri di sistema siano registrate correttamente.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Ripristina controlfile</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">Il controlfile di backup creato da RMAN può anche essere ripristinato da RMAN direttamente nella posizione specificata nel nuovo spfile.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Montare il database e verificare l'uso del nuovo controlfile.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Riproduzione del registro</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">Il database utilizza attualmente i file di dati nella vecchia posizione. Prima di poter utilizzare la copia, è necessario sincronizzarla. È trascorso del tempo durante il processo di copia iniziale e le modifiche sono state registrate principalmente nei registri di archivio. Queste modifiche vengono replicate come segue:</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Eseguire un backup incrementale RMAN, che contiene i registri di archivio.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Riprodurre nuovamente il registro.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Attivazione</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">Il controlfile ripristinato fa ancora riferimento ai file di dati nella posizione originale e contiene anche le informazioni di percorso per i file di dati copiati.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Per modificare i file di dati attivi, eseguire<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">I file di dati attivi sono ora i file di dati copiati, ma potrebbero comunque essere presenti modifiche nei log di ripristino finali.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Per riprodurre tutti i registri rimanenti, eseguire il<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando. Se il messaggio<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> il processo è stato eseguito correttamente.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Questo processo ha modificato solo la posizione dei file di dati normali. I file di dati temporanei devono essere rinominati, ma non devono essere copiati perché sono solo temporanei. Il database è attualmente inattivo, pertanto non sono presenti dati attivi nei file di dati temporanei.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Per spostare i file di dati temporanei, identificarne prima la posizione.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Spostare i file di dati temporanei utilizzando un comando RMAN che imposta il nuovo nome per ciascun file di dati. Con Oracle Managed Files (OMF), il nome completo non è necessario; il gruppo di dischi ASM è sufficiente. Quando il database viene aperto, OMF si collega alla posizione appropriata nel gruppo di dischi ASM. Per spostare i file, eseguire i seguenti comandi:</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migrazione dei log di ripristino</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">Il processo di migrazione è quasi completo, ma i log di ripristino si trovano ancora nel gruppo di dischi ASM originale. I log di ripristino non possono essere spostati direttamente. Viene invece creata una nuova serie di log di ripristino che viene aggiunta alla configurazione, seguita da una rimozione dei log precedenti.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo con una configurazione corrispondente. Se non si utilizza OMF, è necessario specificare il percorso completo. Questo è anche un esempio che utilizza<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> parametri. Come mostrato in precedenza, questo parametro era impostato su +NEWLOGS. Questa configurazione consente di utilizzare i seguenti comandi per creare nuovi registri online senza dover specificare un percorso di file o un gruppo di dischi ASM specifico.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Aprire il database.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Rilasciare i vecchi registri.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Se si verifica un errore che impedisce di rilasciare un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un checkpoint globale. Di seguito è riportato un esempio. Il tentativo di rilasciare il gruppo di file di registro 3, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi. L'archiviazione di un registro dopo un punto di verifica consente di eliminare il file di registro.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Esaminare l'ambiente per assicurarsi che tutti i parametri basati sulla posizione siano aggiornati.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">Nello script seguente viene illustrato come semplificare questo processo:</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Se i gruppi di dischi ASM sono stati completamente evacuati, è possibile smontarli con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Tuttavia, in molti casi i file appartenenti ad altri database o al file ASM spfile/passwd potrebbero essere ancora presenti.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Copia da Oracle ASM al file system</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">La procedura di copia da Oracle ASM a file system è molto simile alla procedura di copia da ASM a ASM, con vantaggi e restrizioni simili. La differenza principale è la sintassi dei vari comandi e parametri di configurazione quando si utilizza un file system visibile anziché un gruppo di dischi ASM.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN viene utilizzato per creare una copia di livello 0 (completa) del database di origine attualmente presente nel gruppo di dischi ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> alla nuova posizione su<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">È necessario forzare lo switch del log di archivio per assicurarsi che i log di archivio contengano tutti i dati necessari per rendere la copia completamente coerente. Senza questo comando, i dati chiave potrebbero essere ancora presenti nei log di ripristino. Per forzare un'opzione del log di archivio, eseguire il comando seguente:</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">L'interruzione inizia in questa fase perché il database viene arrestato e inserito in una modalità di sola lettura ad accesso limitato. Per arrestare il database di origine, eseguire i seguenti comandi:</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Eseguire il backup dei file di controllo nel caso in cui sia necessario interrompere la migrazione e ripristinare la posizione di archiviazione originale. Una copia del controlfile di backup non è richiesta al 100%, ma rende più semplice il processo di ripristino delle posizioni dei file di database nella posizione originale.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Tutti i parametri che fanno riferimento ai vecchi gruppi di dischi ASM devono essere aggiornati e, in alcuni casi, eliminati quando non sono più rilevanti. Aggiornarli per riflettere i nuovi percorsi del file system e salvare il file pfile aggiornato. Assicurarsi che sia elencato il percorso di destinazione completo. Per aggiornare questi parametri, eseguire i seguenti comandi:</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Disattivare il file init.ora originale</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Questo file si trova in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Ed è in genere in un pfile che funge da puntatore a spfile sul gruppo di dischi ASM. Per assicurarsi che spfile originale non sia più utilizzato, rinominarlo. Non eliminarlo, tuttavia, perché questo file è necessario se la migrazione deve essere interrotta.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Questa è la fase finale del trasferimento di spfile. Il file spfile originale non viene più utilizzato e il database viene avviato (ma non montato) utilizzando il file intermedio. Il contenuto di questo file può essere scritto nella nuova posizione spfile come segue:</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">È necessario avviare il database per rilasciare i blocchi sul file intermedio e avviare il database utilizzando solo il nuovo file spfile. L'avvio del database dimostra inoltre che la nuova posizione di spfile è corretta e che i suoi dati sono validi.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">È stato creato un controlfile di backup nel percorso<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> nelle fasi precedenti della procedura. Il nuovo spfile definisce le posizioni controlfile come <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> e.<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Tuttavia, tali file non esistono ancora.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Questo comando ripristina i dati controlfile nei percorsi definiti in spfile.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Eseguire il comando mount in modo che i file di controllo vengano rilevati correttamente e contengano dati validi.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Per convalidare<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> eseguire il seguente comando:</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">Il database sta attualmente utilizzando i file di dati nella vecchia posizione. Prima di poter utilizzare la copia, è necessario sincronizzare i file di dati. È trascorso del tempo durante il processo di copia iniziale e le modifiche sono state registrate principalmente nei registri di archivio. Queste modifiche vengono replicate nei due passaggi seguenti.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Riprodurre i registri.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Per modificare i file di dati attivi, eseguire<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando:</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Sebbene i file di dati debbano essere completamente coerenti, è necessario eseguire un passaggio finale per riprodurre le modifiche rimanenti registrate nei registri di ripristino online. Utilizzare<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando per riprodurre queste modifiche e rendere la copia identica al 100% all'originale. Tuttavia, la copia non è ancora aperta.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Spostare i file di dati temporanei</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Identificare la posizione dei file di dati temporanei ancora in uso sul gruppo di dischi originale.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Per spostare i file di dati, eseguire i seguenti comandi. Se ci sono molti tempfile, utilizzare un editor di testo per creare il comando RMAN e quindi tagliarlo e incollarlo.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">Il processo di migrazione è quasi completo, ma i log di ripristino si trovano ancora nel gruppo di dischi ASM originale. I log di ripristino non possono essere spostati direttamente. Al contrario, viene creata e aggiunta alla configurazione una nuova serie di log di ripristino, in seguito a una perdita dei vecchi log.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo utilizzando le stesse dimensioni del gruppo di log di ripristino corrente utilizzando la nuova posizione del file system.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Rimuovere i vecchi gruppi di file di registro che si trovano ancora nell'archivio precedente.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Se si verifica un errore che blocca l'eliminazione di un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un punto di verifica globale. Di seguito è riportato un esempio. Il tentativo di rilasciare il gruppo di file di registro 3, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi. L'archiviazione dei log seguita da un punto di verifica consente l'eliminazione dei file di log.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">Nel seguente script viene illustrato come semplificare questo processo.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Se i gruppi di dischi ASM sono stati completamente evacuati, è possibile smontarli con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. In molti casi, i file appartenenti ad altri database o al file ASM spfile/passwd possono essere ancora presenti.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Procedura di pulizia del file di dati</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Pulitura della migrazione ASM</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">Il processo di migrazione potrebbe generare file di dati con sintassi lunga o criptica, a seconda del modo in cui è stato utilizzato Oracle RMAN. Nell'esempio illustrato, il backup è stato eseguito con il formato file di<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Indica che RMAN deve creare un nome univoco predefinito per ciascun file di dati. Il risultato è simile a quanto illustrato nel testo seguente. I nomi tradizionali dei file di dati sono incorporati nei nomi. Questo può essere ripulito utilizzando l'approccio basato su script illustrato nella <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Ribilanciamento di Oracle ASM</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Come indicato in precedenza, è possibile eseguire la migrazione trasparente di un gruppo di dischi Oracle ASM in un nuovo sistema di storage utilizzando il processo di ribilanciamento. Riassumendo, il processo di ribilanciamento richiede l'aggiunta di LUN di dimensioni uguali al gruppo esistente di LUN, seguita da un'operazione di disgregazione del LUN precedente. Oracle ASM riposiziona automaticamente i dati sottostanti nel nuovo storage in un layout ottimale e, al termine, rilascia i vecchi LUN.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">Il processo di migrazione utilizza un i/o sequenziale efficiente e non causa generalmente un'interruzione delle performance, ma la velocità di migrazione può essere rallentata quando necessario.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identificazione dei dati da migrare</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Creazione di nuovi LUN</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Creare nuovi LUN delle stesse dimensioni e impostare l'appartenenza a utenti e gruppi come richiesto. I LUN devono essere visualizzati come<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> dischi.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Aggiungere nuovi LUN</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Anche se è possibile eseguire tutte le operazioni di aggiunta e rilascio, in genere è più semplice aggiungere nuovi LUN in due passaggi. Innanzitutto, aggiungere i nuovi LUN al gruppo di dischi. Questo passaggio comporta la migrazione di metà delle estensioni dai LUN ASM correnti ai nuovi LUN.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">La potenza di riequilibrio indica la velocità di trasferimento dei dati. Più alto è il numero, più alto è il parallelismo del trasferimento dei dati. La migrazione viene eseguita con efficienti operazioni di i/o sequenziali che hanno scarse probabilità di causare problemi di performance. Tuttavia, se lo si desidera, il potere di riequilibrio di una migrazione in corso può essere regolato con<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> comando. Le migrazioni tipiche utilizzano un valore di 5.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Funzionamento del monitor</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">È possibile monitorare e gestire un'operazione di ribilanciamento in più modi. Per questo esempio è stato utilizzato il comando seguente.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Una volta completata la migrazione, non vengono segnalate operazioni di ribilanciamento.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">LUN meno recenti</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">La migrazione è ormai a metà strada. Potrebbe essere opportuno eseguire alcuni test delle prestazioni di base per assicurarsi che l'ambiente sia sano. Dopo la conferma, è possibile spostare i dati rimanenti eliminando i vecchi LUN. Tenere presente che ciò non determina il rilascio immediato dei LUN. L'operazione di rilascio indica ad Oracle ASM di riposizionare prima le estensioni e quindi rilasciare il LUN.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">L'operazione di ribilanciamento può essere monitorata e gestita in più modi. Per questo esempio è stato utilizzato il seguente comando:</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Rimuovere i vecchi LUN</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Prima di rimuovere i vecchi LUN dal gruppo di dischi, è necessario eseguire un controllo finale dello stato dell'intestazione. Dopo il rilascio di un LUN da ASM, non viene più elencato un nome e lo stato dell'intestazione viene elencato come<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Questo indica che questi LUN possono essere rimossi in modo sicuro dal sistema.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">Migrazione LVM</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">La procedura qui presentata mostra i principi di una migrazione basata su LVM di un gruppo di volumi chiamato<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Gli esempi sono tratti da Linux LVM, ma i principi si applicano ugualmente a AIX, HP-UX e VxVM. I comandi precisi possono variare.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identificare i LUN attualmente presenti in<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> gruppo di volumi.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Creazione di nuovi LUN di dimensioni fisiche identiche o leggermente superiori e definizione di volumi fisici.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Aggiungere i nuovi volumi al gruppo di volumi.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Eseguire il<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Comando per spostare le estensioni di ogni LUN corrente nel nuovo LUN. Il<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> l'argomento controlla l'avanzamento dell'operazione.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Una volta completato questo processo, rimuovere i LUN precedenti dal gruppo di volumi utilizzando<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> comando. Se l'operazione ha esito positivo, è ora possibile rimuovere il LUN dal sistema in modo sicuro.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Procedure di migrazione Oracle</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">Sono disponibili molte procedure per il database di migrazione Oracle. La giusta dipende dalle vostre esigenze aziendali.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">In molti casi, gli amministratori di sistema e i DBA dispongono dei propri metodi preferiti per trasferire i dati dei volumi fisici, eseguire il mirroring e il demirroring o utilizzare Oracle RMAN per copiare i dati.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Queste procedure vengono fornite principalmente come guida per il personale IT meno esperto di alcune delle opzioni disponibili. Inoltre, vengono illustrate le attività, i requisiti di tempo e le richieste di competenze per ogni approccio alla migrazione. Ciò consente ad altre parti, come NetApp e i servizi professionali dei partner o i responsabili dell'IT, di apprezzare più pienamente i requisiti di ogni procedura.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">Non esiste un'unica Best practice per la creazione di una strategia di migrazione. La creazione di un piano richiede prima di tutto la comprensione delle opzioni di disponibilità e quindi la selezione del metodo più adatto alle esigenze dell'azienda. La figura seguente illustra le considerazioni di base e le conclusioni tipiche dei clienti, ma non è applicabile a tutte le situazioni.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Ad esempio, un passaggio solleva il problema della dimensione totale del database. Il passaggio successivo dipende dal fatto che il database sia maggiore o minore di 1TB. I passaggi consigliati sono solo questi: Consigli basati su pratiche tipiche del cliente. La maggior parte dei clienti non utilizzerebbe DataGuard per copiare un database di piccole dimensioni, ma alcuni potrebbero farlo. La maggior parte dei clienti non tenterebbe di copiare un database 50TB per il tempo necessario, ma alcuni potrebbero avere una finestra di manutenzione sufficientemente grande da consentire tale operazione.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 e versioni successive includono la possibilità di spostare un file dati mentre il database rimane online. Inoltre funziona tra diversi tipi di filesystem. Ad esempio, è possibile spostare un file dati da un filesystem xfs ad ASM. Questo metodo non viene generalmente utilizzato su larga scala a causa del numero di operazioni singole di spostamento del file di dati che sarebbero necessarie, ma è un'opzione che vale la pena considerare con database più piccoli con meno file di dati.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">Inoltre, il semplice spostamento di un file dati è un'ottima opzione per la migrazione di parti di database esistenti. Ad esempio, è possibile ricollocare i file di dati meno attivi in uno storage più conveniente, ad esempio un volume FabricPool che consente di memorizzare blocchi inattivi in Object Store.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migrazione a livello di database</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">La migrazione a livello di database significa consentire il trasferimento dei dati. In particolare, ciò significa spedizione dei log. Tecnologie come RMAN e ASM sono prodotti Oracle, ma, ai fini della migrazione, operano a livello di host in cui copiano i file e gestiscono i volumi.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Spedizione dei log</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">La base per la migrazione a livello di database è il log di archivio di Oracle, che contiene un registro delle modifiche apportate al database. Nella maggior parte dei casi, un registro di archiviazione fa parte di una strategia di backup e ripristino. Il processo di ripristino inizia con il ripristino di un database e quindi la riproduzione di uno o più log di archivio per portare il database allo stato desiderato. Questa stessa tecnologia di base può essere utilizzata per eseguire una migrazione con interruzioni delle operazioni minime o nulle. Cosa ancora più importante, questa tecnologia consente la migrazione senza intaccare il database originale, preservando un percorso di back-out.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">Il processo di migrazione inizia con il ripristino di un backup del database su un server secondario. È possibile farlo in vari modi, ma la maggior parte dei clienti utilizza la normale applicazione di backup per ripristinare i file di dati. Una volta ripristinati i file di dati, gli utenti stabiliscono un metodo per la distribuzione dei log. L'obiettivo è creare un feed costante di log di archivio generati dal database primario e riprodurli sul database ripristinato per mantenerli entrambi vicini allo stesso stato. Quando arriva il tempo di cutover, il database di origine viene completamente arrestato e i log di archivio finali e, in alcuni casi, i log di redo vengono copiati e riprodotti. È fondamentale che i log di ripristino vengano presi in considerazione anche perché potrebbero contenere alcune delle transazioni finali impegnate.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Una volta trasferiti e riprodotti questi log, entrambi i database sono coerenti l'uno con l'altro. A questo punto, la maggior parte dei clienti esegue alcuni test di base. In caso di errori durante il processo di migrazione, la riproduzione del registro dovrebbe segnalare errori e errori. È comunque consigliabile eseguire alcuni test rapidi basati su query note o su attività guidate dalle applicazioni per verificare che la configurazione sia ottimale. È inoltre pratica comune creare una tabella di test finale prima di chiudere il database originale per verificare se è presente nel database migrato. Questa operazione garantisce che non siano stati commessi errori durante la sincronizzazione finale del registro.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Una semplice migrazione log-shipping può essere configurata fuori banda rispetto al database originale, il che lo rende particolarmente utile per i database mission-critical. Non sono richieste modifiche alla configurazione per il database di origine e il ripristino e la configurazione iniziale dell'ambiente di migrazione non hanno alcun effetto sulle operazioni di produzione. Una volta configurato, il log shipping pone alcune richieste di i/o sui server di produzione. Tuttavia, il log shipping è costituito da semplici letture sequenziali dei registri di archivio, che hanno scarse probabilità di influire sulle prestazioni del database di produzione.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">La distribuzione dei log si è dimostrata particolarmente utile per progetti di migrazione a lunga distanza e ad alta velocità di cambiamento. In un'istanza, è stata eseguita la migrazione di un singolo database 220TB in una nuova posizione a circa 500 km di distanza. La velocità di modifica era estremamente elevata e le restrizioni di sicurezza impedivano l'utilizzo di una connessione di rete. La spedizione dei log è stata eseguita utilizzando nastro e corriere. Una copia del database di origine è stata inizialmente ripristinata utilizzando le procedure descritte di seguito. Quindi, i registri sono stati spediti settimanalmente tramite corriere fino al momento del cutover, al momento della consegna del set finale di nastri e dell'applicazione dei registri al database di replica.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">In alcuni casi, è garantito un ambiente DataGuard completo. Non è corretto utilizzare il termine DataGuard per fare riferimento a qualsiasi configurazione del database di standby o di distribuzione dei log. Oracle DataGuard è un framework completo per la gestione della replica dei database, ma non è una tecnologia di replica. Il vantaggio principale di un ambiente DataGuard completo in uno sforzo di migrazione è lo switchover trasparente da un database all'altro. DataGuard consente inoltre uno switchover trasparente nel database originale in caso di problemi, ad esempio problemi di prestazioni o connettività di rete nel nuovo ambiente. Un ambiente DataGuard completamente configurato richiede la configurazione non solo del livello del database ma anche delle applicazioni in modo che le applicazioni siano in grado di rilevare una modifica nella posizione del database primario. In generale, non è necessario utilizzare DataGuard per completare una migrazione, ma alcuni clienti hanno una vasta esperienza DataGuard in-house e già si affidano a essa per le attività di migrazione.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Riarchitettura</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Come discusso in precedenza, per sfruttare le funzionalità avanzate degli storage array è talvolta necessario modificare il layout del database. Inoltre, una modifica nel protocollo di storage, come il passaggio da ASM a un file system NFS, altera necessariamente il layout del file system.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">Uno dei principali vantaggi dei metodi di distribuzione dei log, incluso DataGuard, è che la destinazione di replica non deve corrispondere all'origine. Non vi sono problemi con l'utilizzo di un approccio di log-shipping per migrare da ASM a un normale file system o viceversa. Il layout preciso dei file di dati può essere modificato a destinazione per ottimizzare l'uso della tecnologia Pluggable Database (PDB) o per impostare i controlli QoS in modo selettivo su determinati file. In altre parole, un processo di migrazione basato sul log shipping consente di ottimizzare il layout dello storage del database in modo semplice e sicuro.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Risorse dei server</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">Un limite alla migrazione a livello di database è la necessità di un secondo server. Questo secondo server può essere utilizzato in due modi:</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">È possibile utilizzare il secondo server come nuova casa permanente per il database.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">È possibile utilizzare il secondo server come server di staging temporaneo. Una volta completata e testata la migrazione dei dati nel nuovo storage array, i file system LUN o NFS vengono disconnessi dal server di staging e riconnessi al server originale.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">La prima opzione è la più semplice, ma l'utilizzo potrebbe non essere possibile in ambienti molto grandi che richiedono server molto potenti. La seconda opzione richiede ulteriore lavoro per riportare i file system nella posizione originale. Si tratta di una semplice operazione in cui NFS viene utilizzato come protocollo storage, poiché i file system possono essere smontati dal server di staging e rimontati sul server originale.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">I file system basati su blocchi richiedono lavoro extra per l'aggiornamento dello zoning FC o degli iSCSI initiator. Con la maggior parte dei gestori di volumi logici (incluso ASM), i LUN vengono automaticamente rilevati e portati online una volta resi disponibili sul server originale. Tuttavia, alcune implementazioni di file system e LVM potrebbero richiedere più lavoro per esportare e importare i dati. La procedura precisa può variare, ma in genere è facile stabilire una procedura semplice e ripetibile per completare la migrazione e ripristinare i dati sul server originale.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Sebbene sia possibile impostare la distribuzione dei log e replicare un database all'interno di un singolo ambiente server, la nuova istanza deve avere un SID di processo diverso per riprodurre i log. È possibile visualizzare temporaneamente il database con un diverso gruppo di ID di processo con un SID diverso e modificarlo in un secondo momento. Tuttavia, questo può portare a numerose e complicate attività di gestione ed espone l'ambiente di database al rischio di errori dell'utente.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migrazione a livello di host</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">Migrare i dati a livello di host significa utilizzare il sistema operativo host e le utility associate per completare la migrazione. Questo processo include qualsiasi utility che copia i dati, inclusi Oracle RMAN e Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Copia dei dati</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">Il valore di un'operazione di copia semplice non deve essere sottovalutato. Le moderne infrastrutture di rete sono in grado di spostare i dati a velocità misurate in gigabyte al secondo, mentre le operazioni di copia dei file si basano su un efficiente i/o di lettura e scrittura sequenziale L'interruzione è inevitabile con un'operazione di copia dell'host rispetto alla spedizione dei log, ma la migrazione non riguarda solo lo spostamento dei dati. In genere sono incluse le modifiche alla rete, il tempo di riavvio del database e i test post-migrazione.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">Il tempo effettivo richiesto per copiare i dati potrebbe non essere significativo. Inoltre, l'operazione di copia preserva un percorso di back-out garantito perché i dati originali non vengono intatti. In caso di problemi durante il processo di migrazione, è possibile riattivare i file system originali con i dati originali.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Riformulazione</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">Replatforming si riferisce a una modifica del tipo di CPU. Quando un database viene migrato da una piattaforma Solaris, AIX o HP-UX tradizionale a x86 Linux, i dati devono essere riformattati a causa delle modifiche apportate all'architettura della CPU. Le CPU SPARC, IA64 e POWER sono note come grandi processori endian, mentre le architetture x86 e x86_64 sono note come Little endian. Di conseguenza, alcuni dati all'interno dei file di dati Oracle vengono ordinati in modo diverso a seconda del processore in uso.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">Tradizionalmente, i clienti utilizzano DataPump per replicare i dati su più piattaforme. DataPump è un'utilità che crea un tipo speciale di esportazione dei dati logici che può essere importata più rapidamente nel database di destinazione. Poiché crea una copia logica dei dati, DataPump lascia alle spalle le dipendenze dell'endianness del processore. Anche se alcuni clienti usano DataPump per il replatform, con Oracle 11g è ora disponibile un'opzione più rapida: Tablespace trasportabili su più piattaforme. Questo avanzamento consente di convertire un tablespace in un diverso formato endian. Si tratta di una trasformazione fisica che offre prestazioni migliori rispetto a un'esportazione DataPump, che deve convertire i byte fisici in dati logici e quindi riconvertirli in byte fisici.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">Una discussione completa su DataPump e tablespace trasportabili va oltre la documentazione relativa al NetApp dell'ambito, ma NetApp offre alcuni consigli basati sulla nostra esperienza nell'assistenza ai clienti durante la migrazione a un nuovo log di storage array con una nuova architettura della CPU:</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Se si utilizza DataPump, il tempo necessario per completare la migrazione deve essere misurato in un ambiente di test. A volte i clienti vengono sorpresi del tempo necessario per completare la migrazione. Questo downtime aggiuntivo e inatteso può causare interruzioni delle attività.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">Molti clienti credono erroneamente che gli spazi di tabella trasportabili su più piattaforme non richiedano la conversione dei dati. Quando si utilizza una CPU con un endian diverso, viene utilizzato un RMAN<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> l'operazione deve essere eseguita sui file di dati in anticipo. Non si tratta di un'operazione istantanea. In alcuni casi, il processo di conversione può essere accelerato avendo più thread che operano su file di dati diversi, ma il processo di conversione non può essere evitato.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migrazione guidata dal volume logico</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">Le LVM funzionano prendendo un gruppo di uno o più LUN e suddividendoli in piccole unità generalmente denominate estensioni. Il pool di estensioni viene quindi utilizzato come origine per creare volumi logici essenzialmente virtualizzati. Questo livello di virtualizzazione offre valore in vari modi:</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">I volumi logici possono utilizzare estensioni tratte da più LUN. Quando un file system viene creato su un volume logico, può utilizzare le funzionalità con le performance complete di tutte le LUN. Inoltre, promuove il caricamento uniforme di tutte le LUN nel gruppo di volumi, offrendo performance più prevedibili.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">I volumi logici possono essere ridimensionati aggiungendo e, in alcuni casi, rimuovendo le estensioni. Il ridimensionamento di un file system su un volume logico avviene in genere senza interruzione delle attività.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">È possibile migrare i volumi logici senza interruzioni spostando le estensioni sottostanti.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">La migrazione tramite LVM funziona in due modi: Spostare un'estensione o specchiare/demirrorizzare un'estensione. La migrazione LVM utilizza l'efficiente i/o sequenziale a blocchi di grandi dimensioni e solo raramente crea problemi di performance. In tal caso, sono solitamente disponibili opzioni per la riduzione della velocità di i/O. In tal modo, si aumenta il tempo necessario per completare la migrazione, riducendo al contempo il carico di i/o sui sistemi host e di storage.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Specchiatura e demirrorazione</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Alcuni gestori di volumi, come AIX LVM, consentono all'utente di specificare il numero di copie per ogni estensione e di controllare quali periferiche ospitano ciascuna copia. La migrazione viene eseguita prelevando un volume logico esistente, eseguendo il mirroring delle estensioni sottostanti nei nuovi volumi, attendendo la sincronizzazione delle copie e rilasciando la copia precedente. Se si desidera un percorso di back-out, è possibile creare un'istantanea dei dati originali prima del punto in cui viene rilasciata la copia speculare. In alternativa, è possibile arrestare brevemente il server per mascherare i LUN originali prima di eliminare forzatamente le copie mirror contenute. In tal modo, si preserva una copia recuperabile dei dati nella loro posizione originale.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Estensione della migrazione</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">Quasi tutti i gestori di volumi consentono la migrazione delle estensioni e talvolta esistono diverse opzioni. Ad esempio, alcuni responsabili di volume consentono a un amministratore di spostare le singole estensioni per un volume logico specifico dal vecchio al nuovo storage. I gestori di volume come Linux LVM2 offrono<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Che riposiziona tutti gli extent sul dispositivo LUN specificato in un nuovo LUN. Una volta evacuata, la vecchia LUN può essere rimossa.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">Il rischio principale per le operazioni è la rimozione delle LUN vecchie e non utilizzate dalla configurazione. È necessario prestare la massima attenzione quando si modifica la suddivisione in zone FC e si rimuovono i dispositivi LUN obsoleti.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Gestione automatica dello storage Oracle</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM è un volume manager e un file system logici combinati. A un livello elevato, Oracle ASM prende una raccolta di LUN, le suddivide in piccole unità di allocazione e le presenta come un singolo volume noto come gruppo di dischi ASM. ASM include inoltre la possibilità di eseguire il mirroring del gruppo di dischi impostando il livello di ridondanza. Un volume può essere senza mirror (ridondanza esterna), con mirroring (ridondanza normale) o con mirroring a tre vie (ridondanza elevata). Prestare attenzione durante la configurazione del livello di ridondanza perché non può essere modificato dopo la creazione.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM fornisce anche funzionalità di file system. Sebbene il file system non sia visibile direttamente dall'host, il database Oracle può creare, spostare ed eliminare file e directory in un gruppo di dischi ASM. Inoltre, è possibile navigare nella struttura utilizzando l'utilità asmcmd.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Come per altre implementazioni LVM, Oracle ASM ottimizza le performance di i/o mediante lo striping e il bilanciamento del carico dell'i/o di ciascun file su tutti i LUN disponibili. In secondo luogo, è possibile riposizionare le estensioni sottostanti per consentire sia il ridimensionamento del gruppo di dischi ASM sia la migrazione. Oracle ASM automatizza il processo mediante l'operazione di ribilanciamento. Le nuove LUN vengono aggiunte a un gruppo di dischi ASM e le vecchie LUN vengono eliminate, innescando il trasferimento dell'estensione e la successiva caduta della LUN evacuata dal gruppo di dischi. Questo processo è uno dei metodi di migrazione più comprovati e l'affidabilità di ASM nel fornire una migrazione trasparente è probabilmente la sua caratteristica più importante.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Poiché il livello di mirroring di Oracle ASM è fisso, non può essere utilizzato con il metodo di migrazione mirror e demirroring.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migrazione a livello di storage</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">Migrazione a livello di storage: Migrazione al di sotto del livello dell'applicazione e del sistema operativo. In passato, questo a volte significava l'utilizzo di dispositivi specializzati che copiano i LUN a livello di rete, ma queste funzionalità ora si trovano in modo nativo in ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">La migrazione di database da un sistema NetApp all'altro viene eseguita quasi universalmente con il software di replica dei dati NetApp SnapMirror. Il processo prevede la configurazione di una relazione di mirroring per i volumi da migrare, in modo che possano essere sincronizzati e quindi in attesa della finestra di cutover. Quando arriva, il database di origine viene arrestato, viene eseguito un aggiornamento finale del mirror e il mirror viene interrotto. I volumi di replica sono quindi pronti per l'uso, montando una directory del file system NFS contenuta oppure rilevando i LUN contenuti e avviando il database.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">Il riposizionamento dei volumi in un singolo cluster ONTAP non viene preso in considerazione dalla migrazione, ma piuttosto da una routine<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> operazione. SnapMirror viene utilizzato come motore di replica dei dati all'interno del cluster. Questo processo è completamente automatizzato. Non esistono ulteriori passaggi da eseguire per la migrazione quando gli attributi del volume, come la mappatura delle LUN o le autorizzazioni di esportazione NFS, vengono spostati con il volume stesso. Il trasferimento non comporta interruzioni per le operazioni dell'host. In alcuni casi, l'accesso alla rete deve essere aggiornato per garantire che l'accesso ai dati appena ricollocati sia nel modo più efficiente possibile, ma anche queste attività non comportano interruzione delle attività.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Importazione di LUN esterne (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">FLI è una funzione che consente a un sistema Data ONTAP con versione 8,3 o superiore di migrare una LUN esistente da un altro storage array. La procedura è semplice: Il sistema ONTAP viene sottoposto a zoning sull'array di storage esistente come se fosse un qualsiasi altro host SAN. Data ONTAP può quindi controllare le LUN legacy desiderate ed eseguire la migrazione dei dati sottostanti. Inoltre, il processo di importazione utilizza le impostazioni di efficienza del nuovo volume durante la migrazione dei dati, vale a dire che i dati possono essere compressi e deduplicati inline durante il processo di migrazione.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">La prima implementazione di FLI in Data ONTAP 8,3 consentiva solo la migrazione offline. Si trattava di un trasferimento molto veloce, ma i dati LUN continuavano a non essere disponibili fino al completamento della migrazione. La migrazione online è stata introdotta in Data ONTAP 8,3.1. Questo tipo di migrazione consente di ridurre al minimo le interruzioni, consentendo a ONTAP di fornire dati LUN durante il processo di trasferimento. Si verifica una breve interruzione mentre l'host viene sottoposto a zoning per l'utilizzo dei LUN tramite ONTAP. Tuttavia, non appena tali modifiche vengono apportate, i dati sono ancora una volta accessibili e rimangono accessibili per l'intero processo di migrazione.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">L'i/o in lettura viene fornito con un proxy tramite ONTAP fino al completamento dell'operazione di copia, mentre l'i/o in scrittura viene scritta in modo sincrono su LUN esterna e ONTAP. Le due copie LUN vengono mantenute sincronizzate in questo modo fino a quando l'amministratore non esegue un cutover completo che rilascia la LUN esterna e non replica più le scritture.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI è progettato per funzionare con FC, ma se si desidera passare a iSCSI, la LUN migrata può essere facilmente rimappata come una LUN iSCSI al termine della migrazione.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Tra le caratteristiche di FLI vi è il rilevamento e la regolazione automatici dell'allineamento. In questo contesto, il termine allineamento si riferisce a una partizione su un dispositivo LUN. Per ottenere prestazioni ottimali è necessario allineare l'i/o ai blocchi da 4K KB. Se una partizione viene posizionata su un offset che non è multiplo di 4K, le prestazioni ne risentono.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Esiste un secondo aspetto dell'allineamento che non può essere corretto regolando un offset di partizione, ovvero la dimensione del blocco del file system. Ad esempio, un file system ZFS generalmente utilizza per impostazione predefinita una dimensione di blocco interna di 512 byte. Altri clienti che utilizzano AIX hanno occasionalmente creato file system JFS2 con dimensioni blocco di 512 o 1, 024 byte. Anche se il file system potrebbe essere allineato a un limite di 4K, i file creati all'interno di tale file system non lo sono e le prestazioni ne risentono.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI non deve essere usato in queste circostanze. Anche se i dati sono accessibili dopo la migrazione, il risultato sono file system con gravi limitazioni delle prestazioni. In linea di principio, qualsiasi file system che supporti un carico di lavoro di sovrascrittura casuale su ONTAP dovrebbe utilizzare una dimensione del blocco di 4K KB. Ciò è applicabile principalmente a workload come file di dati di database e implementazioni di VDI. La dimensione del blocco può essere identificata utilizzando i comandi del sistema operativo host pertinente.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Ad esempio, su AIX, la dimensione del blocco può essere visualizzata con<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Con Linux,<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> e.<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> può essere utilizzato per<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> e.<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>, rispettivamente. Con<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, il comando è<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">Il parametro che controlla la dimensione del blocco è<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> e generalmente il valore predefinito è 9, che significa 2^9, o 512 byte. Per prestazioni ottimali, la<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Il valore deve essere 12 (2^12=4K). Questo valore viene impostato al momento della creazione di zpool e non può essere modificato, il che significa che i data zpool con un<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> oltre a 12 deve essere eseguita la migrazione copiando i dati in uno zpool appena creato.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM non ha dimensioni dei blocchi fondamentali. L'unico requisito è che la partizione su cui è stato creato il disco ASM sia allineata correttamente.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">7-Mode Transition Tool</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">7-Mode Transition Tool (7MTT) è un'utility di automazione utilizzata per migrare configurazioni 7- Mode di grandi dimensioni a ONTAP. La maggior parte dei clienti che gestiscono i database trovano altri metodi più semplici, in parte perché eseguono di solito la migrazione dei database piuttosto che trasferire l'intero footprint dello storage. Inoltre, i database sono spesso solo una parte di un ambiente di storage più ampio. Pertanto, spesso i database vengono migrati singolarmente, quindi l'ambiente rimanente può essere spostato con 7MTT.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Alcuni clienti con sistemi di storage dedicati a ambienti di database complicati hanno un numero limitato ma significativo di essi. Questi ambienti potrebbero contenere molti volumi, snapshot e numerosi dettagli di configurazione, come autorizzazioni di esportazione, gruppi iniziatori LUN, autorizzazioni utente e configurazione del protocollo Lightweight Directory Access Protocol. In questi casi, le capacità di automazione di 7MTT possono semplificare una migrazione.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT può funzionare in una delle due modalità seguenti:</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Copy- Based Transition (CBT).* 7MTT con CBT imposta i volumi SnapMirror da un sistema 7- Mode esistente nel nuovo ambiente. Una volta sincronizzati i dati, 7MTT orchestra il processo di cutover.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Copy- Free Transition (CFT).* 7MTT con CFT si basa sulla conversione in-place degli shelf di dischi 7- Mode esistenti. I dati non vengono copiati e gli shelf di dischi esistenti possono essere riutilizzati. La configurazione esistente di data Protection ed efficienza dello storage viene preservata.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">La differenza principale tra queste due opzioni consiste nel fatto che la transizione senza copie è un approccio a big-bang, in cui tutti gli shelf di dischi collegati alla coppia ha 7- Mode originale devono essere ricollocati nel nuovo ambiente. Non esiste alcuna opzione per spostare un sottoinsieme di shelf. L'approccio basato sulla copia consente lo spostamento dei volumi selezionati. Esiste anche potenzialmente una finestra di cutover più lunga con transizione priva di copie a causa del legame necessario per la riselezione degli shelf di dischi e la conversione dei metadati. In base all'esperienza sul campo, NetApp consiglia di lasciare trascorrere 1 ora per il riposizionamento e il ripristino degli shelf di dischi e tra 15 minuti e 2 ore per la conversione dei metadati.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Dal punto di vista del database e dell'host, non sono necessarie operazioni speciali. Dopo l'aggiornamento delle zone FC e la disponibilità dei LUN su ONTAP, LVM dovrebbe essere in grado di leggere i metadati LVM dai LUN. Inoltre, i gruppi di volumi sono pronti per l'uso senza ulteriori passaggi di configurazione. Rari casi, gli ambienti potrebbero includere file di configurazione con hard-code e riferimenti allo storage array precedente. Ad esempio, un sistema Linux che includeva<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Le regole che fanno riferimento a un WWN di un dato dispositivo devono essere aggiornate per riflettere le modifiche introdotte da FLI.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Fare riferimento alla matrice di compatibilità NetApp per informazioni sulle configurazioni supportate. Se il proprio ambiente non è incluso, contattare il rappresentante NetApp per assistenza.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Questo esempio mostra la migrazione di LUN ASM e LVM ospitati su un server Linux. FLI è supportato su altri sistemi operativi e, sebbene i comandi sul lato host possano differire, i principi sono gli stessi e le procedure ONTAP sono identiche.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">Identificare i LUN LVM</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">La prima fase della preparazione consiste nell'identificare i LUN da migrare. Nell'esempio mostrato qui, due file system basati su SAN sono montati su<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> e.<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">Il nome del gruppo di volumi può essere estratto dal nome del dispositivo, che utilizza il formato (nome del gruppo di volumi)-(nome del volume logico). In questo caso, viene chiamato il gruppo di volumi<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">Il<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> Il comando può essere utilizzato come segue per identificare i LUN che supportano questo gruppo di volumi. In questo caso, sono presenti 10 LUN che compongono il<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> gruppo di volumi.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">Identificare i LUN ASM</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">Anche i LUN ASM devono essere migrati. Per ottenere il numero di LUN e percorsi LUN da sqlplus come utente sysasm, eseguire il comando seguente:</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">L'ambiente corrente contiene 20 LUN da migrare. Aggiornare la SAN corrente in modo che ONTAP possa accedere ai LUN correnti. I dati non sono ancora stati migrati, ma ONTAP deve leggere le informazioni di configurazione dalle LUN correnti per creare la nuova home page per quei dati.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Almeno una porta HBA sul sistema AFF/FAS deve essere configurata come porta Initiator. Inoltre, le zone FC devono essere aggiornate in modo che ONTAP possa accedere alle LUN sullo storage array esterno. Alcuni storage array hanno configurato il masking dei LUN, che limita i WWN che possono accedere a una determinata LUN. In tal caso, è necessario aggiornare anche il masking dei LUN per garantire l'accesso ai WWN di ONTAP.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Al termine di questa operazione, ONTAP dovrebbe essere in grado di visualizzare l'array di archiviazione esterno con<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> comando. Il campo chiave restituito è il prefisso utilizzato per identificare il LUN esterno sul sistema. Nell'esempio seguente, i LUN dell'array esterno<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Appare in ONTAP usando il prefisso di<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identificare un array esterno</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identificare i LUN esterni</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">I LUN possono essere elencati passando l'<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> al<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> comando. I dati restituiti vengono referenziati più volte durante la procedura di migrazione.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Registrare LUN di array esterni come candidati di importazione</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Le LUN esterne vengono inizialmente classificate come qualsiasi tipo di LUN specifico. Prima di poter importare i dati, i LUN devono essere contrassegnati come esterni e quindi come candidati al processo di importazione. Questo passaggio viene completato passando il numero di serie a.<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> , come illustrato nell'esempio seguente. Si noti che questa procedura etichetta solo il LUN come estraneo all'interno di ONTAP. Nessun dato viene scritto nella LUN esterna stessa.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Creazione di volumi per l'hosting di LUN migrati</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Per ospitare le LUN migrate è necessario un volume. La configurazione esatta dei volumi dipende dal piano generale per sfruttare le funzionalità di ONTAP. In questo esempio, i LUN ASM vengono posizionati in un volume e i LUN LVM in un secondo volume. In questo modo, puoi gestire le LUN come gruppi indipendenti per scopi come il tiering, la creazione di snapshot o l'impostazione di controlli della qualità del servizio.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Impostare<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. Il processo di migrazione può comportare un notevole ricambio dei dati. Pertanto, potrebbe verificarsi un notevole aumento del consumo di spazio se le istantanee vengono create accidentalmente perché i dati indesiderati vengono acquisiti nelle istantanee.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Creare LUN ONTAP</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Una volta creati i volumi, è necessario creare i nuovi LUN. In genere, la creazione di un LUN richiede all'utente di specificare tali informazioni come la dimensione LUN, ma in questo caso l'argomento del disco esterno viene passato al comando. Di conseguenza, ONTAP replica i dati di configurazione LUN correnti dal numero di serie specificato. Utilizza inoltre la geometria del LUN e i dati della tabella delle partizioni per regolare l'allineamento delle LUN e stabilire prestazioni ottimali.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">In questo passaggio, i numeri di serie devono essere referenziati rispetto all'array esterno per assicurarsi che il LUN esterno corretto corrisponda al nuovo LUN corretto.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Creare relazioni di importazione</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">I LUN sono stati creati ma non sono configurati come destinazione di replica. Prima di eseguire questo passaggio, i LUN devono essere messi offline. Questo passaggio aggiuntivo è progettato per proteggere i dati dagli errori dell'utente. Se ONTAP consentisse di eseguire una migrazione su un LUN online, rischierebbe di provocare la sovrascrittura dei dati attivi con un errore tipografico. Questa fase aggiuntiva, che obbliga l'utente a portare un LUN offline, consente di verificare se viene utilizzato il LUN di destinazione corretto come destinazione della migrazione.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Una volta che i LUN sono offline, è possibile stabilire la relazione di importazione passando il numero di serie del LUN esterno a.<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> comando.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Una volta stabilite tutte le relazioni di importazione, è possibile riportare online i LUN.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Crea gruppo iniziatore</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Conversione protocollo</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">In questo esempio, viene creato un igroup che contiene due WWN corrispondenti alle due porte disponibili sull'HBA dell'host.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Mappare nuovi LUN all'host</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Dopo la creazione di igroup, i LUN vengono quindi mappati all'igroup definito. Questi LUN sono disponibili solo per i WWN inclusi in questo igroup. In questa fase del processo di migrazione, NetApp presume che l'host non sia stato sottoposto a zoning in ONTAP. Questo è importante perché se l'host è contemporaneamente collegato all'array esterno e al nuovo sistema ONTAP, vi è il rischio che su ogni array possano essere rilevati LUN con lo stesso numero di serie. Questa situazione potrebbe causare malfunzionamenti del multipath o danni ai dati.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Script di esempio per l'automazione delle operazioni di migrazione Oracle</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Script di esempio</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Gli script presentati sono forniti come esempi di come eseguire lo script di varie attività del sistema operativo e del database. Vengono forniti così come sono. Se è necessario supporto per una procedura particolare, contattare NetApp o un rivenditore NetApp.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Arresto del database</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">Lo script Perl seguente prende un singolo argomento del SID Oracle e chiude un database. Può essere eseguito come utente Oracle o come root.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Avvio del database</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Convertire il file system in sola lettura</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">Lo script seguente prende un argomento del file system e tenta di smontarlo e rimontarlo in modalità di sola lettura. Questa operazione è utile durante i processi di migrazione in cui un file system deve essere mantenuto disponibile per replicare i dati e deve essere protetto contro danni accidentali.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Sostituire il file system</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">L'esempio di script riportato di seguito viene utilizzato per sostituire un file system con un altro. Poiché modifica il file ``/etc/fstab, deve essere eseguito come root. Accetta un singolo argomento delimitato da virgole per i file system vecchi e nuovi.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Per sostituire il file system, eseguire lo script seguente:</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Come esempio di utilizzo di questo script, si supponga che i dati in<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> viene migrato in<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> e.<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> viene migrato in<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. Uno dei metodi più semplici per eseguire questa attività consiste nell'utilizzare una semplice operazione di copia dei file per riportare la nuova periferica al punto di montaggio originale.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Si supponga che i file system vecchi e nuovi siano presenti in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archiviare come segue:</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Quando viene eseguito, questo script smonta il file system corrente e lo sostituisce con il nuovo:</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">Lo script aggiorna anche<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> file di conseguenza. Nell'esempio illustrato, sono incluse le seguenti modifiche:</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Migrazione automatizzata del database</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">In questo esempio viene illustrato l'utilizzo di script di arresto, avvio e sostituzione del file system per automatizzare completamente la migrazione.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Visualizzare le posizioni dei file</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Questo script raccoglie una serie di parametri critici del database e li stampa in un formato di facile lettura. Questo script può essere utile quando si esaminano i layout dei dati. Inoltre, lo script può essere modificato per altri usi.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Pulitura della migrazione ASM</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Conversione del nome da ASM a file system</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Riprodurre i log sul database</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Questo script accetta un singolo argomento di un SID Oracle per un database in modalità mount e tenta di riprodurre tutti i log di archivio attualmente disponibili.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Riprodurre i registri sul database di standby</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Questo script è identico allo script precedente, tranne che è progettato per un database di standby.</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">La modifica del protocollo utilizzato per accedere a un LUN è un requisito comune.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">In alcuni casi, fa parte di una strategia globale di migrazione dei dati nel cloud. TCP/IP è il protocollo del cloud e il passaggio da FC a iSCSI facilita la migrazione in vari ambienti cloud. In altri casi, iSCSI potrebbe essere desiderabile per sfruttare i costi ridotti di un IP SAN. A volte, una migrazione potrebbe utilizzare un protocollo diverso come misura temporanea. Ad esempio, se un array esterno e LUN basati su ONTAP non possono coesistere sugli stessi HBA, è possibile utilizzare LUN iSCSI abbastanza a lungo da copiare i dati dal vecchio array. Dopo la rimozione dei vecchi LUN dal sistema, è possibile riconvertirli in FC.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">La seguente procedura illustra la conversione da FC a iSCSI, ma i principi generali si applicano a una conversione da iSCSI a FC inversa.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Installare iSCSI Initiator</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">La maggior parte dei sistemi operativi include un iniziatore iSCSI software per impostazione predefinita, ma se non è incluso, può essere facilmente installato.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identificare il nome dell'iniziatore iSCSI</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Durante il processo di installazione viene generato un nome iSCSI initiator univoco. Su Linux, si trova in<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> file. Questo nome viene utilizzato per identificare l'host sulla SAN IP.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Creare un nuovo gruppo iniziatore</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Un gruppo iniziatore (igroup) fa parte dell'architettura di mascheramento LUN di ONTAP. Un LUN appena creato non è accessibile a meno che non venga concesso per la prima volta l'accesso a un host. Questa operazione viene eseguita creando un igroup che elenca i nomi WWN FC o iniziatori iSCSI che richiedono l'accesso.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">In questo esempio, viene creato un igroup che contiene l'iniziatore iSCSI dell'host Linux.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Chiudere l'ambiente</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Prima di modificare il protocollo LUN, è necessario disattivare completamente i LUN. Tutti i database di uno dei LUN da convertire devono essere chiusi, i file system devono essere dismontati e i gruppi di volumi devono essere disattivati. Se si utilizza ASM, assicurarsi che il gruppo di dischi ASM sia smontato e chiudere tutti i servizi della griglia.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">Rimuovere la mappatura dei LUN dalla rete FC</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Una volta terminate completamente le LUN, rimuovere le mappature dall'igroup FC originale.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">Eseguire nuovamente il mapping dei LUN alla rete IP</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Concedere l'accesso a ogni LUN al nuovo gruppo di iniziatori basati su iSCSI.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">Rilevamento delle destinazioni iSCSI</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">Il rilevamento iSCSI richiede due fasi. La prima è scoprire le destinazioni, che non è la stessa cosa per scoprire un LUN. Il<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> il comando mostrato di seguito verifica il gruppo di portali specificato da<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Memorizza un elenco di tutti gli indirizzi IP e le porte che offrono servizi iSCSI. In questo caso, vi sono quattro indirizzi IP con servizi iSCSI sulla porta predefinita 3260.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Il completamento di questo comando può richiedere alcuni minuti se non è possibile raggiungere uno qualsiasi degli indirizzi IP di destinazione.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">Rilevamento delle LUN iSCSI</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Dopo aver rilevato le destinazioni iSCSI, riavviare il servizio iSCSI per rilevare i LUN iSCSI disponibili e creare i dispositivi associati, ad esempio i dispositivi multipath o ASMlib.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Riavviare l'ambiente</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Riavviare l'ambiente riattivando i gruppi di volumi, rimontando i file system, riavviando i servizi RAC e così via. Per precauzione, NetApp consiglia di riavviare il server al termine del processo di conversione, per assicurarsi che tutti i file di configurazione siano corretti e che tutti i dispositivi obsoleti vengano rimossi.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Attenzione: Prima di riavviare un host, assicurarsi che tutte le voci in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Il riferimento alle risorse SAN migrate verrà commentato. Se questa operazione non viene eseguita e si verificano problemi con l'accesso LUN, il risultato può essere un sistema operativo che non si avvia. Questo problema non danneggia i dati. Tuttavia, può essere molto scomodo avviare in modalità rescue o una modalità simile e corretta<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> In modo che il sistema operativo possa essere avviato per consentire l'avvio delle operazioni di risoluzione dei problemi.</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">La gestione sicura ed efficiente di più database Oracle richiede un'efficace strategia di QoS. Il motivo è rappresentato dalle funzionalità di performance in costante aumento offerte da un sistema storage moderno.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Efficienza dello storage e dei database Oracle</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Database Oracle e funzionalità di efficienza ONTAP</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Le funzionalità di efficienza dello spazio di ONTAP sono ottimizzate per i database Oracle. In quasi tutti i casi, l'approccio migliore è quello di lasciare le impostazioni predefinite con tutte le funzioni di efficienza attivate.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID e database Oracle</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID si riferisce all'utilizzo della ridondanza per proteggere i dati dalla perdita di un'unità.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Occasionalmente sorgono domande riguardanti i livelli RAID nella configurazione dello storage NetApp utilizzato per i database Oracle e altre applicazioni aziendali. Molte Best practice Oracle precedenti relative alla configurazione degli array di storage contengono avvisi sull'utilizzo del mirroring RAID e/o sull'eliminazione di determinati tipi di RAID. Sebbene sollevino punti validi, questi sorgenti non si applicano a RAID 4 e alle tecnologie NetApp RAID DP e RAID-TEC utilizzate in ONTAP.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Thin provisioning di Oracle e ONTAP</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Il thin provisioning per un database Oracle richiede un'attenta pianificazione, perché ne consegue che è possibile configurare più spazio su un sistema di storage rispetto a quello necessariamente fisicamente disponibile. Vale la pena di fare tutto questo perché, se eseguito correttamente, il risultato è un notevole risparmio sui costi e un miglioramento della gestibilità.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Provisioning delle SVM per database Oracle</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Database Oracle e Storage Virtual Machine</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">La gestione dello storage del database Oracle è centralizzata su una Storage Virtual Machine (SVM)</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Le operazioni di takeover e switchover dello storage devono garantire l'integrità delle operazioni dei database Oracle. Inoltre, gli argomenti utilizzati dalle operazioni di takeover e switchover possono influire sull'integrità dei dati se utilizzati in modo errato.</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Capacità e spazio libero per database e storage ONTAP</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">La gestione di un database o di un'altra applicazione aziendale con storage aziendale prevedibile, gestibile e ad alte prestazioni richiede spazio libero sulle unità per la gestione di dati e metadati. La quantità di spazio libero richiesta dipende dal tipo di unità utilizzata e dai processi aziendali.</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multiblock_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">Il<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Parametro controlla il numero massimo di blocchi di database Oracle che Oracle legge come singola operazione durante l'i/o sequenziale</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Questo parametro non influisce tuttavia sul numero di blocchi letti da Oracle durante qualsiasi e in tutte le operazioni di lettura, né sull'i/o casuale Ciò influisce solo sulle dimensioni del blocco degli i/o sequenziali.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle consiglia all'utente di lasciare il parametro non impostato. In questo modo, il software del database può impostare automaticamente il valore ottimale. Questo generalmente significa che questo parametro è impostato su un valore che fornisce una dimensione i/o di 1MB. Ad esempio, una lettura 1MB di 8KB blocchi richiederebbe la lettura di 128 blocchi e il valore predefinito per questo parametro sarebbe 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">La maggior parte dei problemi di prestazioni del database osservati da NetApp presso le sedi dei clienti implica un'impostazione errata per questo parametro. Ci sono motivi validi per modificare questo valore con le versioni 8 e 9 di Oracle. Di conseguenza, il parametro potrebbe essere inconsapevolmente presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Perché il database è stato aggiornato in posizione a Oracle 10 e versioni successive. Un'impostazione legacy di 8 o 16, rispetto a un valore predefinito di 128, danneggia significativamente le prestazioni i/o sequenziali.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp recommended* impostando<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> il parametro non deve essere presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file. NetApp non ha mai riscontrato una situazione in cui la modifica di questo parametro ha migliorato le prestazioni, ma in molti casi ha causato evidenti danni al throughput i/o sequenziale.</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC è un prodotto clusterware con diversi tipi di processi heartbeat interni che monitorano lo stato del cluster.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">errore di montaggio</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">Le informazioni contenute in <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> La sezione contiene informazioni critiche per gli ambienti Oracle RAC che utilizzano lo storage di rete e, in molti casi, è necessario modificare le impostazioni predefinite di Oracle RAC per garantire che il cluster RAC sopravviva alle modifiche del percorso di rete e alle operazioni di failover/switchover dello storage.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">disktimeout</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">Il parametro RAC relativo allo storage primario è<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Questo parametro controlla la soglia entro la quale l'i/o del file di voting deve essere completato. Se il<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Il parametro viene superato, quindi il nodo RAC viene eliminato dal cluster. Il valore predefinito per questo parametro è 200. Questo valore dovrebbe essere sufficiente per le procedure standard di takeover e giveback dello storage.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp consiglia di eseguire il test approfondito delle configurazioni RAC prima di metterle in produzione, perché molti fattori influiscono su un takeover o un giveback. Oltre al tempo richiesto per il completamento del failover dello storage, è necessario ulteriore tempo affinché le modifiche LACP (link Aggregation Control Protocol) vengano propagate. Inoltre, il software multipathing SAN deve rilevare un timeout i/o e riprovare su un percorso alternativo. Se un database è estremamente attivo, è necessario accodare e rieseguire una grande quantità di i/o prima di elaborare l'i/o del disco di voting.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">Nel caso in cui non sia possibile eseguire un takeover o un giveback effettivo dello storage, l'effetto può essere simulato con test di pull dei cavi sul server di database.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">Lasciando il<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> parametro al valore predefinito di 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Verificare sempre accuratamente la configurazione di un RAC.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">Il<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> In genere, il parametro influisce solo sull'heartbeat di rete tra i nodi RAC. Il valore predefinito è 30 secondi. Se i binari della griglia si trovano su un array di storage o l'unità di avvio del sistema operativo non è locale, questo parametro potrebbe diventare importante. Ciò comprende host con unità di boot ubicate su una SAN FC, sistemi operativi basati su NFS e unità di boot ubicate in datastore di virtualizzazione, come un file VMDK.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Se l'accesso a un'unità di boot viene interrotto da un takeover o un giveback dello storage, è possibile che la posizione binaria della griglia o l'intero sistema operativo si blocchi temporaneamente. Il tempo necessario affinché ONTAP completi l'operazione di storage e affinché il sistema operativo modifichi i percorsi e riprenda l'i/o potrebbe superare l'<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> soglia. Di conseguenza, un nodo viene eliminato immediatamente dopo il ripristino della connettività al LUN di avvio o ai binari della griglia. Nella maggior parte dei casi, l'eviction e il successivo riavvio si verificano senza messaggi di registrazione per indicare il motivo del riavvio. Non tutte le configurazioni sono interessate dal problema, pertanto è possibile testare host basati su boot SAN, NFS o datastore in un ambiente RAC in modo che RAC rimanga stabile in caso di interruzione della comunicazione con il disco di avvio.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">Nel caso di unità di avvio non locali o di un hosting di file system non locale<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> binari, il<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> deve essere modificato per corrispondere<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Se questo parametro viene modificato, eseguire ulteriori test per identificare anche eventuali effetti sul comportamento RAC, come il tempo di failover dei nodi.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Lasciare la<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> parametro al valore predefinito di 30 a meno che non si verifichi una delle seguenti condizioni:</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> I file binari sono collocati in un disco collegato in rete, inclusi dischi NFS, iSCSI, FC e basati su datastore.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">Il sistema operativo viene avviato SAN.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">In questi casi, valutare l'effetto delle interruzioni di rete che influiscono sull'accesso al sistema operativo o.<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> file system. In alcuni casi, tali interruzioni causano lo stallo dei daemon Oracle RAC, che può portare a un<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>timeout e sfratto basati su -. Il valore predefinito del timeout è 27 secondi, ovvero il valore di<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> meno<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. In questi casi, aumentare<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> a 200 per la corrispondenza<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Parametro di inizializzazione Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Controlla l'utilizzo dell'i/o asincrono e diretto</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Contrariamente a quanto si crede, l'i/o asincrono e diretto non si escludono a vicenda. NetApp ha osservato che questo parametro è spesso configurato in modo non corretto negli ambienti dei clienti e che questa errata configurazione è direttamente responsabile di molti problemi di prestazioni.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">L'i/o asincrono significa che le operazioni i/o di Oracle possono essere parallelizzate. Prima della disponibilità di i/o asincrono su vari sistemi operativi, gli utenti hanno configurato numerosi processi dbwriter e modificato la configurazione del processo del server. Con l'i/o asincrono, il sistema operativo stesso esegue i/o per conto del software di database in modo altamente efficiente e parallelo. La procedura non pone i dati a rischio e le operazioni critiche, come il logging di redo di Oracle, vengono comunque eseguite in maniera sincrona.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">L'i/o diretto ignora la cache buffer del sistema operativo. L'i/o su un sistema UNIX scorre normalmente attraverso la cache del buffer del sistema operativo. Ciò è utile per le applicazioni che non mantengono una cache interna, ma Oracle dispone di una propria cache buffer all'interno di SGA. In quasi tutti i casi, è meglio abilitare l'i/o diretto e allocare la RAM del server all'SGA piuttosto che affidarsi alla cache del buffer del sistema operativo. Oracle SGA utilizza la memoria in modo più efficiente. Inoltre, quando l'i/o fluisce attraverso il buffer del sistema operativo, è soggetto a un'ulteriore elaborazione, che aumenta le latenze. L'aumento delle latenze è particolarmente percepibile con un elevato i/o in scrittura quando una bassa latenza è un requisito critico.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Le opzioni per<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> sono:</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle invia le richieste di i/o al sistema operativo per l'elaborazione. Questo processo consente a Oracle di eseguire altri lavori anziché attendere il completamento dell'i/o e quindi aumentare la parallelizzazione i/O.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle esegue l'i/o direttamente sui file fisici piuttosto che instradare l'i/o attraverso la cache del sistema operativo host.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle utilizza i/o sincroni e bufferizzati In questa configurazione, la scelta tra processi server condivisi e dedicati e il numero di dbwriter è più importante.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*Setall.* Oracle utilizza i/o sia asincrono che diretto In quasi tutti i casi, l'uso di<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> è ottimale.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">Il<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Parametro non ha effetto negli ambienti DNFS e ASM. L'utilizzo di DNFS o ASM comporta automaticamente l'utilizzo dell'i/o asincrono e diretto</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">In passato alcuni clienti hanno riscontrato problemi di i/o asincrono, in particolare con le precedenti versioni di Red Hat Enterprise Linux 4 (RHEL4). Alcuni consigli aggiornati su Internet suggeriscono comunque di evitare l'i/o asincrono a causa di informazioni non aggiornate. L'i/o asincrono è stabile su tutti i sistemi operativi correnti. Non c'è motivo di disabilitarlo, in assenza di un bug noto con il sistema operativo.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Se un database utilizza l'i/o con buffer, un passaggio all'i/o diretto potrebbe anche richiedere una modifica delle dimensioni SGA. La disattivazione dell'i/o con buffer elimina i vantaggi prestazionali che la cache del sistema operativo host fornisce al database. L'aggiunta di RAM alla SGA risolve questo problema. Il risultato netto dovrebbe essere un miglioramento delle performance di i/O.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Sebbene sia quasi sempre meglio utilizzare la RAM per Oracle SGA piuttosto che per il caching del buffer del sistema operativo, potrebbe essere impossibile determinare il valore migliore. Ad esempio, potrebbe essere preferibile utilizzare i/o con buffer di dimensioni SGA molto ridotte su un server di database con molte istanze Oracle attive in modo intermittente. Questa disposizione consente l'utilizzo flessibile della RAM disponibile rimanente sul sistema operativo da parte di tutte le istanze di database in esecuzione. Si tratta di una situazione molto insolita, ma è stata osservata presso alcune sedi dei clienti.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp recommended*<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> a.<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Ma essere consapevoli che in alcune circostanze la perdita della cache del buffer host potrebbe richiedere un aumento nella SGA di Oracle.</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP utilizza internamente dimensioni dei blocchi variabili, il che significa che è possibile configurare i database Oracle con le dimensioni desiderate per i blocchi. Tuttavia, le dimensioni dei blocchi del file system possono influire sulle prestazioni e in alcuni casi una maggiore dimensione dei blocchi di ripristino può migliorare le prestazioni.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Dimensioni dei blocchi di dati</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Alcuni sistemi operativi offrono una scelta di dimensioni dei blocchi del file system. Per i file system che supportano i file di dati Oracle, quando si utilizza la compressione le dimensioni del blocco devono essere pari a 8KB KB. Quando la compressione non è necessaria, è possibile utilizzare dimensioni del blocco pari a 8KB K o 4KB K.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Se un file dati viene inserito in un file system con un blocco di 512 byte, è possibile che i file non siano allineati correttamente. Il LUN e il file system potrebbero essere allineati correttamente in base ai consigli di NetApp, ma l'i/o del file non sarebbe allineato correttamente. Un tale disallineamento causerebbe gravi problemi di prestazioni.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">I file system che supportano i log di ripristino devono utilizzare una dimensione blocco pari a un multiplo della dimensione del blocco di ripristino. In genere, questo richiede che sia il file system del redo log sia il redo log stesso utilizzino una dimensione del blocco di 512 byte.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Ripristina le dimensioni dei blocchi</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">A velocità di ripristino molto elevate, è possibile che le dimensioni dei blocchi di 4KB KB funzionino meglio, perché alte velocità di ripristino consentono di eseguire l'i/o in un numero inferiore di operazioni più efficienti. Se le velocità di ripristino sono superiori a 50Mbps KB, valutare la possibilità di testare dimensioni blocco di 4KB KB.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Sono stati identificati alcuni problemi dei clienti con i database che utilizzano i log di redo con dimensioni dei blocchi di 512 byte in un file system con dimensioni dei blocchi di 4KB KB e molte transazioni di dimensioni molto ridotte. L'overhead coinvolto nell'applicazione di modifiche multiple a 512 byte a un singolo blocco di file system da 4KB ha portato a problemi di performance che sono stati risolti modificando il file system in modo da utilizzare dimensioni dei blocchi di 512 byte.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp consiglia* di non modificare le dimensioni del blocco di redo se non dietro indicazione di un'organizzazione di assistenza clienti o servizi professionali o se la modifica si basa sulla documentazione ufficiale del prodotto.</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">Il disaster recovery si riferisce al ripristino dei servizi dati dopo un evento catastrofico, come un incendio che distrugge un sistema storage o persino un'intera sede.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4591: Oracle Data Protection_ e _TR-4592: Oracle on MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">Il disaster recovery può essere eseguito mediante una semplice replica dei dati tramite SnapMirror, naturalmente, con molti clienti che aggiornano le repliche con mirroring ogni ora.</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster fa riferimento a ONTAP in una configurazione hardware che include storage con mirroring sincrono di basso livello e numerose funzionalità aggiuntive. Le soluzioni integrate come MetroCluster semplificano le complesse e scalabili infrastrutture di database, applicazioni e virtualizzazione. Sostituisce diversi prodotti e strategie di protezione dati esterni con un unico semplice storage array centrale. Fornisce inoltre backup, recovery, disaster recovery e alta disponibilità (ha) integrati in un singolo sistema storage in cluster.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC su MetroCluster</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Per comprendere il funzionamento dei database Oracle in un ambiente MetroCluster è necessario spiegare la progettazione fisica di un sistema MetroCluster.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4592: Oracle su MetroCluster._</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Per comprendere il funzionamento dei database Oracle in un ambiente MetroCluster alsop è necessario spiegare alcune delle funzionalità logiche di un sistema MetroCluster.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Le normali Best practice vengono comunque applicate e se le tue esigenze richiedono solo RPO=0:1 di data Protection, allora MetroCluster ne soddisfa l'esigenza. Tuttavia, la maggior parte dei clienti utilizza MetroCluster non solo per la protezione dei dati con RPO=0, ma anche per migliorare l'RTO in scenari di disastro, oltre a fornire un failover trasparente come parte delle attività di manutenzione del sito.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Failover con un sistema operativo preconfigurato</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Forzare uno switchover su MetroCluster</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Rilevamento di LUN FC (solo SAN)</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">La procedura di attivazione effettiva è semplice. Comandi come il rilevamento delle LUN richiedono solo pochi comandi per ogni porta FC. Il montaggio del file system non è altro che un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> E sia i database che ASM possono essere avviati e arrestati dalla CLI con un unico comando. Se i volumi e i file system non vengono utilizzati nel sito di disaster recovery prima dello switchover, non è necessario impostare alcun requisito<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sui volumi.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Failover con un sistema operativo virtualizzato</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">Il failover degli ambienti di database può essere esteso per includere il sistema operativo stesso. In teoria, questo failover può essere eseguito con le LUN di avvio, ma nella maggior parte dei casi con un sistema operativo virtualizzato. La procedura è simile ai seguenti passaggi:</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Montaggio dei datastore che ospitano le macchine virtuali del server di database</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Avvio delle macchine virtuali</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">La base della protezione dei dati di Oracle con un sistema MetroCluster è SyncMirror, una tecnologia di mirroring sincrono scale-out dalle performance massime.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle RAC esteso con MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">Molti clienti ottimizzano il proprio RTO estendendo un cluster Oracle RAC tra i vari siti, ottenendo una configurazione completamente Active-Active. La progettazione complessiva diventa più complicata perché deve includere la gestione del quorum di Oracle RAC. Inoltre, entrambi i siti accedono ai dati, il che significa che uno switchover forzato può portare all'utilizzo di una copia dei dati non aggiornata.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Sebbene una copia dei dati sia presente in entrambi i siti, solo il controller attualmente proprietario di un aggregato può fornire i dati. Pertanto, con i cluster RAC estesi, i nodi remoti devono eseguire l'i/o attraverso una connessione site-to-site. Il risultato è un'aggiunta di latenza i/o, ma generalmente questa latenza non rappresenta un problema. Anche la rete di interconnessione RAC deve essere estesa su più siti, il che significa che è comunque necessaria una rete ad alta velocità e a bassa latenza. Se la latenza aggiunta causa un problema, il cluster può essere azionato in maniera Active-passive. Quindi, le operazioni i/o-intensive devono essere indirizzate ai nodi RAC locali del controller proprietario degli aggregati. I nodi remoti eseguono quindi operazioni i/o più chiare o vengono utilizzati esclusivamente come server warm standby.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC con ONTAP</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Configurazione a due siti</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Una configurazione RAC estesa a due siti può fornire servizi di database Active-Active che possono sopravvivere a molti scenari ma non a tutti.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">File di voto RAC</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">La prima considerazione da prendere in considerazione per la distribuzione di RAC esteso su MetroCluster deve essere la gestione del quorum. Oracle RAC dispone di due meccanismi per gestire il quorum: Heartbeat del disco e heartbeat della rete. L'heartbeat del disco controlla l'accesso allo storage utilizzando i file di voto. Con una configurazione RAC a sito singolo, una singola risorsa di voto è sufficiente fintanto che il sistema storage sottostante offre funzionalità ha.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">Nelle versioni precedenti di Oracle, i file di voto erano posizionati su dispositivi di archiviazione fisici, ma nelle versioni correnti di Oracle i file di voto sono memorizzati in gruppi di dischi ASM.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC è supportato con NFS. Durante il processo di installazione della griglia, viene creata una serie di processi ASM per presentare la posizione NFS utilizzata per i file della griglia come un gruppo di dischi ASM. Il processo è quasi trasparente per l'utente finale e non richiede alcuna gestione ASM continua al termine dell'installazione.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">Il primo requisito di una configurazione a due siti è garantire che ogni sito possa sempre accedere a più della metà dei file di voto in modo da garantire un processo di disaster recovery senza interruzioni. Questa attività era semplice prima che i file di voto fossero memorizzati in gruppi di dischi ASM, ma oggi gli amministratori devono comprendere i principi di base della ridondanza ASM.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">I gruppi di dischi ASM hanno tre opzioni di ridondanza<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, e.<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. In altre parole, senza mirror, con mirroring e a 3 vie con mirroring. Un'opzione più recente chiamata<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> è anche disponibile, ma raramente utilizzato. Il livello di ridondanza e il posizionamento dei dispositivi ridondanti controllano ciò che accade negli scenari di errore. Ad esempio:</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> la risorsa di ridondanza garantisce l'eliminazione di un sito se la connettività tra siti viene persa.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> La ridondanza con un solo disco ASM per sito garantisce l'eliminazione dei nodi su entrambi i siti se la connettività tra i siti viene persa perché nessuno dei due siti dispone di un quorum di maggioranza.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> la ridondanza con due dischi su un sito e un singolo disco sull'altro sito consente operazioni active-active quando entrambi i siti sono operativi e reciprocamente raggiungibili. Tuttavia, se il sito a disco singolo è isolato dalla rete, il sito viene eliminato.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">Heartbeat rete RAC</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">L'heartbeat della rete Oracle RAC monitora la raggiungibilità dei nodi in tutta l'interconnessione cluster. Per rimanere nel cluster, un nodo deve essere in grado di contattare più della metà degli altri nodi. In un'architettura a due siti, questo requisito crea le seguenti scelte per il numero di nodi RAC:</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">Il posizionamento di un numero uguale di nodi per sito comporta l'espulsione in un sito nel caso in cui la connettività di rete venga persa.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">Il posizionamento di N nodi su un sito e N+1 nodi sul sito opposto garantisce che la perdita di connettività intersito determini nel sito con il maggior numero di nodi rimanenti nel quorum di rete e nel sito con meno nodi evicting.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Prima di Oracle 12cR2, non era fattibile controllare quale lato avrebbe subito un'eviction durante la perdita del sito. Quando ogni sito ha un numero uguale di nodi, l'evocazione è controllata dal nodo master, che in generale è il primo nodo RAC da avviare.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 introduce la funzionalità di ponderazione dei nodi. Questa funzionalità consente agli amministratori di controllare in che modo Oracle risolve le condizioni split-brain. Ad esempio, il seguente comando imposta la preferenza per un nodo specifico in un RAC:</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Dopo aver riavviato Oracle High-Availability Services, la configurazione si presenta come segue:</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> è ora designato come server critico. Se i due nodi RAC sono isolati,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> sopravvive, e.<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> è sfrattato.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Per informazioni dettagliate, consultare il white paper Oracle "Panoramica tecnica su Oracle Clusterware 12c Release 2. "</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Per le versioni di Oracle RAC precedenti a 12cR2, il nodo master può essere identificato controllando i registri CRS come segue:</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Questo registro indica che il nodo master è<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> e il nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Ha un ID di<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Questo significa che<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> non è il nodo master. L'identità del nodo master può essere confermata con il comando<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">Il nodo con un ID di<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> è<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, che è il nodo master. In una configurazione con un numero uguale di nodi su ogni sito, il sito con<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> è il sito che sopravvive se i due set perdono la connettività di rete per qualsiasi motivo.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">È possibile che la voce di log che identifica il nodo master rimanga fuori dal sistema. In questa situazione, è possibile utilizzare i timestamp dei backup OCR (Oracle Cluster Registry).</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">Questo esempio mostra che il nodo master è<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. Indica anche una modifica nel nodo master da<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> a.<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Da qualche parte tra il 2:05 e il 21:39 maggio 4. Questo metodo di identificazione del nodo master è sicuro da utilizzare solo se sono stati controllati anche i log CRS, poiché è possibile che il nodo master sia cambiato dal precedente backup OCR. Se questa modifica si è verificata, dovrebbe essere visibile nei registri OCR.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">La maggior parte dei clienti sceglie un singolo gruppo di dischi di voto che gestisce l'intero ambiente e un numero uguale di nodi RAC su ciascun sito. Il gruppo di dischi deve essere collocato nel sito che contiene il database. Il risultato è che la perdita di connettività provoca sfratto sul sito remoto. Il sito remoto non dispone più del quorum né avrebbe accesso ai file di database, ma il sito locale continua a funzionare normalmente. Quando la connettività viene ripristinata, l'istanza remota può essere riportata nuovamente in linea.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">In caso di emergenza, è necessario uno switchover per portare online i file di database e il gruppo di dischi di voto sul sito rimasto. Se il disastro consente AD AUSO di attivare lo switchover, NVFAIL non viene attivato perché il cluster è sincronizzato e le risorse di storage vengono normalmente online. AUSO è un'operazione molto veloce e dovrebbe essere completata prima del<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> il periodo scade.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Poiché ci sono solo due siti, non è possibile utilizzare alcun tipo di software di rottura automatica esterna, il che significa che lo switchover forzato deve essere un'operazione manuale.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Configurazioni a tre siti</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Un cluster RAC esteso è molto più semplice da progettare con tre siti. I due siti che ospitano ciascuna metà del sistema MetroCluster supportano anche i carichi di lavoro del database, mentre il terzo sito funge da tiebreaker sia per il database che per il sistema MetroCluster. La configurazione di Oracle Tiebreaker può essere semplice come collocare un membro del gruppo di dischi ASM utilizzato per il voto su un sito 3rd e può anche includere un'istanza operativa sul sito 3rd per garantire che vi sia un numero dispari di nodi nel cluster RAC.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Per informazioni importanti sull'utilizzo di NFS in una configurazione RAC estesa, consultare la documentazione Oracle relativa al "gruppo di errori del quorum". In sintesi, potrebbe essere necessario modificare le opzioni di montaggio NFS per includere l'opzione soft per garantire che la perdita di connettività alle risorse quorum di hosting del sito 3rd non blocchi i server Oracle primari o i processi Oracle RAC.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster e NVFAIL</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Singola istanza di Oracle su MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Come indicato in precedenza, la presenza di un sistema MetroCluster non implica necessariamente l'aggiunta o la modifica delle Best practice per l'utilizzo di un database. La maggior parte dei database attualmente in esecuzione sui sistemi MetroCluster dei clienti è a singola istanza e segue le raccomandazioni contenute nella documentazione relativa a Oracle su ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror fornisce una copia sincrona dei dati nel sito di disaster recovery, ma per renderli disponibili sono necessari un sistema operativo e le applicazioni associate. L'automazione di base può migliorare notevolmente il tempo di failover dell'ambiente complessivo. I prodotti Clusterware come Veritas Cluster Server (VCS) vengono spesso utilizzati per creare un cluster in tutti i siti e in molti casi il processo di failover può essere guidato con semplici script.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">In caso di perdita dei nodi primari, il clusterware (o gli script) viene configurato in modo da portare i database online nel sito alternativo. Un'opzione è creare server di standby preconfigurati per le risorse NFS o SAN che compongono il database. Se il sito primario non funziona, il clusterware o l'alternativa con script esegue una sequenza di azioni simile alle seguenti:</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Montaggio di file system e/o montaggio di gruppi di dischi ASM</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Avvio del database</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">Il requisito principale di questo approccio è rappresentato da un sistema operativo in esecuzione sul sito remoto. Deve essere preconfigurato con i file binari di Oracle, il che significa anche che attività come l'applicazione delle patch Oracle devono essere eseguite sul sito primario e di standby. In alternativa, è possibile eseguire il mirroring dei file binari di Oracle nel sito remoto e montarli se viene dichiarato un disastro.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Avvio manuale dei database o configurazione delle macchine virtuali per avviare automaticamente i database, ad esempio, un cluster ESX può estendersi su diversi siti. In caso di disastro, dopo lo switchover, è possibile portare online le macchine virtuali nel sito di disaster recovery. Fino a quando i datastore che ospitano i database server virtualizzati non saranno in uso in occasione di un evento di emergenza, non sarà necessario impostare alcun valore<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sui volumi associati.</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Quasi tutte le applicazioni richiedono la replica dei dati.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">A livello di base, la replica può significare una copia su nastro archiviata fuori sede o una replica a livello di applicazione in una posizione di standby. Il disaster recovery si riferisce all'utilizzo di queste copie di replica per portare un servizio online in caso di perdita catastrofica del servizio.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP offre numerose opzioni di replica per soddisfare numerosi requisiti in maniera nativa all'interno dello storage array e soddisfare una vasta gamma di esigenze. Queste opzioni includono la replica semplice dei backup su un sito remoto fino a una soluzione sincrona e completamente automatizzata che fornisce disaster recovery e alta disponibilità nella stessa piattaforma.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Le principali tecnologie di replica ONTAP applicabili alle applicazioni sono le tecnologie SnapMirror e NetApp SyncMirror di NetApp. Non si tratta di prodotti aggiuntivi, bensì di prodotti completamente integrati in ONTAP e attivati tramite la semplice aggiunta di una chiave di licenza. Anche la replica a livello di storage non è l'unica opzione possibile. La replica a livello di applicazione, come ad esempio Oracle DataGuard, può anche integrarsi in una strategia di protezione dei dati basata su ONTAP.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">La scelta giusta dipende dai requisiti specifici di replica, recovery e conservazione.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">SnapMirror di ONTAP</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror è la soluzione di replica asincrona di NetApp, idealmente creata per proteggere set di dati grandi, complicati e dinamici come database e le loro applicazioni associate. I valori chiave sono i seguenti:</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">*Gestibilità.* SnapMirror è facile da configurare e gestire perché è una parte nativa del software di storage. Non sono richiesti prodotti aggiuntivi. Le relazioni di replica possono essere stabilite in pochi minuti e possono essere gestite direttamente nel sistema storage.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Semplicità.* la replica si basa su volumi FlexVol, ovvero container di LUN o file replicati come unico gruppo coerente.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Efficienza.* dopo aver stabilito la relazione di replica iniziale, vengono replicate solo le modifiche. Inoltre, funzionalità di efficienza come deduplica e compressione sono preservate, riducendo ulteriormente la quantità di dati da trasferire in un sito remoto.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flessibilità.* i mirror possono essere temporaneamente interrotti per consentire il test delle procedure di ripristino di emergenza, e quindi il mirroring può essere facilmente ristabilito senza la necessità di un rimirroring completo. Solo i dati modificati devono essere applicati per riportare i mirror in sincronizzazione. Il mirroring può anche essere invertito per consentire una rapida risincronizzazione dopo il termine del disastro e il sito originale di nuovo in servizio. Infine, sono disponibili per test e sviluppo cloni in lettura e scrittura dei dati replicati.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP offre diverse tecnologie di replica, ma la più flessibile è SnapMirror, un'opzione di mirroring asincrono da volume a volume.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Come accennato in precedenza, un volume FlexVol è l'unità di gestione di base per i backup basati su Snapshot e il ripristino basato su SnapRestore. Un volume FlexVol è anche l'unità di base per la replica basata su SnapMirror. Il primo passaggio consiste nel determinare il mirror di base del volume di origine rispetto al volume di destinazione. Dopo l'inizializzazione di questa relazione mirror, tutte le operazioni successive si basano solo sulla replica dei dati modificati.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Dal punto di vista del ripristino, i valori chiave di SnapMirror sono i seguenti:</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">Le operazioni di SnapMirror sono semplici da comprendere e possono essere facilmente automatizzate.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Un semplice aggiornamento di una replica SnapMirror richiede la replica solo delle modifiche delta, riducendo i requisiti di larghezza di banda e consentendo aggiornamenti più frequenti.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror è altamente granulare. Si basa su semplici relazioni da volume a volume, consentendo la creazione di centinaia di repliche e intervalli di replica gestiti in modo indipendente. Non è necessario che la replica sia adatta a ogni scenario.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">La direzione di specchiatura può essere facilmente invertita, pur mantenendo la capacità di aggiornare la relazione in base alle sole modifiche. In questo modo è possibile usufruire di una rapida funzionalità di failback dopo che il sito primario viene ripristinato in servizio dopo un evento disastroso, ad esempio un'interruzione dell'alimentazione. Solo le modifiche devono essere sincronizzate di nuovo all'origine.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Gli specchi possono essere facilmente rotti e risincronizzati in modo efficiente per consentire la ripetizione delle procedure di ripristino di emergenza.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">SnapMirror in modalità di replica completa a livello di blocco replica non solo i dati di un volume, ma anche gli Snapshot. Questa funzionalità fornisce una copia dei dati e una serie completa di backup sul sito di disaster recovery.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">SnapMirror in modalità flessibile della versione consente la replica di snapshot specifiche, consentendo diversi tempi di conservazione nei siti primario e secondario.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror sincrono</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror Synchronous (SM-S) è una versione avanzata di SnapMirror che offre replica sincrona RPO=0. Viene più spesso utilizzato nelle architetture storage in cui solo il sottoinsieme dei dati totali richiede il mirroring sincrono.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S può operare in due modalità leggermente diverse, Sync e StrictSync.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">In modalità di sincronizzazione, le modifiche vengono replicate prima di essere confermate. Questo garantisce un RPO pari a zero, a condizione che la replica sia operativa. Se la modifica non può essere replicata, SM-S può uscire dalla modalità sincrona e consentire il proseguimento delle operazioni. In questo modo è possibile ottenere RPO=0 in circostanze normali, ma i processi dei dati non si interrompono completamente se la destinazione di replica non è disponibile.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantisce un RPO=0. Un errore di replica delle modifiche causa un errore di i/o, che in genere provoca l'arresto dell'applicazione.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Per una spiegazione completa di SM-S, vedere<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> E la documentazione ufficiale di ONTAP. Le nuove versioni di ONTAP vengono continuamente aggiunte alle nuove funzioni.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Gruppi di coerenza</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP consente la creazione di snapshot di gruppi di coerenza; a partire da 9.13.1, ONTAP può replicare gruppi di volumi (ricorda che un volume nella terminologia ONTAP non è una LUN, ma un container di gestione costituito da uno o più file o LUN) come gruppo coerente.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">Il risultato è che è possibile replicare un set di dati multi-volume e assicurare che tutti i volumi siano cross-coerenti. Tra le altre cose, questo consente operazioni di DR "breaking the mirror and go" senza la necessità di fasi aggiuntive di ripristino del database o delle applicazioni.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster e SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster è anche una soluzione di replica sincrona dedicata a workload mission-critical su larga scala. Replica basata su SyncMirror. Al livello più semplice, SyncMirror crea due set completi di dati con protezione RAID in due posizioni diverse. Potrebbero trovarsi in camere comunicanti all'interno di un data center o a una distanza di molti chilometri.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror è completamente integrato con ONTAP e funziona appena al di sopra del livello RAID. Pertanto, tutte le consuete funzionalità di ONTAP, come le copie Snapshot, SnapRestore e NetApp FlexClone, funzionano perfettamente. Il prodotto rimane ONTAP e include un livello aggiuntivo di mirroring sincrono dei dati.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Una raccolta di controller ONTAP che gestiscono i dati SyncMirror viene chiamata configurazione NetApp MetroCluster. Lo scopo principale di MetroCluster è fornire accesso con high Availability ai dati con mirroring sincrono in una varietà di scenari tipici di errore di disaster recovery.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Di seguito sono riportati i valori chiave della protezione dei dati con MetroCluster e SyncMirror:</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">Nelle operazioni normali, SyncMirror offre mirroring sincrono garantito tra siti. Un'operazione di scrittura non viene riconosciuta fino a quando non è presente su supporti non volatili in entrambi i siti.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">Se si verifica un guasto nella connettività tra i siti, SyncMirror passa automaticamente alla modalità asincrona per mantenere il sito primario che fornisce dati fino al ripristino della connettività. Una volta ripristinato, garantisce una rapida risincronizzazione aggiornando in modo efficiente le modifiche accumulate sul sito primario. La reinizializzazione completa non è necessaria.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror è inoltre completamente compatibile con sistemi basati su SyncMirror. Ad esempio, è possibile che un database primario venga eseguito su un cluster MetroCluster distribuito in due siti geografici. Questo database può anche replicare i backup su un terzo sito come archivi a lungo termine o per la creazione di cloni in un ambiente DevOps.</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Le procedure di replica per un database Oracle sono essenzialmente le stesse delle procedure di backup. Il requisito principale è che gli snapshot che costituiscono un backup recuperabile debbano essere replicati nel sistema di storage remoto.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Come discusso in precedenza nella documentazione sulla protezione locale dei dati, è possibile creare un backup ripristinabile con il processo di hot backup o sfruttando i backup ottimizzati per le istantanee.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Layout dei dati</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Supponendo che i file di dati siano incapsulati in volumi dedicati, la domanda successiva è come gestire i log di ripristino, i log di archivio e i file di controllo. L'approccio più semplice consiste nel posizionare tutti questi tipi di dati in un singolo volume. Il vantaggio è che i log di ripristino replicati, i log di archivio e i controlfile sono perfettamente sincronizzati. Non è necessario un ripristino incompleto o l'utilizzo di un controlfile di backup, sebbene sia consigliabile creare script anche per la creazione di file di controllo di backup per altri scenari di ripristino potenziali.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Layout a due volumi</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">Il layout più semplice è illustrato nella figura seguente.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">Questo è l'approccio più comune. Dal punto di vista dei DBA, potrebbe sembrare insolito colocare tutte le copie dei log di ripristino e dei log di archivio sullo stesso volume. Tuttavia, la separazione non offre molta protezione extra quando file e LUN si trovano tutti sullo stesso set di dischi sottostante.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Layout a tre volumi</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">A volte è necessaria la separazione dei log di ripristino a causa di problemi relativi alla protezione dei dati o della necessità di distribuire i/o dei log di ripristino tra i controller. In tal caso, il layout a tre volumi illustrato nella figura seguente può essere utilizzato per la replica, evitando tuttavia qualsiasi necessità di eseguire un ripristino incompleto o di fare affidamento su file di controllo di backup.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Ciò consente lo striping dei log di redo e dei file di controllo attraverso insiemi indipendenti di mandrini e controllori sulla sorgente. Tuttavia, i log di archivio e una serie di file di controllo e i log di ripristino possono ancora essere replicati in uno stato sincronizzato con i log di archivio.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">In questo modello, il volume Redo Log B non viene replicato.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Procedura di disaster recovery: Backup a caldo</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Per eseguire il ripristino di emergenza utilizzando i backup a caldo, attenersi alla seguente procedura di base:</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prerequisiti</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">I file binari Oracle vengono installati sul server di disaster recovery.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Le istanze di database sono elencate nella<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">Il<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> e.<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> oppure<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> per l'esempio deve essere in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directory. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Disaster recovery</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Interrompere i mirror per i file di dati e il volume di registro comune.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Ripristinare i volumi del file dati nello snapshot di backup a caldo più recente dei file di dati.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Se si utilizza una rete SAN, attivare gruppi di volumi e/o montare file system.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Riprodurre i log di archivio nel punto desiderato.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Se si desidera completare il ripristino, riprodurre i registri di ripristino correnti.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">L'utilizzo di NFS semplifica notevolmente la procedura poiché i file system NFS per i file di dati e di log possono essere montati sul server di disaster recovery in qualsiasi momento. Diventa lettura/scrittura quando gli specchi sono rotti.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Procedura di disaster recovery: Backup ottimizzati per le snapshot</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">Il ripristino da backup ottimizzati per snapshot è quasi identico alla procedura di ripristino hot backup con le seguenti modifiche:</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Ripristinare i volumi del file dati in uno snapshot creato prima della replica del volume del registro corrente.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Queste differenze semplificano la procedura di ripristino generale poiché non è necessario assicurarsi che uno snapshot sia stato creato correttamente sull'origine mentre il database era in modalità di backup a caldo. La procedura di disaster recovery si basa sull'ora delle snapshot nel sito di disaster recovery. Lo stato del database al momento della creazione degli snapshot non è importante.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Disaster recovery con snapshot di backup a caldo</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Questo è un esempio di strategia di disaster recovery basata sulla replica delle snapshot di backup hot. E costituisce anche un esempio di strategia di backup locale semplice e scalabile.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">Il database di esempio si trova in un'architettura di base a due volumi.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene i file di dati e.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> viene utilizzato per i log di ripristino combinati, i log di archivio e i file di controllo.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Sono necessarie due pianificazioni, una per i backup notturni dei file dati e una per i backup dei file di registro. Questi sono chiamati rispettivamente mezzanotte e 15minutes.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Queste pianificazioni vengono quindi utilizzate all'interno dei criteri di snapshot<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> e.<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, come mostrato di seguito:</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Infine, queste policy di snapshot vengono applicate ai volumi,</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Definisce la pianificazione del backup dei volumi. Le snapshot dei file dati vengono create a mezzanotte e conservate per 60 giorni. Il volume di registro contiene 72 snapshot create a intervalli di 15 minuti, con un massimo di 18 ore di copertura.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">Quindi, assicurarsi che il database sia in modalità hot backup quando viene creata una snapshot del file dati. Questo viene fatto con un piccolo script che accetta alcuni argomenti di base che avviano e interrompono la modalità di backup sul SID specificato.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">Questo passaggio garantisce che il database sia in modalità di backup a caldo durante una finestra di quattro minuti che circonda lo snapshot di mezzanotte.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">La replica nel sito di disaster recovery viene configurata come segue:</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">La destinazione del volume del registro viene aggiornata ogni 15 minuti. Questo garantisce un RPO di circa 15 minuti. L'intervallo di aggiornamento preciso varia leggermente a seconda del volume totale dei dati che devono essere trasferiti durante l'aggiornamento.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">La destinazione del volume del file dati viene aggiornata ogni sei ore. Ciò non influisce su RPO o RTO. Qualora fosse necessario un ripristino di emergenza, uno dei primi passaggi consiste nel ripristinare il volume del file dati in uno snapshot di backup a caldo. Lo scopo dell'intervallo di aggiornamento più frequente è di regolare la velocità di trasferimento di questo volume. Se l'aggiornamento è programmato una volta al giorno, tutte le modifiche accumulate durante il giorno devono essere trasferite contemporaneamente. Con aggiornamenti più frequenti, le modifiche vengono replicate più gradualmente nel corso della giornata.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">In caso di disastro, il primo passo è quello di interrompere i mirror per entrambi i volumi:</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Le repliche sono ora in lettura-scrittura. Il passaggio successivo consiste nel verificare la data e l'ora del volume di registro.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">La copia più recente del volume di registro è il 14th marzo alle ore 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">Quindi, identificare lo snapshot di backup a caldo creato immediatamente prima dello stato del volume di registro. Questa operazione è necessaria in quanto il processo di riproduzione dei log richiede la creazione di tutti i log di archivio in modalità hot backup. Pertanto, la replica del volume di registro deve essere precedente alle immagini di backup a caldo oppure non deve contenere i registri richiesti.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">L'istantanea creata più di recente è<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Questa è l'immagine di backup a caldo più recente dei file di dati e viene quindi ripristinata nel modo seguente:</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">A questo punto, il database è pronto per essere recuperato. Se si trattasse di un ambiente SAN, il passaggio successivo includerebbe l'attivazione di gruppi di volumi e il montaggio di file system, un processo facilmente automatizzato. Poiché questo esempio utilizza NFS, i file system sono già montati e diventano in lettura-scrittura senza ulteriore necessità di montaggio o attivazione nel momento in cui i mirror sono stati rotti.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">A questo punto il database può essere ripristinato al punto desiderato oppure può essere completamente recuperato in relazione alla copia dei log di ripristino replicati. In questo esempio viene illustrato il valore del registro di archiviazione combinato, controlfile e del volume del registro di ripristino. Il processo di ripristino è notevolmente più semplice in quanto non è necessario fare affidamento su file di controllo di backup o su file di registro di ripristino.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Disaster recovery con backup ottimizzati per le snapshot</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">La procedura di disaster recovery che utilizza backup ottimizzati per le istantanee è quasi identica alla procedura di disaster recovery per il backup a caldo. Come per la procedura di snapshot di backup a caldo, si tratta essenzialmente anche di un'estensione di un'architettura di backup locale in cui i backup vengono replicati per essere utilizzati per il disaster recovery. Nell'esempio seguente viene illustrata la procedura di configurazione e ripristino dettagliata. Questo esempio richiama inoltre le principali differenze tra i backup hot e quelli ottimizzati per le istantanee.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">Il database di esempio si trova in un'architettura di base a due volumi.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene file di dati, e.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> viene utilizzato per i log di ripristino combinati, i log di archivio e i file di controllo.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Sono necessarie due pianificazioni: Una per i backup notturni dei file dati e una per i backup dei file di registro. Questi sono chiamati rispettivamente mezzanotte e 15minutes.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">Questo controlla la pianificazione di backup finale dei volumi. Le snapshot vengono create a mezzanotte e conservate per 60 giorni. Il volume di registro contiene 72 snapshot create a intervalli di 15 minuti, con un massimo di 18 ore di copertura.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">La destinazione del volume del registro viene aggiornata ogni 15 minuti. In questo modo si ottiene un RPO di circa 15 minuti, con un intervallo di aggiornamento preciso che varia leggermente a seconda del volume totale dei dati che devono essere trasferiti durante l'aggiornamento.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">La destinazione del volume del file dati viene aggiornata ogni 6 ore. Ciò non influisce su RPO o RTO. Se è necessario un ripristino di emergenza, è necessario ripristinare prima il volume del file dati in una snapshot di backup a caldo. Lo scopo dell'intervallo di aggiornamento più frequente è di regolare la velocità di trasferimento di questo volume. Se l'aggiornamento è stato pianificato una volta al giorno, tutte le modifiche accumulate durante il giorno devono essere trasferite contemporaneamente. Con aggiornamenti più frequenti, le modifiche vengono replicate più gradualmente nel corso della giornata.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">In caso di disastro, innanzitutto occorre interrompere i mirror per tutti i volumi:</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">La copia più recente del volume di registro è il 14th marzo alle ore 13:30. Quindi, identificare lo snapshot del file dati creato immediatamente prima dello stato del volume di registro. Ciò è necessario in quanto il processo di riproduzione dei log richiede tutti i log di archivio appena precedenti allo snapshot nel punto di ripristino desiderato.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">L'istantanea creata più di recente è<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Ripristinare questa istantanea.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">Il database è ora pronto per essere recuperato. Se si trattasse di un ambiente SAN, si attiverebbero quindi gruppi di volumi e si montassero file system, un processo facilmente automatizzato. Tuttavia, questo esempio utilizza NFS, quindi i file system sono già montati e sono diventati lettura-scrittura senza ulteriore necessità di montaggio o attivazione nel momento in cui i mirror sono stati rotti.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">A questo punto il database può essere ripristinato al punto desiderato oppure può essere completamente recuperato in relazione alla copia dei log di ripristino replicati. In questo esempio viene illustrato il valore del registro di archiviazione combinato, controlfile e del volume del registro di ripristino. Il processo di recupero è notevolmente più semplice in quanto non è necessario fare affidamento su file di controllo di backup o su file di registro di ripristino.</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">La replica di un gruppo di coerenza può essere semplice come la pianificazione della replica di un singolo volume tramite SnapMirror. Sono inclusi file di dati, file di controllo, log di archivio e log di ripristino. Ogni aggiornamento SnapMirror crea una nuova copia del database nel sito di destinazione coerente e pronta per l'attivazione tramite la rottura del mirror.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Se un database deve span volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot).</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Un ulteriore vantaggio di questa strategia, se utilizzata con SnapMirror in modalità di replica a livello di blocco, è la replica completa di tutti gli snapshot nel sistema di storage di origine. La serie completa di backup viene replicata oltre alla copia di disaster recovery.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Tiering del log di archivio Oracle</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">Forse l'utilizzo più importante per FabricPool è il miglioramento dell'efficienza dei dati cold noti, come i log delle transazioni dei database.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Tiering del backup Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">I backup delle applicazioni tradizionali includono prodotti come Oracle Recovery Manager, che creano backup basati su file al di fuori della posizione del database originale.</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">In ONTAP sono disponibili quattro criteri che controllano il modo in cui i dati Oracle sul livello di prestazioni diventano candidati per il trasferimento al livello di capacità.</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">Anche se il tiering FabricPool opera a livello di blocco, in alcuni casi può essere utilizzato per fornire un tiering a livello di file.</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Poiché FabricPool opera a livello di blocchi, i file soggetti a modifiche possono essere parzialmente suddivisi in Tier nello storage a oggetti e rimanere parzialmente anche nel Tier di performance.</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Interruzioni di accesso agli archivi di oggetti</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">La comprensione dell'impatto del tiering FabricPool su Oracle e altri database richiede una conoscenza dell'architettura FabricPool di basso livello.</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">I criteri di tiering controllano i blocchi di database Oracle sottoposti a tiering dal Tier di performance al Tier di capacità. I criteri di recupero controllano ciò che accade quando viene letto un blocco a cui è stato eseguito il tiering.</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Linee guida per il dimensionamento e il numero di LUN dei database Oracle</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">La scelta delle dimensioni ottimali e del numero di LUN da utilizzare è un elemento critico per ottenere performance e gestibilità ottimali dei database Oracle.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">I database Oracle e NFS vengono affittati e bloccati</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 è stateless. Ciò significa che il server NFS (ONTAP) non tiene traccia di quali file system sono montati, da chi, o quali blocchi sono realmente presenti.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP dispone di alcune funzionalità che registreranno i tentativi di mount, quindi si ha un'idea di quali client possono accedere ai dati e potrebbero essere presenti blocchi di avvisi, ma non è garantito che le informazioni siano complete al 100%. Non può essere completo, perché il tracciamento dello stato del client NFS non fa parte dello standard NFSv3.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">NFSv4 statefulness</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">Al contrario, NFSv4 è stateful. Il server NFSv4 tiene traccia di quali client utilizzano i file system, quali file esistono, quali file e/o aree di file sono bloccati, ecc. Ciò significa che è necessaria una comunicazione regolare tra un server NFSv4 per mantenere aggiornati i dati di stato.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Gli stati più importanti gestiti dal server NFS sono NFSv4 Locks e NFSv4 Leasing, e sono molto interconnessi. Dovete capire come ognuno funziona da se stesso e come si relazionano l'uno con l'altro.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">NFSv4 serrature</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Con NFSv3, i blocchi sono indicativi. Un client NFS può comunque modificare o eliminare un file "bloccato". Un blocco NFSv3 non scade da solo, deve essere rimosso. Questo crea problemi. Ad esempio, se si dispone di un'applicazione in cluster che crea blocchi NFSv3 e uno dei nodi ha esito negativo, come procedere? È possibile codificare l'applicazione sui nodi sopravvissuti per rimuovere i blocchi, ma come si fa a sapere che questo è sicuro? Il nodo "guasto" potrebbe essere operativo, ma non comunica con il resto del cluster?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Con NFSv4, i blocchi hanno una durata limitata. Finché il client che mantiene i blocchi continua il check-in con il server NFSv4, nessun altro client è autorizzato ad acquisire tali blocchi. Se un client non riesce a eseguire il check in con NFSv4, i blocchi vengono revocati dal server e gli altri client potranno richiedere e ottenere i blocchi.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">NFSv4 leasing</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">I blocchi NFSv4 sono associati a un lease NFSv4. Quando un client NFSv4 stabilisce una connessione con un server NFSv4, ottiene un lease. Se il client ottiene un blocco (ci sono molti tipi di blocchi) allora il blocco è associato al lease.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Questo lease ha un timeout definito. Per impostazione predefinita, ONTAP imposta il valore di timeout su 30 secondi:</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Ciò significa che un client NFSv4 deve effettuare il check-in con il server NFSv4 ogni 30 secondi per rinnovare i propri leasing.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">Il leasing viene rinnovato automaticamente da qualsiasi attività, quindi se il client sta lavorando non è necessario eseguire operazioni di aggiunta. Se un'applicazione diventa silenziosa e non sta svolgendo un lavoro reale, sarà necessario eseguire una sorta di operazione keep-alive (chiamata SEQUENZA). In sostanza, è solo dire "sono ancora qui, ti prego di rinnovare i miei contratti di leasing".</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 è stateless. Non si aspetta la comunicazione dai clienti. NFSv4 è stateful, e una volta trascorso il periodo di leasing, il lease scade, i blocchi vengono revocati e i file bloccati vengono resi disponibili ad altri client.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Con NFSv3, è possibile spostare i cavi di rete, riavviare gli switch di rete, apportare modifiche alla configurazione e assicurarsi che non si verifichi alcun problema. Normalmente, le applicazioni aspettavano solo pazientemente che la connessione di rete funzionasse di nuovo.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Con NFSv4, avete 30 secondi (a meno che non abbiate aumentato il valore di quel parametro all'interno di ONTAP) per completare il vostro lavoro. Se si supera questo limite, il tempo di leasing è scaduto. In genere si verificano arresti anomali delle applicazioni.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Ad esempio, se si dispone di un database Oracle e si verifica una perdita di connettività di rete (talvolta chiamata "partizione di rete") che supera il timeout del lease, il database verrà arrestato.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">Di seguito viene riportato un esempio di ciò che accade nel registro degli avvisi di Oracle:</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Se si esaminano i syslogs, si dovrebbero vedere alcuni di questi errori:</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">I messaggi di registro sono in genere il primo segno di un problema, diverso dal blocco dell'applicazione. In genere, durante l'interruzione della rete non viene visualizzato nulla, poiché i processi e il sistema operativo stesso sono bloccati e tentano di accedere al file system NFS.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Gli errori vengono visualizzati dopo che la rete è nuovamente operativa. Nell'esempio precedente, una volta ristabilita la connettività, il sistema operativo tentava di riacquisire i blocchi, ma era troppo tardi. Il leasing era scaduto e i blocchi sono stati rimossi. Ciò genera un errore che si propaga fino al livello Oracle e causa il messaggio nel registro degli avvisi. È possibile che vengano visualizzate variazioni su questi modelli a seconda della versione e della configurazione del database.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">Riassumendo, NFSv3 tollera l'interruzione di rete, ma NFSv4 è più sensibile e impone un periodo di leasing definito.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">Cosa succede se un timeout di 30 secondi non è accettabile? Cosa succede se si gestisce una rete a variazione dinamica in cui gli switch vengono riavviati o i cavi vengono ricollocati e il risultato è un'interruzione occasionale della rete? È possibile scegliere di estendere il periodo di leasing, ma se si desidera farlo richiede una spiegazione di NFSv4 periodi di tolleranza.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">NFSv4 periodi di grazia</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Se un server NFSv3 viene riavviato, è pronto a servire i/o quasi istantaneamente. Non manteneva alcun tipo di stato sui client. Il risultato è che un'operazione di takeover della ONTAP spesso sembra quasi istantanea. Quando un controller è pronto a iniziare a servire i dati, invia un ARP alla rete che segnala la modifica della topologia. I client normalmente rilevano questo quasi istantaneamente e i dati riprendono a fluire.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4, tuttavia, produrrà una breve pausa. È solo una parte di come funziona NFSv4.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">I server NFSv4 devono tenere traccia dei lease, dei blocchi e di chi utilizza i dati. Se un server NFS si riavvia o perde potenza per un momento o viene riavviato durante l'attività di manutenzione, il risultato è il lease/lock e le altre informazioni del client vengono perse. Il server deve individuare quale client utilizza i dati prima di riprendere le operazioni. È qui che entra in gioco il periodo di grazia.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Se all'improvviso si spegne e riaccende il server NFSv4. Quando viene eseguito il backup, i client che tentano di riprendere io riceveranno una risposta che essenzialmente dice: "Ho perso le informazioni di lease/lock. Vuoi registrare nuovamente i blocchi?" Questo è l'inizio del periodo di grazia. Il valore predefinito è 45 secondi su ONTAP:</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">Il risultato è che, dopo un riavvio, un controller sospenderà io mentre tutti i client recuperano i loro lease e blocchi. Al termine del periodo di prova, il server riprenderà le operazioni io.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Timeout leasing vs periodi di grazia</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">NFS diretto di Oracle</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">I database Oracle possono utilizzare NFS in due modi.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">In primo luogo, può usare un filesystem montato usando il client NFS nativo che fa parte del sistema operativo. Questo è talvolta chiamato kernel NFS, o kNFS. Il filesystem NFS è montato e usato dal database Oracle esattamente come qualsiasi altra applicazione userebbe un filesystem NFS.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">Il secondo metodo è Oracle Direct NFS (DNFS). Si tratta di un'implementazione dello standard NFS nel software di database Oracle. Senza modificare le modalità di configurazione o gestione dei database Oracle da parte del DBA. Purché le impostazioni del sistema storage siano corrette, l'utilizzo del DNFS deve essere trasparente per il team DBA e gli utenti finali.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Un database con la funzione DNFS attivata ha ancora i consueti filesystem NFS montati. Una volta aperto il database, il database Oracle apre una serie di sessioni TCP/IP ed esegue direttamente le operazioni NFS.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">NFS diretto</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">Il valore principale di Oracle Direct NFS è quello di ignorare il client NFS host ed eseguire operazioni di file NFS direttamente su un server NFS. Per abilitarla è sufficiente modificare la libreria Oracle Disk Manager (ODM). Le istruzioni per questo processo sono fornite nella documentazione di Oracle.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">L'utilizzo di DNFS porta a un significativo miglioramento delle performance di i/o e riduce il carico sull'host e sul sistema storage poiché l'i/o viene eseguito nel modo più efficiente possibile.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">Inoltre, Oracle DNFS include un'opzione *opzionale* per il multipathing e la fault tolerance dell'interfaccia di rete. Ad esempio, è possibile associare due interfacce 10Gb in modo da ottenere una larghezza di banda di 20Gb Gbps. Un errore di un'interfaccia provoca il tentativo di i/o sull'altra interfaccia. Il funzionamento complessivo è molto simile al multipathing FC. Il multipathing era comune anni fa quando ethernet a 1Gb GB rappresentava lo standard più comune. Una NIC 10Gb è sufficiente per la maggior parte dei carichi di lavoro Oracle, ma se ne richiede di più, è possibile collegare 10Gb NIC.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Quando si utilizza DNFS, è fondamentale che tutte le patch descritte in Oracle Doc 1495104,1 siano installate. Se non è possibile installare una patch, è necessario valutare l'ambiente per assicurarsi che i bug descritti in quel documento non causino problemi. In alcuni casi, l'impossibilità di installare le patch necessarie impedisce l'utilizzo di DNFS.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">Non utilizzare DNFS con alcun tipo di risoluzione dei nomi round-robin, compresi DNS, DDNS, NIS o qualsiasi altro metodo. Ciò include la funzione di bilanciamento del carico DNS disponibile in ONTAP. Quando un database Oracle che utilizza DNFS risolve un nome host in un indirizzo IP, non deve cambiare nelle ricerche successive. Ciò può causare arresti anomali del database Oracle e possibili danni ai dati.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Accesso diretto NFS e file system host</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">L'utilizzo di DNFS può causare occasionalmente problemi per le applicazioni o le attività degli utenti che si basano sui file system visibili montati sull'host perché il client DNFS accede al file system fuori banda dal sistema operativo host. Il client DNFS può creare, eliminare e modificare i file senza conoscere il sistema operativo.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Quando vengono utilizzate le opzioni di montaggio per i database a istanza singola, consentono la memorizzazione nella cache degli attributi di file e directory, il che significa anche che il contenuto di una directory viene memorizzato nella cache. Pertanto, DNFS può creare un file, e c'è un breve ritardo prima che il sistema operativo rilegga il contenuto della directory e il file diventi visibile all'utente. Questo non è generalmente un problema, ma, in rare occasioni, utility come SAP BR*Tools potrebbero avere problemi. In questo caso, risolvere il problema modificando le opzioni di montaggio in modo da utilizzare le raccomandazioni per Oracle RAC. Questa modifica comporta la disabilitazione di tutta la cache dell'host.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Modificare le opzioni di montaggio solo quando (a) viene utilizzato DNFS e (b) un problema deriva da un ritardo nella visibilità dei file. Se DNFS non è in uso, l'utilizzo delle opzioni di montaggio di Oracle RAC su un database a singola istanza comporta un peggioramento delle prestazioni.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Configurazione NFS per database Oracle</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp offre storage NFS Enterprise da oltre 30 anni e il suo utilizzo cresce insieme alla spinta verso infrastrutture basate sul cloud grazie alla sua semplicità.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">Versioni di NFS</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">Il client NFS del sistema operativo deve essere supportato da NetApp.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 è supportato con sistemi operativi che seguono lo standard NFSv3.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 è supportato con il client Oracle DNFS.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 è supportato con tutti i sistemi operativi che seguono lo standard NFSv4.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">I sistemi NFSv4,1 e NFSv4,2 richiedono supporto specifico per il sistema operativo. Consultare <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Per i sistemi operativi supportati.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">Il supporto di Oracle DNFS per NFSv4,1 richiede Oracle 12.2.0.2 o versione successiva.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">Matrice di supporto di NetApp</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">Il <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Per NFSv3 e NFSv4 non sono inclusi sistemi operativi specifici. Tutti i sistemi operativi che rispettano la RFC sono generalmente supportati. Quando si cerca il supporto NFSv3 o NFSv4 nel IMT online, non selezionare un sistema operativo specifico perché non verranno visualizzate corrispondenze. Tutti i sistemi operativi sono implicitamente supportati dalla policy generale.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Tabelle degli slot TCP per Linux NFSv3</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">Le tabelle degli slot TCP sono l'equivalente di NFSv3 della profondità della coda degli HBA (host Bus Adapter). Queste tabelle controllano il numero di operazioni NFS che possono essere in sospeso in qualsiasi momento. Il valore predefinito è di solito 16, che è troppo basso per ottenere prestazioni ottimali. Il problema opposto si verifica sui kernel Linux più recenti, che possono aumentare automaticamente il limite della tabella degli slot TCP a un livello che satura il server NFS con le richieste.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Per prestazioni ottimali e per evitare problemi di prestazioni, regolare i parametri del kernel che controllano le tabelle degli slot TCP.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Eseguire<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> e osservare i seguenti parametri:</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Tutti i sistemi Linux dovrebbero includere<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, ma solo alcuni includono<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Entrambi devono essere impostati su 128.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">La mancata impostazione di questi parametri può avere effetti significativi sulle prestazioni. In alcuni casi, le prestazioni sono limitate poiché il sistema operativo linux non fornisce i/o sufficienti In altri casi, le latenze i/o aumentano quando il sistema operativo linux tenta di emettere più i/o di quanto possa essere gestito.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR e NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Alcuni clienti hanno segnalato problemi di prestazioni derivanti da una quantità eccessiva di i/o sui dati in<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> posizione. Il problema generalmente non si verifica finché non si sono accumulati molti dati sulle prestazioni. Il motivo dell'eccessivo i/o è sconosciuto, ma questo problema sembra essere dovuto ai processi Oracle che eseguono ripetutamente la scansione della directory di destinazione per rilevare eventuali modifiche.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Smontaggio del<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e/o.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Le opzioni di montaggio consentono il caching del sistema operativo host e riducono i livelli di i/o dello storage.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp consiglia* di non piazzare<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> dati su un file system con<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> oppure<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> perché è probabile che si verifichino problemi di prestazioni. Separare<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> dati in un punto di montaggio diverso, se necessario.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">nfs-rootonly e mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP include un'opzione NFS denominata<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Che controlla se il server accetta connessioni di traffico NFS da porte elevate. Come misura di sicurezza, solo l'utente root è autorizzato ad aprire connessioni TCP/IP utilizzando una porta di origine inferiore a 1024, poiché tali porte sono normalmente riservate all'uso del sistema operativo, non ai processi utente. Questa restrizione aiuta a garantire che il traffico NFS provenga da un client NFS del sistema operativo effettivo e non da un processo dannoso che emula un client NFS. Il client Oracle DNFS è un driver userspace, ma il processo viene eseguito come root, quindi in genere non è necessario modificare il valore di<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. I collegamenti sono costituiti da porte basse.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">Il<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> L'opzione è valida solo per NFSv3. Controlla se la chiamata di MONTAGGIO RPC può essere accettata dalle porte superiori a 1024. Quando si utilizza DNFS, il client viene nuovamente eseguito come root, in modo da poter aprire le porte al di sotto di 1024. Questo parametro non ha alcun effetto.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">I processi che aprono connessioni con DNFS su NFS versione 4,0 e successive non vengono eseguiti come root e quindi richiedono porte su 1024. Il<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Il parametro deve essere impostato su disabilitato affinché DNFS completi la connessione.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Se<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> È attivato, il risultato è un blocco durante la fase di mount che apre le connessioni DNFS. L'output di sqlplus è simile a questo:</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">Il parametro può essere modificato come segue:</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">In situazioni rare, potrebbe essere necessario modificare sia nfs-rootonly che mount-rootonly in disabled. Se un server gestisce un numero estremamente elevato di connessioni TCP, è possibile che non siano disponibili porte al di sotto di 1024 e che il sistema operativo sia costretto a utilizzare porte più elevate. Questi due parametri ONTAP devono essere modificati per consentire il completamento della connessione.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">Policy di esportazione NFS: Superuser e setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Se i file binari Oracle si trovano in una condivisione NFS, la policy di esportazione deve includere autorizzazioni superser e setuid.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Le esportazioni NFS condivise utilizzate per servizi file generici come le home directory dell'utente spesso fanno uso dell'utente root. Ciò significa che una richiesta da parte dell'utente root su un host che ha montato un filesystem viene rimappata come un altro utente con privilegi inferiori. In questo modo è possibile proteggere i dati impedendo a un utente root di un determinato server di accedere ai dati del server condiviso. Il bit setuid può anche essere un rischio per la protezione in un ambiente condiviso. Il bit setuid consente di eseguire un processo come un utente diverso da quello che richiama il comando. Ad esempio, uno script della shell di proprietà di root con il bit setuid viene eseguito come root. Se lo script della shell potrebbe essere modificato da altri utenti, qualsiasi utente non root potrebbe eseguire un comando come root aggiornando lo script.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">I file binari di Oracle includono file di proprietà di root e utilizzano il bit setuid. Se i file binari Oracle sono installati su una condivisione NFS, la policy di esportazione deve includere le autorizzazioni appropriate per superutente e setuid. Nell'esempio seguente, la regola include entrambi<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> e permessi<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> Accesso root per client NFS utilizzando l'autenticazione di sistema.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Configurazione NFSv4/4,1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Per la maggior parte delle applicazioni, la differenza tra NFSv3 e NFSv4 è minima. L'i/o delle applicazioni è di solito un i/o molto semplice e non trae alcun vantaggio significativo da alcune delle funzionalità avanzate disponibili in NFSv4. Le versioni più elevate di NFS non devono essere considerate come un "aggiornamento" dal punto di vista dello storage dei database, ma come versioni di NFS che includono funzionalità aggiuntive. Ad esempio, se è richiesta la protezione end-to-end della modalità di privacy Kerberos (krb5p), è necessario NFSv4.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">Dominio NFSv4</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Una spiegazione completa della configurazione NFSv4/4,1 esula dall'ambito di questo documento, ma un problema comunemente riscontrato è una mancata corrispondenza nella mappatura del dominio. Dal punto di vista di sysadmin, i file system NFS sembrano comportarsi normalmente, ma le applicazioni segnalano errori relativi ai permessi e/o setuid su determinati file. In alcuni casi, gli amministratori hanno concluso erroneamente che le autorizzazioni dei binari dell'applicazione sono state danneggiate e hanno eseguito comandi chown o chmod quando il problema effettivo era il nome di dominio.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">Il nome di dominio NFSv4 viene impostato sulla SVM ONTAP:</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">Il nome di dominio NFSv4 sull'host è impostato in<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">I nomi di dominio devono corrispondere. In caso contrario, vengono visualizzati errori di mappatura simili a quelli riportati di seguito nella<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">I file binari delle applicazioni, come i file binari dei database Oracle, includono i file di proprietà di root con il bit setuid, il che significa che una mancata corrispondenza nei nomi di dominio NFSv4 causa errori nell'avvio di Oracle e un avviso sulla proprietà o sulle autorizzazioni di un file chiamato<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, che si trova nella<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> directory. Dovrebbe comparire come segue:</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Se questo file viene visualizzato con proprietà di nessuno, potrebbe esserci un problema di mappatura del dominio NFSv4.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Per risolvere questo problema, controllare<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Eseguire il file in base all'impostazione del dominio id v4 in ONTAP e assicurarsi che siano coerenti. In caso contrario, apportare le modifiche necessarie, eseguire<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, e attendere un momento per la propagazione delle modifiche. La proprietà del file dovrebbe quindi essere riconosciuta correttamente come root. Se un utente aveva tentato di eseguire<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Su questo file prima che la configurazione dei domini NFS sia stata corretta, potrebbe essere necessario eseguire<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> di nuovo.</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">La presenza di una delle seguenti opzioni di montaggio causa la disattivazione della cache host:</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Queste impostazioni possono avere un grave effetto negativo sulla velocità di installazione del software, l'applicazione di patch e le operazioni di backup/ripristino. In alcuni casi, in particolare con le applicazioni in cluster, queste opzioni sono necessarie come conseguenza inevitabile della necessità di garantire la coerenza della cache in tutti i nodi del cluster. In altri casi, i clienti utilizzano erroneamente questi parametri e il risultato è un inutile danno alle prestazioni.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">Molti clienti rimuovono temporaneamente queste opzioni di montaggio durante l'installazione o l'applicazione di patch dei file binari. Questa rimozione può essere eseguita in modo sicuro se l'utente verifica che nessun altro processo stia utilizzando attivamente la directory di destinazione durante il processo di installazione o di applicazione delle patch.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Configurazione dello stripe LVM per database Oracle</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">Lo striping LVM si riferisce alla distribuzione dei dati su più LUN. Il risultato è un significativo miglioramento delle performance per molti database.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Allineamento di LUN con i database Oracle</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">L'allineamento delle LUN si riferisce all'ottimizzazione dell'i/o in relazione al layout del file system sottostante.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Efficienza</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Avvertenze di disallineamento</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">Configurazione host SAN ONTAP</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">L'allineamento negli ambienti Solaris è più complicato. Fare riferimento a.<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Negli ambienti Solaris x86, prestare ulteriore attenzione al corretto allineamento poiché la maggior parte delle configurazioni prevede diversi livelli di partizioni. Le sezioni di partizione di Solaris x86 si trovano solitamente in cima a una tabella di partizioni del record di avvio master standard.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Dimensioni di trasferimento di NFS con Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Dimensioni di trasferimento NFS con database Oracle</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">Per impostazione predefinita, ONTAP limita le dimensioni i/o NFS a 64K.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">L'i/o casuale con la maggior parte delle applicazioni e dei database utilizza blocchi di dimensioni molto inferiori, ben al di sotto del limite massimo di 64K KB. L'i/o a blocchi di grandi dimensioni è solitamente a parallelismo, pertanto anche il massimo di 64K Gbps non costituisce un limite all'ottenimento della massima larghezza di banda.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Ci sono alcuni carichi di lavoro in cui il massimo di 64K crea un limite. In particolare, le operazioni single-threaded, come l'operazione di backup o ripristino o la scansione di un database completa della tabella, vengono eseguite più velocemente e in modo più efficiente se il database è in grado di eseguire un numero di i/o inferiore ma maggiore. Le dimensioni ottimali per la gestione i/o per ONTAP sono 256K KB.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">Le dimensioni massime di trasferimento per una SVM ONTAP possono essere modificate come segue:</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">Non diminuire mai la dimensione massima di trasferimento consentita su ONTAP al di sotto del valore rsize/wsize dei file system NFS attualmente montati. In alcuni sistemi operativi, ciò può causare blocchi o addirittura danni ai dati. Ad esempio, se i client NFS sono attualmente impostati su un valore rsize/wsize di 65536, la dimensione massima di trasferimento ONTAP potrebbe essere regolata tra 65536 e 1048576 senza alcun effetto perché i client stessi sono limitati. La riduzione della dimensione massima di trasferimento inferiore a 65536 GB può danneggiare la disponibilità o i dati.</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP rimuove in modo efficiente i blocchi azzerati scritti su un file o LUN quando la compressione inline è abilitata. Utility come Oracle ASM Reclamation Utility (ASRU) funzionano scrivendo zero in estensioni ASM non utilizzate.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Dal punto di vista del database, il gruppo di dischi ASM contiene zero; la lettura di tali aree del LUN produce un flusso di zero, tuttavia ONTAP non memorizza gli zero sui dischi. Vengono invece apportate semplici modifiche ai metadati che contrassegnano internamente le aree azzerate del LUN come vuote di qualsiasi dato.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Per motivi simili, il test delle performance che implica dati azzerati non è valido, in quanto i blocchi di zero non vengono effettivamente elaborati come scritture all'interno dello storage array.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Quando si utilizza ASRU, assicurarsi che tutte le patch consigliate da Oracle siano installate.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">LUN e LVM vengono ridimensionati con database Oracle</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Quando un file system basato su SAN ha raggiunto il limite di capacità, sono disponibili due opzioni per aumentare lo spazio disponibile:</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Configurazione di NVFAIL per proteggere i database Oracle</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle e NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL è una funzionalità di ONTAP che garantisce l'integrità in scenari di failover catastrofici.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">I database sono vulnerabili al danneggiamento durante gli eventi di failover dello storage perché mantengono grandi cache interne. Se un evento catastrofico richiede l'imposizione di un failover ONTAP o il forzamento dello switchover MetroCluster, a prescindere dallo stato di salute della configurazione complessiva, il risultato viene riconosciuto in precedenza che le modifiche potrebbero essere effettivamente scartate. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco. Questa incoerenza provoca il danneggiamento dei dati.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">La memorizzazione nella cache può avvenire a livello di applicazione o di server. Ad esempio, una configurazione Oracle Real Application Cluster (RAC) con server attivi sia su un sito primario che su un sito remoto memorizza nella cache i dati all'interno di Oracle SGA. Un'operazione di switchover forzata che comportava la perdita di dati rischierebbe di danneggiare il database poiché i blocchi archiviati nell'SGA potrebbero non corrispondere ai blocchi su disco.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">Un uso meno ovvio della memorizzazione nella cache è a livello del file system del sistema operativo. I blocchi di un file system NFS montato possono essere memorizzati nella cache del sistema operativo. In alternativa, un file system in cluster basato su LUN che si trovano nel sito primario può essere montato sui server nel sito remoto e, ancora una volta, i dati possono essere memorizzati nella cache. In queste situazioni, un errore della NVRAM, un takeover forzato o uno switchover forzato possono danneggiare il file system.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP protegge i database e i sistemi operativi da questo scenario con NVFAIL e le relative impostazioni.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">La tecnologia NetApp SnapRestore offre il ripristino rapido dei dati in ONTAP a partire da una snapshot.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Quando un set di dati critico non è disponibile, le operazioni di business critiche non sono attive. I nastri possono interrompersi e persino i ripristini da backup basati su disco possono essere lenti da trasferire sulla rete. SnapRestore consente di evitare questi problemi grazie al ripristino quasi istantaneo dei set di dati. Anche i database di diversi petabyte possono essere ripristinati completamente con pochi minuti di lavoro.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Esistono due forme di SnapRestore: Basata su file/LUN e basata su volume.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Singoli file o LUN possono essere ripristinati in pochi secondi, sia in una LUN da 2TB GB che in un file da 4KB GB.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">Il container di file o LUN può essere ripristinato in pochi secondi, siano essi 10GB o 100TB TB di dati.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Un "contenitore di file o LUN" generalmente si riferisce a un volume FlexVol. Ad esempio, potresti avere 10 LUN che costituiscono un gruppo di dischi LVM in un singolo volume, oppure un volume potrebbe archiviare le home directory NFS di 1000 utenti. Invece di eseguire un'operazione di ripristino per ogni singolo file o LUN, è possibile ripristinare l'intero volume come un'unica operazione. Questo processo funziona anche con container scale-out che includono volumi multipli, come FlexGroup o un gruppo di coerenza ONTAP.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP consente solo l'accesso in sola lettura ai dati snapshot, ma i dati possono essere riattivati con SnapRestore. Lo snapshot viene riabilitato come visualizzazione lettura-scrittura dei dati, riportando i dati allo stato precedente. SnapRestore può operare a livello di volume o di file. La tecnologia è essenzialmente la stessa con alcune differenze minori nel comportamento.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">SnapRestore volume</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">La SnapRestore basata su volume riporta l'intero volume di dati a uno stato precedente. Questa operazione non richiede lo spostamento dei dati, il che significa che il processo di ripristino è essenzialmente istantaneo, sebbene l'elaborazione delle operazioni API o CLI possa richiedere alcuni secondi. Il ripristino di 1GB TB di dati non è più complicato o richiede molto tempo rispetto al ripristino di 1PB TB di dati. Questa funzionalità è il motivo principale per cui molti clienti aziendali migrano ai sistemi storage ONTAP. Offre un RTO misurato in secondi anche per i set di dati più grandi.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">Uno svantaggio di SnapRestore basato su volumi è causato dal fatto che le modifiche all'interno di un volume sono cumulative nel tempo. Pertanto, ogni snapshot e i dati del file attivo dipendono dalle modifiche che hanno portato a quel punto. Ripristinare uno stato precedente di un volume significa ignorare tutte le modifiche successive apportate ai dati. Ciò che è meno ovvio, tuttavia, è che questo include gli snapshot creati successivamente. Ciò non è sempre desiderabile.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Ad esempio, uno SLA di conservazione dei dati può specificare 30 giorni di backup notturni. Il ripristino di un set di dati in uno snapshot creato cinque giorni fa con Volume SnapRestore scaricherebbe tutti gli snapshot creati nei cinque giorni precedenti, violando lo SLA.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Sono disponibili diverse opzioni per risolvere questo limite:</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">I dati possono essere copiati da una snapshot precedente, invece di eseguire un SnapRestore dell'intero volume. Questo metodo funziona meglio con set di dati più piccoli.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">È possibile clonare una snapshot invece di ripristinarla. Il limite a questo approccio è che lo snapshot di origine è una dipendenza del clone. Pertanto, non può essere eliminato a meno che il clone non venga anch'esso eliminato o diviso in un volume indipendente.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Utilizzo di SnapRestore basati su file.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">File SnapRestore (Stato file)</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">SnapRestore basato su file è un processo di ripristino più granulare e basato su snapshot. Invece di ripristinare lo stato di un intero volume, viene ripristinato lo stato di un singolo file o LUN. Non è necessario eliminare gli snapshot, né questa operazione crea alcuna dipendenza da uno snapshot precedente. Il file o LUN diventa immediatamente disponibile nel volume attivo.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">Durante il ripristino di SnapRestore di un file o LUN non è necessario alcuno spostamento dei dati. Tuttavia, alcuni aggiornamenti dei metadati interni sono necessari per riflettere il fatto che i blocchi sottostanti in un file o LUN ora esistono sia in una snapshot che nel volume attivo. Non dovrebbe avere alcun effetto sulle prestazioni, ma questo processo blocca la creazione di snapshot fino al completamento. La velocità di elaborazione è di circa 5Gbps MB (18TB MB/ora) in base alla dimensione totale dei file ripristinati.</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">La corretta architettura di protezione dei dati aziendali dipende dai requisiti di business correlati a conservazione dei dati, ripristinabilità e tolleranza per le interruzioni durante i vari eventi.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Ad esempio, consideriamo il numero di applicazioni, database e set di dati importanti inclusi nell'ambito della fornitura. La costruzione di una strategia di backup per un singolo set di dati che garantisca la conformità con gli SLA tipici è piuttosto semplice, perché non ci sono molti oggetti da gestire. Con l'aumento del numero di set di dati, il monitoraggio diventa più complicato e gli amministratori potrebbero essere costretti a spendere una crescente quantità di tempo nella risoluzione degli errori di backup. Quando un ambiente raggiunge il cloud e scala un service provider, è necessario un approccio completamente diverso.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">Anche le dimensioni del set di dati influiscono sulla strategia. Ad esempio, esistono molte opzioni per il backup e il ripristino con un database da 100GB TB perché il set di dati è così piccolo. La semplice copia dei dati dai supporti di backup con gli strumenti tradizionali in genere offre un RTO sufficiente per il recovery. Un database 100TB ha normalmente bisogno di una strategia completamente diversa, a meno che l'RTO non consenta un'interruzione di più giorni, nel qual caso una tradizionale procedura di backup e ripristino basata sulla copia potrebbe essere accettabile.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Infine, vi sono alcuni fattori che esulano dal processo di backup e ripristino stesso. Ad esempio, esistono database che supportano attività di produzione critiche e che rendono il ripristino una rara eventualità che viene eseguita solo da DBA esperti? In alternativa, i database fanno parte di un grande ambiente di sviluppo in cui il ripristino è un evento frequente e gestito da un team IT generico?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">Uno snapshot è un backup?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">Un'obiezione comunemente sollevata all'utilizzo delle snapshot come strategia di protezione dei dati è rappresentata dal fatto che i dati "reali" e i dati snapshot si trovano sugli stessi dischi. La perdita di tali unità causerebbe la perdita sia dei dati primari che del backup.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Si tratta di un problema valido. Le snapshot locali vengono utilizzate per le esigenze di backup e ripristino quotidiane, e in questo senso la snapshot è un backup. Quasi il 99% di tutti gli scenari di ripristino in ambienti NetApp si affida alle snapshot per soddisfare anche i requisiti RTO più aggressivi.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Gli snapshot locali non dovrebbero, tuttavia, mai essere l'unica strategia di backup, ragione per cui NetApp offre tecnologie come la replica SnapMirror per replicare in modo rapido ed efficiente le snapshot su un set indipendente di dischi. In una soluzione adeguatamente progettata con istantanee e replica snapshot, l'utilizzo del nastro può essere ridotto a icona in un archivio trimestrale o eliminato del tutto.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Backup di gruppi di coerenza</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">Il backup di un gruppo di coerenza implica l'acquisizione dello stato di un dataset (o di più dataset) in un singolo punto atomico nel tempo. Come esempio di database, questo include tutti i componenti del database, come file di dati, file di log e altri file direttamente associati al database. Funziona con quasi tutti i prodotti di database relazionali, tra cui Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL e MariaDB. La protezione di una configurazione VMware con un backup di gruppo di coerenza sarebbe simile: L'acquisizione di tutti gli archivi dati e potenzialmente delle LUN di avvio ESX in un singolo punto atomico nel tempo.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">La creazione di una snapshot di un gruppo di coerenza di questo tipo sta essenzialmente simulando un arresto anomalo, motivo per cui tali backup vengono spesso chiamati backup coerenti con i crash. Talvolta il supporto per gli scenari di ripristino è fonte di preoccupazioni, ma è importante comprendere che in genere non è necessaria alcuna procedura di ripristino. Quando l'applicazione si avvia dopo il ripristino di un backup di un gruppo di coerenza, esegue i consueti processi di recupero dei log, le repliche del journal del file system e altre attività per riprodurre qualsiasi i/o in fase di trasferimento al punto del backup. L'applicazione viene quindi avviata come di consueto.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">In sostanza, qualsiasi applicazione in grado di resistere a un'interruzione dell'alimentazione o a un arresto anomalo del server senza danneggiamento dei dati può essere protetta in questo modo. Ciò può essere dimostrato anche dal numero elevato di applicazioni protette con prodotti di mirroring sincrono e asincrono di numerosi vendor. Se un disastro colpisce improvvisamente il sito primario, il sito di replica contiene un'immagine coerente dell'ambiente originale al momento del disastro. Ancora una volta, non è necessaria alcuna procedura di recupero speciale.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">L'RPO per questo approccio è in genere limitato al punto del backup. In generale, l'RPO minimo per le snapshot a volume singolo è di un'ora. Ad esempio, 48 snapshot ogni ora e altri 30 giorni di snapshot ogni notte sono ragionevoli e non richiederebbero la conservazione di un numero eccessivo di snapshot. Un RPO inferiore a un'ora diventa più difficile da raggiungere e non è consigliato senza la prima consulenza dei servizi professionali NetApp comprendere i requisiti di ambiente, scalabilità e data Protection.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">L'RTO può in genere essere misurato in pochi secondi. R un'applicazione viene arrestata, i volumi vengono ripristinati e l'applicazione viene riavviata.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">L'approccio più semplice consiste nel posizionare tutti i file o le LUN in un singolo gruppo di coerenza del volume, che consente di pianificare la creazione di una snapshot direttamente in ONTAP. Se un set di dati deve occupare più volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot). È possibile configurarlo tramite System Manager o chiamate API RESTful, inoltre SnapCenter è in grado di creare un semplice snapshot del gruppo di coerenza su un elenco definito di volumi.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Architettura di replica e disaster recovery</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">L'RPO di DR è limitato dalla larghezza di banda della rete disponibile e dalle dimensioni totali dei dati da proteggere. Dopo la creazione del trasferimento di base iniziale, gli aggiornamenti si basano solo sui dati modificati, che in genere rappresentano una bassa percentuale dell'impatto totale dei dati, sebbene esistano delle eccezioni.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Ad esempio, un database 10TB con un tasso di modifica settimanale del 10% ha una media di circa 6GB TB all'ora delle modifiche totali. Con 10Gb GB di connettività, il trasferimento di questo database richiede circa sei minuti. Il tasso di modifica varia in base alla fluttuazione del tasso di modifica del database, ma nel complesso dovrebbe essere possibile ottenere un intervallo di aggiornamento di 15 minuti e un RPO di 15 minuti. Se sono presenti 100 database di questo tipo, sono necessari 600 minuti per trasferire i dati. Pertanto, non è possibile un RPO di un'ora. Allo stesso modo, una replica di un singolo database 100TB con un tasso di modifica settimanale del 10% non può essere aggiornata in modo affidabile in un'ora.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">Altri fattori possono influire sulla replica, ad esempio l'overhead e le limitazioni del numero di operazioni di replica simultanee. Tuttavia, la pianificazione globale di una strategia di replica a singolo volume può basarsi sulla larghezza di banda disponibile e generalmente si ottiene un RPO di replica di un'ora. Un RPO inferiore a un'ora diventa più difficile da raggiungere e dovrebbe essere eseguito solo dopo aver consultato i servizi professionali di NetApp. In alcuni casi, è possibile effettuare 15 minuti con un'ottima connettività di rete da sito a sito. Tuttavia, nel complesso, quando è necessario un RPO inferiore a un'ora, l'architettura di riproduzione log multi-volume offre risultati migliori.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">L'RTO con replica di gruppo di coerenza in uno scenario di disaster recovery è eccellente, generalmente misurato in secondi dal punto di vista dello storage. L'approccio più semplice è quello di rompere il mirror e il database è pronto per essere avviato. Il tempo di avvio del database è generalmente di circa 10 secondi, ma database di grandi dimensioni con molte transazioni registrate potrebbero richiedere alcuni minuti.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">Il fattore più importante per determinare l'RTO non è il sistema storage, ma piuttosto l'applicazione e il sistema operativo host in cui viene eseguito. Ad esempio, i dati replicati possono essere resi disponibili in un secondo o due, ma questo rappresenta solo i dati. Deve inoltre essere presente un sistema operativo correttamente configurato con file binari delle applicazioni disponibili per l'utilizzo dei dati.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">In alcuni casi, i clienti hanno preparato istanze di disaster recovery in anticipo con lo storage prerilevato sui sistemi operativi. In questi casi, l'attivazione dello scenario di disaster recovery può richiedere solo la rottura di un mirror e l'avvio dell'applicazione. In altri casi, è possibile eseguire il mirroring del sistema operativo e delle applicazioni associate insieme al database come VMDK (ESX Virtual Machine Disk). In questi casi, l'RPO è determinato dall'investimento effettuato da un cliente nell'automazione per l'avvio rapido del VMDK e la possibilità di avviare le applicazioni.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">Il tempo di conservazione è controllato in parte dal limite dello snapshot. Ad esempio, i volumi in ONTAP hanno un limite di 1024 snapshot. In alcuni casi, i clienti hanno la replica multiplex per aumentare il limite. Ad esempio, se sono necessari 2000 giorni di backup, un'origine può essere replicata su due volumi con aggiornamenti che avvengono in giorni alternativi. Ciò richiede un aumento dello spazio iniziale necessario, ma costituisce comunque un approccio molto più efficiente rispetto a un sistema di backup tradizionale, che prevede l'esecuzione di più backup completi.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Gruppo di coerenza del singolo volume</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">L'approccio più semplice consiste nel posizionare tutti i file o le LUN in un singolo gruppo di coerenza dei volumi, che consente di pianificare gli update di SnapMirror e SnapVault direttamente nel sistema storage. Non è richiesto alcun software esterno.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Gruppo di coerenza multi-volume</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Quando un database deve occupare più volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot). Come sopra menzionato, è possibile configurarlo tramite chiamate di API RESTful o di System Manager, mentre SnapCenter è in grado di creare una semplice snapshot del gruppo di coerenza in un elenco definito di volumi.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">È inoltre prevista un'ulteriore considerazione sull'utilizzo di snapshot coerenti e multi-volumi ai fini del disaster recovery. Quando si esegue un aggiornamento di più volumi, è possibile che si verifichi un disastro mentre è ancora in corso un trasferimento. Il risultato sarebbe un insieme di volumi che non sono coerenti l'uno con l'altro. Se ciò si verificasse, alcuni volumi devono essere ripristinati allo stato di snapshot precedente per fornire un'immagine di database coerente con il crash e pronta per l'uso.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Disaster recovery: Attivazione</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">Il processo di attivazione della copia di disaster recovery dipende dal tipo di storage. Con NFS, i file system possono essere premontati sul server di disaster recovery. Sono in uno stato di sola lettura e diventano lettura-scrittura quando il mirror è rotto. Ciò offre un RPO estremamente basso e il processo generale di disaster recovery è più affidabile, poiché ci sono meno parti da gestire.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">L'attivazione delle configurazioni SAN in caso di disaster recovery diventa più complicata. L'opzione più semplice è in genere quella di rompere temporaneamente i mirror e montare le risorse SAN, tra cui passaggi come il rilevamento della configurazione LVM (incluse funzioni specifiche dell'applicazione come Oracle Automatic Storage Management [ASM]) e l'aggiunta di voci a /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">Il risultato è che i percorsi dei dispositivi LUN, i nomi dei gruppi di volumi e gli altri percorsi dei dispositivi vengono resi noti al server di destinazione. Tali risorse possono quindi essere chiuse e, successivamente, i mirror possono essere ripristinati. Il risultato è un server che si trova in uno stato in grado di portare rapidamente l'applicazione online. I passaggi per attivare gruppi di volumi, montare file system o avviare database e applicazioni sono facilmente automatizzati.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">È necessario assicurarsi che l'ambiente di disaster recovery sia aggiornato. Ad esempio, è probabile che vengano aggiunti nuovi LUN al server di origine, il che significa che è necessario rilevare preventivamente i nuovi LUN sulla destinazione per garantire che il piano di disaster recovery funzioni come previsto.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Disaster recovery Oracle</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">Proteggere i file di dati, i log di archivio, i log di ripristino e i file di controllo con un'unica istantanea è un metodo di backup, ripristino e replica valido.  Tuttavia, l'RPO è limitato al punto del backup stesso. È adatto per un RPO di un'ora o superiore. Se un database si estende su volumi, è necessario creare snapshot cg utilizzando uno degli strumenti descritti in precedenza.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">Ad esempio, l'intero database può trovarsi in un singolo volume con la seguente pianificazione degli snapshot:</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 snapshot ogni ora</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 istantanee notturne</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 snapshot mensili</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Questo garantisce un RPO di un'ora nel periodo corrente delle 72 ore precedenti, più backup notturni e mensili aggiuntivi. È possibile includere più database o file applicativi nel singolo volume o set di snapshot cg per offrire backup coerenti in un ambiente più ampio.</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP è progettato per garantire la massima disponibilità dei database Oracle. Una descrizione completa delle funzioni di alta disponibilità di ONTAP esula dall'ambito di questo documento. Tuttavia, come per la protezione dei dati, una conoscenza di base di questa funzionalità è importante quando si progetta un'infrastruttura di database.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">Coppie HA</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">L'unità di base dell'alta disponibilità è la coppia ha. Ciascuna coppia contiene collegamenti ridondanti per supportare la replica dei dati nella NVRAM. NVRAM non è una cache di scrittura. La RAM all'interno del controller funge da cache di scrittura. Lo scopo della NVRAM è quello di memorizzare temporaneamente i dati come salvaguardia da errori di sistema imprevisti. A questo proposito, è simile a un log di ripristino del database.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">Sia la NVRAM che il redo log del database consentono di memorizzare i dati rapidamente, consentendo il commit delle modifiche ai dati il più rapidamente possibile. L'aggiornamento ai dati persistenti sulle unità (o file di dati) viene eseguito solo in un secondo momento durante un processo chiamato checkpoint sulle piattaforme ONTAP e sulla maggior parte dei database. Durante le normali operazioni, non vengono letti i dati della NVRAM né i log di ripristino del database.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Se un controller si guasta bruscamente, è probabile che vi siano modifiche in sospeso memorizzate nella NVRAM che non sono ancora state scritte sulle unità. Il partner controller rileva il guasto, assume il controllo dei dischi e applica le modifiche richieste che sono state memorizzate nella NVRAM.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Takeover e giveback</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Il takeover e il giveback fanno riferimento al processo di trasferimento della responsabilità delle risorse di storage fra i nodi di una coppia ha. L'acquisizione e il giveback presentano due aspetti:</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Gestione della connettività di rete che consente l'accesso alle unità</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Gestione delle unità stesse</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Le interfacce di rete che supportano il traffico CIFS e NFS sono configurate sia con una posizione home che di failover. Un takeover include lo spostamento delle interfacce di rete nella loro abitazione temporanea su un'interfaccia fisica situata sulla stessa subnet della posizione originale. Un giveback prevede lo spostamento delle interfacce di rete nelle posizioni originali. Il comportamento esatto può essere regolato come richiesto.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Le interfacce di rete che supportano i protocolli a blocchi SAN, come iSCSI e FC, non vengono ricollocate durante il takeover e lo giveback. È invece necessario eseguire il provisioning delle LUN attraverso percorsi che includano una coppia ha completa che si traduce in un percorso primario e un percorso secondario.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">È possibile configurare anche percorsi aggiuntivi per controller aggiuntivi in modo da supportare la riallocazione dei dati tra i nodi di un cluster più grande, non facente parte del processo di ha.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Il secondo aspetto del takeover e dello sconto è il trasferimento della proprietà del disco. Il processo esatto dipende da diversi fattori, tra cui il motivo del takeover/giveback e le opzioni della riga di comando emesse. L'obiettivo è quello di eseguire l'operazione nel modo più efficiente possibile. Anche se il processo complessivo potrebbe richiedere diversi minuti, il momento effettivo in cui la proprietà dell'unità viene trasferita da nodo a nodo può generalmente essere misurato in secondi.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Tempo di takeover</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">L'i/o dell'host subisce una breve pausa in i/o durante le operazioni di takeover e giveback, senza tuttavia alcuna interruzione dell'applicazione in un ambiente configurato correttamente. L'effettivo processo di transizione in cui l'i/o subisce un ritardo viene generalmente misurato in secondi, ma l'host potrebbe richiedere tempo aggiuntivo per riconoscere la modifica nei percorsi di dati e inviare di nuovo le operazioni i/O.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">La natura dell'interruzione dipende dal protocollo:</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Un'interfaccia di rete che supporta il traffico NFS e CIFS emette una richiesta ARP (Address Resolution Protocol) alla rete dopo la transizione a una nuova posizione fisica. Ciò fa sì che gli switch di rete aggiornino le tabelle degli indirizzi MAC (Media Access Control) e riprendano l'elaborazione i/O. Le interruzioni nel caso di takeover e giveback pianificati vengono di solito misurate in secondi e in molti casi non sono rilevabili. Alcune reti potrebbero essere più lente a riconoscere completamente la modifica del percorso di rete e alcuni sistemi operativi potrebbero mettere in coda molti i/o in un breve periodo di tempo che deve essere rieseguito. Ciò può estendere il tempo necessario per riprendere l'i/O.</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Un'interfaccia di rete che supporta i protocolli SAN non passa a una nuova posizione. Un sistema operativo host deve modificare il percorso o i percorsi in uso. La pausa in i/o osservata dall'host dipende da diversi fattori. Dal punto di vista del sistema storage, il periodo in cui non è possibile fornire i/o è di pochi secondi. Tuttavia, sistemi operativi host diversi potrebbero richiedere tempo aggiuntivo per consentire un timeout i/o prima di riprovare. I sistemi operativi più recenti sono in grado di riconoscere un cambiamento di percorso molto più rapidamente, ma i sistemi operativi più vecchi in genere richiedono fino a 30 secondi per riconoscere un cambiamento.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">La seguente tabella illustra i tempi di takeover previsti durante i quali il sistema storage non può fornire i dati a un ambiente applicativo. Non dovrebbero esserci errori in alcun ambiente applicativo, il takeover dovrebbe invece apparire come una breve pausa nell'elaborazione io.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Takeover pianificato</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 sec.</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 sec.</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 sec.</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Takeover non pianificato</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 sec.</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">La protezione dei dati logici all'interno di ONTAP è costituita da tre requisiti principali:</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">I dati devono essere protetti dalla corruzione.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">I dati devono essere protetti da guasti al disco.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Le modifiche ai dati devono essere protette dalla perdita.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Queste tre esigenze sono discusse nelle sezioni seguenti.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Corruzione della rete: Checksum</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">Il livello più basilare di protezione dei dati è il checksum, che è uno speciale codice di rilevamento degli errori memorizzato insieme ai dati. La corruzione dei dati durante la trasmissione di rete viene rilevata con l'utilizzo di un checksum e, in alcuni casi, di checksum multipli.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Ad esempio, un frame FC include una forma di checksum chiamata CRC (Cyclic Redundancy Check) per assicurarsi che il payload non sia corrotto durante il transito. Il trasmettitore invia sia i dati che il CRC dei dati. Il ricevitore di un frame FC ricalcola il CRC dei dati ricevuti per assicurarsi che corrisponda al CRC trasmesso. Se il CRC appena calcolato non corrisponde al CRC collegato al frame, i dati sono corrotti e il frame FC viene scartato o rifiutato. Un'operazione i/o iSCSI include checksum ai livelli TCP/IP ed Ethernet e, per una maggiore protezione, può anche includere la protezione CRC opzionale al livello SCSI. Qualsiasi corruzione di bit sul filo viene rilevata dal livello TCP o IP, che porta alla ritrasmissione del pacchetto. Come nel caso di FC, gli errori nel CRC SCSI determinano un'eliminazione o un rifiuto dell'operazione.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Corruzione dei dischi: Checksum</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">I checksum vengono utilizzati anche per verificare l'integrità dei dati memorizzati sui dischi. I blocchi di dati scritti sui dischi vengono memorizzati con una funzione di checksum che produce un numero imprevedibile e legato ai dati originali. Quando i dati vengono letti dall'unità, il checksum viene ricalcolato e confrontato con il checksum memorizzato. Se non corrisponde, i dati sono corrotti e devono essere recuperati dal livello RAID.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Corruzione dei dati: Scritture perse</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">Uno dei tipi più difficili di corruzione da rilevare è una scrittura persa o posizionata erroneamente. Quando una scrittura viene confermata, deve essere scritta sul supporto nella posizione corretta. La corruzione dei dati sul posto è relativamente semplice da rilevare utilizzando un semplice checksum memorizzato con i dati. Tuttavia, se la scrittura viene semplicemente persa, la versione precedente dei dati potrebbe ancora esistere e il checksum sarebbe corretto. Se la scrittura viene posizionata nella posizione fisica errata, il checksum associato sarebbe ancora una volta valido per i dati memorizzati, anche se la scrittura ha distrutto altri dati.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">La soluzione a questa sfida è la seguente:</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Un'operazione di scrittura deve includere metadati che indicano la posizione in cui dovrebbe essere trovata la scrittura.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Un'operazione di scrittura deve includere un tipo di identificatore di versione.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Quando ONTAP scrive un blocco, include i dati sulla posizione di appartenenza del blocco. Se una lettura successiva identifica un blocco, ma i metadati indicano che esso appartiene alla posizione 123 quando è stato trovato nella posizione 456, allora la scrittura è stata erroneamente posizionata.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Rilevare una scrittura totalmente persa è più difficile. La spiegazione è molto complicata, ma essenzialmente ONTAP memorizza i metadati in modo che un'operazione di scrittura determini aggiornamenti a due posizioni diverse sulle unità. Se una scrittura viene persa, una successiva lettura dei dati e dei metadati associati mostra due diverse identità di versione. Ciò indica che la scrittura non è stata completata dall'unità.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">La corruzione in scrittura persa e posizionata erroneamente è estremamente rara, ma con il continuo aumento dei dischi e la diminuzione dei set di dati nella scala di exabyte, il rischio aumenta. Il rilevamento delle operazioni di scrittura perse deve essere incluso in qualsiasi sistema storage che supporti i carichi di lavoro del database.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Guasti del disco: RAID, RAID DP e RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Se un blocco di dati su un'unità viene rilevato come danneggiato o se l'intera unità si guasta e non è completamente disponibile, i dati devono essere ricostituiti. Questo viene fatto in ONTAP utilizzando unità di parità. Lo striping dei dati viene eseguito su più unità dati, quindi vengono generati i dati di parità. I dati vengono memorizzati separatamente dai dati originali.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP utilizzava in origine RAID 4, che utilizza un singolo disco di parità per ciascun gruppo di unità dati. Il risultato è che un'unità del gruppo potrebbe guastarsi senza causare una perdita di dati. Se l'unità di parità non funziona correttamente, non sono stati danneggiati dati ed è stato possibile costruire una nuova unità di parità. Se si è verificato un errore in una singola unità dati, è possibile utilizzare le unità rimanenti con l'unità di parità per rigenerare i dati mancanti.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Quando le unità erano di piccole dimensioni, la possibilità statistica di due unità che si guastavano contemporaneamente era trascurabile. Con la progressiva crescita della capacità del disco aumentano anche il tempo necessario per ricostruire i dati in seguito a un guasto al disco. Ciò ha aumentato la finestra in cui un guasto di una seconda unità causerebbe la perdita di dati. Inoltre, il processo di ricostruzione crea numerosi i/o aggiuntivi sui dischi ancora in uso. Man mano che i dischi diventano obsoleti, aumenta anche il rischio di carico aggiuntivo che potrebbe causare un guasto al secondo disco. Infine, anche se il rischio di perdita di dati non aumentasse con il continuo utilizzo di RAID 4, le conseguenze della perdita di dati diventerebbero più gravi. Maggiore è la quantità di dati che andrebbero persi in caso di guasto a un gruppo RAID, più tempo occorrerebbe per ripristinare i dati, prolungando l'interruzione del business.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Questi problemi hanno portato NetApp a sviluppare la tecnologia NetApp RAID DP, una variante di RAID 6. Questa soluzione include due unità di parità, il che significa che due unità in un gruppo RAID possono guastarsi senza creare perdite di dati. Le dimensioni dei dischi hanno continuato a crescere, portando infine NetApp a sviluppare la tecnologia NetApp RAID-TEC, che introduce un disco a terza parità.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Alcune procedure consigliate per i database storici consigliano l'uso di RAID-10, noto anche come mirroring con striping. Ciò offre una protezione dei dati inferiore rispetto a quella dei sistemi RAID DP, in quanto vi sono più scenari di guasto a due dischi, mentre in RAID DP non ve ne sono nessuno.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">Esistono inoltre alcune procedure consigliate per i database storici che indicano che le opzioni RAID-10 sono preferite a quelle RAID-4/5/6 a causa di problemi di prestazioni. Queste raccomandazioni a volte fanno riferimento a una penalizzazione RAID. Sebbene queste raccomandazioni siano generalmente corrette, non sono applicabili alle implementazioni di RAID all'interno di ONTAP. Il problema di prestazioni è relativo alla rigenerazione di parità. Con le implementazioni RAID tradizionali, l'elaborazione delle random write di routine eseguite da un database richiede letture multiple del disco per rigenerare i dati di parità e completare la scrittura. La penalità viene definita come gli IOPS in lettura aggiuntivi necessari per eseguire le operazioni di scrittura.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">ONTAP non subisce alcuna penalizzazione RAID perché le scritture vengono organizzate in memoria dove la parità viene generata e quindi scritta su disco come singolo stripe RAID. Non sono richieste letture per completare l'operazione di scrittura.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">In sintesi, rispetto al RAID 10, RAID DP e RAID-TEC offrono una capacità utilizzabile molto maggiore, una migliore protezione contro i guasti ai dischi e nessun compromesso in termini di performance.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Protezione da errori hardware: NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Qualsiasi storage array che gestisce un carico di lavoro del database deve eseguire le operazioni di scrittura il più rapidamente possibile. Inoltre, un'operazione di scrittura deve essere protetta dalla perdita da un evento imprevisto, come un'interruzione dell'alimentazione. Ciò significa che qualsiasi operazione di scrittura deve essere conservata in modo sicuro in almeno due posizioni.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">I sistemi AFF e FAS si affidano alla NVRAM per soddisfare questi requisiti. Il processo di scrittura funziona come segue:</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">I dati di scrittura in entrata sono memorizzati nella RAM.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Le modifiche che devono essere apportate ai dati sul disco vengono registrate nella NVRAM sia sul nodo locale che sul nodo partner. NVRAM non è una cache di scrittura, ma un journal simile a un log di ripristino dei database. In condizioni normali, non viene letta. Viene utilizzata solo per il ripristino, ad esempio in seguito a un'interruzione dell'alimentazione durante l'elaborazione i/O.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">La scrittura viene quindi riconosciuta all'host.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">Il processo di scrittura in questa fase è completo dal punto di vista dell'applicazione e i dati sono protetti dalla perdita, perché vengono memorizzati in due posizioni diverse. Alla fine, le modifiche vengono scritte su disco, ma il processo risulta fuori banda dal punto di vista dell'applicazione perché si verifica dopo il riconoscimento della scrittura e quindi non influisce sulla latenza. Questo processo è ancora una volta simile alla registrazione del database. Una modifica al database viene registrata nei registri di ripristino il più rapidamente possibile e la modifica viene quindi riconosciuta come confermata. Gli aggiornamenti ai file di dati avvengono molto più tardi e non influenzano direttamente la velocità di elaborazione.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">In caso di guasto a un controller, il partner controller assume la proprietà dei dischi richiesti e riproduce i dati registrati nella NVRAM per ripristinare le operazioni di i/o in corso quando si è verificato il guasto.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Protezione da errori hardware: NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Come discusso in precedenza, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight In caso di guasto della NVRAM locale o di guasto della connettività al partner di ha, i dati in-flight non verranno più mirrorati.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Se la NVRAM locale riporta un errore, il nodo si arresta. Questo arresto determina il failover su un controller partner ha. Nessun dato viene perso perché il controller che presenta il guasto non ha confermato l'operazione di scrittura.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP non consente un failover quando i dati non sono sincronizzati, a meno che il failover non sia forzato. La forzatura di una modifica delle condizioni in questo modo riconosce che i dati potrebbero essere lasciati indietro nel controllore originale e che la perdita di dati è accettabile.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">I database sono particolarmente vulnerabili al danneggiamento se un failover viene forzato perché mantengono grandi cache interne di dati su disco. In caso di failover forzato, le modifiche precedentemente riconosciute vengono effettivamente eliminate. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Per proteggere i dati da questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro gli errori della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano l'arresto di un'applicazione in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché qualsiasi scrittura riconosciuta deve essere presente sull'array di storage.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Ogni set di unità su un dato sito viene configurato automaticamente come uno o più gruppi RAID-DP o RAID-TEC completamente ridondanti, indipendentemente dall'utilizzo del mirroring. In questo modo si garantisce una protezione dei dati continua, anche dopo la perdita di un sito.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">La figura precedente illustra una configurazione SyncMirror di esempio. È stato creato un aggregato di 24 dischi sul controller con 12 dischi da uno shelf allocato sul sito A e 12 dischi da uno shelf allocato sul sito B. I dischi sono stati raggruppati in due gruppi RAID con mirroring. Il gruppo RAID 0 include un plesso A 6 unità sul sito A con mirroring su un plesso A 6 unità sul sito B. Analogamente, il gruppo RAID 1 include un plesso A 6 unità sul sito A con mirroring su un plesso A 6 unità sul sito B.</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">Di norma, SyncMirror viene utilizzato per fornire il mirroring remoto con i sistemi MetroCluster, con una copia dei dati in ciascun sito. A volte, è stato utilizzato per fornire un livello di ridondanza extra in un unico sistema. In particolare, fornisce ridondanza a livello di shelf. Uno shelf di dischi contiene già doppi controller e alimentatori e nel complesso è poco più di una lamiera, ma in alcuni casi è consigliabile garantire una protezione extra. Ad esempio, un cliente NetApp ha implementato SyncMirror per una piattaforma mobile di analytics in tempo reale utilizzata durante i test nel settore automobilistico. Il sistema è stato separato in due rack fisici forniti da alimentatori indipendenti da sistemi UPS indipendenti.</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">L'argomento dei checksum è di particolare interesse per i DBA abituati all'utilizzo dei backup in streaming Oracle RMAN che migrano a backup basati su snapshot. Una caratteristica di RMAN è che esegue controlli di integrità durante le operazioni di backup. Sebbene questa funzionalità offra un certo valore, il suo vantaggio principale è quello di un database non utilizzato su uno storage array moderno. Quando si utilizzano dischi fisici per un database Oracle, è quasi certo che il danneggiamento si verifica anche in caso di invecchiamento dei dischi, un problema che viene risolto dai checksum basati su array negli storage array reali.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">L'architettura dei log di ripristino e file dati di Oracle è inoltre progettata per offrire il massimo livello di integrità dei dati possibile, anche in circostanze estreme. A livello massimo, i blocchi Oracle includono il checksum e controlli logici di base con quasi ogni i/O. Se Oracle non è in crash o non ha portato offline uno spazio di tabella, i dati saranno intatti. Il grado di controllo dell'integrità dei dati è regolabile e Oracle può anche essere configurato per confermare le operazioni di scrittura. Di conseguenza, è possibile ripristinare quasi tutti gli scenari di crash e di guasto e, nel caso estremamente raro di una situazione irreversibile, viene immediatamente rilevata la corruzione.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">La maggior parte dei clienti NetApp che utilizzano database Oracle interrompe l'utilizzo di RMAN e di altri prodotti di backup dopo la migrazione a backup basati su snapshot. Esistono ancora opzioni in cui RMAN può essere utilizzato per eseguire un ripristino a livello di blocco con SnapCenter. Tuttavia, ogni giorno, RMAN, NetBackup e altri prodotti vengono utilizzati solo occasionalmente per creare copie di archivio mensili o trimestrali.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Alcuni clienti scelgono di eseguire<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> eseguire periodicamente controlli di integrità dei database esistenti. NetApp scoraggia questa pratica perché crea un carico i/o non necessario. Come illustrato in precedenza, se il database non presentava problemi, la possibilità di<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> Il rilevamento di un problema è prossimo allo zero e questa utility crea un carico i/o sequenziale molto elevato sulla rete e sul sistema di storage. A meno che non vi sia motivo di ritenere che esista una corruzione, come l'esposizione a un bug Oracle noto, non c'è motivo di eseguire<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Backup ottimizzati per le snapshot di storage Oracle</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Sebbene la procedura di ripristino con backup a caldo sia più familiare per gli amministratori di database, da molto tempo è stato possibile utilizzare istantanee che non sono state create mentre il database era in modalità di backup a caldo. Per rendere il database coerente, sono stati necessari ulteriori passaggi manuali con Oracle 10g e 11g durante il ripristino. Con Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> e.<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> contenere la logica aggiuntiva per riprodurre i log di archivio sui backup dei file dati che non erano in modalità hot backup.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Come indicato in precedenza, il ripristino di un backup a caldo basato su snapshot richiede due set di dati:</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Un'istantanea dei file di dati creati in modalità backup</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">I log di archivio generati mentre i file di dati erano in modalità hot backup</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Durante il ripristino, il database legge i metadati dai file di dati per selezionare i log di archivio richiesti per il ripristino.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">Per ottenere gli stessi risultati, il recovery ottimizzato per le snapshot di storage richiede set di dati leggermente diversi:</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Un'istantanea dei file di dati, più un metodo per identificare l'ora in cui è stata creata l'istantanea</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archiviare i log dall'ora del checkpoint del file dati più recente all'ora esatta dello snapshot</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Durante il ripristino, il database legge i metadati dai file di dati per identificare il registro di archivio più recente richiesto. È possibile eseguire il ripristino completo o point-in-time. Quando si esegue un ripristino point-in-time, è fondamentale conoscere l'ora dello snapshot dei file di dati. Il punto di ripristino specificato deve essere successivo all'ora di creazione degli snapshot. NetApp consiglia di aggiungere almeno alcuni minuti all'ora dello snapshot per tenere conto della variazione dell'orologio.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Per informazioni dettagliate, vedere la documentazione di Oracle sull'argomento "Recovery Using Storage Snapshot Optimization" disponibile in varie versioni della documentazione di Oracle 12c. Inoltre, consultare l'ID documento Oracle Doc ID 604683,1 relativo al supporto per le istantanee di terze parti di Oracle.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Layout dei dati</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">Il layout più semplice consiste nell'isolare i file di dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. In questo modo si garantisce che i volumi dei file dati possano essere ripristinati rapidamente con un'operazione SnapRestore senza distruggere un log di ripristino, controlfile o un log di archivio importante.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">LE SAN hanno requisiti simili per l'isolamento dei file dati all'interno di volumi dedicati. Con un sistema operativo come Microsoft Windows, un singolo volume potrebbe contenere più LUN di file dati, ciascuno con un file system NTFS. Con altri sistemi operativi, esiste in genere anche un volume manager logico. Ad esempio, con Oracle ASM, l'opzione più semplice sarebbe quella di limitare i gruppi di dischi a un singolo volume di cui è possibile eseguire il backup e il ripristino come unità. Se per motivi di gestione delle performance o della capacità sono necessari volumi aggiuntivi, la creazione di un gruppo di dischi aggiuntivo sul nuovo volume semplifica la gestione.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Se si seguono queste linee guida, gli snapshot possono essere pianificati direttamente su ONTAP senza che sia necessario eseguire uno snapshot del gruppo di coerenza. Il motivo è che i backup ottimizzati per le istantanee non richiedono che venga eseguito contemporaneamente il backup dei file di dati.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Una complicazione si verifica in situazioni come un gruppo di dischi ASM distribuito tra i volumi. In questi casi, è necessario eseguire uno snapshot cg per assicurarsi che i metadati ASM siano coerenti in tutti i volumi costituenti.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Note]verificare che i file ASM spfile e passwd non siano nel gruppo di dischi che ospita i file di dati. Ciò interferisce con la capacità di ripristinare selettivamente i dati e solo i file di dati.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Procedura di ripristino locale: NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Questa procedura può essere gestita manualmente o tramite un'applicazione come SnapCenter. La procedura di base è la seguente:</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Recuperare i volumi di file dati nello snapshot immediatamente prima del punto di ripristino desiderato.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio, o.<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> oppure<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> può essere indirizzato ai dati in<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directory.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">Inoltre, per i database di dimensioni inferiori, i file di dati possono essere recuperati da un utente finale direttamente da<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Senza l'assistenza di tool di automazione o di un amministratore dello storage per eseguire un comando SnapRestore.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Procedura di ripristino locale: SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Chiudere i gruppi di dischi che ospitano i file di dati. La procedura varia a seconda del volume manager logico scelto. Con ASM, il processo richiede lo smontaggio del gruppo di dischi. Con Linux, i file system devono essere smontati e i volumi logici e i gruppi di volumi sono disattivati. L'obiettivo è quello di interrompere tutti gli aggiornamenti del gruppo di volumi di destinazione da ripristinare.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Ripristinare i gruppi di dischi del file dati nello snapshot immediatamente prima del punto di ripristino desiderato.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Riattivare i gruppi di dischi appena ripristinati.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio portando i LUN del registro di archivio offline ed eseguendo un ripristino. Questo è anche un esempio in cui è utile dividere i log di archivio in volumi dedicati. Se i log dell'archivio condividono un gruppo di volumi con i log di ripristino, i log di ripristino devono essere copiati in un altro punto prima del ripristino del set complessivo di LUN, per evitare di perdere le transazioni finali registrate.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Esempio di recupero completo</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Si supponga che i file di dati siano stati corrotti o distrutti e che sia necessario un ripristino completo. La procedura da seguire è la seguente:</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Esempio di recupero point-in-time</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">L'intera procedura di ripristino è un singolo comando:<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Se è necessario un ripristino point-in-time, l'indicatore data e ora degli snapshot deve essere noto e può essere identificato come segue:</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">L'ora di creazione dell'istantanea è indicata come marzo 9th e 10:10:06. Per essere sicuri, viene aggiunto un minuto all'ora dell'istantanea:</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">Il ripristino viene avviato. È stato specificato un tempo di snapshot di 10:11:00, un minuto dopo il tempo registrato per tenere conto della possibile varianza dell'orologio e un tempo di recupero target di 10:44. Successivamente, sqlplus richiede i registri di archivio necessari per raggiungere il tempo di ripristino desiderato di 10:44.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Completare il ripristino di un database utilizzando gli snapshot utilizzando<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> command non richiede licenze specifiche, ma utilizza un ripristino point-in-time<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Richiede la licenza Oracle Advanced Compression.</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter e altri strumenti</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">In alcuni casi, una semplice configurazione di queste funzionalità chiave direttamente su ONTAP soddisfa i requisiti, ma esigenze più complesse richiedono un livello di orchestrazione.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter è il prodotto di punta della protezione dei dati di NetApp. A un livello molto basso, è simile ai prodotti SnapManager in termini di modalità di esecuzione dei backup del database, ma è stato creato da zero per fornire un singolo pannello di controllo per la gestione della protezione dati sui sistemi di storage NetApp.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">RIPOSO</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP contiene anche un ricco set di API RESTful. Questo consente a 3rd vendor di creare data Protection e altre applicazioni di gestione con una profonda integrazione con ONTAP. Inoltre, l'API RESTful è facile da utilizzare da parte dei clienti che desiderano creare i propri flussi di lavoro e utility di automazione.</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Per proteggere e ripristinare un database Oracle in modalità backup sono richiesti due set di dati. Si noti che questa non è l'unica opzione di backup di Oracle, ma è la più comune.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Un'istantanea dei file di dati in modalità di backup</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">I registri di archivio creati mentre i file di dati erano in modalità backup</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Se è richiesto il recupero completo, comprese tutte le transazioni impegnate, è necessario un terzo elemento:</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Una serie di registri di ripristino correnti</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Esistono diversi modi per eseguire il ripristino di un backup online. Molti clienti ripristinano le snapshot utilizzando l'interfaccia CLI di ONTAP e quindi Oracle RMAN o sqlplus per completare il ripristino. Ciò è particolarmente comune negli ambienti di produzione di grandi dimensioni, in cui la probabilità e la frequenza dei ripristini dei database sono estremamente ridotte e qualsiasi procedura di ripristino viene gestita da un DBA esperto. Per un'automazione completa, soluzioni come NetApp SnapCenter includono un plug-in Oracle con interfacce sia a riga di comando che grafiche.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Alcuni clienti su larga scala hanno adottato un approccio più semplice configurando script di base sugli host per impostare i database in modalità di backup in un momento specifico in preparazione a uno snapshot pianificato. Ad esempio, pianificare il comando<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> alle 23:58,<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> alle 00:02, quindi programmare le snapshot direttamente sul sistema storage a mezzanotte. Il risultato è una strategia di backup semplice e altamente scalabile che non richiede licenze o software esterni.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">Il layout più semplice consiste nell'isolare i file di dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. In questo modo si garantisce che i volumi dei file dati possano essere ripristinati rapidamente tramite un'operazione SnapRestore senza distruggere un log di ripristino, controlfile o un log di archivio importante.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">LE SAN hanno requisiti simili per l'isolamento dei file dati all'interno di volumi dedicati. Con un sistema operativo come Microsoft Windows, un singolo volume potrebbe contenere più LUN di file dati, ciascuno con un file system NTFS. Con altri sistemi operativi, in genere esiste un volume manager logico. Ad esempio, con Oracle ASM, l'opzione più semplice sarebbe limitare i LUN di un gruppo di dischi ASM a un singolo volume che può essere sottoposto a backup e ripristinato come unità. Se per motivi di gestione delle performance o della capacità sono necessari volumi aggiuntivi, la creazione di un gruppo di dischi aggiuntivo sul nuovo volume semplifica la gestione.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Se vengono seguite queste linee guida, le snapshot possono essere pianificate direttamente sul sistema di storage, senza che sia necessario eseguire uno snapshot del gruppo di coerenza. Il motivo è che i backup Oracle non richiedono il backup dei file di dati contemporaneamente. La procedura di backup online è stata progettata per consentire ai file di dati di continuare ad essere aggiornati, poiché vengono lentamente trasmessi su nastro nel corso delle ore.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Una complicazione si verifica in situazioni come l'utilizzo di un gruppo di dischi ASM distribuito tra i volumi. In questi casi, è necessario eseguire uno snapshot cg per assicurarsi che i metadati ASM siano coerenti in tutti i volumi costituenti.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Attenzione:* verificare che l'ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> e.<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> i file non si trovano nel gruppo di dischi che ospita i file di dati. Ciò interferisce con la capacità di ripristinare selettivamente i dati e solo i file di dati.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i log di archivio oppure è possibile indirizzare rman/sqlplus ai dati nella directory snapshot.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">Inoltre, per i database di dimensioni inferiori, i file di dati possono essere recuperati da un utente finale direttamente da<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directory senza l'assistenza di tool di automazione o amministratori dello storage per eseguire una<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> comando.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Chiudere i gruppi di dischi che ospitano i file di dati. La procedura varia a seconda del volume manager logico scelto. Con ASM, il processo richiede lo smontaggio del gruppo di dischi. Con Linux, i file system devono essere smontati e i volumi logici e i gruppi di volumi devono essere disattivati. L'obiettivo è quello di interrompere tutti gli aggiornamenti del gruppo di volumi di destinazione da ripristinare.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Se si desidera eseguire il ripristino completo, riprodurre tutti i registri di ripristino.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio portando i LUN del registro di archivio offline ed eseguendo un ripristino. Questo è anche un esempio in cui è utile dividere i log di archivio in volumi dedicati. Se i log dell'archivio condividono un gruppo di volumi con log di ripristino, i log di ripristino devono essere copiati in un altro punto prima di ripristinare il set complessivo di LUN. Questa fase impedisce la perdita di tali transazioni finali registrate.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Questi requisiti includono fattori quali la velocità del recovery, la perdita massima consentita di dati e le esigenze di conservazione del backup. Il piano di protezione dei dati deve anche tenere in considerazione i vari requisiti normativi per la conservazione e il ripristino dei dati. Infine, è necessario considerare diversi scenari di ripristino dei dati, che vanno dal recupero tipico e prevedibile derivante da errori di utenti o applicazioni fino a scenari di ripristino di emergenza che includono la perdita completa di un sito.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Piccole modifiche alle policy di protezione e ripristino dei dati possono avere un effetto significativo sull'architettura generale dello storage, del backup e del ripristino. È fondamentale definire e documentare gli standard prima di iniziare il lavoro di progettazione, per evitare di complicare un'architettura di protezione dati. Le funzioni o i livelli di protezione non necessari comportano costi e costi di gestione inutili, mentre un requisito inizialmente trascurato può condurre un progetto nella direzione sbagliata o richiedere modifiche di progettazione dell'ultimo minuto.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Recovery time objective</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">L'obiettivo RTO (Recovery Time Objective) definisce il tempo massimo consentito per il ripristino di un servizio. Ad esempio, un database di risorse umane potrebbe avere un RTO di 24 ore perché, sebbene sarebbe molto scomodo perdere l'accesso a questi dati durante la giornata lavorativa, l'azienda può comunque operare. Al contrario, un database che supporta la contabilità generale di una banca avrebbe un RTO misurato in minuti o anche secondi. Un RTO di zero non è possibile, perché deve esserci un modo per distinguere tra un'effettiva interruzione del servizio e un evento di routine, come un pacchetto di rete perso. Tuttavia, un RTO prossimo allo zero è un requisito tipico.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Obiettivo RPO</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">Il recovery point objective (RPO) definisce la massima perdita di dati tollerabile. In molti casi, l'RPO è determinato unicamente dalla frequenza delle snapshot o degli aggiornamenti di snapmirror.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">In alcuni casi, l'RPO può essere reso più aggressivo proteggendo determinati dati con maggiore frequenza. In un contesto di database, l'RPO è in genere una questione di quanti dati di registro possono essere persi in una situazione specifica. In uno scenario di ripristino tipico in cui un database viene danneggiato a causa di un bug del prodotto o di un errore dell'utente, l'RPO deve essere pari a zero, il che significa che non ci devono essere perdite di dati. La procedura di ripristino prevede il ripristino di una copia precedente dei file di database e la riproduzione dei file di registro per portare lo stato del database al momento desiderato. I file di registro necessari per questa operazione dovrebbero essere già presenti nella posizione originale.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">In scenari insoliti, i dati del registro potrebbero andare persi. Ad esempio, un accidentale o dannoso<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> di file di database potrebbe causare l'eliminazione di tutti i dati. L'unica opzione sarebbe il ripristino dal backup, inclusi i file di registro, e alcuni dati andrebbero inevitabilmente persi. L'unica opzione per migliorare gli RPO in un ambiente di backup tradizionale sarebbe l'esecuzione di backup ripetuti dei dati di log. Questo comporta dei limiti, tuttavia, a causa dello spostamento costante dei dati e della difficoltà di mantenere un sistema di backup come servizio in esecuzione costante. Uno dei benefici dei sistemi storage avanzati è la capacità di proteggere i dati da danni accidentali o dannosi ai file e garantire quindi un RPO migliore senza spostamento dei dati.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">Il ripristino di emergenza include l'architettura IT, i criteri e le procedure necessarie per il ripristino di un servizio in caso di emergenza fisica. Tra questi, inondazioni, incendi o persone che agiscono con intento doloso o negligente.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">Il disaster recovery non è solo una serie di procedure di ripristino. Si tratta del processo completo di identificazione dei vari rischi, definizione dei requisiti di ripristino dei dati e continuità del servizio e realizzazione della giusta architettura con le relative procedure.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Durante la definizione dei requisiti di protezione dei dati, è fondamentale differenziare tra i requisiti tipici di RPO e RTO e quelli di RPO e RTO necessari per il disaster recovery. Alcuni ambienti applicativi richiedono un RPO pari a zero e un RTO prossimo allo zero per situazioni di perdita di dati che vanno da errori utente relativamente normali a incendi che distruggono un data center. Tuttavia, vi sono conseguenze amministrative e di costo per questi elevati livelli di protezione.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">In generale, i requisiti di ripristino dei dati non di emergenza devono essere rigorosi per due motivi. Innanzitutto, i bug applicativi e gli errori degli utenti che danneggiano i dati sono prevedibili al punto che sono quasi inevitabili. In secondo luogo, non è difficile progettare una strategia di backup in grado di offrire un RPO pari a zero e un RTO basso finché il sistema storage non viene distrutto. Non c'è motivo di non affrontare un rischio significativo che sia facilmente risolvibile, motivo per cui gli obiettivi di RPO e RTO per il ripristino locale dovrebbero essere aggressivi.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">I requisiti di RTO e RPO per il disaster recovery variano in modo più ampio in base alla probabilità di un disastro e alle conseguenze della perdita di dati associata o dell'interruzione di un business. I requisiti di RPO e RTO devono essere basati sulle effettive esigenze di business e non su principi generali. Devono tenere conto di più scenari di emergenza logici e fisici.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Disastri logici</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">I disastri logici includono la corruzione dei dati causata da utenti, bug delle applicazioni o del sistema operativo e malfunzionamenti del software. I disastri logici possono includere anche attacchi dannosi da parte di terzi con virus o worm o sfruttando le vulnerabilità delle applicazioni. In questi casi, l'infrastruttura fisica rimane intatta, ma i dati sottostanti non sono più validi.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Un tipo sempre più comune di disastro logico è noto come ransomware, in cui un vettore di attacco viene utilizzato per crittografare i dati. La crittografia non danneggia i dati, ma li rende non disponibili fino a quando non viene effettuato il pagamento a terzi. Un numero sempre crescente di aziende è specificatamente preso di mira con gli hack ransomware. A causa di questa minaccia, NetApp offre snapshot a prova di manomissione, in cui nemmeno l'amministratore dello storage può modificare i dati protetti prima della data di scadenza configurata.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Disastri fisici</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">I disastri fisici includono l'errore di componenti di un'infrastruttura che superano le sue capacità di ridondanza e causano una perdita di dati o un'estesa perdita di servizio. Ad esempio, la protezione RAID fornisce la ridondanza dell'unità disco e l'utilizzo di HBA fornisce la ridondanza di porte FC e cavi FC. I guasti hardware di tali componenti sono prevedibili e non influiscono sulla disponibilità.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">In un ambiente aziendale, è generalmente possibile proteggere l'infrastruttura di un intero sito con componenti ridondanti fino al punto in cui l'unico scenario di emergenza fisica prevedibile è la perdita completa del sito. Quindi, il piano di disaster recovery dipende dalla replica sito-sito.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Protezione dei dati sincrona e asincrona</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">In un mondo ideale, tutti i dati verrebbero replicati in modo sincrono tra siti dispersi geograficamente. Tale replicazione non è sempre fattibile o addirittura possibile per diversi motivi:</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">La replica sincrona aumenta inevitabilmente la latenza di scrittura, perché tutte le modifiche devono essere replicate in entrambe le posizioni prima che l'applicazione/database possa procedere con l'elaborazione. L'effetto sulle prestazioni risultante è talvolta inaccettabile, escludendo l'uso del mirroring sincrono.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">La maggiore adozione di storage SSD al 100% implica maggiore probabilità di ottenere una latenza di scrittura aggiuntiva, poiché le aspettative di performance includono centinaia di migliaia di IOPS e latenza sotto al millisecondo. Ottenere tutti i benefici dell'utilizzo di SSD al 100% può richiedere la revisione della strategia di disaster recovery.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">I set di dati continuano a crescere in termini di byte, creando difficoltà per garantire una larghezza di banda sufficiente a sostenere la replica sincrona.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">I set di dati crescono anche in termini di complessità, creando problemi con la gestione della replica sincrona su larga scala.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Le strategie basate sul cloud spesso implicano maggiori distanze di replica e latenza, precludendo ulteriormente l'utilizzo di mirroring sincrono.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp offre soluzioni che includono replica sincrona per le più esigenti richieste di recovery di dati e soluzioni asincrone che consentono performance e flessibilità migliori. Inoltre, la tecnologia NetApp si integra perfettamente con molte soluzioni di replica di terze parti, come Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Tempo di conservazione</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">L'ultimo aspetto di una strategia di protezione dei dati è il tempo di conservazione dei dati, che può variare drasticamente.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Un requisito tipico è rappresentato da 14 giorni di backup notturni sul sito primario e 90 giorni di backup memorizzati su un sito secondario.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">Molti clienti creano archivi trimestrali autonomi archiviati su supporti diversi.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Un database costantemente aggiornato potrebbe non richiedere i dati storici e i backup devono essere conservati solo per alcuni giorni.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">I requisiti normativi potrebbero richiedere la possibilità di recupero fino al punto in cui avviene una transazione arbitraria nell'arco di 365 giorni.</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Backup basati su snapshot</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">I valori chiave sono i seguenti:</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Semplicità.* Uno snapshot è una copia di sola lettura del contenuto di un contenitore di dati in un determinato momento.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Efficienza.* le istantanee non richiedono spazio al momento della creazione. Lo spazio viene occupato solo quando i dati vengono modificati.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Gestibilità.* Una strategia di backup basata sugli snapshot è facile da configurare e gestire perché gli snapshot sono parte nativa del sistema operativo di storage. Se il sistema di archiviazione è acceso, è pronto per creare dei backup.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Scalabilità.* è possibile conservare fino a 1024 backup di un singolo contenitore di file e LUN. Per set di dati complessi, più container di dati possono essere protetti da un singolo set coerente di snapshot.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">Le prestazioni non sono influenzate, indipendentemente dal fatto che un volume contenga 1024 snapshot o nessuno.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Sebbene molti vendor di soluzioni storage offrano la tecnologia Snapshot, la tecnologia Snapshot all'interno di ONTAP è unica e offre benefici significativi per gli ambienti applicativi aziendali e di database:</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Le copie snapshot fanno parte del layout file WAFL (Write-Anywhere file Layout) sottostante. Non si tratta di una tecnologia aggiuntiva o esterna. Questo semplifica la gestione, perché il sistema storage è il sistema di backup.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Le copie Snapshot non influiscono sulle prestazioni, ad eccezione di alcuni casi edge, come ad esempio quando una quantità così elevata di dati viene memorizzata nelle snapshot che il sistema storage sottostante si riempie.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">Il termine "gruppo di coerenza" viene spesso utilizzato per fare riferimento a un raggruppamento di oggetti di storage che vengono gestiti come una raccolta coerente di dati. Uno snapshot di un particolare volume ONTAP costituisce il backup del gruppo di coerenza.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">Le snapshot ONTAP offrono anche una scalabilità migliore rispetto alle tecnologie della concorrenza. I clienti possono memorizzare 5, 50 o 500 snapshot senza influire sulle performance. Il numero massimo di snapshot attualmente consentiti in un volume è 1024. Se è necessaria una conservazione aggiuntiva degli snapshot, sono disponibili opzioni per trasferire gli snapshot in cascata ad altri volumi.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Di conseguenza, la protezione di un set di dati ospitato su ONTAP è semplice e altamente scalabile. I backup non richiedono lo spostamento dei dati, pertanto una strategia di backup può essere personalizzata in base alle esigenze dell'azienda piuttosto che alle limitazioni delle velocità di trasferimento di rete, del numero elevato di unità a nastro o delle aree di staging del disco.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">Una domanda comunemente posta sull'utilizzo delle istantanee come strategia di protezione dei dati è il fatto che i dati "reali" e i dati snapshot si trovano sulle stesse unità. La perdita di tali unità causerebbe la perdita sia dei dati primari che del backup.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Gli snapshot locali, tuttavia, non dovrebbero mai rappresentare l'unica strategia di backup, motivo per cui NetApp offre tecnologie come SnapMirror e la replica SnapVault per replicare in modo rapido ed efficiente le snapshot su un set indipendente di dischi. In una soluzione adeguatamente progettata con istantanee e replica snapshot, l'utilizzo del nastro può essere ridotto a icona in un archivio trimestrale o eliminato del tutto.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Le copie Snapshot di ONTAP sono disponibili diverse opzioni per la protezione dei dati, mentre le snapshot sono alla base di molte altre funzionalità di ONTAP, tra cui replica, disaster recovery e cloning. Una descrizione completa della tecnologia snapshot non rientra nell'ambito di questo documento, ma le sezioni seguenti forniscono una panoramica generale.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Esistono due approcci principali per creare uno snapshot di un dataset:</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Backup coerenti con il crash</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Backup coerenti con le applicazioni</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">I backup coerenti con i crash vengono utilizzati principalmente quando è sufficiente un ripristino point-of-the-backup. Quando è richiesto un ripristino più granulare, sono in genere necessari backup coerenti con l'applicazione.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">La parola "coerente" in "coerente con l'applicazione" è spesso un nome scorretto. Ad esempio, l'inserimento di un database Oracle in modalità di backup viene definito backup coerente con l'applicazione, ma i dati non vengono resi coerenti o disattivati in alcun modo. I dati continuano a cambiare durante il backup. Al contrario, la maggior parte dei backup di MySQL e Microsoft SQL Server disattivano i dati prima di eseguire il backup. VMware può o non può rendere certi file coerenti.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">Il termine "gruppo di coerenza" si riferisce alla capacità di un array di archiviazione di gestire più risorse di archiviazione come una singola immagine. Ad esempio, un database può essere composto da 10 LUN. L'array deve essere in grado di eseguire il backup, il ripristino e la replica delle 10 LUN in modo coerente. Il ripristino non è possibile se le immagini dei LUN non erano coerenti nel punto di backup. La replica di queste 10 LUN richiede che tutte le repliche siano perfettamente sincronizzate l'una con l'altra.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">Il termine "gruppo di coerenza" non viene spesso utilizzato quando si parla di ONTAP perché la coerenza è sempre stata una funzione di base dell'architettura di volumi e aggregati all'interno di ONTAP. Molti altri storage array gestiscono LUN o file system come unità singole. Possono quindi essere configurati facoltativamente come "gruppo di coerenza" ai fini della protezione dei dati, ma questo è un passaggio aggiuntivo nella configurazione.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP è sempre stata in grado di acquisire immagini di dati coerenti locali e replicate. Anche se i vari volumi su un sistema ONTAP non vengono in genere formalmente descritti come un gruppo di coerenza, è proprio questo lo sono. Una snapshot di tale volume è un'immagine del gruppo di coerenza, il ripristino di tale snapshot è un ripristino di un gruppo di coerenza e sia SnapMirror che SnapVault offrono la replica di un gruppo di coerenza.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshot di gruppo di coerenza</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Le snapshot di gruppo di coerenza (cg-Snapshot) sono un'estensione della tecnologia Snapshot di base di ONTAP. Un'operazione Snapshot standard crea un'immagine coerente di tutti i dati all'interno di un singolo volume, ma a volte è necessario creare un set coerente di Snapshot su più volumi e persino su sistemi di storage multipli. Ne risulta una serie di snapshot che possono essere utilizzate allo stesso modo di uno snapshot di un solo volume. Possono essere utilizzati per il recovery locale dei dati, replicati a scopo di disaster recovery o clonati come una singola unità coerente.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">Il più grande utilizzo noto di cg-snapshot è per un ambiente di database di circa 1PB GB su 12 controller. Le cg-Snapshot create su questo sistema sono state utilizzate per il backup, il ripristino e il cloning.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">Nella maggior parte dei casi, quando un set di dati copre i volumi e l'ordine di scrittura deve essere preservato, il software di gestione scelto utilizza automaticamente uno snapshot cg. In questi casi non è necessario comprendere i dettagli tecnici delle istantanee cg. Tuttavia, in alcune situazioni, i complessi requisiti di protezione dei dati richiedono un controllo dettagliato sul processo di protezione e replica dei dati. I flussi di lavoro di automazione o l'uso di script personalizzati per richiamare le API cg-snapshot sono alcune delle opzioni disponibili. La comprensione dell'opzione migliore e del ruolo di cg-snapshot richiede una spiegazione più dettagliata della tecnologia.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">La creazione di una serie di istantanee cg è un processo in due fasi:</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Stabilire il recencing in scrittura su tutti i volumi di destinazione.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Creare Snapshot di tali volumi nello stato fenced (fenced).</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">La recinzione in scrittura viene stabilita in serie. Ciò significa che, mentre il processo di scherma viene configurato su più volumi, l'i/o in scrittura viene bloccato sul primo volume della sequenza mentre continua ad essere assegnato ai volumi che compaiono in seguito. Questo potrebbe inizialmente sembrare una violazione del requisito per il mantenimento dell'ordine di scrittura, ma ciò si applica solo all'i/o emesso in modo asincrono sull'host e non dipende da altre scritture.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Ad esempio, un database potrebbe eseguire numerosi aggiornamenti asincroni del file dati, consentendo al sistema operativo di riordinare l'i/o e completarli in base alla propria configurazione dell'utilità di pianificazione. L'ordine di questo tipo di i/o non può essere garantito perché l'applicazione e il sistema operativo hanno già rilasciato il requisito di mantenere l'ordine di scrittura.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Come esempio di contatore, la maggior parte delle attività di registrazione del database è sincrona. Il database non procede con ulteriori scritture di registro fino a quando l'i/o non viene riconosciuto e l'ordine di tali scritture deve essere conservato. Se un i/o di registro arriva su un volume fenced, non viene riconosciuto e le applicazioni vengono bloccate in ulteriori scritture. Analogamente, l'i/o di metadati del file system è di solito sincrono. Ad esempio, un'operazione di eliminazione file non deve essere persa. Se un sistema operativo con un file system xfs eliminava un file e l'i/o che aggiornava i metadati del file system xfs per rimuovere il riferimento a quel file apposto su un volume recintato, l'attività del file system si interrompeva. Ciò garantisce l'integrità del file system durante le operazioni cg-snapshot.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Dopo aver configurato la funzionalità write fencing nei volumi di destinazione, sono pronti per la creazione di snapshot. Non è necessario creare esattamente gli snapshot contemporaneamente, perché lo stato dei volumi è bloccato da un punto di vista di scrittura dipendente. Per evitare un difetto nell'applicazione che crea le istantanee cg, la recinzione iniziale include un timeout configurabile in cui ONTAP rilascia automaticamente la recinzione e riprende l'elaborazione di scrittura dopo un numero definito di secondi. Se tutte le istantanee vengono create prima dello scadere del periodo di timeout, il gruppo risultante di istantanee è un gruppo di coerenza valido.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Ordine di scrittura dipendente</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Da un punto di vista tecnico, la chiave per un gruppo di coerenza è preservare l'ordine di scrittura e, nello specifico, l'ordine di scrittura dipendente. Ad esempio, un database in scrittura su 10 LUN scrive simultaneamente su tutte. Molte scritture vengono emesse in modo asincrono, il che significa che l'ordine in cui vengono completate non è importante e l'ordine effettivo in cui vengono completate varia in base al comportamento del sistema operativo e della rete.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Alcune operazioni di scrittura devono essere presenti sul disco prima che il database possa procedere con operazioni di scrittura aggiuntive. Queste operazioni critiche di scrittura sono chiamate scritture dipendenti. I/o di scrittura successivi dipendono dalla presenza di queste scritture sul disco. Qualsiasi snapshot, recovery o replica di queste 10 LUN deve garantire l'ordine di scrittura dipendente. Gli aggiornamenti del file system sono un altro esempio di scritture dipendenti dall'ordine di scrittura. L'ordine in cui vengono apportate le modifiche al file system deve essere mantenuto o l'intero file system potrebbe danneggiarsi.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Strategie</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Esistono due approcci principali ai backup basati su snapshot:</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Backup a caldo protetti dagli snapshot</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">I backup Snapshot coerenti con i crash vengono utilizzati principalmente quando è sufficiente un recovery point-of-the-backup. In alcune circostanze è possibile applicare i registri di archivio, ma quando è necessario un ripristino point-in-time più granulare, è preferibile un backup online.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">La procedura di base per un backup online basato su snapshot è la seguente:</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Inserire il database in<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modalità.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Creare una snapshot di tutti i volumi che ospitano file di dati.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Esci<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modalità.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Eseguire il comando<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> per forzare l'archiviazione del registro.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Creare snapshot di tutti i volumi che ospitano i log di archivio.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Questa procedura produce una serie di istantanee contenenti file di dati in modalità backup e i registri di archivio critici generati in modalità backup. Questi sono i due requisiti per il ripristino di un database. I file come i file di controllo dovrebbero essere protetti per comodità, ma l'unico requisito assoluto è la protezione per i file di dati e i registri di archivio.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Sebbene i diversi clienti possano avere strategie molto diverse, quasi tutte queste strategie si basano in ultima analisi sugli stessi principi delineati di seguito.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Recovery basato su Snapshot</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Quando si progettano layout di volumi per database Oracle, la prima decisione è se utilizzare la tecnologia VBSR (Volume-Based NetApp SnapRestore).</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">La funzione SnapRestore basata su volume consente di ripristinare quasi istantaneamente un volume in un point-in-time precedente. Poiché tutti i dati sul volume vengono ripristinati, VBSR potrebbe non essere appropriato per tutti i casi di utilizzo. Ad esempio, se un intero database, inclusi file di dati, log di ripristino e log di archivio, viene memorizzato in un singolo volume e questo volume viene ripristinato con VBSR, i dati vengono persi perché i log di archivio e i dati di ripristino più recenti vengono scartati.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">VBSR non è necessario per il ripristino. Molti database possono essere ripristinati utilizzando SFSR (Single-file SnapRestore) basato su file o semplicemente copiando i file dalla snapshot nel file system attivo.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">L'isolamento dei file di dati in questo modo consente loro di tornare a uno stato precedente senza danneggiare altri file system.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Riserva di Snapshot</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Per ogni volume con i dati Oracle in un ambiente SAN, il<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Dovrebbe essere impostato su zero perché non è utile riservare spazio per uno snapshot in un ambiente LUN. Se la riserva frazionaria è impostata su 100, uno snapshot di un volume con LUN richiede spazio libero sufficiente nel volume, esclusa la riserva snapshot, per assorbire il 100% di turnover di tutti i dati. Se la riserva frazionaria è impostata su un valore inferiore, è necessaria una quantità di spazio libero corrispondente inferiore, ma esclude sempre la riserva istantanea. Ciò significa che viene sprecato lo spazio di riserva di Snapshot in un ambiente LUN.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">In un ambiente NFS, esistono due opzioni:</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Impostare<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> in base al consumo di spazio snapshot previsto.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Impostare<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> a zero e gestire collettivamente il consumo di spazio attivo e snapshot.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Con la prima opzione,<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> è impostato su un valore diverso da zero, in genere intorno al 20%. Questo spazio viene quindi nascosto all'utente. Tuttavia, questo valore non crea un limite di utilizzo. Se un database con una prenotazione del 20% registra un fatturato del 30%, lo spazio snapshot può crescere oltre i limiti della riserva del 20% e occupare spazio non riservato.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">Il vantaggio principale dell'impostazione di una riserva a un valore come 20% è verificare che una parte di spazio sia sempre disponibile per gli snapshot. Ad esempio, un volume da 1TB TB con una riserva del 20% consentirebbe all'amministratore di database (DBA) di memorizzare 800GB TB di dati. Questa configurazione garantisce almeno 200GB GB di spazio per il consumo di snapshot.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Quando<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> è impostato su zero, tutto lo spazio nel volume è disponibile per l'utente finale, il che garantisce una migliore visibilità. Un DBA deve capire che, se rileva un volume di 1TB GB che sfrutta le snapshot, questo 1TB GB di spazio viene condiviso tra i dati attivi e il turnover di Snapshot.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">Non esiste una chiara preferenza tra l'opzione 1 e l'opzione 2 tra gli utenti finali.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">ONTAP e snapshot di terze parti</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683,1 illustra i requisiti per il supporto di snapshot di terze parti e le varie opzioni disponibili per le operazioni di backup e ripristino.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">Il fornitore di terze parti deve garantire che le istantanee dell'azienda siano conformi ai seguenti requisiti:</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Gli snapshot devono integrarsi con le operazioni di ripristino e ripristino consigliate da Oracle.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Gli snapshot devono essere coerenti con il crash del database nel punto dello snapshot.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">L'ordine di scrittura viene mantenuto per ogni file all'interno di uno snapshot.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">I prodotti di gestione ONTAP e NetApp di Oracle sono conformi a questi requisiti.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Data Protection di Oracle con ONTAP</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Un'azienda non può operare senza accesso ai propri dati, e a volte i dati definiscono l'azienda. Questi dati devono essere protetti; tuttavia, la protezione dei dati non è solo garanzia di un backup utilizzabile, ma consiste nell'eseguire i backup in modo rapido e affidabile, oltre a memorizzarli in modo sicuro.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">L'altro lato della protezione dei dati è la recovery. Quando i dati sono inaccessibili, l'azienda ne è interessata e potrebbe non funzionare fino a quando i dati non vengono ripristinati. Questo processo deve essere rapido e affidabile. Infine, la maggior parte dei database deve essere protetta dai disastri, il che significa mantenere una replica del database. La replica deve essere sufficientemente aggiornata. Rendere la replica un database completamente operativo deve anche essere semplice e veloce.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4591: Data Protection di Oracle: Backup, recovery e replica._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Pianificazione</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Il test accurato delle performance dello storage del database è un argomento estremamente complicato. Richiede la comprensione dei seguenti problemi:</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS e throughput</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">La differenza tra le operazioni i/o in primo piano e in background</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">L'effetto della latenza sul database</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Numerose impostazioni del sistema operativo e di rete che influiscono sulle performance dello storage</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">Inoltre, occorre prendere in considerazione attività che non riguardano i database di storage. Esiste un punto in cui l'ottimizzazione delle performance dello storage non produce vantaggi utili perché le performance dello storage non sono più un fattore limitante per le performance.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">La larghezza di banda della rete è una fonte sempre più comune di limitazioni delle prestazioni. Ad esempio, le soluzioni su disco a rotazione sono spesso dei colli di bottiglia per le performance dei database perché la latenza i/o è molto elevata. Quando un array all-flash rimuove le limitazioni di latenza, spesso la barriera passa alla rete. Si tratta di un aspetto particolarmente interessante nel caso di ambienti virtualizzati e sistemi blade in cui è difficile visualizzare la vera connettività di rete. Ciò può complicare il test delle performance se il sistema di storage stesso non può essere pienamente utilizzato a causa di limitazioni della larghezza di banda.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Generalmente, il confronto delle performance di un array all-flash con un array contenente dischi rotanti non è possibile a causa dell'aumento drastico della latenza degli array all-flash. I risultati dei test in genere non sono significativi.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">Il confronto delle performance di picco degli IOPS con un array all-flash spesso non è un test utile, in quanto i database non sono limitati dall'i/o dello storage Ad esempio, si supponga che un array sia in grado di sostenere 500K IOPS casuali, mentre un altro possa sostenere 300K KB. La differenza è irrilevante nel mondo reale se un database impiega il 99% del suo tempo per l'elaborazione della CPU. I carichi di lavoro non utilizzano mai le funzionalità complete dello storage array. Al contrario, le funzionalità degli IOPS di picco potrebbero essere critiche in una piattaforma di consolidamento in cui si prevede che lo storage array venga caricato alle proprie funzionalità di picco.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">In qualsiasi test dello storage, si tiene sempre in considerazione sia la latenza che gli IOPS. Molti storage array sul mercato dichiarano livelli estremi di IOPS, ma la latenza rende quegli IOPS inutili a tali livelli. La destinazione tipica degli array all-flash è il contrassegno 1ms. Un approccio migliore al test non consiste nel misurare gli IOPS massimi possibili, ma nel determinare quanti IOPS può supportare uno storage array prima che la latenza media sia superiore a 1ms ms.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Oracle Automatic workload Repository e benchmarking</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Il gold standard per i confronti delle performance Oracle è un report Oracle Automatic workload Repository (AWR).</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Esistono diversi tipi di rapporti AWR. Da un punto di vista dello storage, un report generato dall'esecuzione di<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> È il comando più completo e utile, in quanto è destinato a una specifica istanza del database e include alcuni istogrammi dettagliati che suddividono gli eventi i/o dello storage in base alla latenza.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">Il confronto fra due array delle performance implica l'esecuzione idealmente dello stesso carico di lavoro su ciascun array e la produzione di un report AWR che punta esattamente al carico di lavoro. Nel caso di un carico di lavoro con esecuzione molto lunga, è possibile utilizzare un singolo rapporto AWR con un tempo trascorso che comprende il tempo di inizio e di fine, ma è preferibile suddividere i dati AWR come rapporti multipli. Ad esempio, se un processo batch è stato eseguito dalla mezzanotte alle 6, creare una serie di rapporti AWR di un'ora dalle 1:1 alle 2:00 e così via.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">In altri casi, è necessario ottimizzare una query molto breve. L'opzione migliore è un report AWR basato su uno snapshot AWR creato all'inizio della query e un secondo snapshot AWR creato al termine della query. Il server di database dovrebbe essere altrimenti silenzioso per ridurre al minimo l'attività in background che potrebbe oscurare l'attività della query in analisi.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Laddove i report AWR non sono disponibili, i report statspack Oracle sono una buona alternativa. Contengono la maggior parte delle stesse statistiche i/o di un rapporto AWR.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR e risoluzione dei problemi</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Un report AWR è anche lo strumento più importante per analizzare un problema di prestazioni.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Come per il benchmarking, il troubleshooting delle performance richiede la misurazione precisa di un determinato carico di lavoro. Quando possibile, fornisci dati AWR quando segnali un problema di performance al centro di supporto NetApp o quando lavori con un account team NetApp o partner in merito a una nuova soluzione.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Quando si forniscono i dati AWR, considerare i seguenti requisiti:</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Eseguire<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> per generare il report. L'output può essere di testo o HTML.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Se si utilizzano Oracle Real Application Clusters (RAC), generare report AWR per ciascuna istanza del cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Indicare l'ora specifica in cui si è verificato il problema. Il tempo massimo accettabile trascorso di un rapporto AWR è generalmente di un'ora. Se un problema persiste per più ore o richiede un'operazione multi-ora, ad esempio un processo batch, fornire più rapporti AWR di un'ora che coprono l'intero periodo da analizzare.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Se possibile, regolare l'intervallo dell'istantanea AWR su 15 minuti. Questa impostazione consente di eseguire un'analisi più dettagliata. Ciò richiede anche ulteriori esecuzioni di<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> per fornire un report per ogni intervallo di 15 minuti.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Se il problema è una query in esecuzione molto breve, fornire un report AWR basato su uno snapshot AWR creato all'inizio dell'operazione e un secondo snapshot AWR creato al termine dell'operazione. Il server di database dovrebbe essere altrimenti silenzioso per ridurre al minimo l'attività in background che oscurrebbe l'attività dell'operazione in analisi.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Se viene segnalato un problema di prestazioni in determinati momenti ma non in altri, fornire dati AWR aggiuntivi che dimostrino buone prestazioni per il confronto.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">calibra_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">Il<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> command non deve mai essere utilizzato per testare, confrontare o eseguire il benchmark dei sistemi storage. Come indicato nella documentazione di Oracle, questa procedura calibra le funzionalità i/o dello storage.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">La calibrazione non è la stessa del benchmarking. Lo scopo di questo comando è di emettere i/o per aiutare a calibrare le operazioni di database e migliorarne l'efficienza ottimizzando il livello di i/o inviato all'host. Poiché il tipo di i/o eseguito da<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> L'operazione non rappresenta l'i/o effettivo dell'utente del database, i risultati non sono prevedibili e spesso non sono nemmeno riproducibili.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, il Silly Little Oracle Benchmark, è diventato lo strumento preferito per la valutazione delle prestazioni del database. È stato sviluppato da Kevin Closson ed è disponibile su <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. Occorrono pochi minuti per installare e configurare, oltre a utilizzare un database Oracle effettivo per generare schemi di i/o su una tablespace definibile dall'utente. È una delle poche opzioni di test disponibili in grado di saturare un array all-flash con l'i/O. È utile anche per generare livelli molto inferiori di i/o per simulare carichi di lavoro di storage che sono IOPS bassi ma sensibili alla latenza.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Panca di rotazione</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench può essere utile per testare le prestazioni del database, ma è estremamente difficile utilizzare Swingbench in un modo che mette a dura prova lo storage. NetApp non ha riscontrato test da Swingbench che hanno dato i/o sufficienti per essere un carico significativo su qualsiasi array AFF. In casi limitati, è possibile utilizzare Order Entry Test (OET) per valutare lo storage dal punto di vista della latenza. Ciò può essere utile in situazioni in cui un database ha una dipendenza di latenza nota per determinate query. Assicurarsi che l'host e la rete siano configurati correttamente per realizzare i potenziali di latenza di un array all-flash.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB è uno strumento di test del database che simula, tra gli altri, i benchmark TPC-C e TPC-H. La creazione di un set di dati di dimensioni sufficienti per eseguire correttamente un test può richiedere molto tempo, ma può rivelarsi uno strumento efficace per valutare le prestazioni delle applicazioni OLTP e di data warehouse.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orion</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">Lo strumento Oracle Orion è stato comunemente utilizzato con Oracle 9, ma non è stato mantenuto per garantire la compatibilità con le modifiche in vari sistemi operativi host. Viene raramente utilizzato con Oracle 10 o Oracle 11 a causa di incompatibilità con il sistema operativo e la configurazione dello storage.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle ha riscritto lo strumento e viene installato per impostazione predefinita con Oracle 12c. Sebbene questo prodotto sia stato migliorato e utilizzi molte delle stesse chiamate utilizzate da un database Oracle reale, non utilizza esattamente lo stesso percorso di codice o lo stesso comportamento i/o utilizzato da Oracle. Ad esempio, la maggior parte degli i/o Oracle viene eseguita in modo sincrono, il che significa che il database si arresta finché l'i/o non viene completato quando l'operazione i/o viene completata in primo piano. Il semplice flooding di un sistema storage con i/o casuali non rappresenta una riproduzione di i/o Oracle reali e non offre un metodo diretto per confrontare gli array di storage o misurare l'effetto delle modifiche alla configurazione.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Detto questo, ci sono alcuni casi d'utilizzo per Orion, come la misurazione generale delle massime prestazioni possibili di una particolare configurazione host-rete-storage, o per misurare lo stato di un sistema storage. Con un test accurato, è possibile ideare test Orion utilizzabili per confrontare gli storage array o valutare l'effetto di una modifica della configurazione, a condizione che i parametri includano la considerazione di IOPS, throughput e latenza e cercare di replicare fedelmente un carico di lavoro realistico.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Allineamento di WAFL per database Oracle</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Verifica dell'allineamento di WAFL per i database Oracle</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">Il corretto allineamento dell'WAFL è fondamentale per garantire buone prestazioni. Sebbene ONTAP gestisca blocchi in 4KB unità, questo fatto non significa che ONTAP esegua tutte le operazioni in 4KB unità. Infatti, ONTAP supporta operazioni a blocchi di diverse dimensioni, ma la contabilità sottostante è gestita da WAFL in 4KB unità.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">Il termine "allineamento" si riferisce al modo in cui l'i/o Oracle corrisponde a queste unità 4KB. Per ottenere prestazioni ottimali è necessario che un blocco Oracle 8KB risieda su due blocchi fisici da 4KB WAFL su un'unità. Se un blocco è sfalsato di 2KB, questo blocco risiede su metà di un blocco 4KB, un blocco 4KB completo separato e quindi sulla metà di un terzo blocco 4KB. Questa disposizione causa un peggioramento delle prestazioni.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">L'allineamento non è un problema con i file system NAS. I file di dati Oracle sono allineati all'inizio del file in base alle dimensioni del blocco Oracle. Pertanto, le dimensioni dei blocchi di 8KB, 16KB e 32KB sono sempre allineate. Tutte le operazioni di blocco sono sfalsate dall'inizio del file in unità di 4 kilobyte.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">I LUN, al contrario, contengono generalmente qualche tipo di intestazione del driver o metadati del file system all'inizio che creano un offset. L'allineamento è raramente un problema nei sistemi operativi moderni, perché questi sistemi operativi sono progettati per unità fisiche che potrebbero utilizzare un settore 4KB nativo, che richiede anche l'allineamento dell'i/o ai confini del 4KB per ottenere prestazioni ottimali.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Ci sono, tuttavia, alcune eccezioni. È possibile che un database sia stato migrato da un sistema operativo meno recente non ottimizzato per i/o 4KB o che un errore utente durante la creazione della partizione abbia causato un offset che non è in unità di 4KB.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">I seguenti esempi sono specifici per Linux, ma la procedura può essere adattata per qualsiasi sistema operativo.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Allineato</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">L'esempio seguente mostra un controllo dell'allineamento su un singolo LUN con una singola partizione.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">Innanzitutto, creare la partizione che utilizza tutte le partizioni disponibili sul disco.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">L'allineamento può essere controllato matematicamente con il seguente comando:</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">L'output mostra che le unità sono 512 byte, e l'inizio della partizione è 32 unità. Si tratta di un totale di 32 x 512 = 16.834 byte, ovvero un multiplo intero di 4KB blocchi WAFL. Questa partizione è allineata correttamente.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Per verificare il corretto allineamento, attenersi alla seguente procedura:</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identificare l'UUID (Universal Unique Identifier) del LUN.</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Immettere la shell del nodo sul controller ONTAP.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Avviare le raccolte statistiche sull'UUID di destinazione identificato nel primo passaggio.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Eseguire alcuni i/O. È importante utilizzare<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argomento per assicurarsi che i/o sia sincrono e non bufferizzato.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Prestare molta attenzione con questo comando. Inversione del<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> e.<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> gli argomenti distruggono i dati.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Arrestare le statistiche e visualizzare l'istogramma di allineamento. Tutti i i/o devono trovarsi in<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket, che indica i/o allineato al limite di un blocco 4KB.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Disallineato</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">L'esempio seguente mostra i/o disallineati:</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Creare una partizione che non si allinea a un confine 4KB. Questo non è il comportamento predefinito sui sistemi operativi moderni.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">Il disallineamento è chiaro. L'i/o rientra principalmente in* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> benna, che corrisponde all'offset previsto. Quando la partizione è stata creata, è stata spostata di 512 byte più avanti nel dispositivo rispetto al valore predefinito ottimizzato, il che significa che l'istogramma è spostato di 512 byte.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">Inoltre, il<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> Le statistiche sono diverse da zero, il che significa che è stato eseguito l'i/o che non ha riempito l'intero blocco da 4KB KB.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Ripristina la logging</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Le procedure qui spiegate sono applicabili ai file di dati. I log di ripristino e gli archivi di Oracle hanno modelli di i/o diversi. Ad esempio, il redo logging è una sovrascrittura circolare di un singolo file. Se si utilizza la dimensione predefinita del blocco da 512 byte, le statistiche di scrittura sono simili a queste:</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">L'i/o viene distribuito in tutti i bucket di istogramma, ma non si tratta di un problema di prestazioni. Velocità di redo-logging estremamente elevate potrebbero, tuttavia, trarre vantaggio dall'utilizzo di dimensioni del blocco di 4KB KB. In questo caso, è consigliabile assicurarsi che i LUN di redo-logging siano allineati correttamente. Tuttavia, questo non è importante per le buone prestazioni come l'allineamento dei file dati.</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Se un server di database Oracle si blocca, potrebbe essersi verificato un problema con blocchi NFS obsoleti al riavvio. Questo problema può essere evitato prestando particolare attenzione alla configurazione della risoluzione dei nomi sul server.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Questo problema si verifica perché la creazione di un blocco e la cancellazione di un blocco utilizzano due metodi di risoluzione dei nomi leggermente diversi. Sono coinvolti due processi: Network Lock Manager (NLM) e il client NFS. NLM utilizza<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> per determinare il nome host, mentre la<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> usi di processo<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Questi nomi host devono corrispondere affinché il sistema operativo elimini correttamente i blocchi obsoleti. Ad esempio, l'host potrebbe cercare i blocchi di proprietà di<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, ma i blocchi sono stati registrati dall'host come<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Se<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> non restituisce lo stesso valore di<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, quindi il processo di rilascio del blocco non ha avuto esito positivo.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">Il seguente script di esempio verifica se la risoluzione dei nomi è completamente coerente:</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Se<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> non corrisponde<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, è probabile che siano presenti blocchi obsoleti. Ad esempio, questo risultato rivela un potenziale problema:</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">La soluzione viene generalmente trovata modificando l'ordine in cui gli host vengono visualizzati<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Ad esempio, si supponga che il file hosts includa questa voce:</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Per risolvere il problema, modificare l'ordine di visualizzazione del nome di dominio completo e del nome host breve:</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> ora restituisce il breve<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> nome host, che corrisponde all'output di<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. I blocchi vengono quindi cancellati automaticamente dopo un arresto anomalo del server.</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Virtualizzazione</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Presentazione storage</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">LUN iSCSI gestite dall'iniziatore iSCSI sulla macchina virtuale, non dall'hypervisor</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilità.* quando una VM è proprietaria dei suoi file system, il processo di spostamento di un ambiente Oracle diventa molto più semplice. I file system possono essere spostati facilmente tra guest virtualizzati e non.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Driver paravirtualizzati</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Per prestazioni ottimali, l'uso di driver di rete paravirtualizzati è fondamentale. Quando si utilizza un datastore, è necessario un driver SCSI paravirtualizzato. Un driver di dispositivo paravirtualizzato consente a un guest di integrarsi più profondamente nell'hypervisor, invece di un driver emulato in cui l'hypervisor spende più tempo CPU che imita il comportamento dell'hardware fisico.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">Overcommit RAM</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">L'overcommit della RAM implica la configurazione di una quantità di RAM virtualizzata su vari host superiore a quella presente sull'hardware fisico. In caso contrario, si potrebbero verificare problemi di prestazioni imprevisti. Quando si virtualizza un database, i blocchi sottostanti di Oracle SGA non devono essere sostituiti con lo storage dall'hypervisor. Ciò causa risultati di prestazioni altamente instabili.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792 fornisce indicazioni per l'utilizzo di NetApp HCI 615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI per l'infrastruttura di desktop virtuale con VMware Horizon 7: Potenzia i tuoi utenti più esperti con la grafica 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792 fornisce indicazioni sull'utilizzo del nodo di calcolo NetApp H615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione. Fornisce inoltre i risultati dei test preliminari di SPECviewperf 13 per H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Questo documento illustra la sicurezza dei prodotti per gli strumenti ONTAP per VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Utilizzo di vVol con ONTAP</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Prodotti e documentazione</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">ONTAP Tools architettura del provider VASA,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Installazione del prodotto</block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentazione del prodotto</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La seguente documentazione è disponibile per facilitare l'implementazione degli strumenti ONTAP.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Inizia subito</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Note di rilascio</block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Implementare gli strumenti ONTAP</block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Aggiornare i tool ONTAP</block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilizzare gli strumenti ONTAP</block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configurare il controllo degli accessi in base al ruolo</block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configurare la disponibilità elevata</block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Proteggere e gestire i datastore</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Dashboard del provider VASA</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Best Practice</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Limiti*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Valori massimi di configurazione</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacità/funzionalità</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">L'utilizzo di ONTAP vVol con vSphere è semplice e segue i metodi vSphere pubblicati (per la versione di ESXi in uso, vedere utilizzo dei volumi virtuali in vSphere Storage nella documentazione VMware). Di seguito sono riportate alcune procedure aggiuntive da prendere in considerazione in combinazione con ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilizzare i tool ONTAP per le estensioni dell'interfaccia utente di VMware vSphere o le API REST per eseguire il provisioning degli archivi dati vVol* *e degli endpoint del protocollo.*</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Non memorizzare mai l'appliance ONTAP Tools o l'appliance vCenter Server (VCSA) su un datastore vVol gestito.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Questo può causare una "situazione a base di uova e pollo" se occorre riavviare le appliance perché non saranno in grado di ricollegare i propri vVol durante il riavvio. È possibile memorizzarli in un datastore vVol gestito da un diverso tool ONTAP e da una distribuzione vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Evitare le operazioni vVol in diverse release di ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Le funzionalità di storage supportate, come QoS, personalità e molto altro, sono cambiate in varie versioni del provider VASA e alcune dipendono dalla release di ONTAP. L'utilizzo di release diverse in un cluster ONTAP o lo spostamento di vVol tra cluster con release diverse può causare comportamenti imprevisti o allarmi di compliance.</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Zoning initiator singolo con quattro nodi,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 Best practice per la MODERNA SAN ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 implementazione e configurazione delle moderne SAN con NVMe-of_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Pianificare FlexVol di supporto in base alle proprie esigenze.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Seguire tutte le Best practice del protocollo.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configurazione di rete con vVol su NFS v3.500</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Questo documento tratta le funzionalità di ONTAP per i volumi virtuali VMware vSphere (vVol), incluse le informazioni più recenti sui prodotti e i casi di utilizzo, oltre a Best practice e altre informazioni per semplificare l'implementazione e ridurre gli errori.</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche che funzionano o sono supportate, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Panoramica dei volumi virtuali (vVol)</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Esistono diversi componenti di cui tenere conto:</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Questo è il componente software che gestisce la comunicazione tra VMware vSphere e il sistema storage. Per ONTAP, il provider VASA viene eseguito in un'appliance nota come tool ONTAP per VMware vSphere (in breve, strumenti ONTAP). Gli strumenti ONTAP includono anche un plugin vCenter, un adattatore per la replica dello storage (SRA) per VMware Site Recovery Manager e un server API REST per la creazione di automazione. Una volta configurati e registrati gli strumenti ONTAP con vCenter, non è più necessario interagire direttamente con il sistema ONTAP, poiché quasi tutte le esigenze di storage possono essere gestite direttamente dall'interfaccia utente di vCenter o tramite l'automazione delle API REST.</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">L'endpoint del protocollo è un proxy per i/o tra gli host ESXi e il datastore vVols. Il provider ONTAP VASA crea automaticamente questi elementi, scegliendo una LUN endpoint di protocollo (4MB GB) per volume FlexVol del datastore vVol o un punto di montaggio NFS per interfaccia NFS (LIF) sul nodo storage che ospita un volume FlexVol nel datastore. L'host ESXi monta questi endpoint di protocollo direttamente piuttosto che singoli LUN vVol e file di dischi virtuali. Non è necessario gestire gli endpoint del protocollo poiché vengono creati, montati, rimossi ed eliminati automaticamente dal provider VASA, insieme a eventuali gruppi di interfacce o policy di esportazione necessari.</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Novità di vSphere 8: Quando si utilizza NVMe over Fabrics (NVMe-of) con vVol, il concetto di endpoint del protocollo non è più rilevante in ONTAP. Al contrario, l'host ESXi crea automaticamente un'istanza di PE virtuale per ciascun gruppo ANA non appena viene accesa la prima macchina virtuale. ONTAP crea automaticamente gruppi ANA per ogni volume FlexVol utilizzato dall'archivio dati.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Un ulteriore vantaggio dell'utilizzo di NVMe-of per vVol è che non sono richieste di bind da parte del provider VASA. L'host ESXi gestisce invece la funzionalità di binding vVol internamente in base a VPE. In questo modo si riduce l'opportunità di un vVol bind storm di impatto sul servizio.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe e volumi virtuali</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Per ulteriori informazioni, vedere<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> acceso<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Gestione basata su criteri</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Conformità delle policy di storage delle macchine virtuali</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Conformità alle policy di storage delle macchine virtuali</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Al momento della pubblicazione, gli ambienti hyperscaler sono limitati solo agli archivi dati NFS v3 tradizionali, pertanto i vVol sono disponibili solo con sistemi ONTAP on-premise o con sistemi connessi al cloud che offrono la funzionalità completa di sistemi on-premise come quelli ospitati da partner e provider di servizi NetApp in tutto il mondo.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentazione del prodotto ONTAP</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Per ulteriori informazioni su ONTAP, vedere<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Vantaggi dell'utilizzo di vVol con ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Quando VMware ha introdotto il supporto vVol con VASA 2.0 nel 2015, lo ha descritto come "un framework di integrazione e gestione che offre un nuovo modello operativo per lo storage esterno (SAN/NAS)". Questo modello operativo offre diversi vantaggi insieme allo storage ONTAP.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Come descritto nella sezione 1,2, la gestione basata su criteri consente di eseguire il provisioning delle macchine virtuali e di gestirle successivamente utilizzando criteri predefiniti. Questo può aiutare le operazioni IT in diversi modi:</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Aumentare la velocità.* i tool ONTAP eliminano il requisito per l'amministratore di vCenter di aprire i ticket con il team di storage per le attività di provisioning dello storage. Tuttavia, i ruoli RBAC dei tool ONTAP in vCenter e nel sistema ONTAP consentono ancora ai team indipendenti (come i team di storage) o alle attività indipendenti dello stesso team limitando l'accesso a funzioni specifiche, se necessario.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Provisioning più intelligente.* le funzionalità del sistema di storage possono essere esposte attraverso le API VASA, consentendo ai flussi di lavoro di provisioning di sfruttare funzionalità avanzate senza che l'amministratore delle macchine virtuali debba comprendere come gestire il sistema di storage.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Provisioning più rapido.* diverse funzionalità di storage possono essere supportate in un singolo datastore e selezionate automaticamente in base alla policy della macchina virtuale.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Evitare errori.* le policy di storage e macchine virtuali vengono sviluppate in anticipo e applicate in base alle necessità senza dover personalizzare lo storage ogni volta che viene eseguito il provisioning di una macchina virtuale. Gli allarmi di compliance vengono generati quando le funzionalità dello storage si scostano dalle policy definite. Come accennato in precedenza, gli SCP rendono il provisioning iniziale prevedibile e ripetibile, mentre basare le policy di storage delle macchine virtuali sugli SCP garantisce un posizionamento preciso.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Gestione granulare delle macchine virtuali nella moderna SAN</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">I sistemi storage SAN che utilizzano Fibre Channel e iSCSI sono stati i primi ad essere supportati da VMware per ESX, ma non hanno la capacità di gestire singoli file e dischi VM dal sistema storage. Al contrario, vengono forniti i LUN e VMFS gestisce i singoli file. Questo rende difficile per il sistema storage gestire direttamente le performance, la clonazione e la protezione dello storage delle singole macchine virtuali. VVol offre una granularità dello storage di cui già godono i clienti che utilizzano lo storage NFS, con le solide funzionalità SAN ad alte performance di ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Ora, con gli strumenti vSphere 8 e ONTAP per VMware vSphere 9.12 e versioni successive, gli stessi controlli granulari utilizzati da vVol per i protocolli basati su SCSI legacy sono ora disponibili nella MODERNA SAN Fibre Channel che utilizza NVMe over Fabrics per ottenere performance ancora maggiori su larga scala. Con vSphere 8.0 update 1, è ora possibile implementare una soluzione NVMe end-to-end completa utilizzando vVol senza alcuna traduzione i/o nello stack di storage dell'hypervisor.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Maggiori funzionalità di offload dello storage</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garanzia di efficienza</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">Mentre VAAI offre una varietà di operazioni che vengono trasferite allo storage, ci sono alcune lacune che vengono affrontate dal provider VASA. SAN VAAI non è in grado di trasferire le snapshot gestite da VMware al sistema storage. NFS VAAI è in grado di trasferire le snapshot gestite da macchine virtuali, ma esistono dei limiti per una macchina virtuale con snapshot native dello storage. Poiché i vVol utilizzano LUN, spazi dei nomi o file singoli per i dischi delle macchine virtuali, ONTAP può clonare in modo rapido ed efficiente i file o le LUN per creare snapshot granulari delle macchine virtuali che non richiedono più file delta. Inoltre, NFS VAAI non supporta operazioni di offload dei cloni per le migrazioni vMotion di storage a caldo (attivate). La macchina virtuale deve essere spenta per consentire l'offload della migrazione quando si utilizza VAAI con datastore NFS tradizionali. Il provider VASA negli strumenti ONTAP consente cloni quasi istantanei ed efficienti in termini di storage per le migrazioni a caldo e a freddo e supporta anche copie quasi istantanee per le migrazioni tra volumi di vVol. Grazie a questi significativi vantaggi in termini di efficienza dello storage, è possibile sfruttare al meglio i carichi di lavoro vVol in base a.<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programma. Allo stesso modo, se i cloni cross-volume con VAAI non soddisfano i tuoi requisiti, sarai in grado di risolvere le sfide per il tuo business grazie ai miglioramenti nell'esperienza di copia con i vVol.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Casi di utilizzo comuni per i vVol</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Oltre a questi vantaggi, vediamo anche questi casi di utilizzo comuni per lo storage vVol:</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Provisioning su richiesta delle VM*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privato o provider di servizi IaaS.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Sfrutta l'automazione e l'orchestrazione tramite la suite aria (in precedenza vRealize), OpenStack, ecc.</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Dischi di prima classe (FCD)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">VMware Tanzu Kubernetes Grid [TKG] volumi persistenti.</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Fornire servizi di Amazon EBS attraverso una gestione indipendente del ciclo di vita VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Provisioning on-demand delle macchine virtuali temporanee*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratori di test/sviluppo</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Ambienti di training</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Vantaggi comuni con vVol</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Se utilizzato a pieno vantaggio, come nei casi di utilizzo precedenti, i vVol forniscono i seguenti miglioramenti specifici:</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">I vVol sono la tecnologia di storage ideale quando si utilizza TKG con vSphere CSI, fornendo classi di storage e capacità discrete gestite dall'amministratore di vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Amazon EBS-like Services può essere fornito attraverso FCD perché un FCD VMDK, come suggerisce il nome, è un cittadino di prima classe in vSphere e ha un ciclo di vita che può essere gestito in modo indipendente separato dalle macchine virtuali a cui potrebbe essere collegato.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protezione di vVol</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">ALTA disponibilità del provider VASA</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">NetApp VASA Provider viene eseguito come parte dell'appliance virtuale insieme al plug-in vCenter, al server REST API (precedentemente noto come Virtual Storage Console [VSC]) e allo Storage Replication Adapter. Se il provider VASA non è disponibile, le VM che utilizzano vVol continueranno a funzionare. Tuttavia, non è possibile creare nuovi datastore vVol e non è possibile creare o vinare vVol da vSphere. Ciò significa che le macchine virtuali che utilizzano vVol non possono essere attivate poiché vCenter non sarà in grado di richiedere la creazione dello swap vVol. Inoltre, le macchine virtuali in esecuzione non possono utilizzare vMotion per la migrazione a un altro host perché i vVol non possono essere associati al nuovo host.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7.1 e versioni successive supportano nuove funzionalità per garantire la disponibilità dei servizi quando necessario. Include nuovi processi di controllo che monitorano il provider VASA e i servizi di database integrati. Se rileva un errore, aggiorna i file di registro e riavvia automaticamente i servizi.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">L'amministratore di vSphere deve configurare un'ulteriore protezione utilizzando le stesse funzionalità di disponibilità utilizzate per proteggere le altre macchine virtuali mission-critical da guasti del software, dell'hardware host e della rete. Non è richiesta alcuna configurazione aggiuntiva sull'appliance virtuale per utilizzare queste funzionalità; è sufficiente configurarle utilizzando gli approcci standard vSphere. Sono stati testati e supportati da NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Strumenti ONTAP per la documentazione di VMware vSphere (configurare l'alta disponibilità per i tool ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability è facilmente configurabile per riavviare una macchina virtuale su un altro host nel cluster host in caso di guasto. VSphere Fault Tolerance offre una maggiore disponibilità creando una macchina virtuale secondaria che viene continuamente replicata e che può assumere il controllo in qualsiasi momento. Ulteriori informazioni su queste funzioni sono disponibili nella<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Oltre alla documentazione VMware vSphere (cercare vSphere Availability sotto ESXi e vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Il provider VASA di ONTAP Tools esegue automaticamente il backup della configurazione vVol in tempo reale sui sistemi ONTAP gestiti in cui le informazioni vVol vengono memorizzate nei metadati dei volumi FlexVol. Nel caso in cui l'appliance ONTAP Tools non fosse disponibile per qualsiasi motivo, è possibile implementarne una nuova e importarne la configurazione in modo semplice e rapido. Fare riferimento a questo articolo della Knowledge base per ulteriori informazioni sulle fasi di ripristino del provider VASA:</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Come eseguire un Disaster Recovery provider VASA - Guida alla risoluzione</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Replica di vVol</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">Molti clienti ONTAP replicano i propri datastore tradizionali su sistemi storage secondari utilizzando NetApp SnapMirror, quindi utilizzano il sistema secondario per ripristinare singole macchine virtuali o un intero sito in caso di disastro. Nella maggior parte dei casi, i clienti utilizzano uno strumento software per la gestione di questo tipo, ad esempio un prodotto software di backup come il plug-in NetApp SnapCenter per VMware vSphere o una soluzione di disaster recovery come Site Recovery Manager di VMware (insieme all'adattatore di replica dello storage negli strumenti ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Questo requisito per uno strumento software è ancora più importante per gestire la replica di vVol. Sebbene alcuni aspetti possano essere gestiti da funzionalità native (ad esempio, le snapshot gestite da VMware di vVol vengono trasferite su ONTAP, che utilizza cloni di file o LUN rapidi ed efficienti), in generale l'orchestrazione è necessaria per gestire la replica e il ripristino. I metadati relativi ai vVol sono protetti da ONTAP e dal provider VASA, ma è necessaria un'ulteriore elaborazione per utilizzarli in un sito secondario.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">I tool ONTAP 9.7.1, insieme alla release 8.3 di VMware Site Recovery Manager (SRM), hanno aggiunto il supporto per il disaster recovery e l'orchestrazione del flusso di lavoro di migrazione sfruttando la tecnologia SnapMirror di NetApp.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">Nella versione iniziale del supporto SRM con i tool ONTAP 9.7.1 era necessario pre-creare FlexVol e abilitare la protezione SnapMirror prima di utilizzarli come volumi di backup per un datastore vVol. A partire dagli strumenti ONTAP 9.10, questo processo non è più necessario. È ora possibile aggiungere la protezione SnapMirror ai volumi di backup esistenti e aggiornare le policy di storage delle macchine virtuali per sfruttare la gestione basata su policy con disaster recovery, orchestrazione e automazione della migrazione integrate con SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Attualmente, VMware SRM è l'unica soluzione di disaster recovery e automazione della migrazione per vVol supportata da NetApp e i tool ONTAP verificheranno l'esistenza di un server SRM 8.3 o successivo registrato con vCenter prima di consentire la replica di vVol, Sebbene sia possibile sfruttare le API REST degli strumenti ONTAP per creare i propri servizi.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Replica di vVol con SRM</block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Supporto MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Sebbene gli strumenti ONTAP non siano in grado di attivare uno switchover MetroCluster, supportano i sistemi NetApp MetroCluster per il backup dei volumi in una configurazione vMSC (vSphere Metro Storage Cluster) uniforme. La commutazione di un sistema MetroCluster viene gestita normalmente.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Anche se NetApp SnapMirror Business Continuity (SM-BC) può essere utilizzato come base per una configurazione vMSC, al momento non è supportato con vVol.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Consulta queste guide per ulteriori informazioni su NetApp MetroCluster:</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_Architettura e progettazione della soluzione IP TR-4689 MetroCluster_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 architettura e progettazione della soluzione NetApp MetroCluster_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 supporto VMware vSphere con NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Panoramica del backup di vVol</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Esistono diversi approcci per la protezione delle macchine virtuali, ad esempio l'utilizzo di agenti di backup in-guest, l'aggiunta di file di dati delle macchine virtuali a un proxy di backup o l'utilizzo di API definite come VMware VADP. I vVol possono essere protetti utilizzando gli stessi meccanismi e molti partner NetApp supportano i backup delle macchine virtuali, inclusi i vVol.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Come accennato in precedenza, le snapshot gestite da VMware vCenter vengono trasferite a cloni di file/LUN ONTAP efficienti in termini di spazio e veloci. Questi possono essere utilizzati per backup manuali e rapidi, ma sono limitati da vCenter a un massimo di 32 snapshot. È possibile utilizzare vCenter per creare snapshot e ripristinarli in base alle necessità.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">A partire dal plug-in SnapCenter per VMware vSphere (SCV) 4.6, se utilizzato insieme ai tool ONTAP 9.10 e versioni successive, aggiunge il supporto per backup e ripristino coerenti in caso di crash delle macchine virtuali basate su vVol, sfruttando le snapshot dei volumi ONTAP FlexVol con il supporto per SnapMirror e la replica SnapVault. Sono supportati fino a 1023 snapshot per volume. SCV può anche memorizzare più snapshot con una maggiore conservazione sui volumi secondari utilizzando SnapMirror con una policy di vault mirror.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">Il supporto di vSphere 8.0 è stato introdotto con SCV 4.7, che utilizzava un'architettura di plug-in locale isolata. Il supporto di vSphere 8.0U1 è stato aggiunto a SCV 4.8, che ha completato la transizione alla nuova architettura di plug-in remoto.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">Backup vVol con plug-in SnapCenter per VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Con NetApp SnapCenter puoi ora creare gruppi di risorse per i vVol basati su tag e/o cartelle per sfruttare automaticamente le snapshot basate su FlexVol di ONTAP per macchine virtuali basate su vVol. Ciò consente di definire servizi di backup e ripristino che proteggeranno automaticamente le macchine virtuali man mano che vengono sottoposte a provisioning dinamico all'interno dell'ambiente.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Il plug-in SnapCenter per VMware vSphere viene implementato come appliance standalone registrata come estensione vCenter, gestita tramite l'interfaccia utente di vCenter o tramite API REST per l'automazione dei servizi di backup e recovery.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architettura SnapCenter</block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Poiché gli altri plug-in di SnapCenter non supportano ancora i vVol al momento di questa scrittura, in questo documento ci concentreremo sul modello di distribuzione standalone.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Poiché SnapCenter utilizza snapshot ONTAP FlexVol, non è previsto alcun overhead su vSphere, né penalità in termini di performance, come si può vedere con le macchine virtuali tradizionali che utilizzano snapshot gestite da vCenter. Inoltre, poiché le funzionalità di SCV sono esposte attraverso le API REST, è semplice creare workflow automatizzati utilizzando tool come VMware aria Automation, Ansible, Terraform e virtualmente qualsiasi altro tool di automazione in grado di utilizzare le API REST standard.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Panoramica delle API REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Per informazioni sulle API REST di SnapCenter, vedere<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">Plug-in SnapCenter per le API REST di VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Per informazioni sulle API REST del plug-in SnapCenter per VMware vSphere, vedere<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Le seguenti Best practice possono aiutarti a ottenere il massimo dalla tua implementazione SnapCenter.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV supporta sia vCenter Server RBAC che ONTAP RBAC e include ruoli vCenter predefiniti che vengono creati automaticamente al momento della registrazione del plug-in. Ulteriori informazioni sui tipi di RBAC supportati<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Utilizzare l'interfaccia utente di vCenter per assegnare l'accesso agli account con privilegi minimi utilizzando i ruoli predefiniti descritti<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Se si utilizza SCV con il server SnapCenter, è necessario assegnare il ruolo _SnapCenterAdmin_.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC si riferisce all'account utente utilizzato per aggiungere e gestire i sistemi di storage utilizzati da SCV. Il role-based access control ONTAP non si applica ai backup basati su vVol. Scopri di più su ONTAP RBAC e SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Replica i set di dati di backup su un secondo sistema utilizzando SnapMirror per repliche complete dei volumi di origine. Come indicato in precedenza, è anche possibile utilizzare policy di vault mirror per la conservazione a lungo termine dei dati di backup indipendentemente dalle impostazioni di conservazione delle snapshot del volume di origine. Entrambi i meccanismi sono supportati con vVol.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Poiché SCV richiede anche strumenti ONTAP per la funzionalità vVol di VMware vSphere, controllare sempre lo strumento matrice di interoperabilità NetApp (IMT) per verificare la compatibilità delle versioni specifiche</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Se si utilizza la replica vVol con VMware SRM, prestare attenzione all'RPO delle policy e alla pianificazione del backup</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Progettare le policy di backup con impostazioni di conservazione che soddisfino gli obiettivi dei punti di ripristino (RPO) definiti dall'organizzazione</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configurare le impostazioni di notifica sui gruppi di risorse per ricevere una notifica dello stato durante l'esecuzione dei backup (vedere la figura 10 di seguito)</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Opzioni di notifica del gruppo di risorse</block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Iniziare a utilizzare SCV utilizzando questi documenti</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">Scopri di più sul plug-in SnapCenter per VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Implementare il plug-in SnapCenter per VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Risoluzione dei problemi</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Sito di supporto NetApp</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">Strumenti ONTAP per VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Oltre a una serie di articoli della Knowledge base per i prodotti di virtualizzazione NetApp, il sito del supporto NetApp offre anche una comoda landing page per<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> prodotto. Questo portale fornisce link ad articoli, download, report tecnici e discussioni sulle soluzioni VMware sulla community NetApp. È disponibile all'indirizzo:</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Sito di supporto NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">La documentazione aggiuntiva sulla soluzione è disponibile qui:</block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Risoluzione dei problemi del prodotto</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">I vari componenti degli strumenti ONTAP, come il plugin vCenter, il provider VASA e l'adattatore di replica dello storage, sono tutti documentati insieme nell'archivio dei documenti NetApp. Tuttavia, ciascuno di essi dispone di una sottosezione separata della Knowledge base e può disporre di procedure specifiche per la risoluzione dei problemi. Queste soluzioni risolvono i problemi più comuni che potrebbero verificarsi con il provider VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problemi dell'interfaccia utente del provider VASA</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">articolo</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Occasionalmente, il client Web vCenter vSphere incontra problemi con i componenti di Serenity, causando la mancata visualizzazione delle voci di menu del provider VASA per ONTAP. Consultare la sezione risoluzione dei problemi di registrazione del provider VASA nella Guida all'implementazione o nella presente Knowledge base<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Il provisioning del datastore di vVol non riesce</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Occasionalmente, i servizi vCenter potrebbero subire un timeout durante la creazione del datastore vVols. Per correggerlo, riavviare il servizio vmware-sps e rimontare il datastore vVols utilizzando i menu vCenter (Storage &gt; New Datastore). Questo argomento viene trattato in vVols datastore provisioning fails with vCenter Server 6.5 nella Administration Guide.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">L'aggiornamento di Unified Appliance non riesce a montare ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">A causa di un bug in vCenter, l'ISO utilizzato per aggiornare Unified Appliance da una release alla successiva potrebbe non essere in grado di eseguire il montaggio. Se è possibile collegare l'ISO all'appliance in vCenter, seguire la procedura descritta in questa Knowledge base<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> per risolvere il problema.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Implementazione dello storage vVol</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migrazione di macchine virtuali da datastore tradizionali a vVol</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Gestione delle VM mediante policy</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Creazione di policy di storage delle macchine virtuali</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">La modifica delle funzionalità delle performance, ad esempio IOPS min e max, richiede un'attenzione particolare alla configurazione specifica.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Gli strumenti ONTAP creano policy QoS individuali non condivise con le versioni attualmente supportate di ONTAP. Pertanto, ogni singolo VMDK riceverà la propria allocazione di IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Riapplicazione dei criteri di storage delle macchine virtuali</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP supporta tutti i principali protocolli di storage utilizzati per la virtualizzazione, come iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) o non-volatile Memory Express over Fibre Channel (NVMe/FC) per ambienti SAN, oltre a NFS (v3 e v4.1) e SMB o S3 per connessioni guest. I clienti sono liberi di scegliere ciò che funziona meglio per il proprio ambiente e possono combinare i protocolli in base alle esigenze su un singolo sistema.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Strumenti di virtualizzazione per ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp offre diversi tool software standalone che possono essere utilizzati insieme a ONTAP e vSphere per gestire l'ambiente virtualizzato.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">I seguenti strumenti sono inclusi con la licenza ONTAP senza costi aggiuntivi. Vedere la Figura 1 per un'illustrazione del funzionamento di questi strumenti nell'ambiente vSphere.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">Le estensioni dell'interfaccia utente di vCenter.* le estensioni dell'interfaccia utente di ONTAP Tools semplificano il lavoro dei team operativi e degli amministratori di vCenter, integrando menu facili da utilizzare e sensibili al contesto per la gestione di host e storage, portlet informativi e funzionalità di avviso native direttamente nell'interfaccia utente di vCenter per flussi di lavoro semplificati.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*Provider VASA per ONTAP.* il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). Viene fornito come parte dei tool ONTAP per VMware vSphere come singola appliance virtuale per una maggiore facilità di implementazione. IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol), la gestione dei profili di capacità dello storage e delle performance di VM vVol individuali e gli allarmi per il monitoraggio della capacità e della conformità con i profili.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* SRA viene utilizzato insieme a VMware Site Recovery Manager (SRM) per gestire la replica dei dati tra siti di produzione e disaster recovery e testare le repliche DR senza interruzioni. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figura seguente mostra gli strumenti ONTAP per vSphere.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS per VMware VAAI</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">Il plug-in NetApp NFS per VMware VAAI è un plug-in per gli host ESXi che consente loro di utilizzare le funzionalità VAAI con gli archivi dati NFS su ONTAP. Supporta l'offload delle copie per le operazioni di cloning, lo space reservation per i file di dischi virtuali con thick provisioning e l'offload delle snapshot. L'offload delle operazioni di copia sullo storage non è necessariamente più veloce da completare, ma riduce i requisiti di larghezza di banda della rete e scarica le risorse host come cicli CPU, buffer e code. È possibile utilizzare i tool ONTAP per VMware vSphere per installare il plug-in sugli host ESXi o, se supportato, vSphere Lifecycle Manager (vLCM).</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Essi consentono una selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di mettere in pausa l'i/o prima di scattare una snapshot VMware.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Gestione basata su criteri di archiviazione e vVol</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">Le API VMware vSphere per Storage Awareness (VASA) semplificano la configurazione dei datastore da parte di un amministratore dello storage con funzionalità ben definite e consentono all'amministratore delle macchine virtuali di utilizzarle quando necessario per eseguire il provisioning delle macchine virtuali senza dover interagire tra loro.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Vale la pena di dare un'occhiata a questo approccio per scoprire in che modo può semplificare le operazioni di virtualizzazione dello storage ed evitare un lavoro molto banale.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con l'amministratore dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, l'amministratore dello storage può definire una serie di funzionalità di storage, tra cui performance, tiering, crittografia e replica. Un insieme di funzionalità per un volume o un set di volumi viene definito SCP (Storage Capability Profile).</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">SCP supporta la qualità del servizio minima e/o massima per i vVol di dati di una VM. La QoS minima è supportata solo sui sistemi AFF. Gli strumenti ONTAP per VMware vSphere includono una dashboard che visualizza le performance granulari delle macchine virtuali e la capacità logica per i vVol sui sistemi ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figura seguente mostra i tool ONTAP per il dashboard di VMware vSphere 9.8 vVol.</block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Una volta definito il profilo di capacità dello storage, è possibile utilizzarlo per eseguire il provisioning delle macchine virtuali utilizzando la policy di storage che ne identifica i requisiti. La mappatura tra il criterio di storage delle macchine virtuali e il profilo di capacità dello storage del datastore consente a vCenter di visualizzare un elenco di datastore compatibili per la selezione. Questo approccio è noto come gestione basata su criteri di storage.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">VASA offre la tecnologia per eseguire query sullo storage e restituire un set di funzionalità di storage a vCenter. I vendor provider VASA forniscono la traduzione tra le API e i costrutti del sistema storage e le API VMware comprese da vCenter. Il provider VASA di NetApp per ONTAP viene offerto come parte dei tool ONTAP per macchina virtuale dell'appliance VMware vSphere, mentre il plug-in vCenter fornisce l'interfaccia per il provisioning e la gestione dei datastore vVol, nonché la capacità di definire profili di funzionalità dello storage (SCP).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vVol può essere costituito da più volumi FlexVol su più nodi del cluster. L'approccio più semplice è un singolo datastore, anche quando i volumi hanno funzionalità diverse. SPBM garantisce l'utilizzo di un volume compatibile per la macchina virtuale. Tuttavia, tutti i volumi devono far parte di una singola SVM ONTAP e devono essere accessibili utilizzando un singolo protocollo. È sufficiente una LIF per nodo per ogni protocollo. Evitare di utilizzare più release di ONTAP all'interno di un singolo datastore vVol, poiché le funzionalità dello storage potrebbero variare tra le varie release.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilizza i tool ONTAP per il plug-in VMware vSphere per creare e gestire datastore vVol. Oltre a gestire il datastore e il relativo profilo, crea automaticamente un endpoint del protocollo per accedere ai vVol, se necessario. Se si utilizzano LUN, tenere presente che i LUN PES vengono mappati utilizzando LUN ID 300 e superiori. Verificare che l'impostazione di sistema avanzata dell'host ESXi sia corretta<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Consente un numero di ID LUN superiore a 300 (il valore predefinito è 1,024). Eseguire questa operazione selezionando l'host ESXi in vCenter, quindi la scheda Configura e trova<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Nell'elenco delle Advanced System Settings (Impostazioni di sistema avanzate).</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">Non installare o migrare il provider VASA, il server vCenter (basato su appliance o Windows) o i tool ONTAP per VMware vSphere in sé su un datastore vVols, perché in tal caso sono dipendenti reciprocamente, limitando la possibilità di gestirli in caso di interruzione dell'alimentazione o di altre interruzioni del data center.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Articolo della Knowledge base</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Eseguire regolarmente il backup della VM del provider VASA. Crea almeno snapshot orarie del datastore tradizionale che contiene il provider VASA. Per ulteriori informazioni sulla protezione e il ripristino del provider VASA, consulta questa sezione<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figura seguente mostra i componenti di vVol.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes (vVol) e Storage Policy Based Management (SPBM)</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: Volumi virtuali VMware vSphere con ONTAP</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Utilizza le snapshot per creare copie rapide della tua macchina virtuale o del datastore senza influire sulle performance, quindi inviale a un sistema secondario utilizzando SnapMirror per la data Protection off-site a lungo termine. Questo approccio riduce al minimo lo spazio di storage e la larghezza di banda della rete memorizzando solo le informazioni modificate.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figura seguente mostra un esempio di implementazione di SnapCenter.</block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Per funzionalità avanzate di disaster recovery, è consigliabile utilizzare NetApp SRA per ONTAP con VMware Site Recovery Manager. Oltre al supporto per la replica di datastore in un sito di DR, consente anche test senza interruzioni nell'ambiente di DR mediante il cloning dei datastore replicati. Anche il ripristino da un disastro e la riconprotezione della produzione dopo la risoluzione dell'interruzione sono semplificabili grazie all'automazione integrata in SRA.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Storage unificato</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualizzazione dello storage</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">VMware Storage Distributed Resource Scheduler</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware Storage Distributed Resource Scheduler (SDR) è una funzionalità vSphere che consente di posizionare le macchine virtuali sullo storage in base alla latenza i/o corrente e all'utilizzo dello spazio.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">Quindi, sposta le VM o i VMDK senza interruzioni tra gli archivi dati in un cluster di datastore (noto anche come pod), selezionando il migliore datastore in cui posizionare le VM o i VMDK nel cluster di datastore. Un cluster di datastore è un insieme di datastore simili che vengono aggregati in una singola unità di consumo dal punto di vista dell'amministratore di vSphere.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Altre Best practice ONTAP per I DSP includono:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tutti gli archivi dati del cluster devono utilizzare lo stesso tipo di storage (ad esempio SAS, SATA o SSD), tutti gli archivi dati VMFS o NFS e avere le stesse impostazioni di replica e protezione.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Considerare l'utilizzo DEGLI SDR in modalità predefinita (manuale). Questo approccio consente di rivedere i suggerimenti e decidere se applicarli o meno. Tenere presente i seguenti effetti delle migrazioni VMDK:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Quando GLI SDR spostano i VMDK tra datastore, qualsiasi risparmio di spazio derivante dalla clonazione o deduplica ONTAP viene perso. È possibile rieseguire la deduplica per recuperare questi risparmi.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Dopo che LE SDR spostano i VMDK, NetApp consiglia di ricreare gli snapshot nel datastore di origine, poiché lo spazio è altrimenti bloccato dalla VM che è stata spostata.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Lo spostamento di VMDK tra datastore sullo stesso aggregato ha pochi benefici e GLI SDR non hanno visibilità su altri carichi di lavoro che potrebbero condividere l'aggregato.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere con ONTAP</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4597: VMware vSphere for ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche supportate che funzionano in ogni ambiente, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Tool di matrice di interoperabilità NetApp</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guida alla compatibilità VMware</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Questo documento si concentra sulle funzionalità delle versioni recenti di ONTAP (9.x) in esecuzione su vSphere 7,0 o versioni successive. Vedere<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> e.<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> per dettagli relativi a release specifiche.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Perché scegliere ONTAP per vSphere?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">Sono molti i motivi per cui decine di migliaia di clienti hanno scelto ONTAP come soluzione storage per vSphere, ad esempio un sistema storage unificato che supporta protocolli SAN e NAS, solide funzionalità di protezione dei dati che utilizzano snapshot efficienti in termini di spazio e molti strumenti per aiutarti a gestire i dati delle applicazioni. L'utilizzo di un sistema storage separato dall'hypervisor consente di trasferire molte funzioni e massimizzare l'investimento nei sistemi host vSphere. Questo approccio non solo garantisce che le risorse host siano incentrate sui carichi di lavoro delle applicazioni, ma evita anche effetti casuali sulle performance delle applicazioni derivanti dalle operazioni di storage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'utilizzo di ONTAP insieme a vSphere è un'ottima combinazione che consente di ridurre le spese relative all'hardware host e al software VMware. Puoi anche proteggere i tuoi dati a un costo inferiore con performance elevate e costanti. Poiché i carichi di lavoro virtualizzati sono mobili, è possibile esplorare diversi approcci utilizzando Storage vMotion per spostare le macchine virtuali tra datastore VMFS, NFS o vVol, tutti sullo stesso sistema storage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Ecco i fattori chiave che i clienti apprezzano oggi:</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Volumi virtuali e gestione basata su policy dello storage.* NetApp è stato un partner di progettazione iniziale di VMware nello sviluppo di vVol (vSphere Virtual Volumes), che offre input architetturali e supporto precoce di vVol e API di VMware vSphere per Storage Awareness (VASA). Questo approccio non solo ha portato a VMFS una gestione granulare dello storage delle macchine virtuali, ma ha anche supportato l'automazione del provisioning dello storage tramite la gestione basata su criteri dello storage. Questo approccio consente agli architetti dello storage di progettare pool di storage con diverse funzionalità che possono essere facilmente utilizzate dagli amministratori delle macchine virtuali. ONTAP è leader nel settore dello storage in termini di scalabilità vVol, supportando centinaia di migliaia di vVol in un singolo cluster, mentre i vendor di array Enterprise e flash array più piccoli supportano solo diverse migliaia di vVol per array. NetApp sta inoltre guidando l'evoluzione della gestione granulare delle macchine virtuali con funzionalità imminenti a supporto di vVol 3.0.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Efficienza dello storage.* sebbene NetApp sia stata la prima a fornire la deduplica per carichi di lavoro di produzione, questa innovazione non è stata la prima o l'ultima in quest'area. Il prodotto è partito dalle snapshot, un meccanismo di protezione dei dati efficiente in termini di spazio, senza effetti sulle performance, e dalla tecnologia FlexClone per creare istantaneamente copie in lettura/scrittura delle macchine virtuali per l'utilizzo in produzione e nel backup. NetApp ha continuato a offrire funzionalità inline, tra cui deduplica, compressione e deduplica a blocchi zero, per eliminare il maggior numero di storage dai costosi SSD. Più di recente, ONTAP ha aggiunto la possibilità di inserire file e operazioni i/o più piccole in un blocco di dischi utilizzando la compattazione. La combinazione di queste funzionalità ha consentito ai clienti di ottenere risparmi fino a 5:1 per VSI e fino a 30:1 per VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud ibrido.* sia che venga utilizzato per il cloud privato on-premise, l'infrastruttura di cloud pubblico o un cloud ibrido che combina il meglio di entrambi, le soluzioni ONTAP ti aiutano a costruire il tuo data fabric per ottimizzare e ottimizzare la gestione dei dati. Inizia con i sistemi all-flash dalle performance elevate, quindi accoppiali con sistemi di storage su disco o cloud per la protezione dei dati e il cloud computing. Scegli tra cloud Azure, AWS, IBM o Google per ottimizzare i costi ed evitare il lock-in. Sfrutta il supporto avanzato per le tecnologie OpenStack e container in base alle esigenze. NetApp offre inoltre backup basato sul cloud (SnapMirror Cloud, Cloud Backup Service e Cloud Sync) e tool di archiviazione e tiering dello storage (FabricPool) per ONTAP per ridurre le spese operative e sfruttare l'ampia portata del cloud.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">*E altro ancora.* sfrutta le performance estreme degli array NetApp AFF Serie A per accelerare l'infrastruttura virtualizzata e gestire i costi. Operazioni senza interruzioni, dalla manutenzione agli aggiornamenti fino alla sostituzione completa del sistema storage, utilizzando cluster ONTAP scale-out. Proteggi i dati inattivi con le funzionalità di crittografia NetApp senza costi aggiuntivi. Assicurati che le performance soddisfino i livelli di servizio di business grazie a funzionalità di qualità dei servizi. Fanno tutti parte dell'ampia gamma di funzionalità offerte da ONTAP, il software di Enterprise data management leader del settore.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Host ESXi consigliato e altre impostazioni ONTAP</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Impostazione host*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valore consigliato da NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Riavvio richiesto*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configurazione avanzata ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratedLocking</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Mantieni predefinito (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Unmap</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">API VMware vSphere: Integrazione degli array (VAAI)</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Impostazioni NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipelHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 o versione successiva, impostato su 32.
Tutte le altre configurazioni NFS, impostate su 30</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sì</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipelHeapMax</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6,0 o versioni successive, impostare su 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 o versione successiva, impostato su 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Impostare su 10 per tutte le configurazioni NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Impostato su 12 per tutte le configurazioni NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Impostare su 5 per tutte le configurazioni NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7,0 o versioni successive, impostare su 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Impostazioni FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Policy di selezione del percorso</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Impostare su RR (round robin) quando si utilizzano percorsi FC con ALUA. Impostare su FISSO per tutte le altre configurazioni.
L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati.
Il valore FISSO è per le configurazioni precedenti non ALUA e aiuta a prevenire i/o proxy In altre parole, consente di evitare che l'i/o venga collegato all'altro nodo di una coppia ad alta disponibilità (ha) in un ambiente con Data ONTAP in 7-Mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Impostare su 32 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Impostare su 8 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Timeout HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilizzare il valore predefinito.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Timeout HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Impostazioni iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Impostare su RR (round robin) per tutti i percorsi iSCSI.
L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Impostare su 32 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">Tastiera VMware 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 - l'opzione di configurazione avanzata di NFS MaxQueueDepth potrebbe non funzionare come previsto quando si utilizzano VMware vSphere ESXi 7.0.1 e VMware vSphere ESXi 7.0.2. Fare riferimento a. <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Gli strumenti ONTAP specificano anche alcune impostazioni predefinite durante la creazione di ONTAP FlexVol Volumes e LUN:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Strumento ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Impostazione predefinita*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Riserva di Snapshot (-percento-spazio-snapshot)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Riserva frazionaria (-riserva frazionaria)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Access time update (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falso</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Readahead minimo (-min-readahead)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Istantanee pianificate</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficienza dello storage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Attivato</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garanzia di volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Nessuno (con thin provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Dimensionamento automatico del volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Prenotazione di spazio LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Disattivato</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocazione dello spazio del LUN</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Impostazioni multipath per performance superiori</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Sebbene non sia attualmente configurato dagli strumenti ONTAP disponibili, NetApp suggerisce le seguenti opzioni di configurazione:</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Documentazione aggiuntiva</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Utilizzo di VMware vSphere 7.x con ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Utilizzo di VMware vSphere 8.x con ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Per NVMe-of, ulteriori dettagli sono disponibili nella pagina NVMe-of host Configuration per ESXi 7.x con ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Per NVMe-of, ulteriori dettagli sono disponibili nella pagina NVMe-of host Configuration per ESXi 8.x con ONTAP</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Clonazione di VM e datastore</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">In vSphere, è possibile clonare una macchina virtuale, un disco virtuale, un vVol o un datastore. Dopo essere stato clonato, l'oggetto può essere ulteriormente personalizzato, spesso attraverso un processo automatizzato. VSphere supporta entrambi i cloni di copia completa e i cloni collegati, in cui tiene traccia delle modifiche separatamente dall'oggetto originale.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">I cloni collegati sono ideali per risparmiare spazio, ma aumentano la quantità di i/o che vSphere gestisce per la macchina virtuale, influenzando le performance di quella macchina virtuale e forse dell'host in generale. Ecco perché i clienti di NetApp spesso utilizzano cloni basati su sistemi storage per ottenere il meglio di entrambi i mondi: Un utilizzo efficiente dello storage e maggiori performance.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La seguente figura illustra la clonazione ONTAP.</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">VVol che utilizzano le API di NetApp vSphere per il provider di consapevolezza dello storage (VASA).  I cloni ONTAP sono utilizzati per supportare le snapshot vVol gestite da vCenter, che sono efficienti in termini di spazio con effetto i/o minimo per crearle ed eliminarle.  Le VM possono anche essere clonate utilizzando vCenter e vengono anche trasferite in ONTAP, sia all'interno di un singolo datastore/volume che tra datastore/volumi.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonazione e migrazione di vSphere con API vSphere – integrazione array (VAAI). Le operazioni di cloning delle macchine virtuali possono essere trasferite su ONTAP in ambienti SAN e NAS (NetApp fornisce un plug-in ESXi per abilitare VAAI per NFS).  VSphere scarica solo le operazioni su macchine virtuali fredde (spente) in un datastore NAS, mentre le operazioni su macchine virtuali hot (cloning e storage vMotion) vengono anche scaricate per LA SAN. ONTAP utilizza l'approccio più efficiente in base all'origine, alla destinazione e alle licenze dei prodotti installate. Questa funzionalità viene utilizzata anche da VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilizzato con VMware Site Recovery Manager). In questo caso, i cloni vengono utilizzati per testare il ripristino della replica DR senza interruzioni.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup e recovery con strumenti NetApp come SnapCenter. I cloni delle macchine virtuali vengono utilizzati per verificare le operazioni di backup e per montare un backup delle macchine virtuali in modo che i singoli file possano essere copiati.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">La clonazione offload di ONTAP può essere invocata da VMware, NetApp e da strumenti di terze parti. I cloni che vengono scaricati su ONTAP presentano diversi vantaggi. Nella maggior parte dei casi, sono efficienti in termini di spazio e richiedono storage solo per le modifiche all'oggetto; non vi sono effetti aggiuntivi sulle performance per la lettura e la scrittura e in alcuni casi le performance sono migliorate grazie alla condivisione dei blocchi nelle cache ad alta velocità. Inoltre, consentono di trasferire cicli CPU e i/o di rete dal server ESXi. L'offload delle copie all'interno di un datastore tradizionale utilizzando un volume FlexVol può essere rapido ed efficiente con FlexClone concesso in licenza, ma le copie tra volumi FlexVol potrebbero essere più lente. Se si mantengono i modelli di macchine virtuali come origine dei cloni, è consigliabile posizionarli all'interno del volume datastore (utilizzare cartelle o librerie di contenuti per organizzarli) per cloni veloci ed efficienti in termini di spazio.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">È inoltre possibile clonare un volume o un LUN direttamente in ONTAP per clonare un datastore. Con gli archivi di dati NFS, la tecnologia FlexClone può clonare un intero volume e il clone può essere esportato da ONTAP e montato da ESXi come altro archivio di dati. Per gli archivi di dati VMFS, ONTAP può clonare un LUN all'interno di un volume o di un intero volume, inclusi uno o più LUN. Un LUN contenente un VMFS deve essere mappato a un gruppo di iniziatori ESXi (igroup) e quindi rassegnato da ESXi per essere montato e utilizzato come datastore regolare. Per alcuni casi di utilizzo temporaneo, è possibile montare un VMFS clonato senza disdire. Dopo aver clonato un datastore, è possibile registrare, riconfigurare e personalizzare le macchine virtuali all'interno dell'IT come se fossero macchine virtuali clonate singolarmente.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">In alcuni casi, è possibile utilizzare funzionalità aggiuntive con licenza per migliorare la clonazione, ad esempio SnapRestore per il backup o FlexClone. Queste licenze sono spesso incluse nei bundle di licenze senza costi aggiuntivi. È necessaria una licenza FlexClone per le operazioni di cloning di vVol e per supportare le snapshot gestite di un vVol (offload dall'hypervisor a ONTAP). Una licenza FlexClone può anche migliorare alcuni cloni basati su VAAI se utilizzati all'interno di un datastore/volume (crea copie istantanee ed efficienti in termini di spazio invece di copie a blocchi).  Viene inoltre utilizzato dall'SRA per il test del ripristino di una replica DR e da SnapCenter per le operazioni di clonazione e per sfogliare le copie di backup per ripristinare singoli file.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Configurazione di rete</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Ecco alcuni aspetti da considerare:</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">I frame jumbo possono essere utilizzati se lo si desidera e supportati dalla rete, in particolare quando si utilizza iSCSI. Se vengono utilizzati, assicurarsi che siano configurati in modo identico su tutti i dispositivi di rete, VLAN e così via nel percorso tra lo storage e l'host ESXi. In caso contrario, potrebbero verificarsi problemi di connessione o di prestazioni. La MTU deve essere impostata in modo identico anche sullo switch virtuale ESXi, sulla porta VMkernel e anche sulle porte fisiche o sui gruppi di interfacce di ciascun nodo ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Quando gli array di storage ESXi e ONTAP sono collegati a reti di storage Ethernet, NetApp consiglia di configurare le porte Ethernet a cui questi sistemi si connettono come porte edge RSTP (Rapid Spanning Tree Protocol) o utilizzando la funzione PortFast di Cisco. NetApp consiglia di abilitare la funzione di trunk PortFast Spanning-Tree in ambienti che utilizzano la funzionalità Cisco PortFast e che dispongono di un trunking VLAN 802.1Q abilitato per il server ESXi o gli array di storage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp consiglia le seguenti Best practice per l'aggregazione dei collegamenti:</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Disattivare LACP per le porte dello switch connesse a ESXi, a meno che non si utilizzi dvSwitch 5.1 o versioni successive con LACP configurato.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilizzare LACP per creare aggregati di link per sistemi storage ONTAP con gruppi di interfacce multimodali dinamiche con hash IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilizzare un criterio di raggruppamento hash IP su ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">La seguente tabella fornisce un riepilogo degli elementi di configurazione di rete e indica la posizione in cui vengono applicate le impostazioni.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Elemento</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Switch</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Indirizzo IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">No**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Aggregazione dei collegamenti</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Switch virtuale</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">No*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Gruppi di porte VMkernel e VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Controllo di flusso</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (per frame jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Switch virtuale e porta VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Sì (impostato su max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Sì (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Gruppi di failover</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Sì (creare)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Sì (selezionare)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Le LIF SVM si connettono a porte, gruppi di interfacce o interfacce VLAN con VLAN, MTU e altre impostazioni. Tuttavia, le impostazioni non vengono gestite a livello di SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Questi dispositivi dispongono di indirizzi IP propri per la gestione, ma non vengono utilizzati nel contesto dello storage di rete ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">In vSphere, esistono tre modi per utilizzare le LUN dello storage a blocchi:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Con datastore VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Con RDM (raw device mapping)</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere include il supporto integrato per più percorsi verso i dispositivi storage, definito NMP (Native Multipathing). NMP è in grado di rilevare il tipo di storage per i sistemi storage supportati e di configurare automaticamente lo stack NMP per supportare le funzionalità del sistema storage in uso.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM è attivato per impostazione predefinita. A meno che non si utilizzino portset, non è necessaria alcuna configurazione aggiuntiva.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Per i LUN creati prima di Data ONTAP 8.3, applicare manualmente SLM eseguendo<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando per rimuovere i nodi di reporting del LUN e limitare l'accesso del LUN al nodo proprietario del LUN e al partner ha.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">I protocolli a blocchi (iSCSI, FC e FCoE) accedono alle LUN utilizzando ID LUN e numeri di serie, insieme a nomi univoci. FC e FCoE utilizzano nomi in tutto il mondo (WWNN e WWPN), mentre iSCSI utilizza nomi iSCSI qualificati (IQN). Il percorso delle LUN all'interno dello storage è privo di significato per i protocolli a blocchi e non viene presentato in alcun punto del protocollo. Pertanto, un volume che contiene solo LUN non deve essere montato internamente e non è necessario un percorso di giunzione per i volumi che contengono LUN utilizzati negli archivi dati. Il sottosistema NVMe in ONTAP funziona in modo simile.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Altre Best practice da prendere in considerazione:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Assicurarsi che venga creata un'interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP per garantire la massima disponibilità e mobilità. La Best practice PER LE SAN ONTAP consiste nell'utilizzare due porte fisiche e LIF per nodo, una per ciascun fabric. ALUA viene utilizzato per analizzare i percorsi e identificare i percorsi attivi ottimizzati (diretti) rispetto ai percorsi attivi non ottimizzati. ALUA viene utilizzato per FC, FCoE e iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Per le reti iSCSI, utilizzare più interfacce di rete VMkernel su diverse subnet di rete con raggruppamento NIC quando sono presenti più switch virtuali. È inoltre possibile utilizzare più NIC fisiche collegate a più switch fisici per fornire ha e un throughput maggiore. La figura seguente mostra un esempio di connettività multipath. In ONTAP, configurare un gruppo di interfacce single-mode per il failover con due o più collegamenti connessi a due o più switch oppure utilizzare LACP o un'altra tecnologia di aggregazione dei collegamenti con gruppi di interfacce multimodali per fornire ha e i vantaggi dell'aggregazione dei collegamenti.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Se il protocollo CHAP (Challenge-Handshake Authentication Protocol) viene utilizzato in ESXi per l'autenticazione di destinazione, deve essere configurato anche in ONTAP utilizzando la CLI <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) O con System Manager (modificare Initiator Security in Storage &gt; SVM &gt; SVM Settings &gt; Protocols &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilizza i tool ONTAP per VMware vSphere per creare e gestire LUN e igroups. Il plug-in determina automaticamente le WWPN dei server e crea gli igroups appropriati. Inoltre, configura i LUN in base alle Best practice e li associa agli igroups corretti.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">modalità di compatibilità fisica e virtuale</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilizzare con cautela gli RDM poiché possono essere più difficili da gestire e utilizzano anche percorsi limitati come descritto in precedenza. I LUN ONTAP supportano entrambi<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guida alla configurazione degli host NVMe/FC di ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Per ulteriori informazioni sull'utilizzo di NVMe/FC con vSphere 7.0, consulta questo articolo<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> e.<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figura seguente mostra la connettività multipath da un host vSphere a un LUN ONTAP.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Quando si utilizza ONTAP NFS con vSphere, si consiglia di seguire le seguenti Best practice:</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Poiché non esiste alcuna conversione automatica del datastore tra NFSv3 e NFSv4.1, creare un nuovo datastore NFSv4.1 e utilizzare Storage vMotion per migrare le macchine virtuali nel nuovo datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Tool NetApp Interoperability Matrix</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Regola di accesso RO: SIS</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonimo</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">I volumi del datastore NFS vengono svincoli dal volume root di SVM; pertanto, ESXi deve anche avere accesso al volume root per navigare e montare i volumi del datastore. La policy di esportazione per il volume root e per qualsiasi altro volume in cui la giunzione del volume del datastore è nidificata deve includere una regola o regole per i server ESXi che concedono loro l'accesso in sola lettura. Ecco un esempio di policy per il volume root, utilizzando anche il plug-in VAAI:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Access Protocol: nfs (che include sia nfs3 che nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW Access Rule: Never (miglior sicurezza per il volume root)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutente: SYS (richiesto anche per il volume root con VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilizza i tool ONTAP per VMware vSphere (la Best practice più importante):</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Quando si creano datastore per cluster VMware con il plug-in, selezionare il cluster anziché un singolo server ESX. Questa opzione attiva il montaggio automatico del datastore su tutti gli host del cluster.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Quando non si utilizzano gli strumenti ONTAP per VMware vSphere, utilizzare una singola policy di esportazione per tutti i server o per ciascun cluster di server in cui è necessario un controllo aggiuntivo degli accessi.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Sebbene ONTAP offra una struttura flessibile dello spazio dei nomi dei volumi per organizzare i volumi in un albero utilizzando le giunzioni, questo approccio non ha alcun valore per vSphere. Crea una directory per ogni VM nella directory principale dell'archivio dati, indipendentemente dalla gerarchia dello spazio dei nomi dello storage. Pertanto, la Best practice consiste nel montare semplicemente il percorso di giunzione per i volumi per vSphere nel volume root della SVM, che è il modo in cui i tool ONTAP per VMware vSphere prevedono il provisioning dei datastore. La mancanza di percorsi di giunzione nidificati significa anche che nessun volume dipende da un volume diverso dal volume root e che la sua eliminazione o la sua eliminazione, anche intenzionalmente, non influisce sul percorso verso altri volumi.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Una dimensione del blocco di 4K è adatta per le partizioni NTFS negli archivi dati NFS. La figura seguente mostra la connettività da un host vSphere a un datastore NFS ONTAP.</block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">La seguente tabella elenca le versioni di NFS e le funzionalità supportate.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funzionalità di vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4,1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion e Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Alta disponibilità</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolleranza agli errori</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profili host</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS dello storage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Controllo i/o dello storage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumi virtuali</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accelerazione hardware (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Autenticazione Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Sì (ottimizzato con vSphere 6.5 e versioni successive per supportare AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Supporto multipathing</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">Qualità del servizio (QoS)</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Il limite massimo di throughput QoS su un oggetto può essere impostato in Mbps e/o IOPS. Se vengono utilizzati entrambi, il primo limite raggiunto viene applicato da ONTAP. Un carico di lavoro può contenere più oggetti e una policy QoS può essere applicata a uno o più carichi di lavoro. Quando una policy viene applicata a più carichi di lavoro, i carichi di lavoro condividono il limite totale della policy. Gli oggetti nidificati non sono supportati (ad esempio, i file all'interno di un volume non possono avere una propria policy). I valori minimi di QoS possono essere impostati solo in IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">I seguenti strumenti sono attualmente disponibili per la gestione delle policy di qualità del servizio ONTAP e per applicarle agli oggetti:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">Gestore di sistema di ONTAP</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit di strumenti NetApp PowerShell per ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Strumenti ONTAP per il provider VMware vSphere VASA</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Per assegnare un criterio QoS a un VMDK su NFS, attenersi alle seguenti linee guida:</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">Non applicare policy ad altri file di macchine virtuali, ad esempio file di swap virtuali <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Quando si utilizza il client Web vSphere per trovare i percorsi di file (datastore &gt; file), tenere presente che combina le informazioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> e.<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> e mostra semplicemente un file con il nome di<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> ma le dimensioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Aggiungi<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> nel nome del file per ottenere il percorso corretto.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Per assegnare una policy di QoS a un LUN, inclusi VMFS e RDM, è possibile ottenere la SVM di ONTAP (visualizzata come Vserver), il percorso del LUN e il numero di serie dal menu dei sistemi storage nella home page degli strumenti ONTAP per VMware vSphere. Seleziona il sistema storage (SVM), quindi gli oggetti correlati &gt; SAN.  Utilizzare questo approccio quando si specifica la qualità del servizio utilizzando uno degli strumenti ONTAP.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP e SIOC VMware</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Proprietà</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Se attivo</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La policy è sempre attiva</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Attivo quando esiste un conflitto (latenza dell'archivio dati oltre la soglia)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Tipo di unità</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mbps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, condivisioni</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">VCenter o ambito applicativo</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Più ambienti vCenter, altri hypervisor e applicazioni</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Singolo server vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Impostare QoS su VM?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK solo su NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK su NFS o VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Impostare QoS su LUN (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Impostare la qualità del servizio su LUN (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Impostare QoS sul volume (datastore NFS)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Impostare QoS su SVM (tenant)?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">Approccio basato su policy?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Sì; può essere condiviso da tutti i carichi di lavoro della policy o applicato in toto a ciascun carico di lavoro della policy.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Sì, con vSphere 6.5 e versioni successive.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licenza richiesta</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Incluso con ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware Storage Distributed Resource Scheduler (SDR) è una funzionalità vSphere che consente di posizionare le macchine virtuali sullo storage in base alla latenza i/o corrente e all'utilizzo dello spazio. Quindi, sposta le VM o i VMDK senza interruzioni tra gli archivi dati in un cluster di datastore (noto anche come pod), selezionando il migliore datastore in cui posizionare le VM o i VMDK nel cluster di datastore. Un cluster di datastore è un insieme di datastore simili che vengono aggregati in una singola unità di consumo dal punto di vista dell'amministratore di vSphere.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">Le API VMware vSphere per Storage Awareness (VASA) semplificano la configurazione dei datastore da parte di un amministratore dello storage con funzionalità ben definite e consentono all'amministratore delle macchine virtuali di utilizzarle quando necessario per eseguire il provisioning delle macchine virtuali senza dover interagire tra loro. Vale la pena di dare un'occhiata a questo approccio per scoprire in che modo può semplificare le operazioni di virtualizzazione dello storage ed evitare un lavoro molto banale.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migrazione e backup del cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Un altro punto di forza di ONTAP è l'ampio supporto per il cloud ibrido, che unisce i sistemi nel tuo cloud privato on-premise con funzionalità di cloud pubblico. Ecco alcune soluzioni cloud NetApp che possono essere utilizzate insieme a vSphere:</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Memorizzazione di più snapshot delle macchine virtuali</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool offre tiering rapido e semplice per i dati ONTAP. È possibile migrare i blocchi cold in un archivio di oggetti nei cloud pubblici o in un archivio di oggetti StorageGRID privato e vengono richiamati automaticamente quando si accede nuovamente ai dati ONTAP. Oppure utilizzare il Tier di oggetti come terzo livello di protezione per i dati già gestiti da SnapVault. Questo approccio può consentirti di farlo<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> Sui sistemi storage ONTAP primari e/o secondari.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilizza lo storage software-defined di NetApp per estendere il tuo cloud privato attraverso Internet a sedi e uffici remoti, dove puoi utilizzare ONTAP Select per supportare i servizi di file e blocchi e le stesse funzionalità di gestione dei dati vSphere presenti nel tuo data center aziendale.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Quando si progettano le applicazioni basate su macchine virtuali, considerare la futura mobilità del cloud. Ad esempio, invece di mettere insieme file di applicazioni e dati, utilizza un'esportazione LUN o NFS separata per i dati. Ciò consente di migrare la macchina virtuale e i dati separatamente ai servizi cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Crittografia per i dati vSphere</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Oggi, la necessità di proteggere i dati inattivi è in aumento grazie alla crittografia. Sebbene l'attenzione iniziale fosse concentrata sulle informazioni finanziarie e sanitarie, c'è sempre più interesse a proteggere tutte le informazioni, che siano archiviate in file, database o altri tipi di dati.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Esistono diversi approcci per la protezione dei dati delle applicazioni virtualizzate in esecuzione su VMware vSphere. Un approccio consiste nel proteggere i dati con il software all'interno della macchina virtuale a livello di sistema operativo guest. Gli hypervisor più recenti, come vSphere 6.5, ora supportano la crittografia a livello di VM come alternativa. Tuttavia, la crittografia del software NetApp è semplice e offre i seguenti vantaggi:</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Nessun effetto sulla CPU del server virtuale.* alcuni ambienti di server virtuali richiedono ogni ciclo di CPU disponibile per le proprie applicazioni, tuttavia i test hanno dimostrato che sono necessarie fino a 5 risorse di CPU con crittografia a livello di hypervisor. Anche se il software di crittografia supporta il set di istruzioni AES-NI di Intel per l'offload del carico di lavoro di crittografia (come fa la crittografia del software NetApp), questo approccio potrebbe non essere fattibile a causa del requisito di nuove CPU che non sono compatibili con i server meno recenti.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Onboard Key Manager incluso.* la crittografia software NetApp include un gestore delle chiavi integrato senza costi aggiuntivi, il che rende semplice iniziare senza server di gestione delle chiavi ad alta disponibilità complessi da acquistare e utilizzare.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Nessun effetto sull'efficienza dello storage.* le tecniche di efficienza dello storage, come deduplica e compressione, sono ampiamente utilizzate oggi e sono fondamentali per utilizzare i supporti su disco flash in modo conveniente. Tuttavia, i dati crittografati non possono in genere essere deduplicati o compressi. La crittografia dello storage e dell'hardware NetApp opera a un livello inferiore e consente l'utilizzo completo delle funzionalità di efficienza dello storage NetApp leader del settore, a differenza di altri approcci.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Crittografia granulare semplice del datastore.* con NetApp Volume Encryption, ogni volume ottiene la propria chiave AES a 256 bit. Se è necessario modificarlo, è possibile farlo con un singolo comando. Questo approccio è ideale se hai più tenant o hai bisogno di dimostrare una crittografia indipendente per diversi reparti o applicazioni. Questa crittografia viene gestita a livello di datastore, il che è molto più semplice della gestione di singole macchine virtuali.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">Iniziare a utilizzare la crittografia del software è semplice. Una volta installata la licenza, è sufficiente configurare il gestore delle chiavi integrato specificando una passphrase e quindi creare un nuovo volume o spostare un volume lato storage per abilitare la crittografia. NetApp sta lavorando per aggiungere un supporto più integrato per le funzionalità di crittografia nelle versioni future dei suoi strumenti VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager offre visibilità sulle macchine virtuali dell'infrastruttura virtuale e consente il monitoraggio e la risoluzione dei problemi relativi a storage e performance nell'ambiente virtuale.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Una tipica implementazione di un'infrastruttura virtuale su ONTAP include diversi componenti distribuiti tra livelli di calcolo, rete e storage. Eventuali ritardi nelle performance in un'applicazione VM potrebbero verificarsi a causa di una combinazione di latenze affrontate dai vari componenti nei rispettivi layer.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La seguente schermata mostra la vista macchine virtuali Active IQ Unified Manager.</block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager presenta il sottosistema sottostante di un ambiente virtuale in una vista topologica per determinare se si è verificato un problema di latenza nel nodo di calcolo, nella rete o nello storage. La vista evidenzia anche l'oggetto specifico che causa il ritardo delle performance per l'adozione di misure correttive e la risoluzione del problema sottostante.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La seguente schermata mostra la topologia espansa di AIQUM.</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datastore e protocolli</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4,1</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Funzionalità</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formato</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS o RDM (raw device mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS o RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N/A.</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Numero massimo di datastore o LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN per host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN per server</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 namespeces per server</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 supporti
Default NFS (NFS predefinito). MaxVolumes è 8. Utilizza i tool ONTAP per VMware vSphere per aumentare fino a 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Dimensione massima datastore</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB di volume FlexVol o superiore con volume FlexGroup</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Dimensione massima del file del datastore</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62TB con ONTAP 9.12.1P2 e versioni successive</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondità ottimale della coda per LUN o file system</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Negoziazione automatica</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">La seguente tabella elenca le funzionalità supportate relative allo storage VMware.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware ha</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDR (Storage Distributed Resource Scheduler)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) o clustering di failover all'interno di una macchina virtuale</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non supportato</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolleranza agli errori</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Macchine virtuali con thin provisioning (dischi virtuali)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Sì
Si tratta dell'impostazione predefinita per tutte le macchine virtuali su NFS quando non si utilizza VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Multipathing nativo di VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Sì, utilizzando il nuovo plug-in ad alte prestazioni (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">La tabella seguente elenca le funzionalità di gestione dello storage ONTAP supportate.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Deduplica dei dati</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Risparmi nell'array</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Risparmi nel datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Thin provisioning</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore o RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Ridimensiona datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Crescere solo</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Crescita, crescita automatica e riduzione</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-in SnapCenter per applicazioni Windows e Linux (in guest)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Monitoraggio e configurazione dell'host con gli strumenti ONTAP per VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisioning con gli strumenti ONTAP per VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">La tabella seguente elenca le funzionalità di backup supportate.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">Istantanee di ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM supportato da backup replicati</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accesso all'immagine VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Software di backup abilitato per VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Software di backup abilitato VADP, vSphere Client e il browser datastore di vSphere Web Client</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accesso a livello di file VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Software di backup abilitato VADP, solo Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Software di backup abilitato VADP e applicazioni di terze parti</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularità NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore o macchina virtuale</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configurazione per il clustering di failover di Windows Server</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Selezione di un protocollo di storage</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">I seguenti fattori potrebbero essere utili per valutare una scelta di protocollo:</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Ambiente attuale del cliente.* sebbene i team IT siano generalmente esperti nella gestione dell'infrastruttura IP Ethernet, non tutti sono esperti nella gestione di un fabric SAN FC. Tuttavia, l'utilizzo di una rete IP generica non progettata per il traffico di storage potrebbe non funzionare bene. Prendi in considerazione l'infrastruttura di rete in uso, gli eventuali miglioramenti pianificati e le competenze e la disponibilità del personale per gestirli.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Facilità di configurazione.* oltre alla configurazione iniziale del fabric FC (switch e cablaggio aggiuntivi, zoning e verifica dell'interoperabilità di HBA e firmware), i protocolli a blocchi richiedono anche la creazione e la mappatura di LUN e il rilevamento e la formattazione da parte del sistema operativo guest. Una volta creati ed esportati, i volumi NFS vengono montati dall'host ESXi e pronti all'uso. NFS non dispone di specifiche qualifiche hardware o firmware da gestire.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Facilità di gestione.* con i protocolli SAN, se è necessario più spazio, sono necessari diversi passaggi, tra cui la crescita di un LUN, la ricerca di nuove dimensioni e la crescita del file system). Sebbene sia possibile aumentare un LUN, non è possibile ridurre le dimensioni di un LUN e il ripristino dello spazio inutilizzato può richiedere ulteriore impegno. NFS consente un facile dimensionamento in alto o in basso e questo ridimensionamento può essere automatizzato dal sistema storage. LA SAN offre la bonifica dello spazio attraverso i comandi TRIM/UNMAP del sistema operativo guest, consentendo di restituire spazio dai file cancellati all'array. Questo tipo di recupero dello spazio è più difficile con gli archivi dati NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Trasparenza dello spazio di storage.* l'utilizzo dello storage è in genere più semplice da visualizzare negli ambienti NFS perché il thin provisioning restituisce immediatamente risparmi. Allo stesso modo, i risparmi di deduplica e clonazione sono immediatamente disponibili per altre macchine virtuali nello stesso datastore o per altri volumi di sistemi storage. La densità delle macchine virtuali è in genere maggiore anche in un datastore NFS, che può migliorare i risparmi della deduplica e ridurre i costi di gestione grazie a un numero inferiore di datastore da gestire.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Layout del datastore</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">L'implementazione di vSphere con datastore NFS di ONTAP offre un'implementazione facile da gestire e dalle performance elevate che offre rapporti VM-datastore che non possono essere ottenuti con protocolli di storage basati su blocchi. Questa architettura può comportare un aumento di dieci volte della densità degli archivi dati con una conseguente riduzione del numero di archivi dati. Anche se un datastore più grande può trarre beneficio dall'efficienza dello storage e offrire vantaggi operativi, è consigliabile utilizzare almeno quattro datastore (volumi FlexVol) per memorizzare le macchine virtuali su un singolo controller ONTAP per ottenere le massime prestazioni dalle risorse hardware. Questo approccio consente inoltre di stabilire datastore con policy di recovery diverse. Alcuni possono essere sottoposti a backup o replicati più frequentemente rispetto ad altri in base alle esigenze aziendali. I volumi FlexGroup non richiedono più datastore per le performance, in quanto sono scalabili in base alla progettazione.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Una buona dimensione per un datastore di volumi FlexVol è di circa 4TB - 8TB. Queste dimensioni rappresentano un buon punto di equilibrio per le performance, la facilità di gestione e la protezione dei dati. Inizia in piccolo (ad esempio, 4 TB) e fai crescere il datastore in base alle necessità (fino a un massimo di 100 TB). I datastore più piccoli sono più veloci da ripristinare dal backup o dopo un disastro e possono essere spostati rapidamente nel cluster. Prendere in considerazione l'utilizzo della funzione di dimensionamento automatico di ONTAP per aumentare e ridurre automaticamente il volume in base alle modifiche dello spazio utilizzato. Per impostazione predefinita, i tool ONTAP per il provisioning guidato degli archivi dati VMware vSphere utilizzano la dimensione automatica per i nuovi archivi dati. È possibile personalizzare ulteriormente le soglie di aumento e riduzione e le dimensioni massime e minime con System Manager o la riga di comando.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Evitare l'uso di utilità di deframmentazione all'interno del sistema operativo guest, poiché ciò non offre vantaggi in termini di prestazioni e influisce sull'efficienza dello storage e sull'utilizzo dello spazio snapshot. È inoltre consigliabile disattivare l'indicizzazione della ricerca nel sistema operativo guest per i desktop virtuali.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ha guidato il settore con innovative funzionalità di efficienza dello storage, che ti consentono di sfruttare al massimo lo spazio su disco utilizzabile. I sistemi AFF aumentano ulteriormente questa efficienza con la deduplica e la compressione inline predefinite. I dati vengono deduplicati in tutti i volumi in un aggregato, quindi non è più necessario raggruppare sistemi operativi simili e applicazioni simili in un singolo datastore per massimizzare i risparmi.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Database Oracle su ONTAP</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">I dischi di prima classe (o dischi virtuali migliorati) consentono dischi gestiti da vCenter indipendenti da una macchina virtuale con vSphere 6.5 e versioni successive. Anche se gestiti principalmente da API, possono essere utili con vVol, soprattutto se gestiti da OpenStack o Kubernetes tools. Sono supportati da ONTAP e dai tool ONTAP per VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migrazione di datastore e macchine virtuali</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Quando si esegue la migrazione delle macchine virtuali da un datastore esistente su un altro sistema storage a ONTAP, è necessario tenere presente alcune procedure:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilizzare Storage vMotion per spostare la maggior parte delle macchine virtuali su ONTAP. Questo approccio non solo non è disgregativo per l'esecuzione di macchine virtuali, ma consente anche funzionalità di efficienza dello storage ONTAP come la deduplica inline e la compressione per elaborare i dati durante la migrazione. Prendere in considerazione l'utilizzo delle funzionalità di vCenter per selezionare più macchine virtuali dall'elenco di inventario e quindi pianificare la migrazione (utilizzare il tasto Ctrl mentre si fa clic su azioni) in un momento appropriato.</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Sebbene sia possibile pianificare con attenzione una migrazione verso datastore di destinazione appropriati, spesso è più semplice eseguire la migrazione in blocco e poi organizzarla in un secondo momento. Potresti voler utilizzare questo approccio per guidare la migrazione verso datastore diversi, se hai esigenze specifiche di data Protection, come ad esempio diverse pianificazioni Snapshot.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La maggior parte delle macchine virtuali e del relativo storage può essere migrata durante l'esecuzione (a caldo), ma la migrazione dello storage collegato (non nel datastore) come gli ISO, i LUN o i volumi NFS da un altro sistema storage potrebbe richiedere la migrazione a freddo.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">Il plug-in consente inoltre di utilizzare altri strumenti ONTAP in ambienti vSphere. Il prodotto consente di installare il plug-in NFS per VMware VAAI, che consente l'offload delle copie in ONTAP per le operazioni di cloning delle macchine virtuali, lo space reservation per i file di dischi virtuali con thick provisioning e l'offload delle snapshot ONTAP.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Rete generale</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Utilizzare switch che supportano l'aggregazione di collegamenti di porte su due chassis switch separati utilizzando un approccio a gruppi di aggregazione di collegamenti multi-chassis, ad esempio Virtual PortChannel (VPC) di Cisco.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Gestione della rete</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Utilizza LACP per creare aggregati di link per sistemi di storage ONTAP con gruppi di interfacce dinamiche multimode con hash porta o IP. Fare riferimento a.<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> per ulteriori indicazioni.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Utilizzare un criterio di raggruppamento hash IP su ESXi quando si utilizza l'aggregazione di collegamenti statici (ad esempio, EtherChannel) e vSwitch standard o l'aggregazione di collegamenti basata su LACP con gli switch distribuiti vSphere. Se non si utilizza l'aggregazione dei collegamenti, utilizzare invece "Route based on the origining virtual port ID" (percorso basato sull'ID della porta virtuale di origine).</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">Volumi FlexGroup</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Considerare il seguente scenario:</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Hai creato un nuovo FlexGroup con 8 componenti</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">Il timeout della cache per il nuovo FlexGroup è impostato su 160 minuti</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">In questo scenario, i primi 8 cloni da completare saranno copie complete, non cloni di file locali. Qualsiasi clonazione aggiuntiva di tale macchina virtuale prima della scadenza del timeout di 160 secondi utilizzerà il motore di clonazione file all'interno di ciascun componente in modo round-robin per creare copie quasi immediate distribuite uniformemente tra i volumi costituenti.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">In ambienti in cui non è possibile sfruttare al meglio la cache FlexGroup, ma è comunque necessario un rapido cloning cross-volume, prendere in considerazione l'utilizzo di vVol. Il cloning tra volumi con vVol è molto più rapido rispetto ai datastore tradizionali, senza fare affidamento su una cache.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI: Come funziona il caching con i volumi FlexGroup?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Per ulteriori informazioni sull'utilizzo di FlexGroup con VAAI, fare riferimento a questo articolo della KB:<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Con la transizione dall'appliance virtuale legacy, gli strumenti ONTAP offrono una vasta gamma di nuove funzionalità, limiti più elevati e nuovo supporto vVol.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nuove funzionalità con gli strumenti SRM e ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Ultime versioni di vSphere e Site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Con il rilascio di SRM 8.7 e versioni successive e con le versioni 9.12 e successive dei tool ONTAP, è ora possibile proteggere le macchine virtuali in esecuzione su VMware vSphere 8 update 1.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp ha condiviso una partnership profonda con VMware da quasi vent'anni e si impegna a fornire il supporto per le ultime release il più presto possibile. Consulta sempre il tool per la matrice di interoperabilità NetApp (IMT) per scoprire le più recenti combinazioni di software qualificate.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">L'NetApp IMT è disponibile all'indirizzo <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">Supporto di vVol (e perché è importante Storage Policy Based Management (SPBM), anche con SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">A partire dalla release 8,3, SRM supporta ora la gestione basata su criteri di storage (SPBM, Storage Policy Based Management) della replica sfruttando vVol e la replica basata su array per datastore che utilizzano iSCSI, FCP e NFS v3. A tale scopo, il server SRM è stato aggiornato per includere un nuovo servizio provider vVol SRM, che comunica al servizio SMS del server vCenter per le attività correlate a VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Uno dei vantaggi di questa architettura è che un SRA non è più necessario, poiché tutto viene gestito tramite VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM è un potente strumento della toolbox vSphere che consente servizi di storage semplificati, prevedibili e coerenti per l'utilizzo da parte dei framework di automazione in ambienti cloud privati e ibridi. Fondamentalmente, SPBM consente di definire le classi di servizio che soddisfano le esigenze della vostra base clienti diversificata. SRM consente ora di esporre le funzionalità di replica ai clienti per i carichi di lavoro critici che richiedono un'efficace orchestrazione e automazione del disaster recovery standard di settore.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Esempio di architettura vVol con FCP o iSCSI:</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Supporto per server SRM basati su appliance</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">I server SRM basati su sistema operativo Photon sono ora supportati, oltre alle piattaforme legacy basate su Windows.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">È ora possibile installare gli adattatori SRA indipendentemente dal tipo di server SRM preferito.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Supporto per IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 è ora supportato con le seguenti limitazioni:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 o versione successiva</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non supportato con SRM 8.2 (8.1, 8.3 e 8. 4 sono supportati)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Tool di matrice di interoperabilità</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Controllare<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> per le ultime versioni qualificate.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Performance migliorate</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">Le performance operative sono un requisito fondamentale per l'esecuzione delle attività SRM. Per soddisfare i requisiti degli RTO e degli RPO moderni, l'SRA con gli strumenti ONTAP ha aggiunto tre nuovi miglioramenti.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Supporto per operazioni simultanee di risproteggere.* introdotto per la prima volta in SRA 9.7.1, questa funzionalità consente di eseguire la risproteggere su due o più piani di ripristino contemporaneamente, riducendo così il tempo necessario per la risproteggere i datastore dopo un failover o una migrazione e rimanendo all'interno dei parametri RTO e RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*Strumenti ONTAP 9.8 aggiunge una nuova modalità ottimizzata solo NAS.* quando si utilizzano account con ambito SVM e connessioni a cluster ONTAP con solo datastore basati su NFS, è possibile abilitare la modalità ottimizzata solo NAS per le massime performance negli ambienti supportati.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*ONTAP Tools 9.12 ha aggiunto il supporto per la funzionalità di risincronizzazione rapida di ONTAP SnapMirror.* ciò consente una rapida risincronizzazione dei mirror con l'obiettivo di dover ricalcolare i risparmi in termini di efficienza dello storage dopo il processo. Questa funzione non viene utilizzata per impostazione predefinita, ma può essere attivata in ambienti su larga scala in cui la risincronizzazione tradizionale richiede troppo tempo o sta per scadere.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Maggiore scalabilità</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Gli strumenti ONTAP SRA possono ora supportare fino a 500 gruppi di protezione (PG) se utilizzati con SRM 8.3 e versioni successive.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Una nuova funzionalità attesa da tempo e molto attesa è SnapMirror Synchronous (SM-S) con ONTAP 9.5 e versioni successive, che offre una soluzione di replica dei dati zero RPO granulare per le applicazioni mission-critical. SM-S richiede gli strumenti ONTAP 9.8 o versioni successive.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Supporto API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configurazione del server SRA può ora essere gestita dalle API REST. È stata aggiunta un'interfaccia utente Swagger per facilitare la creazione dei flussi di lavoro di automazione, disponibile sull'appliance ONTAP Tools all'indirizzo<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4900: VMware Site Recovery Manager con ONTAP_</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Le Best practice integrano altri documenti come guide e strumenti di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. In alcuni casi, le Best practice consigliate potrebbero non essere adatte al tuo ambiente; tuttavia, sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Questo documento è incentrato sulle funzionalità delle recenti release di ONTAP 9, se utilizzato insieme ai tool ONTAP per VMware vSphere 9.12 (che include l'adattatore per la replica dello storage NetApp [SRA] e il provider VASA [VP]), nonché VMware Site Recovery Manager 8.7.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Perché utilizzare ONTAP con SRM?</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Utilizzando SnapMirror per la replica basata su array è possibile sfruttare una delle tecnologie ONTAP più comprovate e mature. SnapMirror offre il vantaggio di trasferimenti di dati sicuri ed altamente efficienti, copiando solo i blocchi di file system modificati, non intere macchine virtuali o datastore. Anche questi blocchi sfruttano il risparmio di spazio, come deduplica, compressione e compattazione. I moderni sistemi ONTAP utilizzano ora SnapMirror indipendente dalla versione, consentendo di scegliere i cluster di origine e di destinazione in modo flessibile. SnapMirror è diventato uno dei tool più potenti disponibili per il disaster recovery.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Sia che stiate utilizzando datastore collegati a NFS, iSCSI o Fibre Channel tradizionali (ora con supporto per datastore vVol), SRM offre una solida offerta di prima parte che sfrutta il meglio delle funzionalità ONTAP per il disaster recovery o la pianificazione e l'orchestrazione della migrazione dei data center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">In che modo SRM sfrutta ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM sfrutta le tecnologie avanzate di gestione dei dati dei sistemi ONTAP integrandosi con i tool ONTAP per VMware vSphere, un'appliance virtuale che include tre componenti principali:</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol) e la gestione dei profili di capacità dello storage (incluse le funzionalità di replica di vVol) e delle performance di VM vVol individuali. Fornisce inoltre allarmi per il monitoraggio della capacità e della conformità con i profili. Se utilizzato in combinazione con SRM, il provider VASA per ONTAP consente il supporto delle macchine virtuali basate su vVol senza richiedere l'installazione di un adattatore SRA sul server SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA viene utilizzato insieme a SRM per gestire la replica dei dati delle macchine virtuali tra siti di produzione e disaster recovery per datastore VMFS e NFS tradizionali e per il test senza interruzioni delle repliche DR. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Dopo aver installato e configurato gli adattatori SRA sul server SRM per proteggere gli archivi dati non vVols e/o aver abilitato la replica vVols nelle impostazioni del provider VASA, è possibile iniziare l'attività di configurazione dell'ambiente vSphere per il disaster recovery.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">I provider SRA e VASA offrono un'interfaccia di controllo e comando per il server SRM per gestire i FlexVol ONTAP che contengono le macchine virtuali VMware e la replica SnapMirror che li protegge.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">A partire da SRM 8.3, nel server SRM è stato introdotto un nuovo percorso di controllo SRM vVols Provider, che consente di comunicare con il server vCenter e, attraverso di esso, con il provider VASA senza la necessità di un SRA. Ciò ha consentito al server SRM di sfruttare un controllo molto più approfondito sul cluster ONTAP rispetto a quanto era possibile in precedenza, perché VASA offre un'API completa per un'integrazione strettamente accoppiata.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM può verificare il vostro piano DR senza interruzioni utilizzando la tecnologia proprietaria FlexClone di NetApp per creare cloni quasi istantanei dei datastore protetti nel sito DR. SRM crea un sandbox per eseguire test in modo sicuro in modo che la tua organizzazione e i tuoi clienti siano protetti in caso di disastro reale, offrendo la sicurezza della capacità delle organizzazioni di eseguire un failover durante un disastro.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">In caso di disastro reale o persino di migrazione pianificata, SRM consente di inviare eventuali modifiche dell'ultimo minuto al dataset tramite un aggiornamento finale di SnapMirror (se si sceglie di farlo). Quindi, interrompe il mirror e monta il datastore sugli host DR. A questo punto, le VM possono essere alimentate automaticamente in qualsiasi ordine in base alla strategia prepianificata.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM con ONTAP e altri casi di utilizzo: Cloud ibrido e migrazione</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Storage privato NetApp in Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">L'integrazione dell'implementazione SRM con le funzionalità avanzate di gestione dei dati di ONTAP consente di migliorare notevolmente scalabilità e performance rispetto alle opzioni di storage locale. Ma oltre a questo, offre la flessibilità del cloud ibrido. Il cloud ibrido ti consente di risparmiare denaro tiering dei blocchi di dati inutilizzati dal tuo array dalle performance elevate all'hyperscaler preferito utilizzando FabricPool, che potrebbe essere un store S3 on-premise come NetApp StorageGRID. È inoltre possibile utilizzare SnapMirror per sistemi edge con software-defined ONTAP Select o DR basata su cloud utilizzando Cloud Volumes ONTAP (CVO) o.<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Per Amazon Web Services (AWS), Microsoft Azure e Google Cloud Platform (GCP) per creare uno stack di storage, networking e servizi di calcolo completamente integrato nel cloud.</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Quindi, grazie a FlexClone, è possibile eseguire un failover di test nel data center di un cloud service provider con un impatto dello storage prossimo allo zero. Proteggere la tua organizzazione può ora costare meno che mai.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM può anche essere utilizzato per eseguire migrazioni pianificate sfruttando SnapMirror per trasferire in modo efficiente le macchine virtuali da un data center all'altro o anche all'interno dello stesso data center, sia esso il tuo, o tramite un numero qualsiasi di partner service provider NetApp.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologie di replica</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">In ONTAP 9, i componenti fisici di un cluster sono visibili agli amministratori del cluster, ma non sono direttamente visibili alle applicazioni e agli host che utilizzano il cluster. I componenti fisici forniscono un pool di risorse condivise da cui vengono costruite le risorse del cluster logico. Le applicazioni e gli host accedono ai dati solo tramite SVM che contengono volumi e LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Ogni SVM NetApp viene trattata come array in VMware vCenter Site Recovery Manager. SRM supporta determinati layout di replica array-to-array (o SVM-to-SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Una singola macchina virtuale non è in grado di gestire i dati (VMDK) o RDM) su più array SRM per i seguenti motivi:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM vede solo la SVM, non un singolo controller fisico.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Una SVM può controllare LUN e volumi che si estendono su più nodi in un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Best practice</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Per determinare la supportabilità, tenere presente questa regola: Per proteggere una macchina virtuale utilizzando SRM e NetApp SRA, tutte le parti della macchina virtuale devono esistere su un solo SVM. Questa regola si applica sia al sito protetto che al sito di ripristino.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Layout SnapMirror supportati</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Le seguenti figure mostrano gli scenari di layout delle relazioni SnapMirror supportati da SRM e SRA. Ogni macchina virtuale nei volumi replicati possiede i dati su un solo array SRM (SVM) in ogni sito.</block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Layout di Array Manager supportati</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Quando si utilizza la replica basata su array (ABR) in SRM, i gruppi di protezione vengono isolati in una singola coppia di array, come illustrato nella seguente schermata. In questo scenario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> e.<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sono in coppia con<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> e.<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> presso il sito di recovery. Tuttavia, è possibile selezionare solo una delle due coppie di array quando si crea un gruppo di protezione.</block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Layout non supportati</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Le configurazioni non supportate dispongono di dati (VMDK o RDM) su più SVM di proprietà di una singola macchina virtuale. Negli esempi illustrati nelle seguenti figure,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione con SRM perché<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Dispone di dati su due SVM.</block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Qualsiasi relazione di replica in cui un singolo volume NetApp viene replicato da una SVM di origine a più destinazioni nella stessa SVM o in SVM differenti viene definita fan-out di SnapMirror. Fan-out non supportato con SRM. Nell'esempio illustrato nella figura seguente,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione in SRM perché viene replicata con SnapMirror in due posizioni diverse.</block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">Cascata di SnapMirror</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM non supporta la sovrapposizione delle relazioni SnapMirror, in cui un volume di origine viene replicato in un volume di destinazione e tale volume di destinazione viene replicato anche con SnapMirror in un altro volume di destinazione. Nello scenario illustrato nella figura seguente, SRM non può essere utilizzato per il failover tra siti.</block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror e SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Il software NetApp SnapVault consente il backup basato su disco dei dati aziendali tra i sistemi storage NetApp. SnapVault e SnapMirror possono coesistere nello stesso ambiente; tuttavia, SRM supporta il failover solo delle relazioni SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA supporta<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> tipo di policy.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault è stato ricostruito da zero per ONTAP 8.2. Anche se gli utenti di Data ONTAP 7-Mode precedenti dovrebbero trovare delle analogie, in questa versione di SnapVault sono stati apportati importanti miglioramenti. Un importante progresso è la capacità di preservare l'efficienza dello storage sui dati primari durante i trasferimenti SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Un'importante modifica architetturale è che SnapVault in ONTAP 9 replica a livello di volume anziché a livello di qtree, come nel caso di 7-Mode SnapVault. Questa configurazione indica che l'origine di una relazione SnapVault deve essere un volume e che tale volume deve replicarsi nel proprio volume sul sistema secondario SnapVault.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">In un ambiente in cui viene utilizzato SnapVault, vengono create snapshot specificatamente denominate sul sistema di storage primario. A seconda della configurazione implementata, gli snapshot denominati possono essere creati sul sistema primario da una pianificazione SnapVault o da un'applicazione come NetApp Active IQ Unified Manager. Gli Snapshot con nome creati sul sistema primario vengono quindi replicati nella destinazione SnapMirror, da dove vengono trasferiti in un vault nella destinazione SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">È possibile creare un volume di origine in una configurazione a cascata in cui un volume viene replicato in una destinazione SnapMirror nel sito DR e da qui viene vault in una destinazione SnapVault. È possibile creare un volume di origine anche in una relazione fan-out in cui una destinazione è una destinazione SnapMirror e l'altra destinazione è una destinazione SnapVault. Tuttavia, SRA non riconfigurerà automaticamente la relazione SnapVault per utilizzare il volume di destinazione SnapMirror come origine per il vault quando si verifica il failover SRM o l'inversione della replica.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Per informazioni aggiornate su SnapMirror e SnapVault per ONTAP 9, vedere<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Se SnapVault e SRM vengono utilizzati nello stesso ambiente, NetApp consiglia di utilizzare una configurazione a cascata da SnapMirror a SnapVault in cui i backup di SnapVault vengono normalmente eseguiti dalla destinazione di SnapMirror nel sito di DR. In caso di disastro, questa configurazione rende il sito primario inaccessibile. Mantenendo la destinazione SnapVault nel sito di recovery, è possibile riconfigurare i backup SnapVault dopo il failover in modo che i backup SnapVault possano continuare mentre si opera nel sito di recovery.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">In un ambiente VMware, ogni datastore dispone di un UUID (Universal Unique Identifier) e ogni VM dispone di un MOID (Managed Object ID) univoco. Questi ID non vengono gestiti da SRM durante il failover o il failback. Poiché gli UUID degli archivi di dati e i MOID delle macchine virtuali non vengono mantenuti durante il failover da SRM, tutte le applicazioni che dipendono da questi ID devono essere riconfigurate dopo il failover di SRM. Un'applicazione di esempio è NetApp Active IQ Unified Manager, che coordina la replica SnapVault con l'ambiente vSphere.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figura seguente mostra una configurazione a cascata da SnapMirror a SnapVault. Se la destinazione SnapVault si trova nel sito di DR o in un sito terzo che non è interessato da un'interruzione nel sito primario, l'ambiente può essere riconfigurato per consentire ai backup di continuare dopo il failover.</block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La seguente figura illustra la configurazione dopo l'utilizzo di SRM per eseguire il reverse della replica di SnapMirror nel sito primario. L'ambiente è stato anche riconfigurato in modo che i backup di SnapVault si verifichino da quella che ora è l'origine di SnapMirror. Questa configurazione è una configurazione fan-out di SnapMirror SnapVault.</block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Dopo che SRM esegue il failback e una seconda inversione delle relazioni SnapMirror, i dati di produzione vengono ripristinati nel sito primario. Questi dati sono ora protetti nello stesso modo in cui erano prima del failover al sito di DR, tramite i backup SnapMirror e SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilizzo di Qtree in ambienti Site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">I qtree sono directory speciali che consentono l'applicazione delle quote del file system per NAS. ONTAP 9 consente la creazione di qtree e qtree possono esistere in volumi replicati con SnapMirror. Tuttavia, SnapMirror non consente la replica di singoli qtree o replica a livello di qtree. Tutte le repliche di SnapMirror sono solo a livello di volume. Per questo motivo, NetApp sconsiglia l'utilizzo di qtree con SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Ambienti misti FC e iSCSI</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Con i protocolli SAN supportati (FC, FCoE e iSCSI), ONTAP 9 offre servizi LUN, ovvero la possibilità di creare e mappare LUN agli host collegati. Poiché il cluster è costituito da più controller, esistono più percorsi logici gestiti da i/o multipath verso qualsiasi LUN individuale. L'ALUA (Asymmetric Logical Unit Access) viene utilizzato sugli host in modo che il percorso ottimizzato per un LUN sia selezionato e reso attivo per il trasferimento dei dati. Se il percorso ottimizzato per qualsiasi LUN cambia (ad esempio, perché il volume contenente viene spostato), ONTAP 9 riconosce automaticamente e regola senza interruzioni per questa modifica. Se il percorso ottimizzato non è disponibile, ONTAP può passare senza interruzioni a qualsiasi altro percorso disponibile.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM e NetApp SRA supportano l'utilizzo del protocollo FC in un sito e del protocollo iSCSI nell'altro. Tuttavia, non supporta la combinazione di datastore FC-attached e datastore iSCSI-attached nello stesso host ESXi o in host diversi nello stesso cluster. Questa configurazione non è supportata con SRM perché, durante il failover SRM o il failover di test, SRM include tutti gli iniziatori FC e iSCSI negli host ESXi nella richiesta.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM e SRA supportano protocolli FC e iSCSI misti tra i siti protetti e di ripristino. Tuttavia, ogni sito deve essere configurato con un solo protocollo, FC o iSCSI, non entrambi nello stesso sito. Se esiste un requisito per la configurazione dei protocolli FC e iSCSI nello stesso sito, NetApp consiglia che alcuni host utilizzino iSCSI e altri host utilizzino FC. In questo caso, NetApp consiglia anche di configurare le mappature delle risorse SRM in modo che le macchine virtuali siano configurate per il failover in un gruppo di host o nell'altro.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Risoluzione dei problemi di SRM quando si utilizza la replica vVol</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Il flusso di lavoro all'interno di SRM è significativamente diverso quando si utilizza la replica vVol da quello utilizzato con SRA e datastore tradizionali. Ad esempio, non esiste alcun concetto di gestore di array. In quanto tale,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> e.<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> i comandi non vengono mai visualizzati.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Durante la risoluzione dei problemi, è utile comprendere i nuovi flussi di lavoro, elencati di seguito:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Rileva gli accordi di replica tra due domini di errore.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Rileva la gerarchia di dominio di errore.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Consente di individuare i gruppi di replica presenti nei domini di origine o di destinazione.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Sincronizza i dati tra origine e destinazione.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Consente di rilevare le repliche point-in-time di una destinazione.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Avvia il failover del test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Termina il failover del test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Promuove un gruppo attualmente in fase di test in produzione.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PrepareFailoverReplicationGroup: Prepara per un disaster recovery.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup: Esegue il disaster recovery.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Avvia la replica inversa.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Trova i container (insieme agli host o ai gruppi di replica) che potrebbero soddisfare una richiesta di provisioning con una determinata policy.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata: Rileva i metadati di tutte le risorse dal provider VASA, l'utilizzo delle risorse può essere restituito come risposta alla funzione QueryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'errore più comune riscontrato durante la configurazione della replica di vVol è il mancato rilevamento delle relazioni di SnapMirror. Ciò si verifica perché i volumi e le relazioni di SnapMirror vengono creati al di fuori dell'ambito di applicazione degli strumenti ONTAP. Pertanto, è consigliabile assicurarsi sempre che la relazione di SnapMirror sia completamente inizializzata e che sia stata eseguita una riscoperta negli strumenti ONTAP in entrambi i siti prima di tentare di creare un datastore vVol replicato.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Ulteriori informazioni</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Tool di matrice di interoperabilità (IMT)</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Best practice per l'implementazione</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Layout e segmentazione SVM per SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri. Gli utenti SVM su una SVM non possono accedere o gestire le risorse da un'altra. In questo modo, è possibile sfruttare la tecnologia ONTAP creando SVM separate per diverse business unit che gestiscono i propri flussi di lavoro SRM sullo stesso cluster per una maggiore efficienza dello storage globale.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Valutare la possibilità di gestire ONTAP utilizzando account con ambito SVM e LIF di gestione SVM per non solo migliorare i controlli di sicurezza, ma anche le performance. Le performance sono intrinsecamente maggiori quando si utilizzano connessioni con ambito SVM perché l'SRA non è richiesto per elaborare tutte le risorse di un intero cluster, incluse le risorse fisiche. Al contrario, l'IT deve solo comprendere le risorse logiche astratte dalla specifica SVM.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Quando si utilizzano solo i protocolli NAS (senza accesso SAN), è anche possibile sfruttare la nuova modalità NAS ottimizzata impostando il seguente parametro (si noti che il nome è tale perché SRA e VASA utilizzano gli stessi servizi di back-end nell'appliance):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Accedere al pannello di controllo all'indirizzo<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> E fare clic su interfaccia CLI basata su Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Eseguire il comando<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Eseguire il comando<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Eseguire il comando<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementare gli strumenti e le considerazioni di ONTAP per i vVol</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Se si intende utilizzare SRM con vVol, è necessario gestire lo storage utilizzando credenziali con ambito cluster e una LIF di gestione del cluster. Questo perché il provider VASA deve comprendere l'architettura fisica sottostante per soddisfare le policy richieste per le policy di storage delle macchine virtuali. Ad esempio, se si dispone di una policy che richiede storage all-flash, il provider VASA deve essere in grado di vedere quali sistemi sono tutti flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Un'altra Best practice per l'implementazione consiste nel non memorizzare mai l'appliance ONTAP Tools su un datastore vVols gestito dall'IT. Ciò potrebbe causare l'impossibilità di accendere il provider VASA perché non è possibile creare lo swap vVol per l'appliance perché l'appliance non è in linea.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Best practice per la gestione dei sistemi ONTAP 9</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Come indicato in precedenza, è possibile gestire i cluster ONTAP utilizzando credenziali cluster o SVM con ambito e LIF di gestione. Per performance ottimali, puoi prendere in considerazione l'utilizzo delle credenziali con ambito SVM ogni volta che non utilizzi vVol. Tuttavia, in questo modo, è necessario conoscere alcuni requisiti e perdere alcune funzionalità.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">L'account SVM vsadmin predefinito non dispone del livello di accesso richiesto per eseguire le attività degli strumenti ONTAP. Pertanto, è necessario creare un nuovo account SVM.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Se si utilizza ONTAP 9,8 o versione successiva, NetApp consiglia di creare un account utente RBAC con privilegi minimi utilizzando il menu utenti di ONTAP System Manager insieme al file JSON disponibile nell'appliance ONTAP Tools all'indirizzo<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilizzare la password di amministratore per scaricare il file JSON. Può essere utilizzato per account SVM o con ambito cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Toolchest del sito di supporto NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Se si utilizza ONTAP 9.6 o versioni precedenti, utilizzare lo strumento RBAC User Creator (RUC) disponibile in<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Poiché il plug-in dell'interfaccia utente di vCenter, il provider VASA e il server SRA sono tutti servizi completamente integrati, è necessario aggiungere storage all'adattatore SRM nello stesso modo in cui si aggiunge storage nell'interfaccia utente di vCenter per gli strumenti ONTAP. In caso contrario, il server SRA potrebbe non riconoscere le richieste inviate da SRM tramite l'adattatore SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">Il controllo del percorso NFS non viene eseguito quando si utilizzano credenziali con ambito SVM. Questo perché la posizione fisica è logicamente astratta dalla SVM. Tuttavia, questo non è motivo di preoccupazione, in quanto i sistemi ONTAP moderni non subiscono più alcun calo significativo delle performance quando si utilizzano percorsi indiretti.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il risparmio di spazio aggregato dovuto all'efficienza dello storage potrebbe non essere segnalato.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Se supportati, i mirror di condivisione del carico non possono essere aggiornati.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">La registrazione EMS potrebbe non essere eseguita sui sistemi ONTAP gestiti con credenziali SVM con ambito.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Se possibile, utilizza sempre gli strumenti ONTAP per eseguire il provisioning di datastore e volumi. In questo modo si garantisce che volumi, percorsi di giunzione, LUN, igroups, policy di esportazione, e altre impostazioni sono configurate in modo compatibile.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Best practice operative</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM supporta iSCSI, Fibre Channel e NFS versione 3 con ONTAP 9 quando si utilizza la replica basata su array tramite SRA. SRM non supporta la replica basata su array per NFS versione 4.1 con datastore tradizionali o vVols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Per confermare la connettività, verificare sempre che sia possibile montare e smontare un nuovo datastore di test sul sito DR dal cluster ONTAP di destinazione. Verificare ogni protocollo che si intende utilizzare per la connettività del datastore. Una Best practice consiste nell'utilizzare gli strumenti ONTAP per creare il datastore di test, poiché sta eseguendo tutta l'automazione del datastore come indicato da SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">I protocolli SAN devono essere omogenei per ciascun sito. È possibile combinare NFS e SAN, ma i protocolli SAN non devono essere combinati all'interno di un sito. Ad esempio, è possibile utilizzare FCP nel sito A e iSCSI nel sito B. Non utilizzare sia FCP che iSCSI nel sito A. Il motivo è che l'SRA non crea gruppi igroup misti nel sito di ripristino e l'SRM non filtra l'elenco di iniziatori fornito all'SRA.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">configurazione automatica dell'aumento o della riduzione dei volumi</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">La dimensione automatica del volume deve essere impostata su<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Per volumi contenenti datastore SAN e.<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Per datastore NFS. Scopri di più <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Gestione basata su criteri storage (SPBM, Storage Policy Based Management) e vVol</block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La seguente schermata fornisce un esempio di pianificazioni SnapMirror visualizzate nella procedura guidata Crea policy di storage VM.</block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Il provider VASA di ONTAP supporta il failover su storage diverso. Ad esempio, il sistema può eseguire il failover da ONTAP Select in una posizione periferica a un sistema AFF nel data center principale. Indipendentemente dalla somiglianza dello storage, è necessario configurare sempre le mappature dei criteri di storage e le mappature inverse per le policy di storage delle macchine virtuali abilitate alla replica per garantire che i servizi forniti nel sito di recovery soddisfino le aspettative e i requisiti. La seguente schermata evidenzia un esempio di mappatura dei criteri.</block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Creare volumi replicati per gli archivi dati vVols</block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Si consiglia di prestare attenzione quando si tratta di vVol e SRM. Non mischiare mai macchine virtuali protette e non protette nello stesso datastore vVols. Il motivo è che quando si utilizza SRM per eseguire il failover sul sito DR, solo le macchine virtuali che fanno parte del gruppo di protezione vengono messe in linea nel DR. Pertanto, quando si esegue una nuova protezione (reverse SnapMirror dal DR di nuovo alla produzione), è possibile sovrascrivere le macchine virtuali che non hanno eseguito il failover e che potrebbero contenere dati preziosi.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Informazioni sulle coppie di array</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Quando si configurano le coppie di array in SRM, è necessario aggiungerle sempre in SRM nello stesso modo in cui sono state aggiunte agli strumenti ONTAP, ovvero devono utilizzare lo stesso nome utente, password e LIF di gestione. Questo requisito garantisce che SRA comunichi correttamente con l'array. La seguente schermata illustra come potrebbe essere visualizzato un cluster negli strumenti ONTAP e come potrebbe essere aggiunto a un gestore di array.</block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Informazioni sui gruppi di replica</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">I gruppi di replica contengono raccolte logiche di macchine virtuali che vengono ripristinate insieme. Il provider VASA di ONTAP Tools crea automaticamente i gruppi di replica. Poiché la replica di ONTAP SnapMirror avviene a livello di volume, tutte le macchine virtuali di un volume si trovano nello stesso gruppo di replica.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Un'ultima considerazione per i gruppi di replica è che ciascuno di essi è per sua natura un gruppo di coerenza logica (da non confondere con i gruppi di coerenza SRM). Questo perché tutte le VM nel volume vengono trasferite insieme utilizzando lo stesso snapshot. Pertanto, se si dispone di macchine virtuali che devono essere coerenti tra loro, è consigliabile memorizzarle nello stesso FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">A proposito dei gruppi di protezione</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">I gruppi di protezione definiscono macchine virtuali e datastore in gruppi che vengono ripristinati insieme dal sito protetto. Il sito protetto è il luogo in cui esistono le macchine virtuali configurate in un gruppo di protezione durante le normali operazioni in stato stazionario. È importante notare che anche se SRM potrebbe visualizzare più gestori di array per un gruppo di protezione, un gruppo di protezione non può estendersi a più gestori di array. Per questo motivo, non è necessario estendere i file delle macchine virtuali tra gli archivi dati su macchine virtuali SVM diverse.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Sui piani di recovery</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">I piani di recovery definiscono quali gruppi di protezione vengono ripristinati nello stesso processo. È possibile configurare più gruppi di protezione nello stesso piano di ripristino. Inoltre, per abilitare più opzioni per l'esecuzione dei piani di ripristino, è possibile includere un singolo gruppo di protezione in più piani di ripristino.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">I piani di recovery consentono agli amministratori SRM di definire i flussi di lavoro di recovery assegnando le macchine virtuali a un gruppo di priorità da 1 (massimo) a 5 (minimo), con 3 (medio) come valore predefinito. All'interno di un gruppo di priorità, le VM possono essere configurate per le dipendenze.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp consiglia vivamente di collaborare con i team delle applicazioni per comprendere l'ordine delle operazioni richieste in uno scenario di failover e per costruire di conseguenza i piani di recovery.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Test del failover</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp consiglia inoltre di confermare occasionalmente la funzionalità delle applicazioni in-guest, soprattutto dopo la riconfigurazione dello storage delle macchine virtuali.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Quando viene eseguita un'operazione di test recovery, viene creata una rete bubble di test privata sull'host ESXi per le macchine virtuali. Tuttavia, questa rete non è connessa automaticamente ad alcun adattatore di rete fisico e pertanto non fornisce connettività tra gli host ESXi. Per consentire la comunicazione tra macchine virtuali in esecuzione su host ESXi diversi durante il test di DR, viene creata una rete fisica privata tra gli host ESXi nel sito di DR. Per verificare che la rete di test sia privata, è possibile separare fisicamente la rete a bolle di test oppure utilizzando VLAN o tag VLAN. Questa rete deve essere separata dalla rete di produzione, in quanto non è possibile posizionare le macchine virtuali sulla rete di produzione con indirizzi IP che potrebbero entrare in conflitto con i sistemi di produzione effettivi. Quando viene creato un piano di ripristino in SRM, la rete di test creata può essere selezionata come rete privata a cui connettere le macchine virtuali durante il test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Una volta convalidato il test e non più necessario, eseguire un'operazione di pulizia. L'esecuzione della pulizia riporta le macchine virtuali protette al loro stato iniziale e ripristina il piano di ripristino allo stato Pronta.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considerazioni sul failover</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Oltre all'ordine delle operazioni indicato in questa guida, è necessario considerare anche altri aspetti relativi al failover di un sito.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Un problema che potrebbe essere dovuto affrontare è rappresentato dalle differenze di rete tra i siti. Alcuni ambienti potrebbero essere in grado di utilizzare gli stessi indirizzi IP di rete sia nel sito primario che nel sito di DR. Questa capacità viene definita come una LAN virtuale estesa (VLAN) o una configurazione di rete estesa. Altri ambienti potrebbero richiedere l'utilizzo di indirizzi IP di rete diversi (ad esempio, in VLAN diverse) nel sito primario rispetto al sito di DR.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">Opzioni NSX-T con SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware offre diversi modi per risolvere questo problema. Per prima cosa, le tecnologie di virtualizzazione di rete come VMware NSX-T Data Center astraggono l'intero stack di rete dai livelli 2 fino a 7 dall'ambiente operativo, consentendo soluzioni più portatili. Scopri di più <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">Documentazione di VMware</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Per configurare SRM in modo che applichi impostazioni di rete diverse a più macchine virtuali senza dover modificare le proprietà di ciascuna di esse nel piano di ripristino, VMware fornisce uno strumento chiamato dr-ip-customizer. Per informazioni sull'utilizzo di questa utilità, fare riferimento alla sezione <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Proteggere di nuovo</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Dopo un ripristino, il sito di ripristino diventa il nuovo sito di produzione. Poiché l'operazione di ripristino ha rotto la replica di SnapMirror, il nuovo sito di produzione non è protetto da eventuali disastri futuri. Una Best practice consiste nel proteggere il nuovo sito di produzione in un altro sito immediatamente dopo un ripristino. Se il sito di produzione originale è operativo, l'amministratore di VMware può utilizzare il sito di produzione originale come nuovo sito di ripristino per proteggere il nuovo sito di produzione, invertendo efficacemente la direzione della protezione. La protezione è disponibile solo in caso di guasti non catastrofici. Pertanto, i server vCenter originali, i server ESXi, i server SRM e i database corrispondenti devono essere ripristinabili. Se non sono disponibili, è necessario creare un nuovo gruppo di protezione e un nuovo piano di ripristino.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Un'operazione di failback è fondamentalmente un failover in una direzione diversa rispetto a prima. Come Best practice, prima di tentare di eseguire il failback o, in altre parole, di eseguire il failover sul sito originale, è necessario verificare che il sito originale sia tornato a livelli di funzionalità accettabili. Se il sito originale è ancora compromesso, è necessario ritardare il failback fino a quando il guasto non viene risolto in modo adeguato.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Un'altra Best practice per il failback consiste nell'eseguire sempre un failover di test dopo aver completato la protezione e prima di eseguire il failback finale. In questo modo si verifica che i sistemi installati presso il sito originale possano completare l'operazione.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Protezione del sito originale</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">L'esecuzione di una nuova protezione dopo il failback riporta sostanzialmente l'ambiente nello stato in cui si trovava all'inizio, con la replica di SnapMirror nuovamente in esecuzione dal sito di produzione al sito di ripristino.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modellazione delle minacce.* lo scopo della modellazione delle minacce è quello di individuare i difetti di sicurezza in una funzionalità, un componente o un prodotto nelle prime fasi del ciclo di vita dello sviluppo software. Un modello di minaccia è una rappresentazione strutturata di tutte le informazioni che influiscono sulla sicurezza di un'applicazione. In sostanza, si tratta di una vista dell'applicazione e del suo ambiente attraverso l'obiettivo della sicurezza.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic Application Security Testing (DAST).* questa tecnologia è progettata per rilevare le condizioni vulnerabili delle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Valuta del codice di terze parti.* nell'ambito dello sviluppo di software con software open-source (OSS), è necessario risolvere le vulnerabilità di sicurezza che potrebbero essere associate a qualsiasi OSS incorporato nel prodotto. Si tratta di un'operazione continua, in quanto una nuova versione di OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Scansione delle vulnerabilità.* lo scopo della scansione delle vulnerabilità è quello di rilevare vulnerabilità di sicurezza comuni e note nei prodotti NetApp prima che vengano rilasciate ai clienti.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità di sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software simile a intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Funzionalità di sicurezza del prodotto</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Login banner.* SSH è disattivato per impostazione predefinita e consente l'accesso una sola volta, se abilitato dalla console della macchina virtuale. Il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*ATTENZIONE:* l'accesso non autorizzato a questo sistema è vietato e sarà perseguito dalla legge. Accedendo a questo sistema, l'utente accetta che le proprie azioni possano essere monitorate in caso di sospetto di utilizzo non autorizzato.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Dopo che l'utente ha completato l'accesso tramite il canale SSH, viene visualizzato il seguente testo:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*RBAC (role-based access control).* due tipi di controlli RBAC sono associati ai tool ONTAP:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilegi vCenter Server nativi</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">questo link</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilegi specifici del plug-in vCenter. Per ulteriori informazioni, vedere<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando la versione 1.2 di TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Esposizione minima delle porte.* solo le porte necessarie sono aperte sul firewall.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">La seguente tabella descrive i dettagli della porta aperta.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">Porta TCP v4/v6 n.</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direzione</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Funzione</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">in entrata</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connessioni HTTPS per API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connessioni HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connessioni HTTPS
Utilizzato per connessioni SOAP su https
Questa porta deve essere aperta per consentire a un client di connettersi al server API degli strumenti ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (Disattivato per impostazione predefinita)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connessioni HTTPS - VP e SRA - connessioni interne solo da loopback</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connessioni HTTPS - VP e SRA
Utilizzato per connessioni SOAP su https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Pacchetti di trap SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">solo interno</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Porta del database Derby, solo tra questo computer e se stesso, connessioni esterne non accettate -- solo connessioni interne</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirezionale</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilizzato per le connessioni ai cluster ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">articolo della knowledge base</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* i tool ONTAP per VMware vSphere supportano i certificati firmati CA. Vedi questo<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Registrazione audit.* i pacchetti di supporto possono essere scaricati e sono estremamente dettagliati. ONTAP Tools registra tutte le attività di login e logout degli utenti in un file di log separato. Le chiamate API VASA vengono registrate in un registro di controllo VASA dedicato (cxf.log locale).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Criteri per le password.* vengono seguite le seguenti policy per le password:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Le password non vengono registrate in alcun file di log.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Le password non vengono comunicate in testo normale.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Le password vengono configurate durante il processo di installazione.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">La cronologia delle password è un parametro configurabile.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">La durata minima della password è impostata su 24 ore.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">Il completamento automatico dei campi della password è disattivato.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Gli strumenti ONTAP crittografano tutte le informazioni sulle credenziali memorizzate utilizzando l'hashing SHA256.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">Plug-in di SnapCenter per VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Il plug-in NetApp SnapCenter per il software engineering VMware vSphere utilizza le seguenti attività di sviluppo sicuro:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Dynamic Application Security testing (DAST).* tecnologie progettate per rilevare condizioni vulnerabili sulle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Valuta del codice di terze parti.* come parte dello sviluppo di software e dell'utilizzo di software open-source (OSS), è importante risolvere le vulnerabilità di sicurezza che potrebbero essere associate a OSS che è stato incorporato nel prodotto. Si tratta di un impegno continuo, in quanto la versione del componente OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità della sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software come intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Il plug-in NetApp SnapCenter per VMware vSphere include le seguenti funzionalità di sicurezza in ciascuna release:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accesso limitato alla shell.* SSH è disattivato per impostazione predefinita e gli accessi una tantum sono consentiti solo se sono abilitati dalla console della macchina virtuale.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avviso di accesso nel banner di accesso.* il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Una volta completato l'accesso tramite il canale SSH, viene visualizzato il seguente output:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilegi vCenter Server nativi.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">RBAC (Role-Based Access Control)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilegi specifici del plug-in VMware vCenter. Per ulteriori informazioni, vedere<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">La seguente tabella fornisce i dettagli della porta aperta.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numero della porta TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connessioni HTTPS per GUI OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (disattivato per impostazione predefinita)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (solo connessioni interne; connessioni esterne disattivate per impostazione predefinita)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (servizi di protezione dei dati)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Come creare e/o importare un certificato SSL nel plug-in SnapCenter per VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* il plug-in SnapCenter per VMware vSphere supporta la funzione dei certificati firmati dalla CA. Vedere<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Password policy.* sono in vigore i seguenti criteri relativi alle password:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Tutte le informazioni sulle credenziali vengono memorizzate utilizzando l'hashing SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Immagine del sistema operativo di base.* il prodotto viene fornito con il sistema operativo di base Debian per OVA con accesso limitato e accesso alla shell disattivato. In questo modo si riduce l'impatto degli attacchi. Ogni sistema operativo SnapCenter release base viene aggiornato con le ultime patch di sicurezza disponibili per la massima copertura di sicurezza.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp sviluppa funzionalità software e patch di sicurezza per quanto riguarda il plug-in SnapCenter per l'appliance VMware vSphere e le rilascia ai clienti come piattaforma software integrata. Poiché queste appliance includono dipendenze specifiche del sistema operativo secondario Linux e il nostro software proprietario, NetApp consiglia di non apportare modifiche al sistema operativo secondario, in quanto questo potrebbe influire sull'appliance NetApp. Ciò potrebbe influire sulla capacità di NetApp di supportare l'appliance. NetApp consiglia di testare e implementare la versione più recente del codice per le appliance, perché vengono rilasciate per correggere eventuali problemi relativi alla sicurezza.</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL su ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">Scheduler i/O.</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Il kernel Linux permette un controllo di basso livello sul modo in cui l'i/o blocca i dispositivi è programmato.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Le impostazioni predefinite su varie distribuzioni di Linux variano notevolmente. MySQL consiglia di utilizzare<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> oppure un<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Scheduler i/o con i/o asincrono nativo (AIO) su Linux. In generale, i clienti NetApp e i test interni mostrano risultati migliori con NoOps.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">Il motore di storage InnoDB di MySQL utilizza il sottosistema i/o asincrono (AIO nativo) su Linux per eseguire richieste di lettura e scrittura per le pagine dei file di dati. Questo comportamento è controllato da<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> opzione di configurazione, attivata per impostazione predefinita. Con un sistema AIO nativo, il tipo di pianificatore i/o influisce maggiormente sulle prestazioni di i/O. Esegui benchmark per determinare quale scheduler i/o offrirà i risultati migliori per il tuo carico di lavoro e l'ambiente.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Per istruzioni sulla configurazione dello scheduler i/o, consultare la documentazione relativa a Linux e MySQL.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Configurazione dello storage</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">innodb_log_file_size</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">La scelta della dimensione corretta per il file di log InnoDB è importante per le operazioni di scrittura e per avere un tempo di ripristino decente dopo un arresto anomalo del server.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Poiché molte transazioni sono registrate nel file, la dimensione del file di registro è importante per le operazioni di scrittura. Quando i record vengono modificati, la modifica non viene immediatamente riscritta nello spazio di tabella. La modifica viene invece registrata alla fine del file di registro e la pagina viene contrassegnata come sporca. InnoDB utilizza il proprio registro per convertire l'i/o casuale in i/o sequenziale</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Quando il log è pieno, la pagina sporca viene scritta nello spazio di tabella in sequenza per liberare spazio nel file di log. Ad esempio, si supponga che un server si blocchi nel corso di una transazione e che le operazioni di scrittura vengano registrate solo nel file di registro. Prima che il server possa tornare attivo, deve passare attraverso una fase di recupero in cui vengono riprodotte le modifiche registrate nel file di registro. Maggiore è il numero di voci presenti nel file di registro, maggiore sarà il tempo necessario al server per il ripristino.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">In questo esempio, la dimensione del file di registro influisce sia sul tempo di ripristino che sulle prestazioni di scrittura. Quando si sceglie il numero giusto per la dimensione del file di registro, bilanciare il tempo di ripristino rispetto alle prestazioni di scrittura. In genere, qualsiasi valore compreso tra 128M e 512M è un buon valore.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">Database MySQL su ONTAP</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL e le sue varianti, tra cui MariaDB e Percona MySQL, è il database più diffuso al mondo.</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_flush_method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">Il parametro innodb_Flush_Method specifica come InnoDB apre e svuota i file di log e di dati.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Ottimizzazioni</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">Nell'ottimizzazione InnoDB, l'impostazione di questo parametro modifica le prestazioni del database, se applicabile.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Le seguenti opzioni consentono di svuotare i file tramite InnoDB:</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema per cancellare sia i file di dati che i file di registro. Questa opzione è l'impostazione predefinita.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> possibilità di aprire e svuotare i file di log e fsync() per svuotare i file di dati. InnoDB non utilizza<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Direttamente, perché ci sono stati problemi con esso su molte varietà di UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> (oppure<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Su Solaris) per aprire i file di dati e gli usi<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> per cancellare sia i file di dati che i file di registro. Questa opzione è disponibile su alcune versioni di GNU/Linux, FreeBSD e Solaris.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Durante lo spurgo dell'i/o, tuttavia, salta<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema successiva. Questa opzione non è adatta per alcuni tipi di file system (ad esempio, XFS). Se non si è certi che il file system richieda un<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema, ad esempio per conservare tutti i metadati dei file, utilizzare<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> invece.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Osservazione</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">Nei test di laboratorio di NetApp, il<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> L'opzione predefinita è stata utilizzata su NFS e SAN ed è stata un'improvvisazione per le prestazioni eccezionale rispetto a<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Mentre si utilizza il metodo di lavaggio come<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Con ONTAP, abbiamo osservato che il client scrive molte scritture a byte singolo al margine del blocco 4096 in modo seriale. Queste operazioni di scrittura hanno aumentato la latenza sulla rete e degradato le performance.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">open_file_limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">Il<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> parametro determina il numero di file che il sistema operativo consente a mysqld di aprire.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">Il valore di questo parametro in fase di esecuzione è il valore reale consentito dal sistema e potrebbe essere diverso dal valore specificato all'avvio del server. Il valore è 0 sui sistemi in cui MySQL non può modificare il numero di file aperti. L'efficace<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> il valore si basa sul valore specificato all'avvio del sistema (se presente) e sui valori di<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> e.<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> utilizzando queste formule:</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> x 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> x 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Limite del sistema operativo se positivo</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Se il limite del sistema operativo è infinito:<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> il valore viene specificato all'avvio; 5.000 se nessuno</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">Il server tenta di ottenere il numero di descrittori di file utilizzando il massimo di questi quattro valori. Se non è possibile ottenere molti descrittori, il server tenta di ottenere il numero di descrittori consentito dal sistema.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_scan_depth</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">Il<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> Parametro influenza gli algoritmi e le euristiche dell'operazione di scaricamento per il pool di buffer InnoDB.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Questo parametro è principalmente di interesse per gli esperti di performance che ottimizzano i carichi di lavoro i/o-intensive. Per ogni istanza del pool di buffer, questo parametro specifica fino a che punto nell'elenco di pagine LRU (Last Recently Used) il thread di pulitura della pagina deve continuare la scansione, cercando le pagine sporche da eliminare. Questa operazione in background viene eseguita una volta al secondo.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">È possibile regolare il valore verso l'alto o verso il basso per ridurre al minimo il numero di pagine libere. Non impostare un valore molto superiore al necessario, poiché le scansioni possono avere un costo significativo in termini di prestazioni. Inoltre, è consigliabile regolare questo parametro quando si modifica il numero di istanze del pool di buffer, perché<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> definisce la quantità di lavoro eseguito dal filo del pulitore di pagina ogni secondo.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Un'impostazione più piccola di quella predefinita è adatta per la maggior parte dei carichi di lavoro. Considerare l'aumento del valore solo se si dispone di capacità i/o di riserva con un workload tipico. Per contro, se un carico di lavoro con un numero elevato di operazioni di scrittura satura la capacità i/o, diminuirne il valore, soprattutto se si dispone di un pool di buffer di grandi dimensioni.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_buffer_pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">Il pool di buffer InnoDB è la parte più importante di qualsiasi attività di ottimizzazione.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB si affida in gran parte al pool di buffer per la memorizzazione nella cache degli indici e il reming dei dati, all'indice hash adattivo, al buffer insert e a molte altre strutture di dati utilizzate internamente. Il pool di buffer memorizza inoltre le modifiche ai dati in modo che le operazioni di scrittura non debbano essere eseguite immediatamente nello storage, migliorando così le prestazioni. Il pool di buffer è parte integrante di InnoDB e le sue dimensioni devono essere regolate di conseguenza. Per impostare le dimensioni del pool di buffer, tenere conto dei seguenti fattori:</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Per una macchina dedicata solo InnoDB, impostare la dimensione del pool di buffer su 80% o più della RAM disponibile.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">Se non si tratta di un server dedicato MySQL, impostare la dimensione al 50% della RAM.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Descrittori di file</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Le utilizza per aprire nuove connessioni, archiviare tabelle nella cache, creare tabelle temporanee per risolvere query complesse e accedere a quelle persistenti. Se mysqld non è in grado di aprire nuovi file quando necessario, può smettere di funzionare correttamente. Un sintomo comune di questo problema è l'errore 24, "troppi file aperti". Il numero di descrittori di file che mysqld può aprire simultaneamente è definito dal<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opzione impostata nel file di configurazione <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Ma<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> dipende anche dai limiti del sistema operativo. Questa dipendenza rende l'impostazione della variabile più complicata.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL non può impostare ITS<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opzione superiore a quanto specificato in<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Pertanto, è necessario impostare esplicitamente questi limiti a livello del sistema operativo per consentire a MySQL di aprire i file in base alle necessità. Ci sono due modi per controllare il limite dei file in Linux:</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">Il<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> command fornisce rapidamente una descrizione dettagliata dei parametri consentiti o bloccati. Le modifiche apportate eseguendo questo comando non sono permanenti e si cancellano dopo un riavvio del sistema.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Modifiche al<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> i file sono permanenti e non sono interessati dal riavvio del sistema.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Assicurarsi di modificare sia i limiti hard che soft per l'utente mysql. I seguenti estratti provengono dalla configurazione:</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">In parallelo, aggiornare la stessa configurazione in<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> per utilizzare completamente i limiti dei file aperti.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">In caso di modifica dei dati, la modifica non viene immediatamente scritta nell'archivio.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">I dati vengono invece registrati in un buffer di registro, che è una porzione di memoria allocata da InnoDB alle modifiche del buffer registrate nel file di registro. InnoDB svuota il buffer nel file di registro quando viene eseguito il commit di una transazione, quando il buffer diventa pieno o una volta al secondo, a seconda dell'evento che si verifica per primo. La variabile di configurazione che controlla questo processo è innodb_Flush_log_at_trx_commit. Le opzioni valore includono:</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Quando si imposta<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB scrive i dati modificati (nel pool di buffer InnoDB) nel file di log (ib_logfile) e scarica il file di log (write to storage) ogni secondo. Tuttavia, non fa nulla quando la transazione è impegnata. Se si verifica un'interruzione dell'alimentazione o un arresto anomalo del sistema, nessuno dei dati non scaricati è recuperabile perché non vengono scritti né nel file di registro né nelle unità.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Quando si imposta<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB scrive il buffer di log nel log delle transazioni e lo svuota nello storage durevole per ogni transazione. Ad esempio, per tutti i commit delle transazioni, InnoDB scrive nel registro e quindi nello storage. La lentezza dello storage influisce negativamente sulle performance, ad esempio riducendo il numero di transazioni InnoDB al secondo.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Quando si imposta<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB scrive il buffer di log nel file di log ad ogni commit; tuttavia, non scrive dati nell'archivio. InnoDB scarica i dati una volta al secondo. Anche in caso di interruzione dell'alimentazione o arresto anomalo del sistema, i dati dell'opzione 2 sono disponibili nel file di registro ed è recuperabile.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Se l'obiettivo principale è la prestazione, impostare il valore su 2. Poiché InnoDB scrive sui dischi una volta al secondo, non per ogni commit delle transazioni, le performance migliorano in modo significativo. Se si verifica un'interruzione dell'alimentazione o un arresto anomalo, i dati possono essere recuperati dal registro delle transazioni.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Se l'obiettivo principale è la sicurezza dei dati, impostare il valore su 1 in modo che per ogni commit di transazione, InnoDB si scarichi sulle unità. Tuttavia, le prestazioni potrebbero risentirne.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp recommended* impostare il valore innodb_Flush_log_trx_commit su 2 per ottenere prestazioni migliori.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">Nel plug-in InnoDB è stato aggiunto un nuovo parametro chiamato innodb_io_Capacity da MySQL 5,7.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Controlla il numero massimo di IOPS eseguiti da InnoDB (che include la velocità di scaricamento delle pagine sporche e la dimensione batch del buffer di inserimento [ibuf]). Il parametro innodb_io_Capacity imposta un limite massimo per le IOPS da parte delle attività in background di InnoDB, come il lavaggio delle pagine dal pool di buffer e l'Unione dei dati dal buffer di modifica.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Impostare il parametro innodb_io_Capacity sul numero approssimativo di operazioni di i/o che il sistema può eseguire al secondo. Idealmente, mantenere l'impostazione più bassa possibile, ma non così bassa che le attività in background rallentano. Se l'impostazione è troppo alta, i dati vengono rimossi dal pool di buffer e il buffer di inserimento troppo rapidamente per la memorizzazione nella cache, per fornire un vantaggio significativo.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp consiglia* che, se si utilizza questa impostazione su NFS, analizzi il risultato del test di IOPS (SysBench/FiO) e imposti il parametro di conseguenza. Utilizzare il valore più piccolo possibile per lo spurgo e lo spurgo per continuare a meno che non vengano visualizzate pagine modificate o sporche di quanto si desidera nel pool di buffer InnoDB.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">Non utilizzare valori estremi come 20.000 o più a meno che non si sia dimostrato che valori inferiori non sono sufficienti per il carico di lavoro.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">Il parametro InnoDB_io_Capacity regola le velocità di lavaggio e i/o correlati</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">È possibile danneggiare seriamente le prestazioni impostando questo parametro o il parametro innodb_io_Capacity_max troppo alto e sprecando le operazioni di i/o con il lavaggio prematuro.</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">Esistono due opzioni per configurare MySQL con SAN utilizzando il solito modello a due volumi.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">È possibile collocare database di dimensioni inferiori su una coppia di LUN standard, a condizione che le richieste di i/o e capacità rientrino nei limiti di un singolo file system LUN. Ad esempio, un database che richiede circa 2K IOPS casuali può essere ospitato su un singolo file system su un singolo LUN. Analogamente, un database di sole 100GB GB di dimensioni dovrebbe adattarsi a un singolo LUN, senza creare problemi di gestione.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Database di dimensioni maggiori richiedono LUN multiple. Ad esempio, un database che richiede 100K IOPS avrà probabilmente bisogno di almeno otto LUN. Un singolo LUN sarebbe diventato un collo di bottiglia a causa del numero inadeguato di canali SCSI per le unità. Analogamente, sarebbe difficile gestire un database da 10TB TB su un singolo LUN da 10TB GB. I gestori di volumi logici sono progettati per unire le funzionalità di performance e capacità di più LUN per migliorare le prestazioni e la gestibilità.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">In entrambi i casi, dovrebbe essere sufficiente una coppia di ONTAP Volumes. Con una configurazione semplice, la LUN dei file di dati viene posizionata in un volume dedicato, come farebbe la LUN di log. Con una configurazione di volume manager logica, tutte le LUN del gruppo di volumi dei file di dati si troverebbero in un volume dedicato e le LUN del gruppo di volumi di log si troverebbero in un secondo volume dedicato.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp consiglia* di utilizzare due file system per le distribuzioni MySQL su SAN:</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">Il primo file system memorizza tutti i dati MySQL inclusi tablespace, dati e indice.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">Il secondo file system archivia tutti i log (log binari, log lenti e log delle transazioni).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Esistono diverse ragioni per separare i dati in questo modo, tra cui:</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">I modelli di i/o dei file di dati e di registro sono diversi. La loro separazione permetterebbe più opzioni con i controlli QoS.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">L'uso ottimale della tecnologia Snapshot richiede la capacità di ripristinare in maniera indipendente i file di dati. L'associazione di file di dati con file di registro interferisce con il ripristino dei file di dati.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">La tecnologia NetApp SnapMirror può essere utilizzata per fornire una semplice funzionalità di disaster recovery con RPO ridotto per un database; tuttavia, richiede diverse pianificazioni della replica per i file di dati e log.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Utilizzare questo layout di base a due volumi per rendere la soluzione a prova di futuro, in modo che tutte le funzioni di ONTAP possano essere utilizzate se necessario.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp consiglia* la formattazione dell'unità con il file system ext4, grazie alle seguenti funzioni:</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Approccio esteso alle funzioni di gestione dei blocchi utilizzate nel file system di journaling (JFS) e nelle funzioni di allocazione differita del file system esteso (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">ext4 permette file system fino a 1 exbibyte (2^60 byte) e file fino a 16 tebibyte (16 * 2^40 byte). Al contrario, il file system ext3 supporta solo file system di dimensioni massime pari a 16TB MB e file di dimensioni massime pari a 2TB MB.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">Nei file system ext4, l'allocazione di più blocchi (mballoc) alloca più blocchi per un file in un'unica operazione, invece di assegnarli uno alla volta, come in ext3. Questa configurazione riduce l'overhead di chiamata dell'allocatore di blocchi diverse volte e ottimizza l'allocazione di memoria.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Anche se XFS è il default per molte distribuzioni Linux, gestisce i metadati in modo diverso e non è adatto per alcune configurazioni MySQL.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp consiglia* di utilizzare le opzioni di dimensione del blocco 4K con l'utilità mkfs per allinearsi alle dimensioni del LUN del blocco esistenti.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">Le LUN NetApp memorizzano dati in blocchi fisici da 4KB KB, ottenendo otto blocchi logici da 512 byte.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Se non si impostano le stesse dimensioni del blocco, l'i/o non verrà allineato correttamente con i blocchi fisici e potrebbe scrivere in due unità diverse in un gruppo RAID, con conseguente latenza.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">È importante allineare l'i/o per semplificare le operazioni di lettura/scrittura. Tuttavia, quando l'i/o inizia ad un blocco logico che non si trova all'inizio di un blocco fisico, l'i/o è disallineato. Le operazioni di i/o sono allineate solo quando iniziano presso un blocco logico, il primo blocco logico in un blocco fisico.</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parametri</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Valori</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_buffer_pool_instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Per impostare i parametri descritti in questa sezione, è necessario modificarli nel file di configurazione MySQL (my.cnf). Le Best practice di NetApp sono il risultato di test eseguiti internamente.</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">La containerizzazione dei database MySQL sta diventando sempre più diffusa.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">La gestione di container a basso livello viene quasi sempre eseguita con Docker. Le piattaforme di gestione dei container come OpenShift e Kubernetes semplificano ulteriormente la gestione di ambienti container di grandi dimensioni. I vantaggi della containerizzazione includono una riduzione dei costi, poiché non è necessario acquistare una licenza per un hypervisor. Inoltre, i container consentono l'esecuzione di più database isolati l'uno dall'altro, condividendo lo stesso kernel e sistema operativo sottostanti. È possibile eseguire il provisioning dei container in microsecondi.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Documentazione di Astra Trident</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">Struttura dei file MySQL</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Struttura dei file</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB funge da livello intermedio tra lo storage e il server MySQL, e memorizza i dati nelle unità.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">Errore: Immagine grafica non trovata</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">I/o MySQL è suddiviso in due tipi:</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">I/o di file casuali</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">I/o di file sequenziale</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">I file di dati vengono letti e sovrascritti in modo casuale, con conseguente aumento degli IOPS. Pertanto, si consiglia di utilizzare l'unità SSD.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">I file di log di ripristino e i file di log binari sono registri transazionali. Vengono scritti in sequenza, così potrai ottenere buone performance sul disco HDD con cache in scrittura. Al momento del ripristino si verifica una lettura sequenziale, che raramente causa problemi di prestazioni, poiché le dimensioni dei file di registro sono in genere inferiori ai file di dati e le letture sequenziali sono più veloci delle letture casuali (che si verificano sui file di dati).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">Il buffer double-write è una caratteristica speciale di InnoDB. InnoDB prima scrive le pagine svuotate nel buffer di doppia scrittura e poi scrive le pagine nelle posizioni corrette sui file di dati. Questo processo impedisce il danneggiamento della pagina. Senza il buffer di scrittura doppia, la pagina potrebbe danneggiarsi se si verifica un'interruzione dell'alimentazione durante il processo di scrittura su unità. La scrittura nel buffer double-write è sequenziale, pertanto è altamente ottimizzato per gli HDD. Al momento del ripristino vengono eseguite letture sequenziali.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Poiché la NVRAM ONTAP fornisce già la protezione in scrittura, non è necessario il doppio buffer in scrittura. MySQL ha un parametro,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, per disattivare il buffer di doppia scrittura. Questa funzione può migliorare notevolmente le prestazioni.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">Il buffer insert è anche una caratteristica speciale di InnoDB. Se i blocchi di indice secondari non univoci non sono in memoria, InnoDB inserisce le voci nel buffer di inserimento per evitare operazioni di i/o casuali. Periodicamente, il buffer di inserimento viene Unito agli alberi di indice secondari nel database. Il buffer di inserimento riduce il numero di operazioni di i/o unendo le richieste di i/o allo stesso blocco; le operazioni di i/o casuali possono essere sequenziali. Anche il buffer di inserimento è altamente ottimizzato per gli HDD. Durante le normali operazioni, vengono eseguite operazioni di scrittura e lettura sequenziali.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">I segmenti di annullamento sono orientati all'i/o casuale. Per garantire la concorrenza multi-versione (MVCC), InnoDB deve registrare le vecchie immagini nei segmenti di annullamento. La lettura delle immagini precedenti dai segmenti di annullamento richiede letture casuali. Se si esegue una transazione lunga con letture ripetibili (come mysqldump, una singola transazione) o si esegue una query lunga, è possibile che si verifichino letture casuali. Pertanto, in questo caso è preferibile memorizzare i segmenti di annullamento negli SSD. Se si eseguono solo transazioni o query brevi, le letture casuali non costituiscono un problema.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp consiglia* il seguente layout di progettazione dello storage a causa delle caratteristiche i/o di InnoDB.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Un unico volume per memorizzare i file di MySQL orientati ai/o casuali e sequenziali</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Un altro volume per memorizzare i file di MySQL orientati a i/o puramente sequenziali</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Questo layout aiuta inoltre a progettare politiche e strategie di protezione dei dati.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">È possibile disattivare questo parametro con<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> per i benchmark o quando siete più preoccupati per le prestazioni superiori che l'integrità dei dati o possibili guasti. InnoDB utilizza una tecnica di scaricamento file chiamata double-write. Prima di scrivere le pagine nei file di dati, InnoDB le scrive in un'area contigua denominata buffer double-write. Una volta completata la scrittura e lo scarico nel buffer di doppia scrittura, InnoDB scrive le pagine nelle posizioni corrette nel file di dati. Se il sistema operativo o un processo mysqld si blocca durante la scrittura di una pagina, InnoDB può in seguito trovare una buona copia della pagina dal buffer di doppia scrittura durante il recupero del crash.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp recommended* disabilitare il buffer double-write. La NVRAM ONTAP svolge la stessa funzione. Il doppio buffering danneggia inutilmente le prestazioni.</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">La documentazione MySQL consiglia di utilizzare NFSv4 per le implementazioni NAS.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">Dimensioni del trasferimento di NFS ONTAP</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">Per impostazione predefinita, ONTAP limiterà le dimensioni di i/o NFS a 64K. I/o casuali con un database MySQL utilizzano blocchi di dimensioni molto inferiori, che sono ben al di sotto del massimo di 64K KB. L'io a blocchi di grandi dimensioni è solitamente parallelizzato, quindi anche il massimo di 64K KB non costituisce un limite.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Ci sono alcuni carichi di lavoro in cui il massimo di 64K crea un limite. In particolare, le operazioni single-threaded, come le operazioni di backup della scansione completa del piano d'esame, verranno eseguite in modo più rapido ed efficiente se il database è in grado di eseguire un numero di io inferiore ma maggiore. La dimensione ottimale di gestione io per ONTAP con carichi di lavoro del database è 256K. Le opzioni di montaggio NFS elencate per i sistemi operativi specifici elencati di seguito sono state aggiornate da 64K a 256K di conseguenza.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Non diminuire mai la dimensione di trasferimento massima consentita su ONTAP al di sotto del valore rsize/wsize dei filesystem NFS attualmente montati. In alcuni sistemi operativi, ciò può causare blocchi o addirittura danni ai dati. Ad esempio, se i client NFS sono attualmente impostati su un valore rsize/wsize di 65536, la dimensione massima di trasferimento ONTAP potrebbe essere regolata tra 65536 e 1048576 senza alcun effetto perché i client stessi sono limitati. La riduzione della dimensione massima di trasferimento inferiore a 65536 GB può danneggiare la disponibilità o i dati.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp consiglia*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Impostazione della seguente impostazione NFSv4 fstab (/etc/fstab):</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">Un problema comune con NFSv3 è stato il blocco dei file di registro InnoDB dopo un'interruzione dell'alimentazione. Questo problema è stato risolto utilizzando i file di registro Time o Switching. Tuttavia, NFSv4 ha operazioni di blocco e tiene traccia dei file aperti e delle delegazioni.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP è la base per la gestione dei dati e la protezione dei dati per molte applicazioni aziendali e tecnologie di database. Le pagine seguenti contengono indicazioni sulle Best practice e le procedure di implementazione per ONTAP e le applicazioni e l'infrastruttura aziendali.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Protezione dei dati di Microsoft SQL Server</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Database open-source</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB e MySQL su ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL su ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Database Oracle</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle su ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Data Protection Oracle</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Migrazione Oracle</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">Soluzioni SAP</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA con AFF e FC</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA con AFF e NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Volumi virtuali (vVol) con ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware Site Recovery Manager con ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Applicazioni aziendali</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA e AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Impostazioni</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Istanza condivisa contro istanza dedicata</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Configurazione della memoria</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">File tempdb</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Sicurezza dei dati</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Limiti di capacità</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Failover e switchover</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Dimensioni dei blocchi di dati e ripristino</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">Oracle RAC</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Configurazione dell'host</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux con ASMlib e AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Interfacce logiche</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Configurazione Ethernet</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">Configurazione FC SAN</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">Striping LVM</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Configurazione</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (DNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">Leasing e blocchi di NFS</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">Caching di NFS</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">Utilità di recupero ASM</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Policy di tiering</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Invio di dati a un archivio di oggetti</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Recupero dei dati dall'archivio oggetti in corso</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Strategie di tiering</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">File interi</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">File parziali</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Selezionare file</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Disponibilità dei dati</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Integrità dei dati</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Backup online basati su snapshot</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Backup ottimizzati per le snapshot di storage</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Architettura fisica</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Architettura logica</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Scenari di errore</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migrazione dei database Oracle</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Procedure</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Copia dei dati host</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Importazione LUN esterne</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Completamento</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Conversione del protocollo</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Note aggiuntive</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Ottimizzazione delle prestazioni e benchmarking</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Blocchi NFS obsoleti</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Storage unificato</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Tool di virtualizzazione</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Gestione basata su policy di Virtual Volume e storage</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Cloning</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">QoS</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Gestione basata su criteri di storage</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Impostazioni consigliate</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Distribuzione dello storage vVol</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Sicurezza dei prodotti</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">Plug-in SnapCenter per VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Containerizzazione</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">Il provider ONTAP Tools VASA si occupa della gestione degli igroup FCP e iSCSI, nonché dei sottosistemi NVMe in ONTAP in base agli iniziatori rilevati degli host ESXi gestiti. Tuttavia, non si integra con gli switch Fibre Channel per gestire lo zoning. Lo zoning deve essere eseguito in base alle Best practice prima di eseguire qualsiasi provisioning. Di seguito è riportato un esempio di zoning a initiator singolo per quattro sistemi ONTAP:</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">Zoning a initiator singolo:</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Fare riferimento ai seguenti documenti per ulteriori Best practice:</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Prendere in considerazione l'utilizzo di IOPS massimi per controllare macchine virtuali sconosciute o di test.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Per la prima volta disponibile nel provider VASA 7.1, è possibile utilizzare il massimo IOPS per limitare gli IOPS a un vVol specifico per un carico di lavoro sconosciuto, in modo da evitare impatti su altri carichi di lavoro più critici. Per ulteriori informazioni sulla gestione delle performance, vedere la Tabella 4.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Fare riferimento alle altre guide alle Best practice di NetApp e VMware specifiche per il protocollo selezionato. In generale, non vi sono modifiche diverse da quelle già menzionate.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Esempio di configurazione di rete utilizzando vVol su NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">Dimensioni trasferimento NFS</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="861f074a1ecd9d1cc088d2fe81903565" category="paragraph"><block ref="861f074a1ecd9d1cc088d2fe81903565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="710e9cd79e3865d47122a799f425b31f" category="paragraph"><block ref="710e9cd79e3865d47122a799f425b31f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38ac6f4e1538397bd4f659237ec03ebf" category="paragraph"><block ref="38ac6f4e1538397bd4f659237ec03ebf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f01518e5f3b18a9ea241bc63a3475dbd" category="paragraph"><block ref="f01518e5f3b18a9ea241bc63a3475dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Panoramica sulla data Protection di Oracle</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">La migrazione su distanze più lunghe in genere richiede un approccio più creativo, ad esempio il processo di distribuzione dei log illustrato nella <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. Le reti IP a lunga distanza raramente dispongono di larghezza di banda in qualsiasi punto vicino alle velocità LAN o SAN. In un caso, NetApp ha assistito alla migrazione a lunga distanza di un database 220TB con tassi di generazione di log di archiviazione molto elevati. L'approccio scelto per il trasferimento dei dati era la spedizione giornaliera dei nastri, perché questo metodo offriva la massima larghezza di banda possibile.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">Ad esempio, la copia di un database 10TB richiede in genere circa sette ore. Se le esigenze aziendali rendono possibile un'interruzione di sette ore, la copia dei file è un'opzione semplice e sicura per la migrazione. Se cinque ore sono inaccettabili, un semplice log-processo di spedizione (vedere <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>) può essere impostato con il minimo sforzo per ridurre il tempo di cutover a circa 15 minuti. Durante questo periodo, un amministratore di database può completare il processo. Se 15 minuti sono inaccettabili, è possibile automatizzare il processo di cutover finale tramite script per ridurre il tempo di cutover a pochi minuti. È sempre possibile accelerare una migrazione, anche se ciò comporta costi di tempo e lavoro. Gli obiettivi del tempo di cutover devono basarsi su ciò che è accettabile per l'azienda.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">Uno zpool deve essere creato solo dopo i passaggi nella <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> vengono eseguite. Se la procedura non viene eseguita correttamente, le prestazioni potrebbero peggiorare notevolmente a causa dell'allineamento i/O. Per ottenere prestazioni ottimali con ONTAP è necessario allineare l'i/o a un confine di 4K su un'unità. I file system creati su uno zpool utilizzano una dimensione di blocco effettiva controllata tramite un parametro chiamato<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, che può essere visualizzato eseguendo il comando<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">La partizione è stata creata con un offset a 33 settori anziché con il valore predefinito 32. Ripetere la procedura descritta in <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. L'istogramma viene visualizzato come segue:</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">Aumentare la dimensione dei LUN</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">Aggiungere un LUN a un gruppo di volumi esistente e aumentare il volume logico contenuto</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">Un gruppo iniziatore (igroup) fa parte dell'architettura di mascheramento LUN di ONTAP. Un LUN appena creato non è accessibile a meno che non venga concesso per la prima volta l'accesso a un host. A tale scopo, creare un igroup in cui siano elencati i nomi WWN FC o iSCSI Initiator a cui è necessario concedere l'accesso. Al momento della scrittura del report, FLI era supportato solo per LUN FC. Tuttavia, la conversione in post-migrazione iSCSI è un'attività semplice, come illustrato nella <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">In questo modo, gli amministratori di database possono recuperare spazio sull'array di storage dopo l'eliminazione dei dati. ONTAP intercetta gli zero e dealloca lo spazio dal LUN. Il processo di recupero dei dati è estremamente rapido, poiché non viene scritto alcun dato all'interno del sistema di storage.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">I sistemi storage ONTAP offrono una grande flessibilità nella creazione di datastore per macchine virtuali e dischi virtuali. Sebbene vengano applicate molte Best practice ONTAP quando si utilizza VSC per il provisioning dei datastore per vSphere (elencate nella sezione <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>), ecco alcune linee guida aggiuntive da prendere in considerazione:</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">In alcuni casi, potrebbe non essere necessario un datastore. Per ottenere performance e gestibilità ottimali, evitare di utilizzare un datastore per applicazioni con i/o elevato, come database e alcune applicazioni. Si consiglia invece di prendere in considerazione file system di proprietà degli ospiti, come NFS o iSCSI, gestiti dal guest o con RDM. Per indicazioni specifiche sulle applicazioni, consulta i report tecnici NetApp relativi alla tua applicazione. Ad esempio, <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> contiene una sezione sulla virtualizzazione con informazioni utili.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">Quando<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> È attivato (impostazione predefinita), InnoDB memorizza tutti i dati due volte: Prima nel buffer di doppia scrittura e poi nei file di dati effettivi.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">Configurazione host per PostgreSQL</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">Configurazione dello storage per PostgreSQL</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">Protezione dei dati per PostgreSQL</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Configurazione del database per Microsoft SQL Server</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Configurazione dello storage per Microsoft SQL Server</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Configurazione del database per Oracle Database</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Configurazione host per database Oracle</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Configurazione di rete per Oracle Database</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Configurazione dello storage per database Oracle</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">Configurazione del database per MySQL</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">Configurazione host per MySQL</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">Configurazione dello storage per MySQL</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">Database PostgreSQL con SAN su ONTAP</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">PostgreSQL con SAN Filesystems</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">I database PostgreSQL con SAN sono generalmente ospitati su filesystem xfs, ma altri possono essere utilizzati se supportati dal fornitore del sistema operativo</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">Mentre un singolo LUN può generalmente supportare fino a 100K IOPS, i database io-intensive richiedono generalmente l'utilizzo di LVM con lo striping.</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">I database PostgreSQL possono essere ospitati su filesystem NFSv3 o NFSv4. L'opzione migliore dipende da fattori esterni al database.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">Per esempio, il comportamento di bloccaggio di NFSv4 può essere preferibile in certi ambienti raggruppati. (Vedere <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> per ulteriori informazioni)</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">In caso contrario, la funzionalità del database dovrebbe essere quasi identica, incluse le prestazioni. L'unico requisito è l'uso di<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> opzione di montaggio. Questo è necessario per garantire che i timeout software non producano errori io irreversibili.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">Se si sceglie NFSv4 come protocollo, NetApp consiglia di utilizzare NFSv4,1. Nel NFSv4,1 sono stati apportati alcuni miglioramenti funzionali al protocollo NFSv4 che migliorano la resilienza rispetto al NFSv4,0.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i carichi di lavoro generali del database:</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">Una volta aumentata la dimensione di trasferimento a livello ONTAP, si utilizzeranno le seguenti opzioni di montaggio:</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">NFSv3 tabelle slot TCP</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">Se NFSv3 viene usato con Linux, è fondamentale impostare correttamente le tabelle degli slot TCP.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Copie Snapshot</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">Le snapshot di storage sono repliche point-in-time dei dati di destinazione. L'implementazione di ONTAP include le funzionalità per impostare varie policy e memorizzare fino a 1024 snapshot per volume. Le Snapshot in ONTAP sono efficienti in termini di spazio. Lo spazio viene consumato solo quando viene modificato il set di dati originale. Sono anche di sola lettura. Uno snapshot può essere eliminato, ma non può essere modificato.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">In alcuni casi, le snapshot possono essere pianificate direttamente su ONTAP. In altri casi, software come SnapCenter potrebbe essere necessario per orchestrare le operazioni dell'applicazione o del sistema operativo prima di creare snapshot. Qualunque sia l'approccio migliore per i tuoi workload, un'aggressiva strategia di snapshot può garantire sicurezza dei dati tramite un accesso frequente e facilmente accessibile ai backup di ogni elemento, dalle LUN di avvio ai database mission-critical.</block>
  <block id="210c45246ad11e0b53bdb20b64266780" category="paragraph">*Nota*: Un volume flessibile ONTAP, o più semplicemente, un volume non è sinonimo di LUN. I volumi sono container di gestione per dati come file o LUN. Ad esempio, un database può essere posizionato su un set di stripe da 8 LUN, con tutti i LUN contenuti in un singolo volume.</block>
  <block id="ad590deba1cd4423ee565e822c3a91d1" category="paragraph">Per ulteriori informazioni sulle istantanee, fare clic su <block ref="211d7effcac0cb0488144c6fc8b3cb7c" category="inline-link-macro-rx"></block></block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">Snapshot a prova di manomissione</block>
  <block id="d2e783db61d20da61c761d4d473bed14" category="paragraph">A partire da ONTAP 9.12.1, le snapshot non sono solo di lettura, ma possono anche essere protette da eliminazioni accidentali o intenzionali. La funzione è denominata istantanee antimanomissione. È possibile impostare e applicare un periodo di conservazione tramite policy snapshot. Gli snapshot risultanti non possono essere eliminati fino a quando non hanno raggiunto la data di scadenza. Non sono presenti sostituzioni amministrative o del centro di supporto.</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">In questo modo, un intruso, un malintenzionato o persino un attacco ransomware non sono in grado di compromettere i backup, anche nel caso in cui abbiano accesso al sistema ONTAP stesso. Se combinato con una pianificazione degli snapshot frequente, offre una data Protection estremamente potente con un RPO molto basso.</block>
  <block id="c64db0c79e66c1c0e5b932c5d2dedfea" category="paragraph">Per ulteriori informazioni sulle istantanee antimanomissione, fare clic su <block ref="134603be635c039f9224bff191c6103c" category="inline-link-macro-rx"></block></block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">Replica SnapMirror</block>
  <block id="1bb837ddfb635c39a6c6e23d847823f9" category="paragraph">Gli snapshot possono anche essere replicati su un sistema remoto. Sono incluse le istantanee antimanomissione, in cui il periodo di conservazione viene applicato e applicato sul sistema remoto. Come risultato otterrai gli stessi vantaggi di protezione dei dati delle snapshot locali, ma i dati verranno posizionati in un secondo storage array. In questo modo si garantisce che la distruzione dell'array originale non comprometta i backup.</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">Un secondo sistema apre anche nuove opzioni per la sicurezza amministrativa. Ad esempio, alcuni clienti NetApp segregano le credenziali di autenticazione per i sistemi di storage primario e secondario. Nessun utente amministrativo singolo ha accesso a entrambi i sistemi, il che significa che un amministratore malintenzionato non può eliminare tutte le copie dei dati.</block>
  <block id="e805272dcce51c35975e830e5ee9ecaf" category="paragraph">Per ulteriori informazioni su SnapMirror, fare clic su <block ref="9abdfd5d94773cf0a996248d1d722cac" category="inline-link-macro-rx"></block></block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">Macchine virtuali di storage</block>
  <block id="d5174dd4c760ef1a826b3e5bc22215e5" category="paragraph">Un sistema di storage ONTAP appena configurato è simile a un server VMware ESX appena configurato, perché nessuno di questi può supportare gli utenti fino alla creazione di una macchina virtuale. Con ONTAP viene creata una Storage Virtual Machine (SVM) che diventa l'unità di gestione dello storage più base. Ciascuna SVM dispone di risorse di storage, configurazioni di protocolli, indirizzi IP e WWN FCP.  Questa è la base di ONTAP mult-tenancy.</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">Ad esempio, è possibile configurare una SVM per i carichi di lavoro di produzione critici e una seconda SVM su un segmento di rete diverso per le attività di sviluppo. Quindi, è possibile limitare l'accesso alla SVM di produzione a determinati amministratori, garantendo al contempo agli sviluppatori un controllo più esteso sulle risorse storage nella SVM di sviluppo. Potrebbe anche essere necessario fornire una terza SVM ai tuoi team finanziari e delle risorse umane per memorizzare dati particolarmente critici solo per gli occhi.</block>
  <block id="18519d16720b1e13890c2639657b5bf8" category="paragraph">Per ulteriori informazioni sulle SVM, fare clic su <block ref="a06a0fd566387240178b1c926e07cb7b" category="inline-link-macro-rx"></block></block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">RBAC amministrativo</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP offre un potente role-based access control (RBAC) per gli accessi amministrativi. Alcuni amministratori potrebbero aver bisogno di un accesso completo al cluster, altri invece potrebbero aver bisogno solo dell'accesso a determinate SVM. Il personale avanzato dell'helpdesk potrebbe aver bisogno di aumentare le dimensioni dei volumi. Il risultato è la possibilità di concedere agli utenti amministrativi l'accesso necessario per eseguire le proprie responsabilità lavorative, e niente di più. Inoltre, è possibile proteggere questi accessi utilizzando PKI di vari fornitori, limitare l'accesso solo alle chiavi ssh e applicare blocchi dei tentativi di accesso non riusciti.</block>
  <block id="6ae13b0198daa7d13d79a8631297e64d" category="paragraph">Per ulteriori informazioni sul controllo dell'accesso amministrativo, fare clic su <block ref="db5be08b697b5ef26e0e94da1d5f4970" category="inline-link-macro-rx"></block></block>
  <block id="671a94a08dff3cf44fad087e2346c8b0" category="section-title">Autenticazione a più fattori</block>
  <block id="945c88a63c229c39ee73ab5592b3ef63" category="paragraph">Per ulteriori informazioni, fare clic su <block ref="03628d0cd13b6640ef56c399aa1c2070" category="inline-link-macro-rx"></block></block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">RBAC API</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">L'automazione richiede chiamate API, ma non tutti gli strumenti richiedono un accesso amministrativo completo. Per contribuire a proteggere i sistemi di automazione, RBAC è disponibile anche a livello di API. È possibile limitare gli account utente di automazione alle chiamate API richieste. Ad esempio, il software di monitoraggio non richiede l'accesso alle modifiche, ma solo l'accesso in lettura. I workflow che forniscono storage non hanno bisogno della capacità di eliminare lo storage.</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">L'autenticazione a più "fattori" può essere ulteriormente eseguita richiedendo l'approvazione di determinate attività da parte di due amministratori diversi, ciascuno con le proprie credenziali. Ciò include la modifica delle autorizzazioni di accesso, l'esecuzione dei comandi diagnostici e l'eliminazione dei dati.</block>
  <block id="e890d04cd745ac382688bbb307655e81" category="paragraph">Per ulteriori informazioni sulla verifica multi-admin (MAV), fare clic su <block ref="88f84d4fec0424d978600980bf11baf0" category="inline-link-macro-rx"></block></block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">Se si prevede un io sequenziale pesante, le dimensioni del trasferimento NFS possono essere aumentate come descritto nella sezione seguente.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4590: Best practice guide for Microsoft SQL Server with ONTAP_</block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">Le guide precedenti hanno consigliato la creazione di una LIF in una località dati. Vale a dire, montare sempre un datastore utilizzando una LIF situata sul nodo che fisicamente possiede il volume. Questo non è più un requisito nelle versioni moderne di ONTAP 9. Quando possibile e se specifiche credenziali di ambito del cluster, i tool ONTAP continueranno a scegliere di bilanciare il carico tra le LIF locali dei dati, ma non è un requisito di high Availability o performance.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM funziona al meglio quando il numero di datastore e quindi di gruppi di protezione viene ridotto al minimo nei piani di ripristino. È quindi opportuno prendere in considerazione l'ottimizzazione della densità delle macchine virtuali negli ambienti protetti con SRM in cui l'RTO è fondamentale.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">Utilizza DRS (Distributed Resource Scheduler) per bilanciare il carico sui cluster ESXi protetti e di recovery. Tenere presente che se si prevede di eseguire il failback, quando si esegue una nuova protezione i cluster precedentemente protetti diventeranno i nuovi cluster di ripristino. Il DRS aiuterà a bilanciare il posizionamento in entrambe le direzioni.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">Ove possibile, evitare di utilizzare la personalizzazione IP con SRM, poiché ciò può aumentare il vostro RTO.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">A partire da SRM 8,3, è supportata la protezione delle macchine virtuali che utilizzano gli archivi dati vVol. Le pianificazioni di SnapMirror sono esposte ai criteri di storage delle macchine virtuali dal provider VASA quando la replica di vVol è attivata nel menu delle impostazioni degli strumenti di ONTAP, come mostrato nelle seguenti schermate.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">Nell'esempio riportato di seguito viene illustrata l'attivazione della replica vVol.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">A differenza dei datastore vVols precedenti, gli archivi dati vVols replicati devono essere creati dall'inizio con la replica abilitata e devono utilizzare volumi pre-creati sui sistemi ONTAP con relazioni SnapMirror. Ciò richiede la preconfigurazione di elementi come il peering dei cluster e il peering SVM. Queste attività devono essere eseguite dall'amministratore ONTAP, in quanto ciò facilita una rigorosa separazione delle responsabilità tra coloro che gestiscono i sistemi ONTAP in più siti e coloro che sono i principali responsabili delle operazioni vSphere.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">Viene creato un gestore di array per ogni coppia di array. Con gli strumenti SRM e ONTAP, ogni accoppiamento di array viene eseguito con l'ambito di una SVM, anche se si utilizzano le credenziali del cluster. Ciò consente di segmentare i flussi di lavoro DR tra tenant in base alle SVM assegnate per la gestione. È possibile creare più array manager per un determinato cluster e possono essere asimmetrici. È possibile eseguire il fan-out o il fan-in tra diversi cluster di ONTAP 9. Ad esempio, è possibile utilizzare SVM-A e SVM-B nel cluster-1 in replica su SVM-C nel cluster-2, SVM-D nel cluster-3 o viceversa.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">Esistono diversi fattori da considerare per i gruppi di replica e il modo in cui si distribuiscono le macchine virtuali tra i volumi FlexVol. Il raggruppamento di macchine virtuali simili nello stesso volume può aumentare l'efficienza dello storage con i sistemi ONTAP meno recenti che non dispongono di una deduplica a livello di aggregato, ma il raggruppamento aumenta la dimensione del volume e riduce l'simultaneità dell'i/O. Il miglior equilibrio tra performance ed efficienza dello storage si può ottenere negli attuali sistemi ONTAP distribuendo le VM su volumi FlexVol nello stesso aggregato, sfruttando così la deduplica a livello di aggregato e ottenendo una maggiore parallelizzazione i/o su più volumi. È possibile ripristinare le macchine virtuali nei volumi insieme perché un gruppo di protezione (discusso di seguito) può contenere più gruppi di replica. Lo svantaggio di questo layout è che i blocchi potrebbero essere trasmessi più volte via cavo perché SnapMirror per i volumi non prende in considerazione la deduplica degli aggregati.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">Ad esempio, la tua azienda potrebbe disporre di un'applicazione business-critical Tier 1 che si affida a un server Microsoft SQL per il proprio database. Quindi, si decide di inserire le macchine virtuali nel gruppo di priorità 1. All'interno del gruppo di priorità 1, si inizia a pianificare l'ordine per visualizzare i servizi. Probabilmente si desidera che il controller di dominio Microsoft Windows venga avviato prima del server Microsoft SQL, che deve essere online prima del server dell'applicazione e così via. È necessario aggiungere tutte queste macchine virtuali al gruppo di priorità e quindi impostare le dipendenze perché le dipendenze si applicano solo all'interno di un determinato gruppo di priorità.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">Come Best practice, eseguire sempre un test di failover ogni volta che viene apportata una modifica alla configurazione di uno storage VM protetto. In questo modo, in caso di emergenza, è possibile verificare che Site Recovery Manager sia in grado di ripristinare i servizi entro la destinazione RTO prevista.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">SRM consente inoltre di modificare la configurazione di rete di una macchina virtuale durante il ripristino. Questa riconfigurazione include impostazioni quali indirizzi IP, indirizzi gateway e impostazioni del server DNS. È possibile specificare diverse impostazioni di rete, che vengono applicate alle singole macchine virtuali non appena vengono recuperate, nelle impostazioni della proprietà di una macchina virtuale nel piano di ripristino.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">Dopo il failback, è necessario confermare con tutti gli stakeholder che i loro servizi sono stati riportati alla normalità prima di eseguire nuovamente la funzione di protezione,</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">File di database e filegroup</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">Allineamento delle LUN</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">Numero di LUN e dimensioni LUN</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">Ridimensionamento LUN</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">Striping LVM</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO, RTO e SLA</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">Elementi di base di backup e recovery</block>
  <block id="3403aac944f3cb6e2d2c7f7d52bc44b9" category="paragraph">Con la crescita esponenziale dei dati, la gestione dei dati diventa più complessa per le aziende. Questa complessità aumenta i costi di licenza, operativi, di supporto e di manutenzione. Per ridurre il TCO complessivo, considerare il passaggio da database commerciali a open-source con storage back-end affidabile e dalle performance elevate.</block>
  <block id="dcac08882e3396bd30210108baa1641d" category="paragraph">ONTAP è una piattaforma ideale, perché ONTAP è letteralmente progettato per i database. Sono state create numerose funzionalità come le ottimizzazioni della latenza io random per la qualità del servizio avanzata fino alle funzionalità FlexClone di base per rispondere specificamente alle esigenze dei carichi di lavoro dei database.</block>
  <block id="1429a98a71e16287326edd7fc1f999fd" category="paragraph">Funzioni aggiuntive come gli aggiornamenti senza interruzioni, (inclusa la sostituzione dello storage) garantiscono la disponibilità dei database critici. Puoi anche disporre di un disaster recovery istantaneo per ambienti di grandi dimensioni tramite MetroCluster o selezionare database tramite la sincronizzazione attiva di SnapMirror.</block>
  <block id="8df3fb35ff15e02683bfb1bc7f852c93" category="paragraph">Soprattutto, ONTAP offre prestazioni senza pari con la possibilità di dimensionare la soluzione in base alle proprie esigenze specifiche. I nostri sistemi high-end possono offrire oltre 1M IOPS con latenze misurate in microsecondi, ma se ti servono solo 100K IOPS, puoi dimensionare al meglio la tua soluzione storage con un controller più piccolo che esegue ancora lo stesso sistema operativo per lo storage.</block>
  <block id="97b4cda00dd31f5be69440f48c4da149" category="summary">Configurazione del database PostgreSQL con ONTAP</block>
  <block id="c4f52498c0db572381512887d7584e53" category="summary">Database PostgreSQL e snapshot di storage</block>
  <block id="b0792163c858a7c221b236d84619b5ef" category="summary">Database PostgreSQL NFS con ONTAP</block>
  <block id="189950ed46e5e8b7e92941531a5bb88b" category="doc">Database PostgreSQL con filesystem NFS</block>
  <block id="6cabd4dcf3582d38c441228705da3bda" category="doc">Protezione dei dati PostgreSQL</block>
  <block id="383a6a5241ecfc558b9fec1d7cff5239" category="summary">Tablespace PostgreSQL</block>
  <block id="20d0e2519b3555a0a2927c8914c17280" category="summary">Software di protezione dei dati PostgreSQL</block>
  <block id="29e2aec511a8e307ecceacbd86c22f14" category="summary">Parametri di inizializzazione PostgreSQL</block>
  <block id="035ecd1be6cacde993302b440e396bc2" category="paragraph">La maggior parte dei clienti che utilizzano database sceglie ora gli array all-flash, il che crea alcune considerazioni aggiuntive. Ad esempio, prendi in considerazione il test delle performance su un sistema AFF A900 a due nodi:</block>
  <block id="33f545d041b93838074263c0efd2e9da" category="list-text">Con un rapporto di lettura/scrittura di 80/20:1, due nodi A900 possono fornire oltre 1M IOPS di database casuali prima che la latenza attraversi anche il contrassegno 150µs. Questo ben oltre le attuali richieste di performance della maggior parte dei database è difficile prevedere il miglioramento previsto. Lo storage verrebbe ampiamente cancellato come collo di bottiglia.</block>
  <block id="0445195555faac96ebff962dbff126ea" category="summary">Parametri di configurazione MySQL</block>
  <block id="c0b7708ffcd66fd65a9d2a4801091563" category="paragraph">NetApp consiglia alcuni importanti parametri di configurazione di MySQL per ottenere prestazioni ottimali.</block>
  <block id="10eb8b7e75da1815860da31490513841" category="summary">MySQL con NFS</block>
  <block id="5249e05857621fbfae51371a73006c44" category="summary">MySQL e NFSv3 slot tables</block>
  <block id="d058f95e3a8d4b7b46802139d6b95982" category="paragraph">NFSv3 le prestazioni di Linux dipendono da un parametro chiamato<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="bf2bdc980948fb9084a63963398846b2" category="paragraph">ONTAP è una piattaforma ideale per database MySQL, perché ONTAP è letteralmente progettato per database. Sono state create numerose funzionalità come le ottimizzazioni della latenza io random per la qualità del servizio avanzata fino alle funzionalità FlexClone di base per rispondere specificamente alle esigenze dei carichi di lavoro dei database.</block>
  <block id="1b3804b7e2292e18f5e66d54f7a9fafc" category="paragraph">Soprattutto, ONTAP offre prestazioni senza pari con la possibilità di dimensionare la soluzione in base alle proprie esigenze specifiche. I nostri sistemi high-end possono offrire oltre 1M IOPS con latenze misurate in microsecondi, ma se ti servono solo 100K IOPS, puoi dimensionare correttamente la tua soluzione storage con un controller più piccolo che esegue ancora lo stesso sistema operativo per lo storage.</block>
  <block id="1339877637a3f7f59745a00e04f304fd" category="summary">MySQL e innodb_log_file_size</block>
  <block id="c1c4e722764621d56a075e42ce48d0c0" category="summary">MySQL e innodb_buffer_pool_size</block>
  <block id="ae14ab6d1e5edd0e782d8897d1721eb4" category="summary">MySQL e innodb_doublewrite</block>
  <block id="689c52e3f5db5d2dafccd7d93cf1abc4" category="summary">MySQL e innodb_Flush_log_at_trx_commi</block>
  <block id="639600080c225673dfdfa012fdbd6146" category="summary">Programmatori MySQL e io</block>
  <block id="32e3724e2b54692cbef969373fbfe040" category="doc">Programmatori i/o e MySQL</block>
  <block id="72985ac51e91797345b2437088a4362e" category="summary">MySQL con SAN</block>
  <block id="d5ef0a45fe252b03f538bfd134b168db" category="summary">MySQL e innodb_lru_Scan_Depth</block>
  <block id="df657260453f6ef228ee0ca22dd7a415" category="summary">Containerizzazione di MySQL</block>
  <block id="885b1b5a90f898c89b664ec58a42121c" category="doc">Containerizzazione MySQL</block>
  <block id="2828450fc6669c8df75f937e227996f1" category="doc">Descrittori di file MySQL</block>
  <block id="9420010a756fb6d3ddeadfa63d2170f6" category="paragraph">Per l'esecuzione, il server MySQL ha bisogno di descrittori di file, e i valori predefiniti non sono sufficienti.</block>
  <block id="62414a5a9c0e2fc12a8d028ad29164b8" category="summary">MySQL e innodb_io_Capacity</block>
  <block id="6219c45bc8c26437c0b7e1a69d4cbe58" category="summary">MySQL e innodb_Flush_Method</block>
  <block id="35d1a5d7b12999ec27f5233dccba043f" category="summary">MySQL e open_file_limits</block>
  <block id="c031febc35017c70bf3b526723756b2a" category="doc">ISCSI e NVMe/TCP</block>
  <block id="4da35d461815e71b97bda03476e89b7b" category="paragraph">Un host che utilizza iSCSI o NVMe/TCP può essere collegato direttamente a un sistema storage e funzionare normalmente. La ragione è la pedata. Le connessioni dirette a due storage controller differenti offrono due percorsi indipendenti per il flusso di dati. La perdita di percorso, porta o controller non impedisce l'utilizzo dell'altro percorso.</block>
  <block id="40715d81cea527f13cdf470773fc3a65" category="paragraph">È possibile utilizzare lo storage NFS con connessione diretta, ma con una limitazione significativa: Il failover non funzionerà senza una significativa attività di scripting, che sarà responsabilità del cliente.</block>
  <block id="d0b13bfd23c05f64222869de30f81000" category="paragraph">Il motivo per cui il failover senza interruzioni è complicato con lo storage NFS connesso direttamente è il routing che si verifica sul sistema operativo locale. Ad esempio, si supponga che un host abbia un indirizzo IP 192.168.1.1/24 e che sia collegato direttamente a un controller ONTAP con un indirizzo IP 192.168.1.50/24. Durante il failover, l'indirizzo 192.168.1.50 può eseguire il failover sull'altro controller e sarà disponibile per l'host, ma in che modo l'host rileva la sua presenza? L'indirizzo 192.168.1.1 originale esiste ancora sulla scheda di rete host che non si connette più a un sistema operativo. Il traffico destinato a 192.168.1.50 continuerebbe ad essere inviato a una porta di rete inutilizzabile.</block>
  <block id="288a0a5ebbc70fb3b968ec58d36d71ab" category="paragraph">La seconda scheda NIC del sistema operativo potrebbe essere configurata come 19 2.168.1.2 e sarebbe in grado di comunicare con l'indirizzo 192.168.1.50 non riuscito, ma le tabelle di routing locali avrebbero un valore predefinito di utilizzo di un solo indirizzo *e di un solo indirizzo* per comunicare con la subnet 192.168.1.0/24. Un amministratore di sistema potrebbe creare un framework di script che rilevi una connessione di rete non riuscita e alteri le tabelle di routing locali o che porti le interfacce verso l'alto e verso il basso. La procedura esatta dipende dal sistema operativo in uso.</block>
  <block id="d6ce8522932df7ae76aa0b963ad9ef7d" category="paragraph">In pratica, i clienti NetApp dispongono di NFS con connessione diretta, ma in genere solo per i workload in cui le pause io durante i failover sono accettabili. Quando si utilizzano i supporti rigidi, non devono verificarsi errori di i/o durante tali pause. L'io dovrebbe bloccarsi finché i servizi non vengono ripristinati, mediante failback o intervento manuale, per spostare gli indirizzi IP tra le schede NIC dell'host.</block>
  <block id="3436a7073ac9f4071820b6720a7789fc" category="section-title">Connessione diretta FC</block>
  <block id="b7981516813a09695906aa429b07f48f" category="paragraph">Non è possibile connettere direttamente un host a un sistema storage ONTAP utilizzando il protocollo FC. Il motivo è l'uso di NPIV. Il WWN che identifica una porta FC ONTAP per la rete FC utilizza un tipo di virtualizzazione chiamato NPIV. Qualsiasi dispositivo collegato a un sistema ONTAP deve essere in grado di riconoscere un WWN NPIV. Attualmente non vi sono fornitori di HBA che offrono un HBA che può essere installato in un host in grado di supportare un target NPIV.</block>
  <block id="97db606ac6781989ea3b189d7be28bf2" category="section-title">Connessione di rete diretta</block>
  <block id="d078ae9a339971900f939db9e82f253d" category="paragraph">Gli amministratori dello storage a volte preferiscono semplificare le loro infrastrutture rimuovendo gli switch di rete dalla configurazione. Questo può essere supportato in alcuni scenari.</block>
  <block id="e817ecc2f82a2b78d828ec8704031da3" category="section-title">Connessione di rete diretta</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">Sono disponibili diverse risorse per la risoluzione dei problemi con ulteriori informazioni.</block>
  <block id="52d04863ac62a6fa67e1b49a31086928" category="paragraph">Nelle seguenti sezioni vengono illustrate le Best practice operative per lo storage SRM e ONTAP di VMware.</block>
  <block id="f24ef4a42850a2b3e3d77e610ae46fee" category="doc">Resilienza per eventi pianificati e non pianificati</block>
  <block id="4bce11924453ef2ee7e40109f79dc66d" category="paragraph">NetApp MetroCluster e SnapMirror Active Sync sono potenti strumenti che migliorano l'alta disponibilità e le operazioni senza interruzioni dell'hardware NetApp e del software ONTAP®.</block>
  <block id="52f49b6400100ac4558d31582b90ca4e" category="paragraph">Questi strumenti garantiscono una protezione a livello di sito per l'intero ambiente di storage, garantendo che i tuoi dati siano sempre disponibili. Che si stiano utilizzando server standalone, cluster di server ad alta disponibilità, container Docker o server virtualizzati, la tecnologia NetApp permette di conservare perfettamente la disponibilità dello storage in caso di black-out totale causato da black-out, raffreddamento o connettività di rete, arresto dello storage array o errori operativi.</block>
  <block id="d267775072875ddbb24c16a41c22d8a2" category="paragraph">La sincronizzazione attiva di MetroCluster e SnapMirror offre tre metodi di base per la continuità dei dati in caso di eventi pianificati o non pianificati:</block>
  <block id="1d3027d09fc1db3087f05f2163af2cb7" category="list-text">Componenti ridondanti per la protezione contro i guasti a un singolo componente</block>
  <block id="f3b83f3b77289efe3b53cf537b7b77f5" category="list-text">Takeover locale di ha in caso di eventi che colpiscono un singolo controller</block>
  <block id="b6ed0cba165f6f9664dc1e57ac3419ec" category="list-text">Protezione completa del sito: Rapida ripresa del servizio mediante il trasferimento dello storage e dell'accesso client dal cluster di origine al cluster di destinazione</block>
  <block id="16afcbe8821dfa582521cd62c1ec130d" category="paragraph">Ciò significa che le operazioni continuano senza problemi in caso di guasto a un singolo componente e vengono ripristinate automaticamente al funzionamento ridondante una volta sostituito il componente guasto.</block>
  <block id="8fab78e8b214cad43d962b802bf568f8" category="paragraph">Tutti i cluster ONTAP, ad eccezione dei cluster a nodo singolo (in genere versioni software-defined, come ad esempio ONTAP Select), offrono funzionalità di ha integrate chiamate takeover e giveback. Ciascun controller del cluster è accoppiato con un altro controller in modo da formare una coppia ha. Queste coppie garantiscono che ogni nodo sia connesso localmente allo storage.</block>
  <block id="83e1749664841043ce8b1e894769a201" category="paragraph">Il takeover è un processo automatizzato in cui un nodo assume il controllo dello storage dell'altro per la gestione dei servizi dati. Giveback è il processo inverso che ripristina il normale funzionamento. Il takeover può essere pianificato, ad esempio durante la manutenzione hardware o gli upgrade della ONTAP, o non pianificato, derivante da un nodo di panico o da un guasto dell'hardware.</block>
  <block id="834d83f4ff04b7e3948831f336559b7c" category="paragraph">Durante un takeover, le interfacce logiche NAS (Network Attached Storage) nelle configurazioni MetroCluster eseguono automaticamente il failover. Tuttavia, le LIF (SAN) di Storage Area Network non subiscono failover e continueranno a utilizzare il percorso diretto dei LUN (Logical Unit Number).</block>
  <block id="0b0403a9258293da1f6a5fc84d24a18e" category="inline-link">Panoramica sulla gestione delle coppie HA</block>
  <block id="df5ca9bc3ee60e70aa9fd870a1ce1065" category="paragraph">Per ulteriori informazioni sul takeover e lo sconto ha, consulta la<block ref="5a72801b431f75b7489a0e7de50680bf" category="inline-link-rx"></block>. È importante notare che questa funzionalità non è specifica per MetroCluster o SnapMirror Active Sync.</block>
  <block id="cf654073ce9eb8f38d3f05292ed83cc5" category="paragraph">Lo switchover del sito con MetroCluster viene eseguito quando un sito è offline o come attività pianificata per la manutenzione di un intero sito. Il sito rimanente presuppone la proprietà delle risorse storage (dischi e aggregati) del cluster offline e le SVM del sito guasto vengono messe online e riavviate nel sito di disaster recovery, preservando la loro identità completa per l'accesso client e host.</block>
  <block id="4dd2305dcb9d7412784238dd42dcdc21" category="paragraph">Con la sincronizzazione attiva di SnapMirror, poiché entrambe le copie vengono utilizzate contemporaneamente in modo attivo, gli host esistenti continueranno a funzionare. Il NetApp Mediator è necessario per garantire che il failover del sito avvenga correttamente.</block>
  <block id="823bd5c6c005e340599d915e134d851c" category="summary">Panoramica della soluzione VMware vSphere</block>
  <block id="be26d39d86de44047c65c1fed157d529" category="paragraph">VCenter Server Appliance (VCSA) è un potente sistema di gestione centralizzato e un singolo pannello di controllo per vSphere che consente agli amministratori di utilizzare in modo efficace i cluster ESXi. Agevola le funzioni chiave come provisioning delle macchine virtuali, funzionamento di vMotion, alta disponibilità (ha), Distributed Resource Scheduler (DRS), Tanzu Kubernetes Grid e altro ancora. Si tratta di un componente essenziale negli ambienti cloud VMware e deve essere progettato tenendo presente la disponibilità del servizio.</block>
  <block id="8ba8694e23f6560a60d85c4de549122b" category="section-title">Alta disponibilità vSphere</block>
  <block id="4b5543b81af03f01e26fcb74614f7062" category="paragraph">La tecnologia cluster di VMware raggruppa i server ESXi in pool di risorse condivise per le macchine virtuali e offre vSphere High Availability (ha). VSphere ha offre alta disponibilità e facile da utilizzare per le applicazioni eseguite su macchine virtuali. Quando la funzionalità ha è abilitata sul cluster, ogni server ESXi mantiene la comunicazione con altri host in modo che, se un host ESXi non risponde o si isola, il cluster di ha può negoziare il recovery delle macchine virtuali in esecuzione sull'host ESXi tra gli host sopravvissuti nel cluster. In caso di errore del sistema operativo guest, vSphere ha riavvia la macchina virtuale interessata sullo stesso server fisico. VSphere ha consente di ridurre i downtime pianificati, prevenire i downtime non pianificati e eseguire un rapido ripristino in caso di interruzioni.</block>
  <block id="01036edb3159652090a3f7149fe1ce2f" category="paragraph">Cluster vSphere ha in grado di ripristinare le VM dal server guasto.</block>
  <block id="15496c3917565cea1f21bbc7e6eba996" category="image-alt">Diagramma vMSC</block>
  <block id="c1bb7aa3a002a819d935439c7e347826" category="paragraph">È importante comprendere che VMware vSphere non conosce NetApp MetroCluster o SnapMirror Active Sync e vede tutti gli host ESXi nel cluster vSphere come host idonei per le operazioni del cluster ha in base alle configurazioni di affinità dei gruppi VM e host.</block>
  <block id="dcff37ab37f2cb6a72aeb3c30e3ed5aa" category="section-title">Rilevamento errori host</block>
  <block id="7069d861b63dd4095cfb7b2ee30587f5" category="paragraph">Non appena viene creato il cluster ha, tutti gli host nel cluster partecipano alle elezioni e uno degli host diventa un master. Ogni slave esegue heartbeat di rete al master, e il master a sua volta esegue heartbeat di rete su tutti gli host slave. L'host master di un cluster vSphere ha è responsabile del rilevamento del guasto degli host slave.</block>
  <block id="73b629afd8ef39d8d0147696412538c8" category="paragraph">A seconda del tipo di errore rilevato, potrebbe essere necessario eseguire il failover delle macchine virtuali in esecuzione sugli host.</block>
  <block id="e12cf4015a45ff29f1f84ae1a3ee0390" category="paragraph">In un cluster vSphere ha, vengono rilevati tre tipi di errore dell'host:</block>
  <block id="4eac346eb6cdd3a1a98ee9bc71ebccaa" category="list-text">Errore - Un host smette di funzionare.</block>
  <block id="3875a4c584a7715edf4a221ce53d45fc" category="list-text">Isolamento - Un host diventa isolato dalla rete.</block>
  <block id="82fba11358d642111efbcf36273159f2" category="list-text">Partizione - Un host perde la connettività di rete con l'host master.</block>
  <block id="5f72ceebd161159fe623ff01ac0cf1b4" category="paragraph">L'host master monitora gli host slave nel cluster. Questa comunicazione viene fatta attraverso lo scambio di heartbeat di rete ogni secondo. Quando l'host master smette di ricevere questi heartbeat da un host slave, controlla la liveness dell'host prima di dichiarare che l'host non è riuscito. Il controllo liveness che l'ospite principale effettua è di determinare se l'ospite secondario sta scambiando i heartbeat con uno dei datastore. Inoltre, l'host master verifica se l'host risponde ai ping ICMP inviati ai propri indirizzi IP di gestione per rilevare se è semplicemente isolato dal suo nodo master o completamente isolato dalla rete. Per farlo, eseguire il ping del gateway predefinito. È possibile specificare manualmente uno o più indirizzi di isolamento per migliorare l'affidabilità della convalida dell'isolamento.</block>
  <block id="5546466ab10e5cbfbc4b286cd60b8b4a" category="section-title">_Best practice_</block>
  <block id="0456a7ce7bf92fb68980571fdd2defa1" category="paragraph">NetApp consiglia di specificare un minimo di due indirizzi di isolamento aggiuntivi e che ciascuno di questi indirizzi sia locale al sito. Ciò migliorerà l'affidabilità della convalida dell'isolamento.</block>
  <block id="19c262cd1e1bb07c491e359333f04a29" category="section-title">Risposta di isolamento dell'host</block>
  <block id="7a2723aad08de3c674693adf221e4a48" category="paragraph">Risposta di isolamento è un'impostazione in vSphere ha che determina l'azione attivata sulle macchine virtuali quando un host in un cluster vSphere ha perde le connessioni di rete di gestione ma continua a essere eseguito. Sono disponibili tre opzioni per questa impostazione: "Disabilitato", "Arresta e riavvia le macchine virtuali" e "Spegni e riavvia le macchine virtuali".</block>
  <block id="715e310d886b45856c3ab0f69b06241b" category="paragraph">Lo "spegnimento" è migliore dello "spegnimento", che non svuota le modifiche più recenti al disco o esegue il commit delle transazioni. Se le macchine virtuali non si sono arrestate entro 300 secondi, vengono spente. Per modificare il tempo di attesa, utilizzare l'opzione avanzata das.isolationshutdowntimeout.</block>
  <block id="620b4ae663a26c98656d1c81bec1a6c2" category="paragraph">Prima che ha avvii la risposta di isolamento, verifica prima se l'agente master ha vSphere è proprietario del datastore che contiene i file di configurazione della VM. In caso contrario, l'host non attiverà la risposta di isolamento, poiché non vi è alcun master per riavviare le VM. L'host controllerà periodicamente lo stato del datastore per determinare se viene richiesto da un agente vSphere ha che detiene il ruolo master.</block>
  <block id="6824ef1b1c5e58e8ea5ebc8b2cf94be2" category="paragraph">NetApp consiglia di impostare la risposta di isolamento dell'host su Disabilitato.</block>
  <block id="6bd7b146f345eefac88b336a89aa3754" category="paragraph">Una condizione split-brain può verificarsi se un host viene isolato o partizionato dall'host master vSphere ha e il master non è in grado di comunicare tramite datastore heartbeat o tramite ping. Il master dichiara l'host isolato inattivo e riavvia le macchine virtuali su altri host nel cluster. Esiste ora una condizione split-brain perché esistono due istanze della macchina virtuale in esecuzione, una sola delle quali è in grado di leggere o scrivere i dischi virtuali. Le condizioni split-brain possono ora essere evitate configurando VMCP (VM Component Protection).</block>
  <block id="df05a421ed8ba49f97f18dc085495ee4" category="section-title">Protezione dei componenti VM (VMCP)</block>
  <block id="1418d127ee81cc7f3e114029e9ba6856" category="paragraph">Uno dei miglioramenti delle funzionalità di vSphere 6, relativi all'ha, è VMCP. VMCP fornisce una protezione avanzata da APD (All Path Down) e PDL (Permanent Device Loss) per lo storage a blocchi (FC, iSCSI, FCoE) e a file (NFS).</block>
  <block id="fc35e15d00ef5b037a1a56c77ef3e17c" category="section-title">Perdita permanente del dispositivo (PDL)</block>
  <block id="967b20f28092443585be2b9649d0ba93" category="paragraph">PDL è una condizione che si verifica quando un dispositivo di memorizzazione si guasta in modo permanente o viene rimosso amministrativamente e non deve essere restituito. L'array di storage NetApp invia un codice di rilevamento SCSI a ESXi dichiarando che il dispositivo è perso in modo permanente. Nella sezione Condizioni di guasto e Risposta VM di vSphere ha, è possibile configurare la risposta che deve essere dopo il rilevamento di una condizione PDL.</block>
  <block id="7cf4fdbfc8e1deb9f567848f2df19e91" category="paragraph">NetApp consiglia di impostare "Risposta per datastore con PDL" su "*Spegni e riavvia VM*". Quando viene rilevata questa condizione, una VM viene riavviata istantaneamente su un host integro all'interno del cluster vSphere ha.</block>
  <block id="6d623de2ea8c5007def6f2349d9ad8b9" category="section-title">Tutti i percorsi verso il basso (APD)</block>
  <block id="15d2d9b1f25022e7080482582e155265" category="paragraph">APD è una condizione che si verifica quando un dispositivo di archiviazione diventa inaccessibile all'host e non sono disponibili percorsi all'array. ESXi considera questo un problema temporaneo con il dispositivo e si aspetta che diventi nuovamente disponibile.</block>
  <block id="f89caca297ba86d190d90ef30c409ccf" category="paragraph">Quando viene rilevata una condizione APD, viene avviato un timer. Dopo 140 secondi, la condizione APD viene dichiarata ufficialmente e il dispositivo viene contrassegnato come timeout APD. Una volta trascorsi i 140 secondi, ha inizia il conteggio dei minuti specificati nell'APD Delay for VM failover. Una volta trascorso il tempo specificato, ha riavvia le macchine virtuali interessate. È possibile configurare VMCP in modo che risponda in modo diverso, se lo si desidera (Disattivato, Eventi problema o Spegni e riavvia le macchine virtuali).</block>
  <block id="8f179a61d789dab9b994ecd0ca8c53cb" category="paragraph">NetApp consiglia di configurare "Risposta per datastore con APD" su "*Spegni e riavvia le VM (conservative)*".</block>
  <block id="76d29c3c5f57a16a7f080459356c3793" category="paragraph">Conservative si riferisce alla probabilità che ha sia in grado di riavviare le VM. Quando è impostata su Conservative, ha riavvia la VM interessata dall'APD solo se sa che un altro host può riavviarla. In caso di problemi aggressivi, ha tenterà di riavviare la macchina virtuale anche se non conosce lo stato degli altri host. Ciò può comportare il mancato riavvio delle VM se non vi è alcun host con accesso al datastore su cui si trova.</block>
  <block id="c64ef72a18526e28efe7c08b3ff3889a" category="paragraph">Se lo stato APD viene risolto e l'accesso allo storage viene ripristinato prima del termine del timeout, l'ha non riavvia inutilmente la macchina virtuale a meno che non sia stata configurata esplicitamente. Se si desidera una risposta anche quando l'ambiente è stato ripristinato dalla condizione APD, è necessario configurare la risposta per il ripristino APD dopo il timeout APD in modo da ripristinare le VM.</block>
  <block id="580bc3953adcf3e3a20c5497f67f8b2c" category="paragraph">NetApp consiglia di configurare la risposta per il ripristino APD dopo il timeout APD su Disabilitato.</block>
  <block id="a067a9a0e98c97f62fba4698bde30edc" category="section-title">Implementazione VMware DRS per NetApp MetroCluster</block>
  <block id="3bf3e67966e8b0e07b0812dae7b86ce7" category="paragraph">VMware DRS è una funzionalità che aggrega le risorse host in un cluster e viene utilizzata principalmente per il bilanciamento del carico all'interno di un cluster in un'infrastruttura virtuale. VMware DRS calcola principalmente le risorse di CPU e memoria per eseguire il bilanciamento del carico in un cluster. Poiché vSphere non è consapevole del clustering allungato, considera tutti gli host in entrambi i siti durante il bilanciamento del carico. Per evitare il traffico tra siti, NetApp consiglia di configurare le regole di affinità DRS per gestire una separazione logica delle VM. In questo modo si garantisce che, a meno che non si verifichi un errore completo del sito, ha e DRS utilizzino solo host locali.</block>
  <block id="b9e04f46a88c8139fbb91780a2ff9064" category="paragraph">Se si crea una regola di affinità DRS per il cluster, è possibile specificare in che modo vSphere applica tale regola durante il failover di una macchina virtuale.</block>
  <block id="f903d43a0acb7412db93e8201ab12be3" category="paragraph">Esistono due tipi di regole che è possibile specificare il comportamento di failover di vSphere ha:</block>
  <block id="a96c8bab3a450bb828e3093d16f7e32c" category="list-text">Le regole di anti-affinità delle macchine virtuali costringono le macchine virtuali specificate a rimanere separate durante le azioni di failover.</block>
  <block id="1fa3a04279011cbc6001c96c0f6f27fb" category="list-text">Le regole di affinità degli host VM collocano macchine virtuali specifiche su un host specifico o su un membro di un gruppo definito di host durante le azioni di failover.</block>
  <block id="225e3f7204b6e5bf6cd388af7bb16eb4" category="paragraph">Utilizzando le regole di affinità degli host delle macchine virtuali in VMware DRS, si può avere una separazione logica tra il sito A e il sito B in modo che la macchina virtuale venga eseguita sull'host nello stesso sito dell'array configurato come controller di lettura/scrittura principale per un determinato datastore. Inoltre, le regole di affinità degli host delle macchine virtuali consentono alle macchine virtuali di rimanere locali rispetto allo storage, il che a sua volta determina la connessione della macchina virtuale in caso di errori di rete tra i siti.</block>
  <block id="db03e2255e35df6fa9719c800850c397" category="paragraph">Di seguito è riportato un esempio di gruppi di host VM e regole di affinità.</block>
  <block id="d400b2cf908bc5f979847146ff8ac816" category="paragraph">NetApp consiglia di implementare le regole "should" invece di quelle "must", in quanto vengono violate da vSphere ha in caso di errore. L'utilizzo di regole "must" può potenzialmente causare interruzioni del servizio.</block>
  <block id="e9503bc9ad84f6517ddc938c85541dd5" category="paragraph">La disponibilità dei servizi dovrebbe sempre prevalere sulle prestazioni. Nello scenario in cui si verifica un guasto di un data center completo, le regole "must" devono scegliere gli host dal gruppo di affinità degli host VM e, quando il data center non è disponibile, le macchine virtuali non verranno riavviate.</block>
  <block id="b3c45603f3738ac1e1f8e1e87569c00c" category="section-title">Implementazione di VMware Storage DRS con NetApp MetroCluster</block>
  <block id="4669dbcf4d42583b3fae1c79fa228078" category="paragraph">Il controllo i/o dello storage è abilitato per impostazione predefinita sui cluster DRS abilitati per Storage DRS. Il controllo i/o dello storage consente a un amministratore di controllare la quantità di i/o dello storage allocata alle macchine virtuali nei periodi di congestione dell'i/o e di conseguenza le macchine virtuali più importanti possono preferire le macchine virtuali meno importanti per l'allocazione delle risorse i/O.</block>
  <block id="f06483bf36a941eebbb2f78a89b6bf68" category="paragraph">Storage DRS utilizza Storage vMotion per migrare le macchine virtuali in datastore diversi all'interno di un cluster di datastore. In un ambiente NetApp MetroCluster, la migrazione di una macchina virtuale deve essere controllata all'interno dei datastore di quel sito. Ad esempio, la macchina virtuale A, in esecuzione su un host nel sito A, dovrebbe idealmente migrare all'interno dei datastore della SVM nel sito A. In caso contrario, la macchina virtuale continuerà a funzionare ma con prestazioni ridotte, poiché la lettura/scrittura del disco virtuale avverrà dal sito B attraverso collegamenti tra siti.</block>
  <block id="2438f6a80b933cf058ad052d26ac0703" category="paragraph">La clonazione di un oggetto storage consente di creare rapidamente copie da utilizzare ulteriormente, ad esempio il provisioning di macchine virtuali aggiuntive, operazioni di backup/recovery e così via.</block>
  <block id="1a795345e422d7dbcca8fe38671a9371" category="summary">Linee guida per la progettazione e l'implementazione di vMSC.</block>
  <block id="b73deaadc37ea1c7a13ad17af6730c42" category="doc">Linee guida per la progettazione e l'implementazione di vMSC</block>
  <block id="3512760e2d3fc1a9dd2116e83bb0cada" category="paragraph">Questo documento delinea le linee guida di progettazione e implementazione per vMSC con i sistemi di storage ONTAP.</block>
  <block id="556669df5b5073ab3d2ddcf638e942d9" category="section-title">Configurazione dello storage NetApp</block>
  <block id="7f4d4fbe08a8a895671d05c4a82b0c85" category="inline-link">Documentazione MetroCluster</block>
  <block id="002eb41870df47521a2b59424d251f60" category="inline-link">Panoramica di SnapMirror Business Continuity</block>
  <block id="447566f62201eb825a1f6fb7a570873f" category="paragraph">Una volta configurato MetroCluster, gestirlo è come gestire un ambiente ONTAP tradizionale. Puoi configurare Storage Virtual Machine (SVM) utilizzando vari strumenti come l'interfaccia a riga di comando (CLI), System Manager o Ansible. Una volta configurate le SVM, occorre creare nel cluster interfacce logiche (LIF), volumi e LUN (Logical Unit Number) da utilizzare per le normali operazioni. Questi oggetti verranno replicati automaticamente sull'altro cluster utilizzando la rete di peering del cluster.</block>
  <block id="b5486be95ed9ae2e4681a39cf8fe8041" category="inline-link">Panoramica dei gruppi di coerenza</block>
  <block id="57166da54d8751e1ed084f00b3f169e3" category="section-title">Creare un cluster vSphere ha</block>
  <block id="829006223e7bdcfd478d2261f1d5ac40" category="inline-link">Come creare e configurare i cluster nel client vSphere su docs.vmware.com</block>
  <block id="2bbae4763835d2e2dd123c1b4b0ae73d" category="paragraph">La creazione di un cluster vSphere ha è un processo in più fasi documentato all'indirizzo<block ref="dd51ccd863dd3c9fbca770681f8e68a9" category="inline-link-rx"></block>. In poche parole, devi prima creare un cluster vuoto, quindi, utilizzando vCenter, devi aggiungere host e specificare l'ha vSphere del cluster e le altre impostazioni.</block>
  <block id="d50e63b9f70efedde8dc093be8ec12b2" category="inline-link">Procedure consigliate per VMware vSphere Metro Storage Cluster</block>
  <block id="950954623b197b80e3ebb95b0adcc3de" category="paragraph">Per configurare un cluster ha, completare i seguenti passaggi:</block>
  <block id="1073102bd8c6cbd17340f2a19043583f" category="list-text">Connettersi all'interfaccia utente di vCenter.</block>
  <block id="ebf69ea3a3e34739bde13d589e85ef10" category="list-text">In host e cluster, individuare il data center in cui si desidera creare il cluster ha.</block>
  <block id="d8fd85bbc0cd4746e5d80e291696b86c" category="list-text">Fare clic con il pulsante destro del mouse sull'oggetto del data center e selezionare nuovo cluster. In base alle nozioni di base, assicurarsi di aver abilitato vSphere DRS e vSphere ha. Completare la procedura guidata.</block>
  <block id="f2c634ca704e26f96be1723db6dda32a" category="image-alt">Schermata della descrizione di un computer generata automaticamente</block>
  <block id="f4f59bf1e324854573172ca2b5070d45" category="list-text">Selezionare il cluster e accedere alla scheda di configurazione. Selezionare vSphere ha e fare clic su Modifica.</block>
  <block id="329c69e52a7de6215aa4dbfa19940f2d" category="list-text">In monitoraggio host, selezionare l'opzione attiva monitoraggio host.</block>
  <block id="9fc231ac455a53f2fabc59f29ab537ad" category="list-text">Nella scheda guasti e risposte, in monitoraggio VM, selezionare l'opzione solo monitoraggio VM o monitoraggio VM e applicazione.</block>
  <block id="58aea8c81a7e8b8160584574af309fbb" category="list-text">In controllo ammissione, impostare l'opzione di controllo ammissione ha su Cluster Resource Reserve; utilizzare 50% CPU/MEM.</block>
  <block id="d94a9f01bee7dcc2643864bf92ab4e59" category="list-text">Fare clic su "OK".</block>
  <block id="3f059eee365aa5c64c0be1d6dba81d69" category="list-text">Selezionare DRS e fare clic su MODIFICA.</block>
  <block id="7b5f9be03fd1421a9da56c2c7677ad69" category="list-text">Impostare il livello di automazione su manuale, a meno che non sia richiesto dalle applicazioni.</block>
  <block id="a8ee10582e28e3623629963a88ff5ec9" category="image-alt">vmsc 3 5</block>
  <block id="256164bb48582e5267e408f2e67e1939" category="inline-link">docs.vmware.com</block>
  <block id="91fb89f03b846483f7108d3f1bfb0156" category="list-text">Abilitare la protezione dei componenti VM, fare riferimento a.<block ref="fc88c93ad20ad804a211f4e6fea63e56" category="inline-link-rx"></block>.</block>
  <block id="918c2d8e02dbd2c1f4cc3a0062690387" category="list-text">Le seguenti impostazioni aggiuntive di vSphere ha sono consigliate per vMSC con MCC:</block>
  <block id="d64ed3e9c10229648e069f56e32f4c8e" category="cell">Risposta</block>
  <block id="f3c1d0e4118d5d9501e1a7aeed19d224" category="cell">Errore host</block>
  <block id="45d583cd5692c76d45e96536edce2a0e" category="cell">Riavviare le VM</block>
  <block id="1c3a7ae924920b573baede481becd22f" category="cell">Isolamento degli host</block>
  <block id="2e011e74abc75a2823c627b7ee9e22a7" category="cell">Datastore con perdita permanente di dispositivi (PDL)</block>
  <block id="49476a1ad365d5f8deb36464de7fe33b" category="cell">Spegnere e riavviare le macchine virtuali</block>
  <block id="e7bbd35db169028c75e7c8ae655bf6ae" category="cell">Datastore con tutti i percorsi verso il basso (APD)</block>
  <block id="e7480b00a5e3efd904a08ca88804de45" category="cell">L'ospite non batte il cuore</block>
  <block id="e8896c595f3effde37ef29d7c6233703" category="cell">Ripristinare le VM</block>
  <block id="59695df3d45a3a21b8ff0bf57fda6a2b" category="cell">Policy di riavvio della VM</block>
  <block id="a150f56b87fd99bf9bf019f8447ba68b" category="cell">Determinato dall'importanza della VM</block>
  <block id="370a480458a8c63a838940f1241e14ee" category="cell">Risposta per l'isolamento dell'host</block>
  <block id="11f30f9be08cd4f9e500290222ddc552" category="cell">Arrestare e riavviare le VM</block>
  <block id="fb53fafa45c0de9bd41d368c7455c9f1" category="cell">Risposta per il datastore con PDL</block>
  <block id="d7c3b9f5568eb60f08076b29490afcaf" category="cell">Risposta per datastore con APD</block>
  <block id="423b2d98eae113ae3391aa0b12f11935" category="cell">Spegnere e riavviare le macchine virtuali (conservative)</block>
  <block id="132bbe6dbceb01227dba5ab04db7202b" category="cell">Ritardo del failover delle macchine virtuali per APD</block>
  <block id="8d15ed7d27d83ed6229a66b1f44b7696" category="cell">3 minuti</block>
  <block id="8c7b0644547f0ee3fe537e8ba441566d" category="cell">Risposta per il ripristino APD con timeout APD</block>
  <block id="4dea08318b2824f845e9b889a6e17778" category="cell">Sensibilità di monitoraggio VM</block>
  <block id="f535a28adc173e28610c129d0dc578ae" category="cell">Preimpostazione alta</block>
  <block id="83164803a765d1ea1f10d50dfdd26130" category="section-title">Configurare gli archivi dati per Heartbeating</block>
  <block id="22c81b09ec3086b2dce8f68867a221e0" category="paragraph">VSphere ha utilizza i datastore per monitorare gli host e le macchine virtuali in caso di guasto alla rete di gestione. È possibile configurare in che modo vCenter seleziona i datastore heartbeat. Per configurare gli archivi dati per il heartbeat, completare i seguenti passaggi:</block>
  <block id="64809e5386c9dc53f894f772f27d1b44" category="list-text">Nella sezione Heartbeating del datastore, selezionare Usa archivi dati dall'elenco specificato e completare automaticamente se necessario.</block>
  <block id="fc66ba7317ceb4220dc88aa267db085d" category="list-text">Seleziona i datastore che desideri utilizzare vCenter da entrambi i siti e premi OK.</block>
  <block id="1d2b14769d080b9214d9e407dfc92a64" category="section-title">Configurare le opzioni avanzate</block>
  <block id="a9316d69e5abcfaffc56fc8f5e645412" category="paragraph">Gli eventi di isolamento si verificano quando gli host all'interno di un cluster ha perdono la connettività alla rete o ad altri host nel cluster. Per impostazione predefinita, vSphere ha utilizzerà il gateway predefinito per la propria rete di gestione come indirizzo di isolamento predefinito. Tuttavia, è possibile specificare indirizzi di isolamento aggiuntivi per l'host al ping per determinare se deve essere attivata una risposta di isolamento. Aggiungere due IP di isolamento in grado di eseguire il ping, uno per sito. Non utilizzare l'indirizzo IP del gateway. L'impostazione avanzata vSphere ha utilizzata è das.isolationaddress. A tale scopo, è possibile utilizzare gli indirizzi IP ONTAP o Mediator.</block>
  <block id="3f44bb4a3b9420d495e400b9afbda2c7" category="paragraph">L'aggiunta di un'impostazione avanzata denominata das.heartbeatDsPerHost può aumentare il numero di datastore heartbeat. Utilizzare quattro datastore heartbeat (HB DSS), due per sito. Utilizzare l'opzione "Select from List but complent" (Seleziona da elenco ma complimento). Questo è necessario perché se un sito non funziona, è necessario ancora due HB DSS. Tuttavia, questi elementi non devono essere protetti con la sincronizzazione attiva di MCC o SnapMirror.</block>
  <block id="eaa1dfe3982e06655ce64e240c139b81" category="paragraph">Affinità con VMware DRS per NetApp MetroCluster</block>
  <block id="e32221c52eb3b0bbeb3ca79aad6c90f6" category="paragraph">In questa sezione vengono creati gruppi DRS per VM e host per ciascun sito/cluster nell'ambiente MetroCluster. Quindi configuriamo le regole VM\host per allineare l'affinità dell'host VM con le risorse di storage locali. Ad esempio, il sito A fa parte del gruppo VM sitea_VM e gli host del sito A appartengono al gruppo host sitea_hosts. Successivamente, in VM\host Rules, si afferma che sitea_vm deve essere eseguito sugli host in sitea_hosts.</block>
  <block id="5bfa0d712f66aef47f8a2ea582bc0b72" category="list-text">NetApp consiglia vivamente la specifica *deve essere eseguita sugli host nel gruppo* piuttosto che sulla specifica *deve essere eseguita sugli host nel gruppo*. In caso di guasto dell'host del sito A, è necessario riavviare le macchine virtuali del sito A sugli host del sito B attraverso vSphere ha, ma quest'ultima specifica non consente all'ha di riavviare le macchine virtuali sul sito B perché è una regola rigida. La specifica precedente è una regola debole e viene violata in caso di ha, abilitando in tal modo la disponibilità anziché le prestazioni.</block>
  <block id="cc6a363013bd2a8c1e05304f1c6abd79" category="inline-link">Monitoraggio e performance di vSphere</block>
  <block id="124de7d2bc72d75be9e481c1cc56ada2" category="section-title">Creare gruppi host DRS</block>
  <block id="0759e9476d3bf1868f88356025adafb2" category="paragraph">Per creare gruppi di host DRS specifici per il sito A e il sito B, attenersi alla seguente procedura:</block>
  <block id="a69dff3dd4b284f60243dfd62fa4e57f" category="list-text">Nel client web vSphere, fare clic con il pulsante destro del mouse sul cluster nell'inventario e selezionare Impostazioni.</block>
  <block id="a130b4af254ead99e9ea83044e54ea1d" category="list-text">Fare clic su VM\host Groups.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Fare clic su Aggiungi.</block>
  <block id="62c4d1538f957af2951f2c93ee191d0b" category="list-text">Digitare il nome del gruppo (ad esempio, sitea_hosts).</block>
  <block id="df22605898fc890edbcb2a126aa202ce" category="list-text">Dal menu tipo, selezionare Gruppo host.</block>
  <block id="57c0028584902f6cee210dcc13bc9745" category="list-text">Fare clic su Aggiungi e selezionare gli host desiderati dal sito A, quindi fare clic su OK.</block>
  <block id="583e6d8c3b1006b0561d4b360e58994f" category="list-text">Ripetere questi passaggi per aggiungere un altro gruppo di host per il sito B.</block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Fare clic su OK.</block>
  <block id="154964ee7fc6d3261ec55811b0ff9972" category="section-title">Creare gruppi DRS VM</block>
  <block id="40c1eaba5f178f243c57b595b6af4d5e" category="paragraph">Per creare gruppi di macchine virtuali DRS specifici per il sito A e il sito B, attenersi alla seguente procedura:</block>
  <block id="9a209a741c26968fc13ed8192523df15" category="list-text">Digitare il nome del gruppo (ad esempio, sitea_vm).</block>
  <block id="f947c7c9f173289b1c2565b3297095f0" category="list-text">Dal menu tipo, selezionare Gruppo VM.</block>
  <block id="40a2a21a084c8d16395113cb79a19ebb" category="list-text">Fare clic su Add (Aggiungi) e selezionare le VM desiderate dal sito A, quindi fare clic su OK.</block>
  <block id="e2e7af699096077fe178ebf021fb2273" category="section-title">Crea regole host VM</block>
  <block id="0a6075f3d3fdbe7c133268face0f5c82" category="paragraph">Per creare regole di affinità DRS specifiche per il sito A e il sito B, completare i seguenti passaggi:</block>
  <block id="df4f9bcca0ceb7a67ba25d886a18743b" category="list-text">Fare clic su VM\host Rules.</block>
  <block id="876a25c102b5c301814921d1a9c0e625" category="list-text">Digitare il nome della regola (ad esempio, sitea_Affinity).</block>
  <block id="d4b5f57f4e2bd5c357ad9b1fbdc2cf8e" category="list-text">Verificare che l'opzione Enable Rule (attiva regola) sia selezionata.</block>
  <block id="d1169f525bd934df7f1a7e3bcf401997" category="list-text">Dal menu Type (tipo), selezionare Virtual Machines to hosts (macchine virtuali a host).</block>
  <block id="77328c16c697ce1d6c036c3f950e7542" category="list-text">Selezionare il gruppo VM (ad esempio, sitea_vm).</block>
  <block id="b36943ce975d4c5c6e9481a4ca396270" category="list-text">Selezionare il gruppo host (ad esempio, sitea_hosts).</block>
  <block id="32fbcb32cfae9a0656233943c28f7c94" category="list-text">Ripetere questi passaggi per aggiungere un'altra VM\regola host per il sito B.</block>
  <block id="488f70e76f3c9ddf155b693e31c5a1e1" category="paragraph">Per configurare un cluster di datastore per ciascun sito, attenersi alla seguente procedura:</block>
  <block id="1dfbc2b980c0b56a5d9889c6d9a25460" category="list-text">Utilizzando il client web vSphere, individuare il data center in cui risiede il cluster ha in Storage.</block>
  <block id="dfc332b252ad3de167b6a336d7e70d46" category="list-text">Fare clic con il pulsante destro del mouse sull'oggetto del data center e selezionare Storage &gt; New Datastore Cluster.</block>
  <block id="829b62dbd6a4923b66591b2bff38ed5b" category="list-text">Selezionare il cluster ha e fare clic su Next.</block>
  <block id="30fe6cfa0a4c5fb23fccfe149cefc006" category="list-text">Selezionare gli archivi dati appartenenti al sito A e fare clic su Avanti.</block>
  <block id="4ea461b22638db4c94aa076d62a2065f" category="list-text">Rivedere le opzioni e fare clic su fine.</block>
  <block id="7b79e97caff76847cf350f1197c49953" category="list-text">Ripetere questa procedura per creare il cluster di datastore del sito B e verificare che siano selezionati solo i datastore del sito B.</block>
  <block id="d8f83b09bd6b864f22076c109cfaae66" category="section-title">Disponibilità di vCenter Server</block>
  <block id="605b8c1efcf2de9164e5d5425c67bdcd" category="paragraph">Le appliance vCenter Server (VCSA) devono essere protette con vCenter ha. VCenter ha ti consente di implementare due VCSA in una coppia ha Active-passive. Uno in ogni dominio di errore. Puoi leggere ulteriori informazioni su vCenter ha all'indirizzo<block ref="173ca8434bdf39dd0a60efe576d066cd" category="inline-link-rx"></block>.</block>
  <block id="70901a02a148fd2dfc1ff5736f4f5336" category="list-text">Separare il traffico di rete dello storage dalle altre reti. È possibile ottenere una rete separata utilizzando una VLAN dedicata o switch separati per lo storage. Se la rete di storage condivide percorsi fisici come gli uplink, potrebbe essere necessario QoS o porte di uplink aggiuntive per garantire una larghezza di banda sufficiente. Non connettere gli host direttamente allo storage; utilizzare gli switch per disporre di percorsi ridondanti e consentire a VMware ha di funzionare senza alcun intervento. Vedere <block ref="2d54da766c3f840b00eab5923273fca5" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="59cfc5aaa0678bcb883492b4397c71b8" category="cell">Sì (ONTAP 9.14.1)</block>
  <block id="a58c81d13cac4e9b37bba2bd7fc3a93d" category="paragraph">L'hypervisor vSphere leader del settore di VMware può essere implementato come cluster stretched indicato come vSphere Metro Storage Cluster (vMSC).</block>
  <block id="e3224e391e08365c1593c07b9fe99cfa" category="section-title">Soluzioni di disponibilità continua per ambienti vSphere</block>
  <block id="ffa76ec5527e36c51f49fe091541cca6" category="paragraph">NetApp MetroCluster utilizza la funzione di ha (failover del controller o CFO) di NetApp per la protezione dai guasti dei controller. Include inoltre la tecnologia SyncMirror locale, il failover cluster in caso di disastro (failover controller on-demand o CFOD), la ridondanza hardware e la separazione geografica per ottenere livelli elevati di disponibilità. SyncMirror esegue il mirroring sincrono dei dati tra le due metà della configurazione MetroCluster scrivendo i dati su due plessi: Il plesso locale (sullo shelf locale) fornendo attivamente i dati e il plesso remoto (sullo shelf remoto) normalmente non fornendo i dati. La ridondanza hardware viene implementata per tutti i componenti MetroCluster, come controller, storage, cavi, switch (utilizzati con Fabric MetroCluster) e adattatori.</block>
  <block id="d3e911c902a6b066f9c31d471d16fb21" category="paragraph">Per creare un cluster VMware ha/DRS su due siti, gli host ESXi vengono utilizzati e gestiti da un'appliance vCenter Server (VCSA). Le reti di gestione vSphere, vMotion® e delle macchine virtuali sono collegate tramite una rete ridondante tra i due siti. VCenter Server che gestisce il cluster ha/DRS può connettersi agli host ESXi in entrambi i siti e deve essere configurato utilizzando vCenter ha.</block>
  <block id="da76be2bc20d4e043d9a2019b817214f" category="inline-link">Come creare e configurare i cluster nel client vSphere</block>
  <block id="e02f3e9258a23204655bd512ec53911d" category="paragraph">Fare riferimento a.<block ref="c06ae090600e7aa086edfa28514435e7" category="inline-link-rx"></block> Per configurare vCenter ha.</block>
  <block id="38910d3dab2318849fd5f1a1dfbe0152" category="inline-link">Guida alla compatibilità dello storage VMware</block>
  <block id="838b66b875df1b432ac420a98cba3db6" category="paragraph">Per ulteriori informazioni sulle linee guida di progettazione per vSphere Metro Storage Cluster, consultare la seguente documentazione:</block>
  <block id="07aaf2aebfd07b8763284018d1ebbf57" category="inline-link">Supporto di VMware vSphere con NetApp MetroCluster</block>
  <block id="a4a5fd5b00daf98bd381d80257378acd" category="list-text"><block ref="a4a5fd5b00daf98bd381d80257378acd" category="inline-link-rx"></block></block>
  <block id="c3dc11e39d996a00b095022f4e56583d" category="inline-link">Supporto di VMware vSphere con business continuity di NetApp SnapMirror</block>
  <block id="8f675397d9c0ef95aa8b3f0ada9d601a" category="list-text"><block ref="f53214cfd764fa0267c92323be0d7337" category="inline-link-rx"></block> (Adesso noto come SnapMirror Active Sync)</block>
  <block id="ee0a206d2287c89b2a7b780e07929b81" category="paragraph">A seconda delle considerazioni sulla latenza, NetApp MetroCluster può essere implementato in due diverse configurazioni da utilizzare con vSphere:</block>
  <block id="b553530def78406c0977f70d5e90b9e8" category="list-text">Stretch MetroCluster</block>
  <block id="2d90abe978ed8084d304295ad0a8c8fd" category="list-text">Fabric MetroCluster</block>
  <block id="b03023e82bda6a71adc49c4834e3b6ab" category="paragraph">Di seguito viene illustrato uno schema topologico di alto livello di Stretch MetroCluster.</block>
  <block id="b0c20dc8226bb49f35f0f68f7ef77bba" category="image-alt">Diagramma vMSC con MCC</block>
  <block id="119be031ef4485d20c7683d291d0e9f6" category="inline-link">Documentazione MetroCluster</block>
  <block id="ad9122c6d75ebaa024669fde1c0bdfb8" category="paragraph">Fare riferimento a.<block ref="d8a206747dbcec13122724b2aee18957" category="inline-link-rx"></block> Per informazioni specifiche sulla progettazione e la distribuzione di MetroCluster.</block>
  <block id="b47354fcd7d17ab4fbb3283f71677efe" category="paragraph">SnapMirror Active Sync può anche essere implementato in due modi diversi.</block>
  <block id="314084a577b998d8089dff72c98c58b0" category="list-text">Asimmetrico</block>
  <block id="bca8b52c503406abc3e9e50c5352d0a2" category="paragraph">In questo documento viene presentata la soluzione ONTAP per VMware Site Recovery Manager (SRM), il software di disaster recovery (DR) leader del settore di VMware, che include le informazioni più recenti sui prodotti e le Best practice per semplificare la distribuzione, ridurre i rischi e semplificare la gestione continua.</block>
  <block id="4f46fffb0ac7017fd2b42c10d6aa03fc" category="paragraph">Il backup delle macchine virtuali e il loro rapido ripristino sono tra i grandi punti di forza di ONTAP per vSphere ed è facile gestirla all'interno di vCenter con il plug-in SnapCenter per VMware vSphere.</block>
  <block id="b69cd5a82aaf0c524a71d46ec6fdd29c" category="cell">Il trunking di sessione NFS v4,1 richiede ONTAP 9.14.1 e versioni successive</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">Il plug-in è anche l'interfaccia di gestione per molte funzioni del provider VASA per ONTAP, supportando la gestione basata su policy di storage con vVol. Una volta registrati i tool ONTAP per VMware vSphere, utilizzali per creare profili di capacità storage, mapparli allo storage e garantire la conformità dei datastore con i profili nel tempo. Il provider VASA fornisce anche un'interfaccia per creare e gestire datastore vVol.</block>
  <block id="d9c9eb44a58ee1ce90daa68527aa8930" category="summary">Scenari di errore per vMSC con MCC</block>
  <block id="e7c7574b0826c9074f480de76c889ba8" category="paragraph">Nelle sezioni seguenti vengono illustrati i risultati attesi da vari scenari di guasto con i sistemi vMSC e NetApp MetroCluster.</block>
  <block id="c8a2eebb480fef69e6ed917ea7f7a9d3" category="section-title">Errore singolo percorso di storage</block>
  <block id="b99e8e694b032f593bbd01f6205b4a98" category="paragraph">In questo scenario, se componenti come la porta HBA, la porta di rete, la porta dello switch dati front-end o un cavo FC o Ethernet si guastano, quel particolare percorso al dispositivo di storage viene contrassegnato come inattivo dall'host ESXi. Se vengono configurati diversi percorsi per il dispositivo storage fornendo resilienza alla porta HBA/rete/switch, ESXi esegue uno switchover del percorso. Durante questo periodo, le macchine virtuali rimangono in esecuzione senza alcun impatto, perché la disponibilità dello storage viene garantita attraverso l'offerta di più percorsi al dispositivo di storage.</block>
  <block id="80fc15dd1deb985234440745e8a78d4c" category="paragraph">Negli ambienti in cui vengono utilizzati volumi NFS/iSCSI, NetApp consiglia di avere almeno due uplink di rete configurati per la porta vmkernel NFS nel vSwitch standard e lo stesso nel gruppo di porte in cui è mappata l'interfaccia vmkernel NFS per il vSwitch distribuito. Il raggruppamento NIC può essere configurato in modalità Active-Active o Active-standby.</block>
  <block id="0c8694e8ef7f8935edbfac605753bc95" category="paragraph">Inoltre, per i LUN iSCSI, il multipathing deve essere configurato legando le interfacce vmkernel agli adattatori di rete iSCSI. Per ulteriori informazioni, fai riferimento alla documentazione dello storage vSphere.</block>
  <block id="0fc808fdb968eb089fbc5124c0a8e15a" category="paragraph">Negli ambienti in cui vengono utilizzate le LUN Fibre Channel, NetApp consiglia di disporre di almeno due HBA, che garantiscono resilienza a livello di HBA/porta. NetApp consiglia inoltre di utilizzare lo zoning a destinazione singola come Best practice per la configurazione dello zoning.</block>
  <block id="238c3d1c7bf8b5b42237392383a4c7ab" category="paragraph">È necessario utilizzare Virtual Storage Console (VSC) per impostare policy di multipathing, perché imposta policy per tutti i dispositivi storage NetApp nuovi ed esistenti.</block>
  <block id="217811709dfb096c78e73934de01271c" category="section-title">Errore host ESXi singolo</block>
  <block id="93bc89a0478478dd84d8159a18f6c1a2" category="image-alt">Errore di un singolo host.</block>
  <block id="15023af3b440b4004f509e961bfe1e30" category="paragraph">In questo scenario, se si verifica un guasto dell'host ESXi, il nodo master nel cluster VMware ha rileva il guasto dell'host in quanto non riceve più gli heartbeat di rete. Per determinare se l'host è effettivamente inattivo o solo una partizione di rete, il nodo master monitora gli heartbeat del datastore e, se sono assenti, esegue un controllo finale eseguendo il ping degli indirizzi IP di gestione dell'host guasto. Se tutti questi controlli sono negativi, il nodo master dichiara l'host un host guasto e tutte le macchine virtuali in esecuzione su questo host guasto vengono riavviate sull'host rimasto nel cluster.</block>
  <block id="9a11158d52f71012ae8722b09bf8bf29" category="paragraph">Se sono state configurate le regole di affinità per DRS VM e host (le VM nel gruppo VM sitea_VM devono eseguire gli host nel gruppo host sitea_hosts), il master ha controlla prima le risorse disponibili nel sito A. Se non ci sono host disponibili nel sito A, il master tenta di riavviare le VM sugli host nel sito B.</block>
  <block id="7922c92ff860eb0508dc8cc8aae3ffdd" category="paragraph">È possibile che le macchine virtuali vengano avviate sugli host ESXi nell'altro sito se è presente un vincolo di risorse nel sito locale. Tuttavia, le regole di affinità definite per DRS VM e host verranno corrette in caso di violazione di regole mediante la migrazione delle macchine virtuali a qualsiasi host ESXi rimasto nel sito locale. Nei casi in cui DRS è impostato su manuale, NetApp consiglia di richiamare DRS e applicare le raccomandazioni per correggere il posizionamento della macchina virtuale.</block>
  <block id="387b5a49326be3a47e081682e75e19b4" category="paragraph">In questo scenario, non vi sono cambiamenti nel comportamento di MetroCluster e tutti i datastore continuano a essere intatti dai rispettivi siti.</block>
  <block id="a11ffa7d20dab792fe5aa9c27017493e" category="section-title">Isolamento dell'host ESXi</block>
  <block id="17e01652089acd413e26ea89cf98a2b8" category="image-alt">Isolamento dell'host ESXi</block>
  <block id="8a4b746274e9d7129602d54434624806" category="paragraph">In questo scenario, se la rete di gestione dell'host ESXi non è attiva, il nodo master nel cluster ha non riceverà alcun heartbeat, pertanto l'host viene isolato nella rete. Per determinare se si è verificato un errore o se è solo isolato, il nodo master inizia a monitorare l'heartbeat del datastore. Se è presente, l'host viene dichiarato isolato dal nodo master. A seconda della risposta di isolamento configurata, l'host può scegliere di spegnere, spegnere le macchine virtuali o persino lasciare accese le macchine virtuali. L'intervallo predefinito per la risposta di isolamento è di 30 secondi.</block>
  <block id="a070f7923919fed39772c5d3f91bf482" category="section-title">Guasto a shelf di dischi</block>
  <block id="e8acf0e4f25cdd641c9a047482d56ba5" category="paragraph">In questo scenario, si verifica un errore di più di due dischi o di un intero shelf. I dati vengono distribuiti dal plesso restante senza alcuna interruzione dei servizi dati. Il guasto del disco potrebbe influire su un plesso locale o remoto. Gli aggregati vengono visualizzati come modalità degradata perché è attivo un solo plesso. Una volta sostituiti i dischi guasti, gli aggregati interessati si risincronizzano automaticamente per ricostruire i dati. Dopo la risincronizzazione, gli aggregati tornano automaticamente alla normale modalità con mirroring. Se più di due dischi all'interno di un singolo gruppo RAID si sono guastati, il plex deve essere ricostruito da zero.</block>
  <block id="4f90d34a41c7ebc83024a5e3ca35ff3a" category="image-alt">Guasto a un singolo shelf di dischi.</block>
  <block id="1c872dcd4bcebb1d7567f383901dfc0d" category="section-title">Guasto a un singolo storage controller</block>
  <block id="68badb604dbd29653979fdc7083cbffe" category="paragraph">In questo scenario, uno dei due storage controller si guasta in un solo sito. Poiché è presente una coppia ha in ciascun sito, un guasto di un nodo attiva automaticamente il failover sull'altro nodo. Ad esempio, in caso di guasto al nodo A1, il relativo storage e carichi di lavoro vengono trasferiti automaticamente al nodo A2. Le macchine virtuali non saranno interessate perché tutti i plessi rimangono disponibili. I nodi del secondo sito (B1 e B2) non sono interessati. Inoltre, vSphere ha non intraprenderà alcuna azione perché il nodo master nel cluster riceverà comunque gli heartbeat di rete.</block>
  <block id="0ac25682ea568511724f2e0819127d89" category="image-alt">Guasto a un singolo nodo</block>
  <block id="e7b4c0523308b3fd46189b6ab4867fe5" category="paragraph">Se il failover fa parte di un rolling disaster (il nodo A1 esegue il failover su A2) e si verifica un successivo guasto di A2 o il guasto completo del sito A, è possibile eseguire lo switchover in seguito a un disastro nel sito B.</block>
  <block id="7b590b52d9f3d4d40cda67758ff92ba1" category="section-title">Errori del collegamento interswitch</block>
  <block id="9df08f82abe35d87c6f7c96b18dab755" category="section-title">Errore collegamento interswitch sulla rete di gestione</block>
  <block id="ed0711cbc7a050952e0e370bab079bff" category="image-alt">Errore del collegamento interswitch sulla rete di gestione</block>
  <block id="a32c6c77bb8d407cf5825aec175bab4b" category="paragraph">In questo scenario, se i collegamenti ISL nella rete di gestione host front-end si guastano, gli host ESXi nel sito A non saranno in grado di comunicare con gli host ESXi nel sito B. Ciò determina una partizione di rete poiché gli host ESXi in un determinato sito non sono in grado di inviare gli heartbeat di rete al nodo master nel cluster ha. Come tale, ci saranno due segmenti di rete a causa della partizione e vi sarà un nodo master in ogni segmento che proteggerà le VM da guasti host all'interno del sito specifico.</block>
  <block id="628309883a8d1307131d205b200c56ae" category="section-title">Errore collegamento interswitch sulla rete di storage</block>
  <block id="a9da7e2a43bcea673a22b949355e619d" category="image-alt">Errore collegamento interswitch sulla rete di storage</block>
  <block id="625db96c5ee1e9b5197b6cb3c1715021" category="paragraph">In questo scenario, se si verifica un errore nei collegamenti ISL nella rete di storage backend, gli host sul sito A perderanno l'accesso ai volumi di storage o alle LUN del cluster B nel sito B e viceversa. Le regole VMware DRS sono definite in modo che l'affinità tra il sito host e il sito di storage faciliti l'esecuzione delle macchine virtuali senza impatti all'interno del sito.</block>
  <block id="8d9609f32cbee8fa5080f95d71a2a142" category="paragraph">Durante questo periodo, le macchine virtuali rimangono in esecuzione nei rispettivi siti e in questo scenario non si verifica alcuna modifica nel comportamento di MetroCluster. Tutti i datastore continuano a essere intatti dai rispettivi siti.</block>
  <block id="719831bfdda20be14c04e2b165cce85e" category="paragraph">Se per qualche motivo è stata violata la regola di affinità (ad esempio VM1, che doveva essere eseguito dal sito A in cui i dischi risiedono sui nodi del cluster locale A vengono eseguiti su un host nel sito B), il disco della macchina virtuale può essere acceduto in remoto tramite i link ISL. A causa di un errore del collegamento ISL, VM1 in esecuzione nel sito B non sarebbe in grado di scrivere sui propri dischi perché i percorsi del volume di storage non sono attivi e quella particolare macchina virtuale non è attiva. In queste situazioni, VMware ha non intraprende alcuna azione poiché gli host stanno inviando heartbeat. Tali macchine virtuali devono essere spente e attivate manualmente nei rispettivi siti. La figura seguente illustra una VM che viola una regola di affinità DRS.</block>
  <block id="09ba89b1ea49214c15fbf8ea6f129cb0" category="image-alt">Una VM che viola una regola di affinità DRS non è in grado di scrivere sui dischi dopo un errore ISL</block>
  <block id="49f26967af2ad76cacf7888cbeeb0590" category="section-title">Guasto a tutti gli interswitch o partizione completa del data center</block>
  <block id="bc331d84348670dff6731555166fa378" category="paragraph">In questo scenario, tutti i collegamenti ISL tra i siti sono interrotti ed entrambi i siti sono isolati l'uno dall'altro. Come discusso in scenari precedenti, come ad esempio un errore ISL nella rete di gestione e nella rete di storage, le macchine virtuali non sono interessate da un errore ISL completo.</block>
  <block id="a40e8cf2a5b5b1e22fec9f26cce85b9d" category="paragraph">Dopo la partizione degli host ESXi tra i siti, l'agente vSphere ha controlla gli heartbeat del datastore e, in ciascun sito, gli host ESXi locali saranno in grado di aggiornare gli heartbeat del datastore nei rispettivi volumi/LUN di lettura/scrittura. Gli host nel sito A presumono che gli altri host ESXi nel sito B non abbiano avuto esito positivo perché non vi sono heartbeat di rete/datastore. VSphere ha nel sito A tenta di riavviare le macchine virtuali del sito B, operazione che alla fine ha esito negativo perché i datastore del sito B non saranno accessibili a causa di un guasto all'ISL di storage. Una situazione simile si ripete nel sito B.</block>
  <block id="3543d47d1f3a8dc6989a32f62ce3ea77" category="image-alt">Guasto a tutto l'ISL o partizione completa del data center</block>
  <block id="3a096ef571101010add81b37081d3276" category="paragraph">NetApp consiglia di determinare se una macchina virtuale ha violato le regole DRS. Tutte le macchine virtuali in esecuzione da un sito remoto non potranno accedere al datastore, quindi vSphere ha riavvia la macchina virtuale nel sito locale. Una volta che i collegamenti ISL sono tornati in linea, la macchina virtuale in esecuzione nel sito remoto verrà interrotta, poiché non possono esistere due istanze di macchine virtuali in esecuzione con gli stessi indirizzi MAC.</block>
  <block id="87e9384cb464ff9a4ce385fc59a178a2" category="image-alt">Una partizione del data center in cui VM1 violava una regola di affinità DRS</block>
  <block id="0951e388ebea20c49e71af25ef84947d" category="section-title">Errore collegamento interswitch su entrambi i fabric in NetApp MetroCluster</block>
  <block id="1e9be78885a356d1a2ec0ab0d4a4cecb" category="paragraph">In uno scenario di errore di uno o più ISL, il traffico continua attraverso i collegamenti rimanenti. In caso di errore di tutti gli ISL su entrambi i fabric, in modo da eliminare un collegamento tra i siti per la replica di storage e NVRAM, ciascun controller continuerà a fornire i propri dati locali. Al ripristino di un minimo di un ISL, la risincronizzazione di tutti i plessi avviene automaticamente.</block>
  <block id="715cbc6f6bcf5da6b73f10233847d3a1" category="paragraph">Eventuali scritture che si verificano dopo che tutti gli ISL sono inattivi non verranno mirrorate nell'altro sito. Uno switchover in caso di disastro, mentre la configurazione si trova in questo stato, causerebbe una perdita dei dati non sincronizzati. In questo caso, è necessario un intervento manuale per il ripristino dopo lo switchover. Se è probabile che non saranno disponibili ISL per un periodo prolungato, un amministratore può scegliere di arrestare tutti i servizi dati per evitare il rischio di perdita di dati se occorre eseguire uno switchover in caso di disastro. L'esecuzione di questa azione deve essere valutata rispetto alla probabilità che un evento disastroso richieda lo switchover prima che almeno un ISL diventi disponibile. In alternativa, in caso di errore degli ISL in uno scenario a cascata, un amministratore può attivare uno switchover pianificato verso uno dei siti prima che tutti i collegamenti abbiano avuto esito negativo.</block>
  <block id="89f375bfe8be0893bf175b89ce754b8e" category="image-alt">Errore di collegamento interswitch su entrambi i fabric in NetApp MetroCluster.</block>
  <block id="bc813a6fdbbeebf4d230b7e33d8c3a76" category="section-title">Errore collegamento cluster in peering</block>
  <block id="1919456d1613248a128c65a84b235fe5" category="paragraph">In uno scenario di guasto al link del cluster in peering, poiché gli ISL del fabric sono ancora attivi, i servizi dati (letture e scritture) continuano in entrambi i siti verso entrambi i plessi. Eventuali modifiche alla configurazione del cluster, ad esempio l'aggiunta di una nuova SVM, il provisioning di un volume o di una LUN in una SVM esistente, non possono essere propagate all'altro sito. Questi vengono conservati nei volumi di metadati CRS locali e propagati automaticamente all'altro cluster al ripristino del collegamento di cluster sottoposto a peering. Se occorre uno switchover forzato prima del ripristino del link del cluster in peering, le modifiche alla configurazione del cluster in sospeso verranno riprodotte automaticamente dalla copia replicata remota dei volumi di metadati presenti nel sito rimasto nel processo di switchover.</block>
  <block id="77130a0b52e4379c6b6667cf7f8e155c" category="image-alt">Guasto al link del cluster in peering</block>
  <block id="9dc32d7afddc9a265c5c2713db55fc70" category="section-title">Errore completo del sito</block>
  <block id="d0d6a03c382bc5412f1822e5c97d5142" category="paragraph">In uno scenario di guasto completo del sito A, gli host ESXi nel sito B non otterranno l'heartbeat di rete dagli host ESXi nel sito A perché non sono attivi. Il master ha nel sito B verificherà che gli heartbeat del datastore non siano presenti, dichiarerà che gli host nel sito A non sono riusciti e tenterà di riavviare le macchine virtuali del sito A nel sito B. Durante questo periodo, l'amministratore dello storage esegue uno switchover per riprendere i servizi dei nodi guasti del sito rimasto e ripristinare i servizi di storage del sito A del sito B. Dopo che i volumi o le LUN del sito A sono disponibili nel sito B, l'agente master ha tenterà di riavviare le macchine virtuali del sito A nel sito B.</block>
  <block id="23e5761401326cc21bcf9d108b9e3e7f" category="paragraph">Se il tentativo dell'agente master vSphere ha di riavviare una VM (che comporta la registrazione e l'accensione) non riesce, il riavvio viene rieseguito dopo un ritardo. Il ritardo tra i riavvii può essere configurato fino a un massimo di 30 minuti. VSphere ha tenta di riavviare il sistema per un numero massimo di tentativi (sei tentativi per impostazione predefinita).</block>
  <block id="085a4a3eba6c30fa589bfee20eb0c294" category="paragraph">Se il sito A è stato sottoposto a switchover, un guasto successivo di uno dei nodi del sito B sopravvissuto può essere gestito senza problemi attraverso il failover verso il nodo rimasto. In questo caso, il lavoro di quattro nodi viene ora eseguito da un solo nodo. Il ripristino in questo caso consisterebbe nell'esecuzione di un giveback al nodo locale. Quindi, quando il sito A viene ripristinato, viene eseguita un'operazione di switchback per ripristinare il funzionamento regolare della configurazione.</block>
  <block id="2b9b713afb0d80ef371a0b55e58366b6" category="image-alt">Guasto del sito completo</block>
  <block id="e6364c2f5314a32cd95be04b4c2112e6" category="paragraph">Nelle seguenti sezioni vengono illustrate le procedure e le Best practice per l'utilizzo di vVol VMware con lo storage ONTAP.</block>
  <block id="a9da618400fb93b20c20f5343efaefa7" category="sidebar">Cluster di storage VMware vSphere Metro con ONTAP</block>
  <block id="2f58fa882a22b5af5f0741f03abaf611" category="sidebar">VSphere Metro Storage Cluster con ONTAP</block>
  <block id="4a884da785a62e8b1758932191ff42de" category="paragraph">La virtualizzazione dei database con VMware, Oracle OLVM o KVM è una scelta sempre più comune per i clienti NetApp che hanno scelto la virtualizzazione anche per i database mission-critical.</block>
  <block id="3a8ba1ff8824968961222d6b447b4973" category="section-title">Supportabilità</block>
  <block id="3231d83af741101eb02b16e5d7a6dffc" category="paragraph">Esistono numerosi preconcetti sui criteri di supporto Oracle per la virtualizzazione, in particolare per i prodotti VMware. Non è raro che Oracle Outright non supporti la virtualizzazione. Questa nozione non è corretta e porta alla perdita di opportunità per trarre vantaggio dalla virtualizzazione. Oracle Doc ID 249212,1 illustra i requisiti effettivi e raramente viene considerato un problema da parte dei clienti.</block>
  <block id="722bd611ee4f38780607b400c8a604c0" category="paragraph">Se si verifica un problema su un server virtualizzato e il supporto di Oracle non lo conosce, al cliente potrebbe essere richiesto di riprodurre il problema sull'hardware fisico. Un cliente Oracle che utilizza una versione all'avanguardia di un prodotto potrebbe non voler utilizzare la virtualizzazione a causa di potenziali problemi di supportabilità, ma questa situazione non è stata un problema reale per i clienti che utilizzano versioni di prodotti Oracle generalmente disponibili.</block>
  <block id="c8a4476ecddeda66dbd2c354c8fb2c6b" category="paragraph">I clienti che stanno considerando la virtualizzazione dei propri database devono basare le proprie decisioni di storage sulle esigenze aziendali. Sebbene questa affermazione sia generalmente vera per tutte le decisioni IT, è particolarmente importante per i progetti di database, poiché le dimensioni e l'ambito dei requisiti variano notevolmente.</block>
  <block id="835ce293f862d9fb74e50f4cf928c56d" category="paragraph">Sono disponibili tre opzioni di base per la presentazione dello storage:</block>
  <block id="327813abbc0ae1e9d3abe282303bf00c" category="list-text">LUN virtualizzate nei datastore di hypervisor</block>
  <block id="1a1af5efffda8c766ead9f73fc782e0e" category="list-text">File system NFS montati dalla macchina virtuale (non da un datastore basato su NFS)</block>
  <block id="f9bf9489147891f7ee7ba15126a27fda" category="list-text">Mappatura diretta dei dispositivi. Gli RDM VMware sono svantaggiati dai clienti, ma spesso i dispositivi fisici sono ancora mappati in modo simile direttamente con la virtualizzazione KVM e OLVM.</block>
  <block id="69b0ac6bf6ea8e1ab4e4fc896294da01" category="paragraph">Il metodo di presentazione dello storage a un guest virtualizzato non influisce in genere sulle prestazioni. I sistemi operativi host, i driver di rete virtualizzati e le implementazioni del datastore degli hypervisor sono tutti altamente ottimizzati e generalmente possono consumare tutta la larghezza di banda della rete FC o IP disponibile tra l'hypervisor e il sistema storage, purché vengano seguite le Best practice di base. In alcuni casi, ottenere prestazioni ottimali può essere leggermente più semplice utilizzando un approccio di presentazione dello storage rispetto a un altro, ma il risultato finale dovrebbe essere comparabile.</block>
  <block id="a2e8fb5328f6558e3a119d8c224a1897" category="paragraph">Il fattore chiave nella scelta di come presentare lo storage a un guest virtualizzato è la manovrabilità. Non esiste un metodo giusto o sbagliato. L'approccio migliore dipende dalle esigenze operative, dalle competenze e dalle preferenze DELL'IT.</block>
  <block id="e4919ac0a074fa1bba5303f596a5f591" category="paragraph">I fattori da prendere in considerazione includono:</block>
  <block id="c422e10bbf04c180f4c47f81ed9a1f7a" category="list-text">*Trasparenza.* quando una VM gestisce i propri file system, è più facile per un amministratore di database o un amministratore di sistema identificare l'origine dei file system per i propri dati. L'accesso ai file system e ai LUN non avviene in modo diverso rispetto a un server fisico.</block>
  <block id="42de52ad09be3101fc535dea2aedce1d" category="list-text">*Coerenza.* quando una VM è proprietaria dei file system, l'utilizzo o il mancato utilizzo di un livello di hypervisor influisce sulla gestibilità. È possibile utilizzare le stesse procedure per il provisioning, il monitoraggio, la protezione dei dati e così via nell'intero ambiente, inclusi ambienti virtualizzati e non.</block>
  <block id="0562446bc5eefe9a584e23ffb3061cbf" category="paragraph">D'altra parte, in un data center altrimenti virtualizzato al 100% potrebbe essere preferibile utilizzare anche lo storage basato su datastore per l'intera impronta, sulla stessa logica sopra menzionata, la coerenza, la capacità di utilizzare le stesse procedure per il provisioning, la protezione, il montoring e la protezione dei dati.</block>
  <block id="7269a37b557c66664c0377693f62ec8a" category="list-text">*Stabilità e risoluzione dei problemi.* quando una VM possiede i propri file system, fornire prestazioni buone e stabili e risolvere i problemi è più semplice perché l'intero stack di storage è presente sulla VM. L'unico ruolo dell'hypervisor è il trasporto di frame FC o IP. Quando un datastore è incluso in una configurazione, complica la configurazione introducendo un altro insieme di timeout, parametri, file di log e potenziali bug.</block>
  <block id="c160b6d86853c20a432e2407b82866e6" category="list-text">*Vendor lock-in.* una volta posizionati i dati in un datastore, diventa difficile utilizzare un hypervisor diverso o estrarre i dati dall'ambiente virtualizzato.</block>
  <block id="a42abd01a1e0c89cfa2112dc09378967" category="list-text">*Abilitazione snapshot.* le procedure di backup tradizionali in un ambiente virtualizzato possono diventare un problema a causa della larghezza di banda relativamente limitata. Ad esempio, un trunk 10GbE a quattro porte potrebbe essere sufficiente per supportare le esigenze quotidiane di prestazioni di molti database virtualizzati, ma tale trunk non sarebbe sufficiente per eseguire backup utilizzando RMAN o altri prodotti di backup che richiedono lo streaming di una copia di dimensioni complete dei dati. Il risultato è che un ambiente virtualizzato sempre più consolidato ha bisogno di eseguire backup tramite snapshot di storage. In questo modo si evita la necessità di sovrascrivere la configurazione dell'hypervisor solo per supportare i requisiti di larghezza di banda e CPU nella finestra di backup.</block>
  <block id="86c36175331b4a95c083fabdcca8b8a0" category="paragraph">L'utilizzo di file system guest facilita a volte l'utilizzo di backup e ripristini basati su snapshot, poiché gli oggetti storage che necessitano di protezione possono essere indirizzati più facilmente. Tuttavia, esiste un numero sempre maggiore di prodotti di data Protection di virtualizzazione che si integrano perfettamente con datastore e snapshot. La strategia di backup deve essere considerata attentamente prima di prendere una decisione su come presentare lo storage a un host virtualizzato.</block>
  <block id="8c19dda4c4cab5e52edf9463f196b97d" category="section-title">Striping dei datastore</block>
  <block id="8fa77493c52e71f201ccdb67db26446d" category="paragraph">Quando si utilizzano database con datastore, c'è un fattore critico da considerare in relazione allo striping delle performance.</block>
  <block id="53ab623a905e6ec84d908f0b99a8d1c8" category="paragraph">Le tecnologie dei datastore come VMFS sono in grado di estendersi su più LUN, ma non su dispositivi suddivisi in striping. I LUN sono concatenati. Il risultato finale può essere costituito da hot spot LUN. Ad esempio, un database Oracle tipico potrebbe avere un gruppo di dischi ASM di 8 LUN. È possibile eseguire il provisioning di tutte le 8 LUN virtualizzate in un datastore VMFS da 8 LUN, senza tuttavia alcuna garanzia su quali LUN risiedono i dati. La configurazione risultante potrebbe essere tutta una LUN virtualizzata da 8 GB che occupa una singola LUN nel datastore VMFS. Ciò si traduce in un collo di bottiglia per le prestazioni.</block>
  <block id="e6bb99e411f5495b03c1e0a4e75a1434" category="paragraph">Lo striping è in genere necessario. Con alcuni hypervisor, incluso KVM, è possibile creare un datastore utilizzando lo striping LVM come descritto <block ref="dd0ff2598ebb26feb9ff73a59186b79f" category="inline-link-macro-rx"></block>. Con VMware, l'architettura appare un po' diversa. Ogni LUN virtualizzata deve essere posizionata in un datastore VMFS diverso.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Ad esempio:</block>
  <block id="6ec151851a31c86edd358bc49f80908c" category="paragraph"><block ref="6ec151851a31c86edd358bc49f80908c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ff2667d6b190dea65bae42217aa310" category="paragraph">Il driver principale di questo approccio non è ONTAP, ma è dovuto alla limitazione intrinseca del numero di operazioni che una singola VM o LUN dell'hypervisor può eseguire in parallelo. In genere, un singolo LUN ONTAP può supportare un maggior numero di IOPS rispetto a quello richiesto da un host. Il limite di prestazioni di un singolo LUN è quasi universalmente il risultato del sistema operativo host. Il risultato è che per soddisfare le esigenze di performance della maggior parte dei database sono necessarie LUN comprese tra 4 e 8 GB.</block>
  <block id="59f9d8d1b212a8ff6bd3476975e17620" category="paragraph">Le architetture VMware devono pianificare con attenzione le proprie architetture per garantire che questo approccio non soddisfi i massimi di datastore e/o percorso LUN. Inoltre, non è necessario un set univoco di datastore VMFS per ogni database. L'esigenza principale consiste nel garantire che ogni host disponga di un set pulito di percorsi io da 4-8 GB dalle LUN virtualizzate alle LUN di backend sul sistema storage stesso. In rare occasioni, anche un numero maggiore di datatores può rivelarsi vantaggioso per richieste di performance veramente estreme, ma le LUN da 4-8 GB sono in genere sufficienti per il 95% di tutti i database. Un singolo volume ONTAP contenente 8 LUN può supportare fino a 250.000 IOPS casuali con blocchi Oracle con una tipica configurazione di sistema operativo/ONTAP/rete.</block>
  <block id="7564f732469e12963d8b416572cf4efb" category="section-title">Che cos'è vSphere Metro Storage Cluster?</block>
  <block id="830d984ea50f71fa76636d0524167a3a" category="doc">Panoramica delle funzionalità del datastore e del protocollo di vSphere</block>
  <block id="cc0f7f705e4495c607aea288505e31bf" category="sidebar">Panoramica di vMSC</block>
  <block id="de9a829f775bc333b77fdacbc333f7a1" category="sidebar">Soluzione vSphere ha</block>
  <block id="70b29c8dabeb7a16884003c35e163f96" category="sidebar">Progettazione vMSC</block>
  <block id="6c4755219197ce467bf892a552c8663a" category="sidebar">Resilienza vMSC</block>
  <block id="13376e3e9b02a56731aa64aeb10947b2" category="sidebar">Scenari vMSC con MCC</block>
  <block id="f0a36f02b824ef55cbd63aa2700a4ec9" category="summary">Backup e ripristino basati su snapshot dei database Oracle</block>
  <block id="77243afc69ab08d8277d0e23dda813d9" category="doc">Backup online dei database Oracle</block>
  <block id="4ac7e99e454283880f5bdf93e9d59eb9" category="summary">Tiering FabricPool dei file completi dei database Oracle</block>
  <block id="3dd6786160916127fc2f6fc2ec955bbe" category="summary">Utilità di recupero ASM con rilevamento ONTAP zero-block</block>
  <block id="89c60635365825dfa13d154785577592" category="summary">Configurazione Oracle e TCP/IP ed ethernet</block>
  <block id="aaa024a70ffabce1e14fdc1a4b17fe8d" category="doc">Configurazione TCP/IP ed ethernet per database Oracle</block>
  <block id="665de76ea0059ac13982f04e19e74216" category="summary">Database Oracle con Microsoft Windows</block>
  <block id="0d4fbbc8820271a0ce5d46a15e7bf90f" category="paragraph">Argomenti di configurazione per database Oracle su Microsoft Windows con ONTAP.</block>
  <block id="422956aac4f76239935ded6a492144f2" category="summary">ONTAP è progettato per i database Oracle. Scopri come.</block>
  <block id="795da6575a33e265d7d9a5774cd10e6f" category="summary">Backup del gruppo di coerenza per i database Oracle su ONTAP</block>
  <block id="33c729820ffa60f55745fa3c259e273c" category="doc">Backup di gruppi di coerenza dei database Oracle</block>
  <block id="56abf0735f338713ce53e8cdecd6994e" category="paragraph">Per un backup il più semplice possibile, posiziona l'intero database Oracle in un singolo volume ONTAP</block>
  <block id="190d2bad1c6e231bc18c33e002e663c7" category="summary">Database Oracle e connettività ONTAP a collegamento diretto</block>
  <block id="4a3f422632f7d08bf0e6c05affea24e4" category="summary">Database Oracle con SyncMirror</block>
  <block id="5bbdf1e19bb3f7b70de51a3764fc5f19" category="doc">Backup ottimizzati per le istantanee dello storage dei database Oracle</block>
  <block id="a962af081661ee46d4ef879de33c841e" category="paragraph">Il backup e il ripristino basati su Snapshot sono diventati ancora più semplici quando è stato rilasciato Oracle 12c perché non è necessario collocare un database in modalità hot backup. Il risultato è la possibilità di pianificare backup basati su snapshot direttamente in un sistema storage, preservando comunque la capacità di eseguire ripristini completi o point-in-time.</block>
  <block id="fdf9dde4dc297fff7ac7b3c1458b0dad" category="doc">Striping LVM con database Oracle</block>
  <block id="d3c8171a7167ce43c547aac8fdd86cfb" category="doc">Migrazione dei file dati Oracle</block>
  <block id="9718528cb14225785c79e3afc4152efc" category="doc">Dimensionamento e numero di LUN dei database Oracle</block>
  <block id="ea7df930bd6bec6222e23d2b3af02a50" category="paragraph">SnapMirror Active Sync supporta due tipi di operazioni di failover dello storage: Pianificate e meno, che funzionano in modi leggermente diversi. Un failover pianificato viene avviato manualmente dall'amministratore per uno switchover rapido verso un sito remoto, mentre il failover non pianificato viene avviato automaticamente dal mediatore del terzo sito. Lo scopo principale di un failover pianificato è quello di eseguire patch e aggiornamenti incrementali, eseguire test di disaster recovery o adottare una politica formale di commutazione delle operazioni tra i siti nel corso dell'anno per dimostrare la piena funzionalità di sincronizzazione attiva.</block>
  <block id="f7c8b0ba16967990d91c2ca78d655eaa" category="paragraph">I diagrammi mostrano cosa accade durante le normali operazioni di failover e failback. Per maggiore facilità di illustrazione, sono raffigurati un LUN replicato. In una configurazione di sincronizzazione attiva di SnapMirror effettiva, la replica si basa sui volumi, dove ogni volume contiene una o più LUN, ma per semplificarne la visione, il livello del volume è stato rimosso.</block>
  <block id="cfa86460b638615878bbee89b1b6d4c7" category="paragraph">La linea verde è un percorso attivo, ma richiede una maggiore latenza, perché i/o su quel percorso devono essere passati attraverso il percorso di sincronizzazione attivo di SnapMirror. La latenza aggiuntiva dipende dalla velocità dell'interconnessione tra i siti utilizzati per la sincronizzazione attiva di SnapMirror.</block>
  <block id="175d350addf4717d454787f950938adf" category="paragraph"><block ref="175d350addf4717d454787f950938adf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="033e21b9b80fa06986d25123f3025db5" category="paragraph"><block ref="033e21b9b80fa06986d25123f3025db5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4d4f8b4d1153d0a9894be19e1f52e4e" category="paragraph"><block ref="f4d4f8b4d1153d0a9894be19e1f52e4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ea45ef5d49a1b807d571799d80613d" category="paragraph">Una volta che il sistema di origine è tornato in servizio, SnapMirror Active Sync può risincronizzare la replica, ma eseguendo l'altra direzione. Attualmente la configurazione è essenzialmente la stessa del punto di partenza, con la sola eccezione che i siti mirror attivi sono stati invertiti.</block>
  <block id="3dd37fdc28ae50bae909f461c8eae979" category="paragraph"><block ref="3dd37fdc28ae50bae909f461c8eae979" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702e101c97ce9a58738b1a4089319df" category="summary">Architettura logica MetroCluster e database Oracle</block>
  <block id="784fdd6bf0ebb9c00eaefafc3f9a9cee" category="doc">RAID e database Oracle</block>
  <block id="204d288bf0e9d1ee9912d68d6282d7a9" category="summary">Database Oracle con AIX</block>
  <block id="90b3697759466f587c318ce55df76258" category="doc">Database Oracle con IBM AIX</block>
  <block id="14ab10a24aa8f6c18bfdfd0d8a394dcb" category="paragraph">Argomenti di configurazione per database Oracle su IBM AIX con ONTAP.</block>
  <block id="b67d277a8a8f29f7b869c9bdbff5fcd1" category="summary">Database Oracle e criteri di recupero FabricPool</block>
  <block id="2e34d4efdcf01f27eb9407a010ca1621" category="summary">Migrazione Oracle con FLI: Cutover</block>
  <block id="c5753b0ef1dfc2c724f24235a689d1ab" category="summary">Policy di tiering FabricPool dei database Oracle</block>
  <block id="57d15767e9302dbb67058ed0bd9eebac" category="doc">Database Oracle e NVFAIL</block>
  <block id="4f03272fa32b53344924740fd30fc52d" category="summary">Database Oracle con Solaris</block>
  <block id="206960915d76763c590449d5ef03639a" category="summary">Database Oracle su ONTAP e il ruolo delle snapshot</block>
  <block id="4bc550014af4fefad8f4cc8f0827c4b5" category="doc">Database Oracle e backup basati su snapshot</block>
  <block id="cf5bc9d838fb937caa7978b4a9b0f98a" category="paragraph">La base della protezione dei dati dei database Oracle su ONTAP è la tecnologia Snapshot di NetApp.</block>
  <block id="ba5a23e78f51c1bcb1b82efbe1797502" category="summary">Parametri del database Oracle - db_file_multiblock_Read_count</block>
  <block id="ea84db84607112a0d40fca3ff45dfffa" category="summary">Gestione delle performance dei database Oracle con QoS ONTAP</block>
  <block id="0af83eb081b1a831789867d7f0867610" category="summary">Tool di gestione e automazione del database Oracle</block>
  <block id="7c58d5a62a9c29d2a846b210deea95f2" category="paragraph">Il valore primario di ONTAP in un ambiente di database Oracle deriva dalle tecnologie principali di ONTAP, come copie Snapshot istantanee, semplice replica SnapMirror e creazione efficiente dei volumi FlexClone.</block>
  <block id="591b3149d6cb247a04883c411dab3e24" category="summary">Checksum e integrità del database Oracle</block>
  <block id="56f014c6fc8fac3e242c9d2e42c654c0" category="paragraph">ONTAP e i protocolli supportati includono svariate funzionalità che proteggono l'integrità del database Oracle, inclusi dati a riposo e dati trasmessi sulla rete.</block>
  <block id="31b3368edcb737b712ee02926409c837" category="doc">Oracle Databases, MetroCluster e NVFAIL</block>
  <block id="490e2f530e53cf85f8ce9b052a8336ec" category="paragraph">NVFAIL è una funzionalità generale di integrità dei dati di ONTAP progettata per massimizzare la protezione dell'integrità dei dati con i database.</block>
  <block id="f2cf6b943d224a732c92223538580ee9" category="doc">Singola istanza di Oracle su MetroCluster</block>
  <block id="ea1d91c32fcf0f4a1090fd0da341c014" category="paragraph">A differenza di altre soluzioni di disaster recovery per lo storage, SnapMirror Active Sync offre una flessibilità asimmetrica della piattaforma. Non è necessario che l'hardware di ciascun sito sia identico. Questa funzionalità consente di dimensionare correttamente l'hardware utilizzato per supportare la sincronizzazione attiva di SnapMirror. Il sistema di storage remoto può essere identico al sito primario se deve supportare un carico di lavoro di produzione completo, ma se un disastro determina una riduzione dell'i/o, rispetto a un sistema più piccolo nel sito remoto potrebbe risultare più conveniente.</block>
  <block id="3873b13983c66ae61dd877b0443a3828" category="summary">Disaster recovery di database Oracle e gruppo di coerenza</block>
  <block id="ede2d3fcaec1bb9dcda5a75c90f37368" category="summary">Massimizzazione della disponibilità con database Oracle su ONTAP</block>
  <block id="9688c9c1c1d15e2f91a3a5b8e5f14bd4" category="doc">Disponibilità dei database Oracle con ONTAP</block>
  <block id="44e95a6c3878f189a550b4c0314d3b33" category="paragraph">NetApp sa che i dati più mission-critical sono presenti nei database.</block>
  <block id="7aa93b5fc17b83fc9e4816155f8f59ab" category="summary">Test delle performance dei database Oracle</block>
  <block id="0b3a030b64747fb3830c79e1ffbef7ee" category="summary">Interruzioni di accesso ai database Oracle e agli archivi di oggetti</block>
  <block id="99a1755be2504777b7e266ed14b33168" category="doc">Failover/switchover dei database Oracle e del controller ONTAP</block>
  <block id="8dbb58cb7fbd4c7db3f14b9674e7d4e6" category="summary">Recovery rapida dei database Oracle con SnapRestore</block>
  <block id="fd0d4a1100bcbce28e8252537f7c4ef4" category="summary">SLA di protezione dei dati dei database Oracle</block>
  <block id="48130805e35d0c7ab5afbcb71abb1ad0" category="doc">RTO, RPO e pianificazione SLA dei database Oracle</block>
  <block id="f359cd007fda575e70269cac76fab4af" category="paragraph">ONTAP ti consente di personalizzare facilmente una strategia di protezione dei dati dei database di Oracle in base ai tuoi requisiti di business.</block>
  <block id="05f9f35345d8f2164958f3b6b7098fa7" category="summary">Tiering FabricPool parziale dei file Oracle</block>
  <block id="48e2495d3eeb1b57ea7d073e06620063" category="doc">Migrazione del database Oracle tramite log shipping</block>
  <block id="2cba4042f0a43491e4ea8f14238ae6e4" category="summary">Tiering delle snapshot di Oracle e FabricPool</block>
  <block id="6f7b1d0f996b7d49f60586ce7fbeca36" category="doc">Oracle con tiering delle snapshot FabricPool</block>
  <block id="35b12c67685c33721c1a59e8b736fd61" category="summary">Caching NFS con database Oracle</block>
  <block id="1404b2da267c376dac716bd5455f4ff3" category="summary">Migrazione Oracle con FLI: Conversione del protocollo</block>
  <block id="c37c1629ee55e6d553c16bbab86adbde" category="doc">Migrazione dei database Oracle sui sistemi di storage ONTAP</block>
  <block id="f1d34b6e878aac7179a735d301e4fb76" category="paragraph">L'utilizzo delle funzionalità di una nuova piattaforma di storage impone un requisito inevitabile e prevede il posizionamento dei dati nel nuovo sistema di storage. ONTAP semplifica il processo di migrazione, inclusi aggiornamenti e migrazioni da ONTAP a ONTAP, importazioni di LUN esterne e procedure per l'utilizzo diretto del sistema operativo host o del software di database Oracle.</block>
  <block id="b7433f552fcf8a4e34f2ccc357037d4e" category="doc">Copia dei dati host del database Oracle</block>
  <block id="1cede70bc6077ecbac9a77b03d1bc6e1" category="summary">Pianificazione della protezione dei dati per i database Oracle</block>
  <block id="e2bc0913921cafeb725765069883b685" category="paragraph">La corretta architettura di protezione dei dati del database Oracle dipende dai requisiti di business relativi alla conservazione dei dati, alla ripristinabilità e alla tolleranza per le interruzioni durante i vari eventi.</block>
  <block id="c0b79db5f258f0c991a383cbdbf001dd" category="inline-link-macro">Sincronizzazione attiva di SnapMirror</block>
  <block id="8a05777f407870cbc2668230c8117503" category="summary">Database Oracle con Linux e driver di filtro ASMlib/ASM</block>
  <block id="494900ae2c2cdb5abdba3806f4dfaeb0" category="doc">Database Oracle con ASMSLib/AFD (driver filtro ASM)</block>
  <block id="afae47e326854c63cbc85989720416e0" category="summary">Migrazione di Oracle con FLI: Pianificazione</block>
  <block id="85cef7bf4ac9d983cf8e1e11785eeef1" category="summary">Migrazione Oracle con FLI - completamento</block>
  <block id="0c5284e14535835121effc8afb702b28" category="summary">Disaster recovery dei database Oracle con ONTAP</block>
  <block id="2ba21d57ee7f1d78a405b9e80c6aaf6b" category="paragraph">Per la maggior parte dei clienti, il disaster recovery non richiede solo una copia remota dei dati, ma anche la capacità di sfruttarli in maniera rapida. NetApp offre due tecnologie che soddisfano questa esigenza: MetroCluster e SnapMirror Active Sync</block>
  <block id="107bcc34799abe752a088be24869419c" category="paragraph">SnapMirror Active Sync si basa su SnapMirror Synchronous. Con MetroCluster, ogni controller ONTAP è responsabile della replica dei dati dell'unità in una posizione remota. Con la sincronizzazione attiva di SnapMirror, avrai essenzialmente due sistemi ONTAP diversi che mantengono copie indipendenti dei dati LUN, ma cooperano per presentare una singola istanza di tale LUN. Dal punto di vista dell'host, si tratta di una singola entità LUN.</block>
  <block id="50ae143b75fc238e91c09c750cf211c1" category="summary">Parametri del database Oracle - filesystemio_options</block>
  <block id="cf451e0aed3c944d3f1c761387762e56" category="summary">Database Oracle con Linux</block>
  <block id="e712ed441aacc4eeecb5656d5493c99c" category="summary">Database Oracle con HP-UX</block>
  <block id="c36ae718fe9d7978c8781b19d0b3dee0" category="paragraph">Argomenti di configurazione per database Oracle su HP-UX con ONTAP.</block>
  <block id="45df37151f6a0fd8a3b55d0423459f82" category="doc">Allineamento LUN per l'i/o del database Oracle</block>
  <block id="857a8adc9eda2d9e197a52323daca558" category="doc">Panoramica sul tiering FabricPool dei database Oracle</block>
  <block id="fd73b1ca3b942a1514078a7e59c7433b" category="summary">Database Oracle e blocchi NFSv3 obsoleti</block>
  <block id="102aeb54bf1a69403672f53090c52878" category="summary">Database Oracle DR tramite log shipping</block>
  <block id="d470f5db851ef84aaa776600805af48b" category="summary">Introduzione alla virtualizzazione del database Oracle</block>
  <block id="b8fc1174bb3f1c65475334182829f75e" category="doc">Virtualizzazione del database Oracle</block>
  <block id="b1b3f70e4333a9dbda75a98ceb78db39" category="summary">Architettura fisica di MetroCluster e database Oracle</block>
  <block id="250bce9fbefc7872908d9c2708fc753b" category="doc">Tiering del backup dei database Oracle</block>
  <block id="4fbe2d000cdf5390ca980149d98eec4d" category="summary">Pianificazione della migrazione dei database Oracle</block>
  <block id="d11e22f56fe0c9dd85597038a25cd80d" category="doc">Gestione della capacità dello storage e dei database Oracle</block>
  <block id="1234e92308935cf0a5a22541f312c541" category="summary">Database Oracle con SnapMirror e SyncMirror</block>
  <block id="a4cdac841b6453db2f51ce52a1303209" category="paragraph">La replica di SnapMirror e l'interruzione della relazione CG di SnapMirror preservano la coerenza tra i volumi, mentre la sincronizzazione di SnapMirror Synchronous e SnapMirror Active Sync preservano la coerenza tra i volumi costituenti.</block>
  <block id="454ff7e5f4a8d37cf6b16b804deca2b6" category="summary">Dimensioni dei blocchi dei database Oracle</block>
  <block id="eed7df980a6ae17f8e0fecdecf0e25f4" category="doc">Script di esempio della procedura di migrazione Oracle</block>
  <block id="fac6d6b61dd6bd3ee73d5b425bc5a3b7" category="doc">Thin provisioning con database Oracle</block>
  <block id="35ebaedc3385b350dff13e0cfa869c9f" category="summary">Timeout Oracle RAC</block>
  <block id="710cf627a103721a0452cb72494ea742" category="admonition">Per una spiegazione dell'interazione tra efficienza dello storage e prenotazione frazionata, vedere le sezioni seguenti sul thin provisioning.</block>
  <block id="8bc1cc1880ea3a623cb9b80b8cbb7b72" category="paragraph">Esistono diversi modi per comprimere i dati. Molti database includono proprie funzionalità di compressione, sebbene raramente queste vengano osservate negli ambienti dei clienti. Il motivo è solitamente la penalizzazione delle prestazioni per una *modifica* dei dati compressi, mentre con alcune applicazioni vi sono elevati costi di licenza per la compressione a livello di database. Infine, ci sono le conseguenze globali delle performance sulle operazioni di database. Ha poco senso pagare un costo elevato di licenza per CPU per una CPU che esegue la compressione e la decompressione dei dati piuttosto che un vero lavoro di database. Un'opzione migliore è trasferire il lavoro di compressione sul sistema storage.</block>
  <block id="3e98696b9bb83904c14603458a8c3728" category="admonition">Le dimensioni dei blocchi utilizzate dalla compressione adattiva possono essere aumentate fino a 32KB KB. Questo può migliorare l'efficienza di archiviazione e dovrebbe essere considerato per i file inattivi come i log delle transazioni e i file di backup quando una quantità sostanziale di tali dati è memorizzata nell'array. In alcune situazioni, i database attivi che utilizzano dimensioni blocco 16KB KB o 32KB KB possono anche trarre vantaggio dall'aumento delle dimensioni blocco della compressione adattiva per adeguarsi. Consulta un NetApp o un rappresentante del partner per ottenere indicazioni relative all'adeguatezza del tuo carico di lavoro.</block>
  <block id="0e6f69b7cb8364ed908c411686154808" category="admonition">Le dimensioni dei blocchi di compressione superiori a 8KB KB non devono essere utilizzate insieme alla deduplica nelle destinazioni di backup in streaming. Il motivo è che piccole modifiche ai dati di backup influiscono sulla finestra di compressione 32KB. Se la finestra si sposta, i dati compressi risultanti differiscono per l'intero file. La deduplica si verifica dopo la compressione, il che significa che il motore di deduplica vede ogni backup compresso in modo diverso. Se è richiesta la deduplica dei backup in streaming, è consigliabile utilizzare solo la compressione adattiva per blocchi da 8KB KB. La compressione adattiva è preferibile, perché funziona a blocchi di dimensioni inferiori e non interrompe l'efficienza di deduplica. Per motivi simili, la compressione lato host interferisce anche con l'efficienza della deduplica.</block>
  <block id="e8a7060409e1a82af9dacfe72458ffac" category="paragraph">Ad esempio, una scrittura 8KB in un file viene compressa solo se si allinea con un limite 8KB all'interno del file system stesso. Questo punto significa che deve rientrare nel primo 8KB del file, nel secondo 8KB del file e così via. Il modo più semplice per garantire un corretto allineamento è utilizzare il tipo di LUN corretto, ogni partizione creata dovrebbe avere un offset dall'inizio del dispositivo che è un multiplo di 8K, e utilizzare una dimensione del blocco del file system che è un multiplo della dimensione del blocco del database.</block>
  <block id="96738983d52a374cb4a8c958e924836e" category="paragraph">Dati come backup o log delle transazioni sono operazioni scritte in sequenza che coprono più blocchi, tutti compressi. Pertanto, non è necessario considerare l'allineamento. L'unico modello di i/o che desta preoccupazione sono le sovrascritture casuali dei file.</block>
  <block id="1afe2c0821b67085f9ea2d2deeb2e92a" category="paragraph">La data compaction è una tecnologia che migliora l'efficienza di compressione. Come indicato in precedenza, la sola compressione adattiva può garantire risparmi 2:1:1 al meglio, perché è limitata alla memorizzazione di un i/o da 8KB KB in un blocco WAFL da 4KB KB. I metodi di compressione con dimensioni dei blocchi maggiori garantiscono una maggiore efficienza. Tuttavia, non sono adatte per i dati che sono soggetti a piccole sovrascritture dei blocchi. La decompressione di 32KB unità di dati, l'aggiornamento di una porzione 8KB, la ricompressione e la riscrittura sui dischi crea overhead.</block>
  <block id="82116b39cd4d0d1920fab1ab4515603b" category="paragraph">Il grado di risparmio ottenuto varia. I dati già compressi o crittografati non possono in genere essere ulteriormente compressi, e pertanto tali set di dati non traggono vantaggio dalla compattazione. Al contrario, i file di dati appena inizializzati contenenti poco più dei metadati dei blocchi e la compressione di zeri fino a 80:1.</block>
  <block id="2608473fa5767385d01f256eccbc1cc4" category="paragraph">Molti array della concorrenza rivendicano la capacità di deduplicare i database sulla base del presupposto che un database venga copiato più volte. Anche in questo caso è possibile utilizzare la deduplica NetApp, ma ONTAP offre un'opzione migliore: La tecnologia FlexClone di NetApp. Il risultato finale è lo stesso; vengono create più copie di un database che condividono la maggior parte dei blocchi fisici sottostanti. L'utilizzo di FlexClone è molto più efficiente della necessità di dedicare tempo alla copia e alla deduplica dei file di database. In effetti, non viene effettuata alcuna duplicazione piuttosto che deduplica, poiché al primo posto non viene mai creato un duplicato.</block>
  <block id="7e96c1b651af3f28c27b78807f0310e2" category="paragraph">Il thin provisioning è vivamente consigliato in quanto consente di semplificare la gestione, offrendo al contempo un sostanziale miglioramento della capacità utilizzabile con conseguenti risparmi sui costi. Il motivo è semplice: Gli ambienti di database includono spesso molto spazio vuoto, un elevato numero di volumi e LUN e dati comprimibili. Il thick provisioning crea la riserva di spazio sullo storage per volumi e LUN, nel caso in cui un giorno raggiungano il 100% di riempimento e contengano dati non comprimibili al 100%. È improbabile che ciò accada mai. Il thin provisioning consente di recuperare lo spazio e di utilizzarlo altrove e consente la gestione della capacità basata sul sistema storage stesso piuttosto che su molti volumi e LUN più piccoli.</block>
  <block id="0f55b43344575cc268bf51ae032d47c2" category="paragraph">NetApp consiglia di:</block>
  <block id="f67b854e2d644480b0ec40d7de2b773d" category="paragraph">I volumi creati su ONTAP in esecuzione su un sistema AFF all-flash vengono sottoposti a thin provisioning con tutte le funzionalità di efficienza inline abilitate. Sebbene in genere i database non beneficino della deduplica e possano includere dati non comprimibili, le impostazioni predefinite sono comunque appropriate per quasi tutti i carichi di lavoro. ONTAP è progettato per elaborare in modo efficiente tutti i tipi di dati e gli schemi i/o, indipendentemente dal fatto che comportino risparmi. Le impostazioni predefinite devono essere modificate solo se le ragioni sono pienamente comprese e se vi è un vantaggio a deviare.</block>
  <block id="649141c6b8267ea3df10949a853d22cb" category="list-text">Non utilizzare sia la compressione 32KB che la deduplica con i backup del database. Vedere la sezione <block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="5059ada12bae6c7e7fac9338d88301b5" category="doc">Tiering del log di archivio dei database Oracle</block>
  <block id="b7e89b3a1ff13c93cc5c038440e48f58" category="paragraph">Per ulteriori informazioni, avviare il sistema https://docs.netapp.com/us-en/ontap-automation/rest/rbac_overview.html[here.]</block>
  <block id="4abda684ecc952239d7800547dcf2995" category="sidebar">Oracle si su MetroCluster</block>
  <block id="bdebc59bb8c11012c00a4be61b8bdb5d" category="summary">Distribuzione delle istanze di Microsoft SQL Server</block>
  <block id="030194212f0e1890126b205fdbcfe852" category="summary">Protezione di Microsoft SQL Server su ONTAP</block>
  <block id="76e6e519036ed33c414d681e342c73be" category="paragraph">La protezione di un ambiente di database SQL Server è un'operazione multidimensionale che va oltre la gestione del database stesso. ONTAP offre diverse funzioni esclusive progettate per proteggere gli aspetti dello storage dell'infrastruttura di database.</block>
  <block id="972d09960af01a5f3831f2eac1c75d12" category="summary">Disaster recovery per Microsoft SQL Server con ONTAP</block>
  <block id="db78788a721b9a9a669c4935d455a593" category="paragraph">I database e le infrastrutture applicative aziendali spesso richiedono la replica per proteggersi da disastri naturali o interruzioni impreviste del business, con tempi di inattività minimi.</block>
  <block id="fad02ab7a45b438ba1a4c024b9edb2be" category="paragraph">Di seguito sono riportati alcuni consigli su SnapMirror per SQL Server:</block>
  <block id="ff1af055b96eb7cd0f0ab71b2cc80c3d" category="list-text">Per motivi di coerenza, non pianificare gli update SnapMirror dai controller. Attiva invece gli update di SnapMirror da SnapCenter per aggiornare SnapMirror al termine del backup completo o del log.</block>
  <block id="60654048dbcae98cde53dc0449c8e47b" category="summary">Considerazioni sullo storage Microsoft SQL Server</block>
  <block id="71cc52562b241f23c0f5c74c589fc56c" category="paragraph">Gli aggregati sono i container di storage di livello più basso per le configurazioni di storage NetApp. Su Internet esiste una documentazione legacy che consiglia di separare i/o su diversi set di unità sottostanti. Questa operazione non è consigliata con ONTAP. NetApp ha eseguito diverse prove di caratterizzazione dei carichi di lavoro i/o utilizzando aggregati condivisi e dedicati con file di dati e file di log delle transazioni separati. I test dimostrano che un aggregato di grandi dimensioni con più gruppi RAID e dischi ottimizza e migliora le performance dello storage ed è più semplice da gestire per due motivi:</block>
  <block id="994dbcbb2492daba25572c539cc12968" category="list-text">Un aggregato di grandi dimensioni rende disponibili per tutti i file le funzionalità i/o di tutte le unità.</block>
  <block id="900188651b4134e36897865047c3fb5b" category="list-text">Impostare il valore di riserva snapshot nel volume su zero per semplificare il monitoraggio dal punto di vista operativo.</block>
  <block id="27d9533edb3ad60370502d101cd38d2b" category="list-text">Disattivare le pianificazioni delle snapshot e i criteri di conservazione. Utilizzare invece SnapCenter per coordinare le copie Snapshot dei volumi di dati di SQL Server.</block>
  <block id="a09a2d9023a555d2d5a72621bf3395b3" category="list-text">Posizionare i database di sistema di SQL Server su un volume dedicato.</block>
  <block id="7b3c6a2d089eb1b6f8959e7e61a50c07" category="section-title">LUN</block>
  <block id="a2f15f0d2a5091a4b232a8fa89bb43f8" category="paragraph">Quando viene eseguita una query, SQL Server tenta di allocare la quantità ottimale di memoria per un'esecuzione efficiente.</block>
  <block id="a549d3d5e3e6aa1db52e782527a9664d" category="summary">Posizionamento dei file del database Microsoft SQL Server</block>
  <block id="329282f5b4d197877079b3b130756d76" category="paragraph">Il corretto posizionamento dei file del database SQL Server su ONTAP è fondamentale durante la fase di distribuzione iniziale. Ciò garantisce prestazioni ottimali, gestione dello spazio, tempi di backup e ripristino che possono essere configurati in base alle esigenze aziendali.</block>
  <block id="d8969d8106a5ac08f38277a3c0b813dc" category="paragraph">La possibilità di inserire più file di dati all'interno del filegroup consente di distribuire il carico su diversi dispositivi di archiviazione, migliorando le prestazioni di i/o del sistema. Al contrario, il log delle transazioni non trae vantaggio dai file multipli poiché SQL Server scrive nel log delle transazioni in modo sequenziale.</block>
  <block id="bd87ed7f70b7f9173319df18e5b5b751" category="paragraph">Ogni volta che SQL Server espande i file, riempie di zero lo spazio appena allocato. Questo processo blocca tutte le sessioni che devono scrivere nel file corrispondente o, in caso di crescita del log delle transazioni, genera record di log delle transazioni.</block>
  <block id="7a64f7e9c9b5737a434bdcc8f935c5ce" category="summary">Efficienza dello storage di Microsoft SQL Server e ONTAP</block>
  <block id="20f0346a9d65f2fba1523d3343d7c6e7" category="doc">Microsoft SQL Server ed efficienza dello storage</block>
  <block id="9df29e7c756637e30b37f014d02117ef" category="paragraph">SQL Server dispone inoltre di funzionalità per comprimere e gestire in modo efficiente i dati. Attualmente SQL Server supporta due tipi di compressione dati: Compressione riga e compressione pagina.</block>
  <block id="09ddfa236e0fa1173f8d86a5ad0c148f" category="summary">Directory di registro di Microsoft SQL Server</block>
  <block id="cc2c23339c0ad05c5ae1704b4a0ecb37" category="paragraph">La directory di registro è specificata in SQL Server per memorizzare i dati di backup del registro delle transazioni a livello di host. Se si utilizza SnapCenter per eseguire il backup dei file di registro, ciascun host SQL Server utilizzato da SnapCenter deve disporre di una directory di registro host configurata per eseguire i backup dei registri. SnapCenter dispone di un repository di database, pertanto i metadati relativi alle operazioni di backup, ripristino o clonazione vengono memorizzati in un repository di database centrale.</block>
  <block id="59412263456ecc0573b76fe1c40d55fb" category="paragraph">ONTAP offre una soluzione per la sicurezza e le prestazioni di livello aziendale per i database Microsoft SQL Server e allo stesso tempo fornisce strumenti di prim'ordine per la gestione dell'ambiente.</block>
  <block id="e8b13d430655a3ab009ba8e90e51ce5a" category="paragraph">NetApp presuppone che il lettore disponga delle seguenti conoscenze operative:</block>
  <block id="c7f2945182947499933dea6fafeb22d3" category="summary">Posizionamento dei tempdb in Microsoft SQL Server su ONTAP</block>
  <block id="03162932e80c8f83c1ad9e36b16c1dcf" category="summary">Configurazione della CPU di Microsoft SQL Server</block>
  <block id="074e88cde37f7aba58ac120bbc874e77" category="paragraph">Esistono due opzioni per la licenza di SQL Server. Il primo è noto come modello server + licenza di accesso client (CAL); il secondo è il modello core per processore. Sebbene sia possibile accedere a tutte le funzioni del prodotto disponibili in SQL Server con la strategia server + CAL, esiste un limite hardware di 20 core CPU per socket. Anche se si dispone di SQL Server Enterprise Edition + CAL per un server con più di 20 core di CPU per socket, l'applicazione non può utilizzare tutti questi core alla volta in tale istanza.</block>
  <block id="cc3873d6002920194cf7e9dd493c5863" category="paragraph">È improbabile che sia necessario modificare le impostazioni predefinite di affinità del processore a meno che non si verifichino problemi di prestazioni, ma vale ancora la pena capire cosa sono e come funzionano.</block>
  <block id="4317f0d20ae625ae3139762a94175cbd" category="paragraph">Per impostazione predefinita, SQL Server utilizza tutte le CPU disponibili durante l'esecuzione delle query, se si sceglie la licenza core per processore.</block>
  <block id="ff03ad08d7a38270e44c8c74372d0e7c" category="summary">Protezione dei database Microsoft SQL Server su ONTAP con comandi SnapCenter e T-SQL.</block>
  <block id="a72812111b6cfc428e19135820c476bc" category="paragraph">SnapCenter è il software di data Protection di NetApp per le applicazioni aziendali. I database di SQL Server possono essere protetti in modo rapido e semplice con il plug-in SnapCenter per SQL Server e con operazioni del sistema operativo gestite dal plug-in SnapCenter per Microsoft Windows.</block>
  <block id="62c187efa0cd9f4191b84ae987d522c9" category="paragraph">L'istanza di SQL Server può essere un'installazione autonoma, un'istanza cluster di failover o può essere un gruppo di disponibilità sempre attivo. Il risultato è che, grazie a un singolo pannello di controllo, i database possono essere protetti, clonati e ripristinati da una copia primaria o secondaria. SnapCenter può gestire database SQL Server sia on-premise, nel cloud che in configurazioni ibride. Le copie dei database possono essere create in pochi minuti sull'host originale o alternativo per lo sviluppo o per il reporting.</block>
  <block id="8a3aceb6ed4b21af2f2c00ecb032f75f" category="paragraph">In SQL Server 2022, Microsoft ha introdotto le istantanee T-SQL che offrono un percorso per la creazione di script e l'automazione delle operazioni di backup. Invece di eseguire copie di dimensioni normali, è possibile preparare il database per le snapshot. Una volta che il database è pronto per il backup, è possibile sfruttare le API REST di ONTAP per creare snapshot.</block>
  <block id="eeeb4e610a7896c1b1f2e2ea9b3f52a0" category="list-text">Bloccare un database con il comando ALTER. In questo modo il database viene preparato per uno snapshot coerente sullo storage sottostante. Dopo il blocco è possibile scongelare il database e registrare lo snapshot con il comando di BACKUP.</block>
  <block id="fd95362fecccbbb7b017317e8bede3b5" category="admonition">Questa documentazione su ONTAP e il database MySQL sostituisce il database _TR-4722: MySQL pubblicato in precedenza sulle Best practice di ONTAP._</block>
  <block id="03591504f4566055ad54d9422f8a0488" category="paragraph">NetApp offre Astra Trident per fornire funzionalità di gestione avanzate dello storage. Ad esempio, Astra Trident consente a un container creato in Kubernetes di eseguire il provisioning automatico del proprio storage nel Tier appropriato, applicare policy di esportazione, impostare policy di snapshot e persino clonare un container in un altro. Per ulteriori informazioni, consultare <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="887757e2405372a0b9e17cc054ab38f3" category="paragraph">Il motivo per cui SnapRestore funziona in modo così rapido ed efficiente è dovuto alla natura di uno snapshot, che è essenzialmente una vista parallela di sola lettura del contenuto di un volume in uno specifico momento. I blocchi attivi sono i blocchi reali che è possibile modificare, mentre lo snapshot è una vista di sola lettura dello stato dei blocchi che costituiscono i file e le LUN al momento della creazione dello snapshot.</block>
  <block id="f9b673452d1da030fef3f976bbbbb103" category="paragraph">In questo esempio, il database di origine si trova su un sistema ONTAP. Il metodo più semplice per creare un backup di un database consiste nell'utilizzare uno snapshot. Il database viene messo in modalità di backup a caldo per alcuni secondi mentre un<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> l'operazione viene eseguita sul volume che ospita i file di dati.</block>
  <block id="630a571b99791968d41f9caba4a3e39c" category="paragraph">Il risultato è un'istantanea sul disco chiamata<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> che contiene un'immagine dei file di dati in modalità di backup a caldo. Se combinati con i log di archivio appropriati per rendere i file di dati coerenti, i dati di questa snapshot possono essere utilizzati come base di un ripristino o di un clone. In questo caso, viene replicato sul nuovo server.</block>
  <block id="96a1129a5a4b32943286cafd5e0ca2e1" category="paragraph">In questo esempio, SnapMirror viene utilizzato per replicare l'hot backup dello snapshot in una nuova posizione.</block>
  <block id="0c4e214451012c456ece194f5465deb2" category="paragraph">SnapCenter include le funzioni di base come backup e ripristini basati su snapshot, la replica SnapMirror e SnapVault e altre funzionalità necessarie per operare su larga scala per le grandi imprese. Queste funzionalità avanzate includono una funzionalità estesa di controllo degli accessi in base al ruolo (RBAC), API RESTful per l'integrazione con prodotti di orchestrazione di terze parti, gestione centrale senza interruzioni dei plug-in SnapCenter sugli host di database e un'interfaccia utente progettata per ambienti cloud-scale.</block>
  <block id="ee4b6ce05339d0d985309ece9b7d4372" category="inline-link-macro">Best practice NFS su ONTAP TR-4067</block>
  <block id="7a3ba6ac400bdd362b5db9daabcefca2" category="paragraph">Il protocollo NFS include diverse versioni con diversi requisiti. Per una descrizione completa della configurazione NFS con ONTAP, vedere <block ref="d594eac583da3f61bc51209142764c76" category="inline-link-macro-rx"></block>. Le sezioni seguenti descrivono alcuni dei requisiti più critici e gli errori comuni degli utenti.</block>
  <block id="dabc72adea00cc712e7650b066f1d8c6" category="inline-link">Best practice TR-4067 NFS su ONTAP</block>
  <block id="36911cfd2b35ef0ca97dab53c7e045f0" category="paragraph">Il passaggio a NFSv4 è più complicato che cambiare semplicemente le opzioni di montaggio da vers=3 a vers=4,1. Una spiegazione più completa della configurazione NFSv4 con ONTAP, incluse le istruzioni sulla configurazione del sistema operativo, vedere<block ref="92f446ddde3e320c4e32b449cbe3112d" category="inline-link-rx"></block>. Le seguenti sezioni di questo TR spiegano alcuni dei requisiti di base per l'utilizzo di NFSv4.</block>
  <block id="a80438f1b3354b284cf31082c45b33b3" category="summary">Infrastruttura di storage Hyper-V con ONTAP</block>
  <block id="cfbb26e347d5746581822f8046be20c4" category="paragraph">Un'infrastruttura di storage Hyper-V può essere ospitata sui sistemi di storage ONTAP. Lo storage per Hyper-V per la memorizzazione dei file della macchina virtuale e dei relativi dischi può essere fornito utilizzando i LUN di NetApp o le condivisioni CIFS di NetApp, come illustrato nella figura seguente.</block>
  <block id="25aa60030552ee28c6e802f74d96f111" category="inline-image-macro">Infrastruttura storage Hyper-V su NetApp, larghezza=624, altezza=338</block>
  <block id="818a20c74e71223c5a644895a6dd4095" category="paragraph"><block ref="818a20c74e71223c5a644895a6dd4095" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c5672e01a7d0a8e068c2573fbdd4c2" category="section-title">Storage Hyper-V su LUN NetApp</block>
  <block id="1d9f855d005777411eca330fd3c883a1" category="inline-link-macro">Provisioning negli ambienti SAN</block>
  <block id="d02671c8f4f293bf5688d34f44e5b87b" category="list-text">Eseguire il provisioning di una LUN NetApp sulla macchina server Hyper-V. Per ulteriori informazioni, vedere la sezione "<block ref="9659d1fb07c4af2143cd165cb4b6822e" category="inline-link-macro-rx"></block>."</block>
  <block id="2771a58b129233810f1c389eedd2207f" category="list-text">Aprire Hyper-V Manager dalla sezione Strumenti di Server Manager.</block>
  <block id="ee15a170a42b1f37e0d70bf3b367f2ee" category="list-text">Selezionare il server Hyper-V e fare clic su Impostazioni Hyper-V.</block>
  <block id="b9cc0276ae5386d0ed5e9ed31ceb340d" category="list-text">Specificare la cartella predefinita in cui memorizzare la VM e il relativo disco come LUN. In questo modo, viene impostato il percorso predefinito come LUN per lo storage Hyper-V. Se si desidera specificare esplicitamente il percorso di una VM, è possibile farlo durante la creazione.</block>
  <block id="72feffd29972ad4bc2fb9f5705e60864" category="inline-link-macro">Provisioning negli ambienti SMB</block>
  <block id="ace87f7890ab6204f4ef6abd0afaf28a" category="paragraph">Prima di iniziare i passaggi elencati in questa sezione, rivedere la sezione "<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>." Per configurare lo storage Hyper-V sulla CIFS share di NetApp, attenersi alla seguente procedura:</block>
  <block id="d3f9aa7fc4289533bdeb015bbd645a22" category="list-text">Specificare la cartella predefinita in cui memorizzare la macchina virtuale e il relativo disco come condivisione CIFS. In questo modo, viene impostato il percorso predefinito come CIFS share per lo storage Hyper-V. Se si desidera specificare esplicitamente il percorso di una VM, è possibile farlo durante la creazione.</block>
  <block id="a531c67c9d6be93b7864c891efc5480a" category="paragraph">A sua volta, ciascuna macchina virtuale di Hyper-V può essere fornita con i LUN di NetApp e le condivisioni CIFS fornite all'host fisico. Questa procedura è la stessa di qualsiasi host fisico. È possibile utilizzare i seguenti metodi per il provisioning dello storage su una macchina virtuale:</block>
  <block id="b7756c6e1b92d15f0367db534aa4fdc2" category="list-text">Aggiunta di una LUN di storage tramite FC Initiator all'interno della macchina virtuale</block>
  <block id="dda418820dd5a8b649a681b73da4ba97" category="list-text">Aggiunta di una LUN di storage tramite l'iniziatore iSCSI all'interno della macchina virtuale</block>
  <block id="ee0537a6d83f8b83e99ac0b7b3d0af82" category="list-text">Aggiunta di un disco fisico pass-through a una VM</block>
  <block id="a842c008b079c30c444ab4c9d78524e6" category="list-text">Aggiunta di VHD/VHDX a una VM dall'host</block>
  <block id="50fba9282607c757ab39ad110cd0fde4" category="list-text">Quando una macchina virtuale e i relativi dati vengono memorizzati nello storage NetApp, NetApp consiglia di eseguire la deduplica NetApp a livello di volume a intervalli regolari. Questa pratica consente notevoli risparmi di spazio quando macchine virtuali identiche vengono ospitate in una condivisione CSV o SMB. La deduplica viene eseguita sullo storage controller e non influisce sul sistema host e sulle performance delle macchine virtuali.</block>
  <block id="6421e175d1ef977d73a52a6a90626eb8" category="list-text">Quando si utilizzano LUN iSCSI per Hyper-V, accertarsi di abilitare<block ref="0a6a9fc5db5706ee3ac704f21780cb07" prefix=" " category="inline-code"></block> e.<block ref="d8ed6ba87266cde713ed7ac6c907ff7e" prefix=" " category="inline-code"></block> Nelle impostazioni del firewall sull'host Hyper-V. In questo modo, si consente il passaggio del traffico iSCSI da e verso l'host Hyper-V e il controller NetApp.</block>
  <block id="6b4ecf09c5310b6b905c86b910a57012" category="list-text">NetApp consiglia di deselezionare l'opzione Consenti al sistema operativo di gestione di condividere la scheda di rete per lo switch virtuale Hyper-V. In questo modo si crea una rete dedicata per le VM.</block>
  <block id="d39c100d166d09a8e573d5c4980c0674" category="list-text">Il provisioning di una macchina virtuale tramite Fibre Channel virtuale richiede un HBA FC abilitato Virtualizationâ N_Port ID. È supportato un massimo di quattro porte FC.</block>
  <block id="8f20505d01de58b8e00048581d2d7244" category="list-text">Se il sistema host è configurato con più porte FC e presentato alla macchina virtuale, MPIO deve essere installato nella macchina virtuale per consentire il multipathing.</block>
  <block id="e003acc3eceda748125d4c7bf41052e7" category="list-text">Non è possibile fornire all'host dischi pass-through se si utilizza MPIO su quell'host, poiché i dischi pass-through non supportano MPIO.</block>
  <block id="aa7c5f68a034b43fa3bafa90ea6a6c2b" category="list-text">Il disco utilizzato per i file VHD/VHDx deve utilizzare la formattazione 64K per l'allocazione.</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matrice di interoperabilità NetApp</block>
  <block id="34de012edea0d70cf76edda88efae407" category="list-text">Per informazioni sugli HBA FC, consultare la<block ref="03bbc27528de80852aa5d0d1250f8442" category="inline-link-rx"></block>.</block>
  <block id="5aa08a9ab39b4ff0ad3ec476f9c0a7a9" category="inline-link">Panoramica di Hyper-V Virtual Fibre Channel</block>
  <block id="17d2fe1a1b42dbc4c914a82ff9a06cbf" category="list-text">Per ulteriori informazioni su Fibre Channel virtuale, consultare Microsoft<block ref="ffefda586e5fabc71f0e43393b116d4c" category="inline-link-rx"></block> pagina.</block>
  <block id="6736b7040d05d12679268b13fae93377" category="paragraph">Con ODX, è più rapido ed efficiente copiare i file all'interno delle condivisioni SMB, nelle LUN e tra le condivisioni SMB e le LUN, se si trovano nello stesso volume. Questo approccio risulta più utile in uno scenario in cui sono necessarie più copie dell'immagine dorata di un sistema operativo (VHD/VHDX) all'interno dello stesso volume. Se le copie si trovano all'interno dello stesso volume, è possibile eseguire più copie della stessa immagine Golden in tempi notevolmente inferiori. ODX viene applicato anche nella migrazione live dello storage Hyper-V per lo spostamento dello storage delle macchine virtuali.</block>
  <block id="53003aec095203ae2075a8150e8ead4e" category="paragraph">Se la copia è tra i volumi, potrebbe non esserci un aumento significativo delle prestazioni rispetto alle copie basate su host.</block>
  <block id="80f704dacc785527bc57a7851889f8b3" category="paragraph">Per abilitare la funzionalità ODX su CIFS, esegui i seguenti comandi dell'interfaccia a riga di comando sullo storage controller NetApp:</block>
  <block id="9c8ee5398727fdb2573f25e0535d686d" category="list-text">Abilita ODX per CIFS.
#impostare il livello di privilegio su diagnostico
cluster::&gt; diagnostica set -privilege</block>
  <block id="574eac1c36a4e6832136e6cf051cc147" category="list-text">Per abilitare la funzionalità ODX su SAN, esegui i seguenti comandi dell'interfaccia a riga di comando sullo storage controller NetApp:
#impostare il livello di privilegio su diagnostico
cluster::&gt; diagnostica set -privilege</block>
  <block id="ea782640f98557c065767874aded89e7" category="list-text">Per CIFS, ODX è disponibile solo se sia il client che il server di storage supportano SMB 3,0 e la funzionalità ODX.</block>
  <block id="c2dca5b1810c92e856cc04f6f2a88586" category="list-text">Per gli ambienti SAN, l'ODX è disponibile solo se sia il client che il server di storage supportano la funzione ODX.</block>
  <block id="f41987326c80680c60b359697adfa4cc" category="inline-link">Miglioramento delle prestazioni di Microsoft Remote Copy</block>
  <block id="fcb65106bb1fd73c88cf9528cb579ed5" category="inline-link">Trasferimenti dati con offload Microsoft</block>
  <block id="65994fb0563b49bfe0e59359edf5513d" category="paragraph">Per informazioni su ODX, vedere<block ref="29f9e15a4017cdf9ae06e098a7a28381" category="inline-link-rx"></block> e.<block ref="f884f78ec6d36ebebd3d9fc57e8c3734" category="inline-link-rx"></block> .</block>
  <block id="20029977789a74e480e6f8d14c07b48a" category="paragraph">I cluster di failover offrono disponibilità e scalabilità elevate per i server Hyper-V. Un cluster di failover è un gruppo di server Hyper-V indipendenti che lavorano insieme per aumentare la disponibilità e la scalabilità delle VM.</block>
  <block id="1b5f8c43b61e9249f3c82e39f9649160" category="section-title">Volumi condivisi del cluster</block>
  <block id="c3e01cf065f02a4feb72ac75d534fa2e" category="paragraph">I CSV consentono a più nodi in un cluster di failover di avere contemporaneamente l'accesso in lettura/scrittura allo stesso LUN NetApp su cui viene eseguito il provisioning di un volume NTFS o refs. Con i CSV, è possibile eseguire rapidamente il failover di ruoli in cluster da un nodo a un altro senza richiedere una modifica della proprietà delle unità o lo smontaggio e rimontaggio di un volume. I CSV semplificano inoltre la gestione di un numero potenzialmente elevato di LUN in un cluster di failover. I CSV forniscono un file system in cluster per scopi generali, ad esempio superiore a NTFS o Ref.</block>
  <block id="92f30d2ddb9cc7fbf92029307c6dbe98" category="inline-image-macro">Cluster di failover Hyper-V e NetApp, larghezza=624, altezza=271</block>
  <block id="873c6f06eca771e8f918112aaf233170" category="paragraph"><block ref="873c6f06eca771e8f918112aaf233170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c1d777ad1068fcefc91b140eba543bf" category="list-text">NetApp consiglia di disattivare la comunicazione del cluster sulla rete iSCSI per impedire il flusso di comunicazioni interne del cluster e del traffico CSV sulla stessa rete.</block>
  <block id="b53334a2710cb18a4e717240b312807f" category="list-text">NetApp consiglia di disporre di percorsi di rete ridondanti (switch multipli) per garantire resilienza e qualità del servizio.</block>
  <block id="f251ad17cf6806e0e3667148cda40e43" category="list-text">I dischi utilizzati per CSV devono essere partizionati con NTFS o Rif. I dischi formattati con FAT o FAT32 non possono essere utilizzati per un CSV.</block>
  <block id="161432666d89990b3c1112afe633ff8e" category="list-text">I dischi utilizzati per i CSV devono utilizzare la formattazione 64K per l'allocazione.</block>
  <block id="36cf7806cbb55a382b64bd9b65b2939b" category="inline-link-macro">Distribuire il cluster Hyper-V.</block>
  <block id="390167e852a9bfc97d6ed31462a05b2f" category="paragraph">Per informazioni sull'implementazione di un cluster Hyper-V, fare riferimento all'Appendice B: <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block>.</block>
  <block id="32730f5882545bbe6a81ac49049968f0" category="section-title">Hyper-V Live Migration: Migrazione delle VM</block>
  <block id="d7f2f7b4116921a3d8d4b8e5892420a7" category="paragraph">A volte è necessario, durante il ciclo di vita delle macchine virtuali, spostarle in un altro host del cluster Windows. Questa operazione potrebbe essere necessaria se l'host sta esaurendo le risorse del sistema o se è necessario riavviare l'host per motivi di manutenzione. Analogamente, potrebbe essere necessario spostare una macchina virtuale in un LUN o una condivisione SMB differente. Ciò potrebbe essere necessario se lo spazio del LUN o della condivisione attuale sta per esaurirsi o sta producendo prestazioni inferiori al previsto. La migrazione live di Hyper-V sposta le macchine virtuali in esecuzione da un server Hyper-V fisico all'altro senza alcun effetto sulla disponibilità delle macchine virtuali per gli utenti. È possibile eseguire in tempo reale la migrazione di macchine virtuali tra server Hyper-V che fanno parte di un cluster di failover o tra server Hyper-V indipendenti che non fanno parte di un cluster.</block>
  <block id="92829881718abd402c6c73b34be944da" category="section-title">Migrazione live in un ambiente cluster</block>
  <block id="e8881f62af8c1495a1f4869b97e95505" category="paragraph">È possibile spostare perfettamente le macchine virtuali tra i nodi di un cluster. La migrazione delle macchine virtuali è istantanea perché tutti i nodi del cluster condividono lo stesso storage e hanno accesso alla macchina virtuale e al relativo disco. La figura seguente illustra la migrazione live in un ambiente in cluster.</block>
  <block id="8cda6697809dd81e112a12c43f6f89f4" category="inline-image-macro">Migrazione live in un ambiente con cluster, larghezza=580, altezza=295</block>
  <block id="d668981cacbbf412643956687c03fc0d" category="paragraph"><block ref="d668981cacbbf412643956687c03fc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4797d6b2727c9902e114fa95ed076fc2" category="list-text">Disporre di una porta dedicata per il traffico di migrazione live.</block>
  <block id="7c021f26d9ab2ec9934fc24d167ceaa4" category="list-text">Disporre di una rete host di migrazione live dedicata per evitare problemi relativi alla rete durante la migrazione.</block>
  <block id="a725857d2338d476a409fd1fb67b1f56" category="inline-link-macro">Appendice C: Implementare Hyper-V Live Migration in un ambiente cluster</block>
  <block id="45f7134e494aae2cba3b60b3fe769caa" category="paragraph">Per informazioni sulla distribuzione della migrazione live in un ambiente in cluster, vedere <block ref="b584c2d96a6b139fbe05976580afae94" category="inline-link-macro-rx"></block>.</block>
  <block id="07cb5e9c694ee3a8dcc475a38371ad5c" category="paragraph">Puoi eseguire la migrazione live di una macchina virtuale tra due server Hyper-V indipendenti e non in cluster. Questo processo può utilizzare la migrazione in tempo reale senza elementi condivisi o condivisi.</block>
  <block id="87b94a12a79a6dbc08decd540810bb26" category="inline-image-macro">Migrazione live condivisa in un ambiente non in cluster, larghezza=331, altezza=271</block>
  <block id="f442dd66197cc65f49ad8ec9c50e8076" category="paragraph"><block ref="f442dd66197cc65f49ad8ec9c50e8076" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207d1150dff7488c7f8bfafe7036a222" category="list-text">Nella migrazione live senza elementi condivisi, ogni server Hyper-V ha il proprio storage locale (può essere una condivisione SMB, un LUN o un DAS) e lo storage della macchina virtuale è locale al proprio server Hyper-V. Quando una VM viene migrata in tempo reale, viene eseguito il mirroring dello spazio di archiviazione della VM sul server di destinazione sulla rete client, quindi viene eseguita la migrazione della VM. La macchina virtuale memorizzata in DAS, un LUN o una condivisione SMB/CIFS può essere spostata in una condivisione SMB/CIFS sull'altro server Hyper-V, come illustrato nella figura seguente. Può anche essere spostata in un LUN, come mostrato nella seconda figura.</block>
  <block id="8df9231bc9de1239aa92c6a9d1116db4" category="inline-image-macro">Migrazione live senza elementi condivisi in un ambiente non in cluster alle condivisioni SMB, larghezza=624, altezza=384</block>
  <block id="c6acea552c059bcc9ccb207ad6b8cee1" category="paragraph"><block ref="c6acea552c059bcc9ccb207ad6b8cee1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="559b3e5c1d4ea7b8f3eaf8cbc0e4155e" category="inline-image-macro">Migrazione live senza elementi condivisi in un ambiente non in cluster alle LUN, larghezza=624, altezza=384</block>
  <block id="3d0d53528ff4699abb6fab11a6bf756d" category="paragraph"><block ref="3d0d53528ff4699abb6fab11a6bf756d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b19cfe6ea61be3a5ed442a8a975a6406" category="inline-link-macro">Appendice D: Implementazione di Hyper-V Live Migration al di fuori di un ambiente in cluster</block>
  <block id="b7c375b5c0ef95eecd45b0a4614c2c68" category="paragraph">Per informazioni sull'implementazione della migrazione live al di fuori di un ambiente in cluster, vedere <block ref="52490817f607e6265e62f91bb3c3799a" category="inline-link-macro-rx"></block>.</block>
  <block id="061731a1a3266df0eda8efe87e649dbb" category="section-title">Migrazione live dello storage Hyper-V.</block>
  <block id="ecaa2ddd351a3f5a9704aaea9a13abaf" category="paragraph">Durante il ciclo di vita di una macchina virtuale, potrebbe essere necessario spostare lo storage della macchina virtuale (VHD/VHDX) su una diversa condivisione LUN o SMB. Ciò potrebbe essere necessario se lo spazio del LUN o della condivisione attuale sta per esaurirsi o sta producendo prestazioni inferiori al previsto.</block>
  <block id="1f976b42d4bb2c18a943d132252997d6" category="paragraph">Il LUN o la condivisione che attualmente ospita la macchina virtuale possono esaurire lo spazio, essere riutilizzati o fornire prestazioni ridotte. In tali circostanze, è possibile spostare la macchina virtuale senza tempi di inattività su un'altra LUN o condivisione su un volume, aggregato o cluster diverso. Questo processo è più rapido se il sistema storage dispone di funzionalità di offload delle copie. I sistemi di storage NetApp sono abilitati all'offload delle copie per impostazione predefinita per gli ambienti CIFS e SAN.</block>
  <block id="bbaae8d50419225b92db654852107b29" category="paragraph">La funzionalità ODX esegue copie di file completi o di file secondari tra due directory che risiedono su server remoti. Una copia viene creata copiando i dati tra i server (o lo stesso server se entrambi i file di origine e di destinazione si trovano sullo stesso server). La copia viene creata senza che il client legga i dati dall'origine o scriva nella destinazione. Questo processo riduce l'utilizzo di processore e memoria per il client o il server e riduce al minimo la larghezza di banda i/o della rete. La copia è più veloce se è all'interno dello stesso volume. Se la copia è tra i volumi, potrebbe non esserci un aumento significativo delle prestazioni rispetto alle copie basate su host. Prima di procedere con un'operazione di copia sull'host, verificare che le impostazioni di offload delle copie siano configurate sul sistema di storage.</block>
  <block id="843c69ad55fb8bac002321dee51a4770" category="paragraph">Quando la migrazione live dello storage delle macchine virtuali viene avviata da un host, l'origine e la destinazione vengono identificate e l'attività di copia viene scaricata nel sistema storage. Poiché l'attività viene eseguita dal sistema di archiviazione, l'utilizzo della CPU, della memoria o della rete host è trascurabile.</block>
  <block id="27d2fda0da241bb37583fba1af25cd09" category="paragraph">Gli storage controller NetApp supportano i seguenti scenari ODX:</block>
  <block id="48a53ae81ff0c821cba0e11bd2383bf3" category="list-text">*IntraSVM.* i dati sono di proprietà della stessa SVM:</block>
  <block id="ec3d44fd176b5d51f4f60dff319cea6b" category="list-text">*Intravolume, intranode.* i file o LUN di origine e di destinazione risiedono nello stesso volume. La copia viene eseguita con la tecnologia file FlexClone che offre ulteriori vantaggi in termini di prestazioni delle copie remote.</block>
  <block id="980ca02c9855a39b86e9fbf5acd955b4" category="list-text">*Intervolume, intranode.* i file o LUN di origine e di destinazione si trovano su volumi diversi che si trovano sullo stesso nodo.</block>
  <block id="8a4d33d47a803a1796b431a0df5a8016" category="list-text">*Intervolume, internodi.* i file o LUN di origine e di destinazione si trovano su volumi diversi che si trovano su nodi diversi.</block>
  <block id="81d5c73c98489729a8f91afe4936dbd2" category="list-text">*InterSVM.* i dati sono di proprietà di diverse SVM.</block>
  <block id="ea9799ac312b9050a36864c98be8f73f" category="list-text">*Intervolume, internodi.* i file o LUN di origine e di destinazione si trovano su volumi diversi che si trovano su nodi diversi.</block>
  <block id="3693f5a47e6bfc0762c5b2c174e653be" category="list-text">*Intercluster.* a partire da ONTAP 9,0, ODX è supportato anche per i trasferimenti di LUN intercluster in ambienti SAN. Intercluster ODX è supportato solo dai protocolli SAN, non da SMB.</block>
  <block id="8e459b300b9b5f521f0cc464bc1a7137" category="paragraph">Al termine della migrazione, è necessario riconfigurare i criteri di backup e replica in modo da riflettere il nuovo volume che contiene le VM. Non è possibile utilizzare i backup precedenti eseguiti.</block>
  <block id="9cabe6ff649f754acc3a863e852828e8" category="paragraph">Lo storage delle macchine virtuali (VHD/VHDX) può essere migrato tra i seguenti tipi di storage:</block>
  <block id="49a63af944b72883bd718eb8c8ff01c8" category="list-text">DAS e la condivisione SMB</block>
  <block id="85fbd1c03217c7c62157aac97d16ecf9" category="list-text">DAS e LUN</block>
  <block id="876c6424f49d57e8be596b8caadf5a61" category="list-text">Una condivisione SMB e un LUN</block>
  <block id="1518cb86dc78f6083ed8b1d292b87ed8" category="list-text">Tra LUN</block>
  <block id="7257cd316393b74da62868c27652c6c0" category="list-text">Tra condivisioni SMB</block>
  <block id="17785c3ef4bbda06e9db9c15908dc0c6" category="inline-image-macro">Migrazione live dello storage Hyper-V, larghezza=339, altezza=352</block>
  <block id="eccf932baf8f6019c69035ea09e26c2c" category="paragraph"><block ref="eccf932baf8f6019c69035ea09e26c2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="319572d5872182625e2834b8615517f2" category="inline-link-macro">Appendice e: Implementare Hyper-V Storage Live Migration</block>
  <block id="04a136595cb35e5c42e3ea764e9cd259" category="paragraph">Per informazioni sulla distribuzione della migrazione attiva dello storage, vedere <block ref="e0d213bcf75379722df0c1b3af5063a2" category="inline-link-macro-rx"></block>.</block>
  <block id="86174aa4d77b1853f72b6e1a6f32c753" category="paragraph">Replica di Hyper-V replica le macchine virtuali Hyper-V da un sito primario a una replica delle macchine virtuali su un sito secondario, fornendo in modo asincrono il disaster recovery per le macchine virtuali. Il server Hyper-V nel sito primario che ospita le macchine virtuali è noto come server primario, mentre il server Hyper-V nel sito secondario che riceve le macchine virtuali replicate è noto come server di replica. Nella figura seguente viene mostrato uno scenario di esempio di replica Hyper-V. È possibile utilizzare Hyper-V Replica per macchine virtuali tra server Hyper-V che fanno parte di un cluster di failover o tra server Hyper-V indipendenti che non fanno parte di un cluster.</block>
  <block id="28e90920ae557bd81a8056f93fb4b0ee" category="inline-image-macro">Replica Hyper-V, larghezza=624, altezza=201</block>
  <block id="4fc821418df9e4488323cc70692d5083" category="paragraph"><block ref="4fc821418df9e4488323cc70692d5083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c340dc334134096f68b880b42a8692c" category="section-title">Replica</block>
  <block id="b9bce4677e5b3ea1c310fddca6123c9f" category="paragraph">Dopo aver abilitato la replica Hyper-V per una macchina virtuale sul server primario, la replica iniziale crea una macchina virtuale identica sul server di replica. Dopo la replica iniziale, Hyper-V Replica mantiene un file di registro per i VHD della VM. Il file di registro viene riprodotto in ordine inverso al VHD di replica secondo la frequenza di replica. Questo registro e l'utilizzo dell'ordine inverso garantiscono che le ultime modifiche vengano memorizzate e replicate in modo asincrono. Se la replica non avviene in linea con la frequenza prevista, viene emesso un avviso.</block>
  <block id="ec9fc8b78968b1d0daadf7598a4e2ab6" category="paragraph">Hyper-V Replica supporta la replica estesa in cui è possibile configurare un server di replica secondario per il disaster recovery. È possibile configurare un server di replica secondario affinché il server di replica riceva le modifiche sulle VM di replica. In uno scenario di replica estesa, le modifiche apportate alle macchine virtuali primarie sul server primario vengono replicate sul server di replica. Le modifiche vengono quindi replicate nel server di replica esteso. È possibile eseguire il failover delle macchine virtuali sul server di replica esteso solo quando i server primario e di replica si arrestano.</block>
  <block id="a3f36244dba1d116dac91134dda3b9db" category="paragraph">Il failover non è automatico; il processo deve essere attivato manualmente. Esistono tre tipi di failover:</block>
  <block id="f8487dcb10cf762a4d3f28da4635bd2a" category="list-text">*Test failover.* questo tipo viene utilizzato per verificare che una VM di replica possa avviarsi correttamente sul server di replica e venga avviata sulla VM di replica. Questo processo crea una macchina virtuale di prova duplicata durante il failover e non influisce sulla normale replica di produzione.</block>
  <block id="09f4056fddf2108616fe7bf3194540ba" category="list-text">*Failover pianificato.* questo tipo viene utilizzato per eseguire il failover delle macchine virtuali durante tempi di inattività pianificati o interruzioni previste. Questo processo viene avviato sulla macchina virtuale primaria, che deve essere disattivata sul server primario prima di eseguire un failover pianificato. Dopo il failover della macchina, Hyper-V Replica avvia la VM di replica sul server di replica.</block>
  <block id="0ad8df7e141c378e7ad1debc5721cecf" category="list-text">*Failover non pianificato.* questo tipo viene utilizzato quando si verificano interruzioni impreviste. Questo processo viene avviato sulla macchina virtuale di replica e deve essere utilizzato solo in caso di guasto della macchina principale.</block>
  <block id="d8afbc541b39d23648c823057cffe3a5" category="section-title">Recovery (recupero)</block>
  <block id="53b169078c7c6ecee01802b49b675c54" category="paragraph">Quando si configura la replica per una VM, è possibile specificare il numero di punti di ripristino. I punti di ripristino rappresentano i punti nel tempo da cui è possibile ripristinare i dati da un computer replicato.</block>
  <block id="31e96602ee944674a6ee07052bc6552a" category="inline-link-macro">Implementazione di replica Hyper-V all'esterno di un ambiente cluster</block>
  <block id="fd09d6344b235cdd2863e5027a2716e8" category="list-text">Per informazioni sulla distribuzione di replica Hyper-V all'esterno di un ambiente cluster, vedere la sezione "<block ref="376f647d5b86bfed7dfffbd7c50e7d1e" category="inline-link-macro-rx"></block>."</block>
  <block id="23b6fa788d78e992f84931ddd3cef629" category="inline-link-macro">Implementare la replica Hyper-V in un ambiente cluster</block>
  <block id="a3538f75015c27ee42ac1f1c0b535a61" category="list-text">Per informazioni sulla distribuzione di replica Hyper-V in un ambiente cluster, vedere la sezione "<block ref="e81baea973ee37d0bb61473f872cfb84" category="inline-link-macro-rx"></block>."</block>
  <block id="57a0eb5139789611b6b213a5f3fa5412" category="summary">La presente appendice descrive l'implementazione di un cluster Hyper-V ad alta disponibilità sullo storage NetApp.</block>
  <block id="e286734bc8843e9f46f2812455917ea5" category="paragraph">La presente appendice descrive l'implementazione di un cluster Hyper-V.</block>
  <block id="fa0edb5816386e7e049e5c77d9cdb367" category="list-text">Almeno due server Hyper-V sono connessi tra loro.</block>
  <block id="a7bad6853c4b367ee245a88ab3195af0" category="list-text">Su ciascun server Hyper-V è configurato almeno uno switch virtuale.</block>
  <block id="ebdc83ef4c8d2993b67ae667bcb0cd50" category="list-text">La funzione cluster di failover è abilitata su ogni server Hyper-V.</block>
  <block id="65e98c7fa4c69ce7bd0d182ede13991a" category="list-text">Le condivisioni SMB o i CSV vengono utilizzati come storage condiviso per memorizzare macchine virtuali e relativi dischi per il clustering Hyper-V.</block>
  <block id="22f4b86bcfebce25bb61ddd3ee8d6f7f" category="list-text">Lo storage non deve essere condiviso tra cluster diversi. È necessaria una sola condivisione CSV/CIFS per cluster.</block>
  <block id="c2377be670723e586c1324a4a12607a5" category="list-text">Se la condivisione SMB viene utilizzata come storage condiviso, è necessario configurare le autorizzazioni sulla condivisione SMB in modo da consentire l'accesso agli account computer di tutti i server Hyper-V nel cluster.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">Implementazione</block>
  <block id="3627e168149dcf185918371a7adb5680" category="list-text">Accedere a uno dei server Windows Hyper-V come membro del gruppo di amministratori.</block>
  <block id="0cc618f3a272a1fc35b193fc6efa1122" category="list-text">Avviare Server Manager**.**</block>
  <block id="f30124a5c887cea53cc6397d6c9e40a6" category="list-text">Nella sezione Strumenti, fare clic su failover Cluster Manager.</block>
  <block id="54be8be618f1803d7fc1579e2fad9a6c" category="list-text">Fare clic sul menu Create Cluster from Actions (Crea cluster da azioni).</block>
  <block id="6bcb4b141d153c7cee9fc6b2633a703c" category="list-text">Fornire dettagli sul server Hyper-V che fa parte di questo cluster.</block>
  <block id="58ee4cb30b6b0dd4665be3c60c65e0f1" category="list-text">Convalidare la configurazione del cluster. Selezionare Sì quando viene richiesta la convalida della configurazione del cluster e selezionare i test necessari per verificare se i server Hyper-V superano i prerequisiti per far parte del cluster.</block>
  <block id="8a2ec0e7f4a4ecb848794b1aba47839b" category="list-text">Una volta completata la convalida, viene avviata la procedura guidata Crea cluster. Nella procedura guidata, specificare il nome del cluster e l'indirizzo IP del cluster per il nuovo cluster. Viene quindi creato un nuovo cluster di failover per il server Hyper-V.</block>
  <block id="ce73c2e33e5d228466b28690400c8c14" category="list-text">Fare clic sul nuovo cluster creato in failover Cluster Manager e gestirlo.</block>
  <block id="904aa93ec80c2a5ca93ed8ace0e52220" category="list-text">Definire lo storage condiviso da utilizzare per il cluster. Può trattarsi di una condivisione SMB o di un CSV.</block>
  <block id="d69f1a0923232e84331ec6d30315124c" category="list-text">L'utilizzo di una condivisione SMB come storage condiviso non richiede passaggi particolari.</block>
  <block id="3b045123cc5f216c3aa18614a4cabf45" category="list-text">Configurazione di una CIFS share su uno storage controller NetApp. A tale scopo, vedere la sezione "<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>".</block>
  <block id="c0edb31f94845e5a1f67d2f79db4408f" category="list-text">Per utilizzare un file CSV come archivio condiviso, attenersi alla seguente procedura:</block>
  <block id="dfd86a662700832b7931201c3abdf13f" category="list-text">Configurare le LUN su uno storage controller NetApp. A tale scopo, vedere la sezione "Provisioning in ambienti SAN".</block>
  <block id="49873862ecc43076ac3a4de327f3efdb" category="list-text">Assicurarsi che tutti i server Hyper-V nel cluster di failover siano in grado di vedere i LUN NetApp. A tale scopo, per tutti i server Hyper-V che fanno parte del cluster di failover, assicurarsi che i relativi iniziatori siano aggiunti al gruppo iniziatore sullo storage NetApp. Verificare inoltre che i LUN siano stati rilevati e che MPIO sia attivato.</block>
  <block id="4fe4609b22418e84ea85667368c2e742" category="list-text">Su uno qualsiasi dei server Hyper-V nel cluster, completare i seguenti passaggi:</block>
  <block id="de824a62ee353b5481bb4eeb5c13d899" category="list-text">Portare il LUN online, inizializzare il disco, creare un nuovo volume semplice e formattarlo utilizzando NTFS o refs.</block>
  <block id="340f3a4d7fad2c45eadfe69d5b56ce38" category="list-text">In failover Cluster Manager, espandere il cluster, espandere Storage, fare clic con il pulsante destro del mouse su dischi, quindi fare clic su Add Disks (Aggiungi dischi). In questo modo si apre la procedura guidata Aggiungi dischi a un cluster che mostra il LUN come disco. Fare clic su OK per aggiungere il LUN come disco.</block>
  <block id="a685089b1d550296b9407033a7411217" category="list-text">Ora il LUN è denominato Clustered Disk e viene indicato come Available Storage in Disks (Storage disponibile in dischi).</block>
  <block id="2970ece9496766e632c3e2c23145cfcf" category="list-text">Fare clic con il pulsante destro del mouse su LUN (disco in cluster) e scegliere Aggiungi a volumi condivisi cluster. Ora il LUN viene visualizzato come CSV.</block>
  <block id="c473a447596255e12e2e772012c42b17" category="list-text">Il CSV è simultaneamente visibile e accessibile da tutti i server Hyper-V del cluster di failover nella sua posizione locale C:\ClusterStorage\.</block>
  <block id="b735c11dd95d1b42d173adb43b3a1df2" category="list-text">Creare una macchina virtuale altamente disponibile:</block>
  <block id="27f977a1c170f87899be67daf203a268" category="list-text">In failover Cluster Manager, selezionare ed espandere il cluster creato in precedenza.</block>
  <block id="569f3bea800216a760ac935540b72c1e" category="list-text">Fare clic su ruoli, quindi su macchine virtuali in azioni. Fare clic su Nuova macchina virtuale.</block>
  <block id="4380a9c5c56776fad0f4492a0d3c63f5" category="list-text">Selezionare il nodo dal cluster in cui deve risiedere la VM.</block>
  <block id="a8be7e73ae88a070ad15a4a6f6d515fe" category="list-text">Nella procedura guidata per la creazione della macchina virtuale, fornire lo storage condiviso (SMB share o CSV) come percorso di archiviazione della macchina virtuale e dei relativi dischi.</block>
  <block id="9da4e10b0da989c65844cd59ed2a0991" category="list-text">Utilizzare Hyper-V Manager per impostare lo storage condiviso (SMB share o CSV) come percorso predefinito per l'archiviazione della VM e dei relativi dischi per un server Hyper-V.</block>
  <block id="064cd683bf50cb65205de6b9298201b3" category="list-text">Verifica del failover non pianificato. Arrestare il servizio cluster sul server proprietario della VM.</block>
  <block id="c7bfaead2ee1aea320b1d91da7ba31d7" category="summary">Ulteriori informazioni sullo storage NetApp e sull'ambiente server Windows</block>
  <block id="5c8c98e7f403562b754941b4d0c17f65" category="paragraph">Come indicato nella <block ref="ba92ae7cf3bb4a058d2b231c16067714" category="inline-link-macro-rx"></block>, I controller di storage NetApp forniscono un'architettura realmente unificata che supporta protocolli di file, blocchi e oggetti. Sono inclusi SMB/CIFS, NFS, NVMe/TCP, NVMe/FC, iSCSI, FC(FCP) e S3, inoltre, creano un accesso unificato a client e host. Lo stesso storage controller può offrire simultaneamente un servizio di storage a blocchi sotto forma di LUN SAN e un file service come NFS e SMB/CIFS. ONTAP è disponibile anche come All SAN Array (ASA) in grado di ottimizzare l'accesso host attraverso un multipathing Active-Active simmetrico con iSCSI e FCP, mentre i sistemi ONTAP unificati utilizzano un multipathing Active-Active asimmetrico. In entrambe le modalità, ONTAP utilizza ANA per la gestione multipath NVMe over Fabrics (NVMe-of).</block>
  <block id="b39d47dbcb48e2064ea0978dea0793ae" category="list-text">Macchine virtuali in hosting sulle condivisioni SMB 3,0 sempre disponibili</block>
  <block id="be1d5dd432dd053b97f14401fc060813" category="list-text">VM ospitate su LUN CSV (Cluster Shared Volume) in esecuzione su iSCSI o FC</block>
  <block id="fc27a7625c9ffb2fe9dd539f1960c978" category="list-text">Database SQL Server su condivisioni SMB 3,0</block>
  <block id="658f98073361780ad39f8c0d45eca2f8" category="list-text">Database SQL Server su NVMe-of, iSCSI o FC</block>
  <block id="d2ed21657f98def30346884514f11cce" category="list-text">Altri workload delle applicazioni</block>
  <block id="b7da44d6d6578097c611512549b04555" category="paragraph">Inoltre, le funzionalità di efficienza dello storage di NetApp come la deduplica, le copie FlexClone(R) di NetApp, la tecnologia Snapshot di NetApp, il thin provisioning, la compressione, inoltre, il tiering dello storage offre un valore significativo per i carichi di lavoro in esecuzione su Windows Server.</block>
  <block id="b76d8ce5a4b5758745257d0223494701" category="section-title">Gestione dei dati ONTAP</block>
  <block id="37b74b1418c82d2f0f3a093c4da8e7de" category="paragraph">ONTAP è un software di gestione eseguito su uno storage controller del NetApp. Detto nodo, uno storage controller NetApp è un dispositivo hardware dotato di processore, RAM e NVRAM. Il nodo può essere connesso a dischi SATA, SAS o SSD, o a una combinazione di questi dischi.</block>
  <block id="16e8274a6170bfb8f7a4b80869edaca0" category="paragraph">I nodi multipli vengono aggregati in un sistema in cluster. I nodi nel cluster comunicano continuamente tra loro per coordinare le attività del cluster. I nodi possono anche spostare i dati in modo trasparente da nodo a nodo utilizzando percorsi ridondanti verso una rete cluster dedicata costituita da due switch Ethernet 10Gb. I nodi nel cluster possono sostituirsi l'uno all'altro per fornire alta disponibilità in qualsiasi scenario di failover. I cluster vengono amministrati su un intero cluster piuttosto che su un singolo nodo e i dati vengono distribuiti da una o più Storage Virtual Machine (SVM). Un cluster deve avere almeno una SVM per fornire i dati.</block>
  <block id="a93b9d090163c0668a090fac714f7578" category="paragraph">L'unità di base di un cluster è il nodo, che viene aggiunto al cluster nell'ambito di una coppia ha (high Availability). Le coppie HA offrono un'elevata disponibilità comunicando tra loro in un'interconnessione ha (separata dalla rete dedicata dei cluster) e mantenendo le connessioni ridondanti ai dischi della coppia ha. I dischi non sono condivisi tra coppie ha, anche se gli shelf potrebbero contenere dischi appartenenti a uno dei membri di una coppia ha. La figura seguente illustra una distribuzione dello storage NetApp in un ambiente Windows Server.</block>
  <block id="4472647bb1219b68f4b76e737a20ce52" category="inline-image-macro">Distribuzione dello storage NetApp in ambiente Windows Server, larghezza=624, altezza=479</block>
  <block id="79ea3c938053f84aab6e3d9a963056f6" category="paragraph"><block ref="79ea3c938053f84aab6e3d9a963056f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7df39ad25b0e96b5a09cafef15c90e83" category="paragraph">ONTAP SVM è uno storage server logico che offre l'accesso ai dati di LUN e/o un namespace NAS da una o più interfacce logiche (LIF). La SVM è quindi l'unità di base di segmentazione storage per la multitenancy sicura in ONTAP. Ciascuna SVM è configurata in modo da gestire i volumi storage forniti da un aggregato fisico e da interfacce logiche (LIF) assegnate a una rete Ethernet fisica o a porte di destinazione FC.</block>
  <block id="ded35f53d6a4c12f9aa23622a273290c" category="paragraph">I dischi logici (LUN) o le condivisioni CIFS vengono creati all'interno dei volumi di una SVM e vengono mappati agli host e ai cluster Windows per fornire loro spazio di storage, come illustrato nella seguente figura. Le SVM sono indipendenti dai nodi e basate sul cluster e possono utilizzare risorse fisiche come volumi o porte di rete in qualsiasi punto del cluster.</block>
  <block id="66bfba6c82925242c27d2f07403b627e" category="inline-image-macro">ONTAP Storage Virtual Machine, larghezza=572, altezza=443</block>
  <block id="9bcb5e161ae4c106ccd0f2dc96989097" category="paragraph"><block ref="9bcb5e161ae4c106ccd0f2dc96989097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f64c369fcdc9c990f5540ce53430671" category="paragraph">È possibile eseguire il provisioning dello storage su Windows Server in ambienti SAN e NAS. In un ambiente SAN, lo storage viene fornito come dischi dalle LUN sul volume NetApp come storage a blocchi. In un ambiente NAS, lo storage viene fornito come condivisioni CIFS/SMB sui volumi NetApp come file storage. I dischi e le condivisioni possono essere applicati in Windows Server nel modo seguente:</block>
  <block id="8572daf67b8cf4929b8a104909d42a03" category="list-text">Storage per host Windows Server per workload dell'applicazione</block>
  <block id="460622219d2e0a7fe2d7339d37894127" category="list-text">Stoccaggio per Nano Server e container</block>
  <block id="24148b9d626dc3494e0f1a07f5ddf180" category="list-text">Storage per singoli host Hyper-V per archiviare le macchine virtuali</block>
  <block id="c9d2a95802a3dc0a7c1033928d3cfc3f" category="list-text">Storage condiviso per i cluster Hyper-V sotto forma di CSV per archiviare le VM</block>
  <block id="76c319d8818e93b50538dff2f4427cbc" category="list-text">Storage per database SQL Server</block>
  <block id="13a4fb282282699692756c149d94bbbe" category="paragraph">Per connettere, configurare e gestire lo storage NetApp da Windows Server 2016, utilizzare uno dei seguenti metodi:</block>
  <block id="81ef8774b45c60d7387b0e91d9c4eb05" category="list-text">*Secure Shell (SSH).* utilizzare qualsiasi client SSH su Windows Server per eseguire i comandi CLI di NetApp.</block>
  <block id="935df6062271011aad64300fe0f8a6c7" category="list-text">*System Manager.* questo è il prodotto di gestibilità basato su GUI di NetApp.</block>
  <block id="85c7991eb4ed1078ecb54aacffe3a3a2" category="list-text">*Toolkit PowerShell NetApp.* questo è il toolkit PowerShell di NetApp per l'automazione e l'implementazione di script e workflow personalizzati.</block>
  <block id="1fb25b443082bb79703b1237630cd9b6" category="section-title">Toolkit PowerShell NetApp</block>
  <block id="a5038d870bfecae7a8fb1fb0d8ba892b" category="list-text">NetApp non supporta gli spazi di archiviazione di Windows Server. Gli spazi di archiviazione sono utilizzati solo per JBOD (solo un gruppo di dischi) e non funzionano con alcun tipo di RAID (DAS (Direct-Attached Storage) o SAN).</block>
  <block id="b37ae3efea13417cff3fdb198db41274" category="list-text">I pool di storage in cluster in Windows Server non sono supportati da ONTAP.</block>
  <block id="436593f3429fec64588705fe44025823" category="list-text">NetApp supporta il formato VHDX (Virtual Hard Disk Format) condiviso per il clustering guest in ambienti SAN Windows.</block>
  <block id="a3a862b96d666cb7005617313f703378" category="list-text">Windows Server non supporta la creazione di pool di storage utilizzando LUN iSCSI o FC.</block>
  <block id="570d38aae09bbf84ba37f9219909a7cb" category="list-text">Per ulteriori informazioni sul toolkit PowerShell di NetApp, visitare il<block ref="12f72d9ce1eab5b7cd58718fecdd145c" category="inline-link-rx"></block>.</block>
  <block id="699f0a44719fb3de5404046fc6caa8af" category="inline-link">TR-4475: Guida alle Best practice per il toolkit PowerShell di NetApp</block>
  <block id="532d077f114744273b1a7cd2a4794077" category="list-text">Per informazioni sulle Best practice del toolkit PowerShell di NetApp, vedere<block ref="87b47631a9123c9d2a382039a9ba503e" category="inline-link-rx"></block>.</block>
  <block id="64f3248fbae79dd41841377bf7dd37c6" category="paragraph">Le reti Ethernet possono essere ampiamente segregate nei seguenti gruppi:</block>
  <block id="0047d4a23ffec6d4afe912d0a2598e58" category="list-text">Una rete client per le VM</block>
  <block id="d6cf6da705ce58c7b649fea1cd43c470" category="list-text">Un'altra rete di storage (connessione iSCSI o SMB ai sistemi di storage)</block>
  <block id="0d8658721aaab8eb43f9b6d72283b8f8" category="list-text">Una rete di comunicazione cluster (heartbeat e altre comunicazioni tra i nodi del cluster)</block>
  <block id="338c97ec16c135df1c972ba5b92db129" category="list-text">Una rete di gestione (per monitorare e risolvere i problemi del sistema)</block>
  <block id="7b6753ef35b59e8866faf1b43b213520" category="list-text">Una rete di migrazione (per la migrazione live dell'host)</block>
  <block id="0f31fc2f15105bd45773e0fe5a33814a" category="list-text">Replica VM (replica Hyper-V)</block>
  <block id="11ef3cd9dc7173f009417493a7a51f57" category="list-text">NetApp consiglia di disporre di porte fisiche dedicate per ciascuna delle funzionalità precedenti per l'isolamento e le prestazioni della rete.</block>
  <block id="84f729d0d6ae07e1ea7697e418337328" category="list-text">Per ciascuno dei precedenti requisiti di rete (ad eccezione dei requisiti di storage), è possibile aggregare più porte di rete fisiche per distribuire il carico o fornire la tolleranza agli errori.</block>
  <block id="89831505b6fb0eb3bfb78852c3e8838a" category="list-text">NetApp consiglia di creare uno switch virtuale dedicato sull'host Hyper-V per la connessione dello storage guest all'interno della macchina virtuale.</block>
  <block id="301b0a1048a669cb6b56215ce25f83d2" category="list-text">Accertarsi che i percorsi dei dati iSCSI host e guest di Hyper-V utilizzino porte fisiche e switch virtuali diversi per un isolamento sicuro tra l'host e l'host.</block>
  <block id="38d14a6f7d54295d21bfb890bbfac145" category="list-text">NetApp consiglia di evitare il raggruppamento delle schede di rete per le schede di rete iSCSI.</block>
  <block id="3b5eab23ccdc37978e26fa584647f2f5" category="list-text">NetApp consiglia di utilizzare MPIO (ONTAP Multipath Input/Output) configurato sull'host a scopo di storage.</block>
  <block id="6395caf6c767d5f8026b684721c1e27e" category="list-text">NetApp consiglia di utilizzare MPIO all'interno di una macchina virtuale guest se si utilizzano initiator iSCSI guest. L'utilizzo di MPIO deve essere evitato all'interno del guest se si utilizzano dischi pass-through. In questo caso, è sufficiente installare MPIO sull'host.</block>
  <block id="55892ded4e0eac09cd2bd256ea8e4f49" category="list-text">NetApp consiglia di non applicare policy di QoS allo switch virtuale assegnato alla rete di storage.</block>
  <block id="9e33949565ff57eed3e484a27adca687" category="list-text">NetApp consiglia di non utilizzare l'indirizzamento IP privato automatico (APIPA) su schede di rete fisiche, poiché APIPA non è instradabile e non è registrato nel DNS.</block>
  <block id="b06f6cf7b5c4e8ac8117fe6238a15184" category="list-text">NetApp consiglia di attivare frame jumbo per reti CSV, iSCSI e di migrazione live per aumentare la capacità di trasmissione e ridurre i cicli della CPU.</block>
  <block id="d34fac956ae63cd93b204c541399ec3f" category="list-text">NetApp consiglia di deselezionare l'opzione Consenti al sistema operativo di gestione di condividere questa scheda di rete per lo switch virtuale Hyper-V per creare una rete dedicata per le VM.</block>
  <block id="0d3e51fc3c7ecb31cb6dcf3ea104060c" category="list-text">NetApp consiglia di creare percorsi di rete ridondanti (switch multipli) per la migrazione live e la rete iSCSI per garantire resilienza e qualità del servizio.</block>
  <block id="72a46482f366b350b6b0215baa631137" category="summary">Ulteriori risorse per Microsoft Windows e Hyper-V.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dove trovare ulteriori informazioni</block>
  <block id="0650b34324cf33e3bf1ba6d5db9aa14c" category="list-text">Novità di Hyper-V su Windows Server +
<block ref="8508224d602483e88bde8402b5d1f2d1" category="inline-link-rx"></block></block>
  <block id="1139a59d4aa15acd59f31d05c5a9d642" category="summary">In questa appendice viene descritta la distribuzione di replica Hyper-V all'esterno di un ambiente in cluster.</block>
  <block id="be9cfe5b3b6e5354686be0cb736fe70d" category="list-text">Sono necessari server Hyper-V standalone ubicati in posizioni geografiche identiche o separate che servono come server primari e di replica.</block>
  <block id="427aef80e259ae74b835c2b646e8fba8" category="list-text">Se si utilizzano siti separati, è necessario configurare il firewall di ciascun sito per consentire la comunicazione tra i server primario e di replica.</block>
  <block id="3ac92c1d06a47463c6ea9f2c4289a625" category="list-text">Il server di replica deve disporre di spazio sufficiente per archiviare i carichi di lavoro replicati.</block>
  <block id="6db575d6d23958eefd722c2559c2ae2b" category="list-text">Configurare il server di replica.</block>
  <block id="f348eb2699776a23b340068fa13ba378" category="list-text">Affinché le regole del firewall in entrata consentano il traffico di replica in entrata, eseguire il seguente cmdlet PowerShell:</block>
  <block id="b3741a0bf4f272b05520af3145ce6b20" category="list-text">Fare clic su Impostazioni Hyper-V da azioni.</block>
  <block id="0b81c69f5b40344714e859c333f7e46d" category="list-text">Fare clic su Replication Configuration (Configurazione replica) e selezionare Enable this computer as a Replica Server (Abilita questo computer come server di replica).</block>
  <block id="23e173753ad1fc5a192335afcd91aaa2" category="list-text">Nella sezione Authentication and Ports (autenticazione e porte), selezionare il metodo e la porta di autenticazione.</block>
  <block id="c67571ac7fd00493d3ca7147b7756914" category="list-text">Nella sezione autorizzazione e archiviazione, specificare la posizione in cui archiviare le VM e i file replicati.</block>
  <block id="c6f470c780ac40391a73366709e36fae" category="list-text">Abilitare la replica VM per le VM sul server primario. La replica delle macchine virtuali è abilitata in base alle macchine virtuali e non per l'intero server Hyper-V.</block>
  <block id="84f81856434a0c817bfd8ec7ba575d63" category="list-text">In Hyper-V Manager, fare clic con il pulsante destro del mouse su una macchina virtuale e fare clic su Enable Replication (Abilita replica) per aprire la procedura guidata Enable Replication (Abilita replica).</block>
  <block id="bb27dca619d145c6538ad523a5c5aec7" category="list-text">Fornire il nome del server di replica in cui la VM deve essere replicata.</block>
  <block id="368e47c642802a224da6a1e9196c2345" category="list-text">Fornire il tipo di autenticazione e la porta del server di replica configurata per ricevere il traffico di replica sul server di replica.</block>
  <block id="df839b9a847de722b03fb6f8db4abd3d" category="list-text">Selezionare i VHD da replicare.</block>
  <block id="7e2b2defa62bab724dad332e0efe93d4" category="list-text">Scegliere la frequenza (durata) in cui le modifiche vengono inviate al server di replica.</block>
  <block id="f1358329d5a84d751f47c4d4e4882286" category="list-text">Configurare i punti di ripristino per specificare il numero di punti di ripristino da mantenere sul server di replica.</block>
  <block id="13bb9737452c217970585237bf9a3c67" category="list-text">Scegliere Initial Replication Method (metodo di replica iniziale) per specificare il metodo di trasferimento della copia iniziale dei dati VM al server di replica.</block>
  <block id="e7773df7e8bec8a84ededaaba6cc3b5c" category="list-text">Rivedere il riepilogo e fare clic su fine.</block>
  <block id="eaa408dd6135876f9368b7e9e8447340" category="list-text">Questo processo crea una replica VM sul server di replica.</block>
  <block id="c6c9686c38a42b00345f77c5ddbe044a" category="list-text">Eseguire un failover di test per assicurarsi che la VM di replica funzioni correttamente sul server di replica. Il test crea una VM temporanea sul server di replica.</block>
  <block id="4b07a5223e241d6b4d7935c2282616a5" category="list-text">Accedere al server di replica.</block>
  <block id="baaaeb9b824a8922645198d46a10e27a" category="list-text">In Hyper-V Manager, fare clic con il pulsante destro del mouse su una macchina virtuale di replica, fare clic su Replication (Replica) e su Test failover (Test failover).</block>
  <block id="b9950331695e861c821d48077fe8b1f1" category="list-text">Scegliere il punto di ripristino da utilizzare.</block>
  <block id="b1d034cdaa7ef0d2bc761b948c78838a" category="list-text">Questo processo crea una macchina virtuale con lo stesso nome aggiunto a -Test.</block>
  <block id="8c95c5ef4d5593fe860313c283fab784" category="list-text">Verificare la VM per accertarsi che tutto funzioni correttamente.</block>
  <block id="e5c73308bdacf8978516ccda5462e80a" category="list-text">Dopo il failover, la macchina virtuale di prova della replica viene eliminata se si seleziona Stop Test failover.</block>
  <block id="c4eacda4a6022cafe1bfc0d735075dce" category="list-text">Eseguire un failover pianificato per replicare le ultime modifiche sulla macchina virtuale primaria nella macchina virtuale di replica.</block>
  <block id="7c3c0f256f21e1f117a98a5afa47dd56" category="list-text">Accedere al server primario.</block>
  <block id="2d6fd035cbd8062dcc29935ff448420e" category="list-text">Disattivare la macchina virtuale da sottoporre a failover.</block>
  <block id="582c3456f1d3f75fd04a3dfcdb20c132" category="list-text">In Hyper-V Manager, fare clic con il pulsante destro del mouse sulla macchina virtuale disattivata, fare clic su Replica, quindi su failover pianificato.</block>
  <block id="4ed0c56504eba0632689dfc8056e3c49" category="list-text">Fare clic su failover per trasferire le ultime modifiche VM al server di replica.</block>
  <block id="f490046b13ec9105a4adb8f885b5688f" category="list-text">Eseguire un failover non pianificato in caso di guasto principale della VM.</block>
  <block id="c01438bcded7cda6d1ee326fa268f93c" category="list-text">In Hyper-V Manager, fare clic con il pulsante destro del mouse su una VM di replica, fare clic su Replication (Replica) e su failover.</block>
  <block id="94faab2d3840f3d8320e20ad4a90e6cd" category="list-text">Fare clic su failover per eseguire il failover della VM.</block>
  <block id="4be45953e45cfa5fc987ba108c1e5793" category="summary">Questa appendice descrive la distribuzione della migrazione live in un ambiente in cluster.</block>
  <block id="388b92a1de3321595dcfbdc1c67ce749" category="paragraph">Per utilizzare la migrazione live in un ambiente in cluster, attenersi alla seguente procedura:</block>
  <block id="b66a6c742469f1d08a2d11bcf4f211ff" category="list-text">In failover Cluster Manager, selezionare ed espandere il cluster. Se il cluster non è visibile, fare clic su failover Cluster Manager, fare clic su Connetti al cluster e fornire il nome del cluster.</block>
  <block id="e3883376513ba0aeb2f3d190d4e0377d" category="list-text">Fare clic su ruoli, che elenca tutte le VM disponibili in un cluster.</block>
  <block id="e164db40505184b94012bbbd4aa4c1a2" category="list-text">Fare clic con il pulsante destro del mouse sulla macchina virtuale e fare clic su Sposta. In questo modo, sono disponibili tre opzioni:</block>
  <block id="6a1e101231f8f4bcd4a75390cc0eddc2" category="list-text">*Migrazione live.* è possibile selezionare un nodo manualmente o consentire al cluster di selezionare il nodo migliore. Durante la migrazione live, il cluster copia la memoria utilizzata dalla macchina virtuale dal nodo corrente a un altro nodo. Pertanto, quando la macchina virtuale viene migrata su un altro nodo, la memoria e le informazioni di stato necessarie alla macchina virtuale sono già disponibili per la macchina virtuale. Questo metodo di migrazione è quasi istantaneo, ma è possibile eseguire la migrazione in tempo reale di una sola macchina virtuale alla volta.</block>
  <block id="4374953843b8a5507e79ee5145fd88cd" category="list-text">*Migrazione rapida.* è possibile selezionare un nodo manualmente o consentire al cluster di selezionare il nodo migliore. Durante una migrazione rapida, il cluster copia la memoria utilizzata da una macchina virtuale in un disco nello storage. Pertanto, quando la macchina virtuale viene migrata su un altro nodo, le informazioni di memoria e di stato necessarie alla macchina virtuale possono essere lette rapidamente dal disco dall'altro nodo. Con una migrazione rapida, è possibile migrare più macchine virtuali contemporaneamente.</block>
  <block id="f1321d73ebfb5a92e710d313fd53c21c" category="list-text">*Migrazione dell'archiviazione di macchine virtuali.* questo metodo utilizza la procedura guidata Sposta archivio di macchine virtuali. Questa procedura guidata consente di selezionare il disco della macchina virtuale e altri file da spostare in un'altra posizione, ad esempio una condivisione CSV o SMB.</block>
  <block id="36397d251acf4232a7e91edc7ae649c7" category="summary">Storage NAS ONTAP per Hyper-V utilizzando SMB3</block>
  <block id="a06ae7fcee90c7ab1e1321d0dd8b2242" category="paragraph">ONTAP offre storage NAS resiliente e dalle performance elevate per le macchine virtuali Hyper-V utilizzando il protocollo SMB3.</block>
  <block id="2efbb65fec3bad963652820bc484fe59" category="paragraph">Al momento della creazione di una SVM con il protocollo CIFS, viene eseguito un server CIFS sopra la SVM che fa parte del dominio Active Directory di Windows. Le condivisioni SMB possono essere utilizzate per una home directory e per ospitare carichi di lavoro Hyper-V e SQL Server. In ONTAP sono supportate le seguenti funzionalità di SMB 3,0:</block>
  <block id="55339f66c60fe6973920932c368d5b51" category="list-text">Handle persistenti (condivisioni di file sempre disponibili)</block>
  <block id="94713d3b3a69a2fd695bffeb252007d3" category="list-text">Protocollo testimone</block>
  <block id="adb115272d11e09afdfd8702a652d626" category="list-text">Failover dei client in cluster</block>
  <block id="f5025b9fcd1b24276af8ec2da3aa4cd7" category="list-text">Consapevolezza in termini di scale-out</block>
  <block id="81abcea6e16bc538d9843e8808b2066b" category="list-text">ODX</block>
  <block id="f4ad9c4d51155dbb3fb746c7c497c145" category="list-text">VSS remoto</block>
  <block id="56a26f5f5f602966c3a3088fc05c7383" category="paragraph">L'utilizzo dello storage NetApp in ambienti NAS in Windows Server presenta i seguenti requisiti:</block>
  <block id="5f3a2953a5f6d187ed4babba3c754b95" category="list-text">Il cluster ONTAP dispone di una licenza CIFS valida.</block>
  <block id="2744237d602ca5ed3f1a6370ed8ebe91" category="list-text">Viene creato almeno un aggregato.</block>
  <block id="89917a1bea2d5c48569d9ed0a9526f74" category="list-text">Viene creata una singola interfaccia logica dei dati (LIF) che deve essere configurata per CIFS.</block>
  <block id="87a2c188e55f400a5936550cc2f91148" category="list-text">Sono presenti un server di dominio Windows Active Directory configurato con DNS e credenziali di amministratore di dominio.</block>
  <block id="da920c4d42bb062c9dbfd877c84ef133" category="list-text">Ogni nodo nel cluster NetApp viene sincronizzato in base all'ora con il controller di dominio Windows.</block>
  <block id="f04e0c239705cd7c6e249d3ed6991627" category="section-title">Controller di dominio Active Directory</block>
  <block id="2e0bc40db7949b4af757ea11110ae955" category="paragraph">È possibile unire e utilizzare uno storage controller NetApp all'interno di un Active Directory simile a un server Windows. Durante la creazione della SVM, è possibile configurare il DNS fornendo i dettagli relativi al nome di dominio e al server dei nomi. La SVM tenta di cercare un controller di dominio Active Directory eseguendo una query al DNS per un server LDAP (Active Directory/Lightweight Directory Access Protocol) in modo simile a Windows Server.</block>
  <block id="dee2aa3e7614e2fc47c6fbbb5cd123b5" category="paragraph">Per il corretto funzionamento della configurazione CIFS, i controller di archiviazione NetApp devono essere sincronizzati a tempo con il controller di dominio Windows. NetApp consiglia di rispettare un intervallo di tempo non superiore a cinque minuti tra il controller di dominio Windows e il controller di storage NetApp. Si consiglia di configurare il server NTP (Network Time Protocol) per il cluster ONTAP in modo che venga sincronizzato con un'origine dell'ora esterna. Per configurare il controller di dominio Windows come server NTP, eseguire il comando seguente sul cluster ONTAP:</block>
  <block id="2d60b04429a0c7bcf1dc0021d1c01046" category="list-text">Creazione di una nuova SVM con CIFS del protocollo NAS attivato. È possibile creare una nuova SVM utilizzando uno dei seguenti metodi:</block>
  <block id="26ed02718973e705cd69ee6e109400e0" category="list-text">System Manager</block>
  <block id="fc05c3b0a7017fa6841b856230e365bb" category="list-text">Il toolkit PowerShell di NetApp</block>
  <block id="bbee3ec15cf30d6e65d6a020f6d4af1e" category="list-text">Configurare il protocollo CIFS</block>
  <block id="8de4bddcd1cd8e4614e52342eef41752" category="list-text">Fornire il nome del server CIFS.</block>
  <block id="a817c1f7bf7af809fd90c63b2a8e4447" category="list-text">Fornire l'Active Directory a cui è necessario accedere al server CIFS. È necessario disporre delle credenziali di amministratore del dominio per unirsi al server CIFS in Active Directory.</block>
  <block id="bf8cf0b24d936c2fe2e3681004650bf0" category="list-text">Assegna una SVM con LIF a ciascun nodo del cluster.</block>
  <block id="5d77fb569194f93fead7154a8d1d1bc3" category="list-text">Avviare il servizio CIFS nell'SVM.</block>
  <block id="547edc4d2fb156c3e495e6325eae5a4a" category="list-text">Creare un volume con lo stile di protezione NTFS dall'aggregato.</block>
  <block id="1418b945a2d25e4f6514fc52e9d6c7ef" category="list-text">Creare un qtree sul volume (opzionale).</block>
  <block id="f0bbe023b40d4d11ed83d36a68894cae" category="list-text">Creare condivisioni che corrispondono al volume o alla directory del qtree in modo da potervi accedere da Windows Server. Selezionare attiva disponibilità continua per Hyper-V durante la creazione della condivisione, se la condivisione è utilizzata per lo storage Hyper-V. In questo modo, si abilita un'elevata disponibilità per le condivisioni dei file.</block>
  <block id="9ef47a6b1a5d19245750aa732054173a" category="list-text">Modificare la condivisione creata e le autorizzazioni necessarie per accedere alla condivisione. Le autorizzazioni per la condivisione SMB devono essere configurate per consentire l'accesso agli account computer di tutti i server che accedono alla condivisione.</block>
  <block id="053003e418b94e54d509f16e6a5ac54f" category="paragraph">Per rilevare la condivisione CIFS creata in precedenza con Windows Server, attenersi alla procedura illustrata di seguito:</block>
  <block id="9eb306535570bd14746bad4f0768684f" category="list-text">Accedere a Windows Server come membro del gruppo di amministratori.</block>
  <block id="4cac21133029fce3cd01fb6d42f8bedb" category="list-text">Accedere a run.exe e digitare il percorso completo della condivisione CIFS creata per l'accesso alla condivisione.</block>
  <block id="cf48b5bae22bbcd1956b57470865f653" category="list-text">Per mappare in modo permanente la condivisione su Windows Server, fare clic con il pulsante destro del mouse su questo PC, selezionare Connetti unità di rete e specificare il percorso della condivisione CIFS.</block>
  <block id="304c9374426bb10ac275b8d050d77a72" category="list-text">Per aprire MMC in Windows Server, fare clic su Gestione computer nella sezione Strumenti di Gestione server.</block>
  <block id="e731a6a9193d81f0140801ba9fb7c316" category="list-text">Fare clic su altre azioni e su Connetti a un altro computer per aprire la finestra di dialogo Seleziona computer.</block>
  <block id="92b70da99a18efe7530353abe1820089" category="list-text">Inserisci il nome del server CIFS o l'indirizzo IP del LIF SVM per la connessione al server CIFS.</block>
  <block id="2d6dbdc8809506c631cd711d19c21958" category="list-text">Espandere Strumenti di sistema e cartelle condivise per visualizzare e gestire file, sessioni e condivisioni aperti.</block>
  <block id="3a38167e840fd7939f34e194afadd957" category="list-text">Per confermare l'assenza di downtime quando un volume viene spostato da un nodo a un altro o in caso di guasto a un nodo, NetApp consiglia di attivare l'opzione di disponibilità continua nella condivisione file.</block>
  <block id="7a98f276625e5966a817f0783982ef86" category="list-text">Nel provisioning delle macchine virtuali per un ambiente Hyper-V-over-SMB, NetApp consiglia di abilitare l'offload delle copie nel sistema storage. In questo modo si riduce il tempo di provisioning delle VM.</block>
  <block id="8bb66ec4b6ef9437bd1c4c88328028b9" category="list-text">Se il cluster di storage ospita diversi carichi di lavoro SMB come SQL Server, Hyper-V e server CIFS, NetApp consiglia di ospitare diversi carichi di lavoro SMB su SVM separate in aggregati separati. Questa configurazione è utile perché ciascuno di questi carichi di lavoro garantisce layout unici di volumi e reti di storage.</block>
  <block id="ce424317fa59851e16cfbe4cbac13386" category="list-text">Durante la migrazione di macchine virtuali da una condivisione SMB 3,0 all'altra, NetApp consiglia di attivare la funzionalità di offload delle copie CIFS nel sistema storage, in modo da rendere la migrazione più veloce.</block>
  <block id="be7159d8a65544f2712c72dc0254f9be" category="list-text">Quando si eseguono il provisioning di volumi per ambienti SMB, questi volumi devono essere creati con lo stile di protezione NTFS.</block>
  <block id="bb17c7edf27266c09bc64edcc1299db5" category="list-text">Le impostazioni di tempo sui nodi nel cluster devono essere configurate di conseguenza. Utilizzare il protocollo NTP se il server CIFS NetApp deve far parte del dominio Active Directory di Windows.</block>
  <block id="261b72d9729025ebf489205324a048d5" category="list-text">Gli handle persistenti funzionano solo tra nodi in una coppia ha.</block>
  <block id="e185fb0d3a49c7a3318c954d8aa25c05" category="list-text">Il protocollo di controllo opera solo tra i nodi in una coppia ha.</block>
  <block id="67d7fd26a92bba839041dd45a19cec56" category="list-text">Le condivisioni di file continuamente disponibili sono supportate solo per i workload di Hyper-V e SQL Server.</block>
  <block id="fa2e04a9f0cdcb5ad0e9f1e5ad1ada82" category="list-text">Il multicanale SMB è supportato a partire da ONTAP 9,4.</block>
  <block id="f357368b2f195de4f8b4463eed2bf004" category="list-text">RDMA non supportato.</block>
  <block id="f55cb235b18bf3d499f9276cd235bfb6" category="list-text">I riferimenti non sono supportati.</block>
  <block id="fb97dc994a0600d8610daca021159b33" category="paragraph">Nano Server non richiede software client aggiuntivo per accedere ai dati della condivisione CIFS su un controller di storage NetApp.</block>
  <block id="2be09e0be799992463b5c9542ce31dd8" category="paragraph">Per copiare file da Nano Server a una condivisione CIFS, eseguire i seguenti cmdlet sul server remoto:</block>
  <block id="2e0d4f41db110bf64a66493b31c9b168" category="list-text"><block ref="6f88c516ba3d9ab0cd23b81fc43dd697" prefix="" category="inline-code"></block> È la CIFS share sullo storage controller NetApp.</block>
  <block id="5e017ad7a7df43934bccc7c27031a140" category="list-text">Per copiare i file su Nano Server, eseguire il cmdlet seguente:</block>
  <block id="d153ba0c2e04ac16dcece009a842216e" category="paragraph">Per copiare l'intero contenuto di una cartella, specificare il nome della cartella e utilizzare il parametro -Recurse alla fine del cmdlet.</block>
  <block id="c9f4515194bc7b2927aa17b7d9b4aa25" category="summary">Come configurare la migrazione live dello storage Hyper-V.</block>
  <block id="a49764977574be237e816e868b16bd9e" category="doc">Distribuire Hyper-V Storage Live Migration</block>
  <block id="587db979ac1f69c45774cb09d6d6670b" category="paragraph">Scoprite come configurare la migrazione live dello storage Hyper-V.</block>
  <block id="0146445d75059a401441fd65f1bae1e0" category="list-text">È necessario disporre di un server Hyper-V standalone con storage indipendente (DAS o LUN) o storage SMB (locale o condiviso tra altri server Hyper-V).</block>
  <block id="71c2ecf4798ba7bf00669c37826cb55b" category="inline-link-macro">Live Migration al di fuori di un ambiente cluster</block>
  <block id="4a8052295fad176b01067c772f7c7e5d" category="list-text">Il server Hyper-V deve essere configurato per la migrazione live. Esaminare la sezione relativa alla distribuzione in <block ref="0e7f526c94c2d5b9ef424b7a8a1c9587" category="inline-link-macro-rx"></block>.</block>
  <block id="43434644e024fa3073cc9c64dba551d0" category="list-text">Aprire Hyper-V Manager.</block>
  <block id="3999a6e17f16c7f048684f76a1a59e38" category="list-text">Fare clic con il pulsante destro del mouse su una macchina virtuale, quindi fare clic su Sposta.</block>
  <block id="1d838d1a72e03329477d7f4024eec108" category="list-text">Selezionare Sposta memoria della macchina virtuale.</block>
  <block id="45d2d7245527e5e6e9be62e79d5a46d8" category="list-text">Selezionare le opzioni per spostare la memoria in base alle proprie preferenze.</block>
  <block id="13d0ba1c0320910efd0d040f2d461527" category="list-text">Fornire la nuova posizione per gli elementi della VM.</block>
  <block id="6efadc6e298c560f1699100ac97c7378" category="list-text">Rivedere il riepilogo e fare clic su OK per spostare la memoria della VM.</block>
  <block id="b2d949a2d7f46bb1e39037d38eea14e4" category="summary">L'efficienza dello storage ONTAP con Microsoft Hyper-V.</block>
  <block id="bd2eab4ffe0ab602b60386dfdd3ef913" category="paragraph">ONTAP offre un'efficienza dello storage leader del settore per ambienti virtualizzati, incluso Microsoft Hyper-V. NetApp offre anche programmi di garanzia di efficienza dello storage.</block>
  <block id="e957a0e8016b502f05bb1966b2ec6064" category="paragraph">La deduplica NetApp rimuove i blocchi duplicati a livello di volume di storage, archiviando una sola copia fisica, indipendentemente dal numero di copie logiche presenti. La deduplica si fa quindi illusione nel fatto che esistano numerose copie di quel blocco. La deduplica rimuove automaticamente i blocchi di dati duplicati su un livello di blocco di 4KB KB in un intero volume. Questo processo recupera lo storage per ottenere spazio e potenziali risparmi sulle performance, riducendo il numero di scritture fisiche su disco. La deduplica può garantire un risparmio di spazio superiore al 70% negli ambienti Hyper-V.</block>
  <block id="44ee5e4157e5291ffc8bc5d1d9b5959d" category="paragraph">Il thin provisioning è un modo efficiente per il provisioning dello storage perché lo storage non è preallocato in anticipo. In altre parole, quando un volume o LUN viene creato utilizzando il thin provisioning, lo spazio nel sistema di storage non viene utilizzato. Lo spazio rimane inutilizzato fino a quando i dati non vengono scritti sul LUN o sul volume e viene utilizzato solo lo spazio necessario per memorizzare i dati. NetApp consiglia di attivare il thin provisioning sul volume e di disattivare la prenotazione LUN.</block>
  <block id="8bc14f0cb78851f59e85c1d447c2c99f" category="section-title">Qualità del servizio</block>
  <block id="5f4c07a9f526ef861fd661ab7d801ef0" category="paragraph">La qualità del servizio di storage di Clustered ONTAP consente di raggruppare gli oggetti di storage e di impostare limiti di throughput per il gruppo. È possibile utilizzare la qualità del servizio di storage per limitare il throughput ai carichi di lavoro e monitorare le performance del carico di lavoro. Grazie a questa possibilità, gli amministratori dello storage possono separare i workload in base all'organizzazione, all'applicazione, alla business unit o agli ambienti di produzione o sviluppo.</block>
  <block id="8649c492f1adfda9b6ab44990a1a7580" category="paragraph">Negli ambienti aziendali, la qualità del servizio di storage aiuta a ottenere quanto segue:</block>
  <block id="ca944817219b4a5d2cb25894ee7bac2d" category="list-text">Impedisce che i carichi di lavoro degli utenti influiscano l'uno sull'altro.</block>
  <block id="1d5819479882e9b1b8133fda618801e5" category="list-text">Protegge le applicazioni critiche con tempi di risposta specifici che è necessario soddisfare in ambienti IT-as-a-service (ITaaS).</block>
  <block id="b06d1116eb0db3e3c8c51d1707dfcf99" category="list-text">Impedisce che i tenant si influenzino l'uno con l'altro.</block>
  <block id="1d7dd784ada3e9fe62630025fa82dc80" category="list-text">Evita il peggioramento delle performance con l'aggiunta di ogni nuovo tenant.</block>
  <block id="3c7577ceba90e087950e69f357ce949b" category="paragraph">La qualità del servizio consente di limitare il quantitativo di i/o inviato a una SVM, a un volume flessibile, a una LUN o a un file. L'i/o può essere limitato dal numero di operazioni o dal throughput raw.</block>
  <block id="0ac164a0cdedc812bd371348407d8df2" category="paragraph">La figura seguente illustra l'SVM con una propria policy QoS che applica un limite di throughput massimo.</block>
  <block id="4cd97525569a4c4f332a1fbadea31367" category="inline-image-macro">Storage virtual machine con la propria policy di qualità del servizio, larghezza=319, altezza=341</block>
  <block id="11751e265ace69b487d325224006c7e5" category="paragraph"><block ref="11751e265ace69b487d325224006c7e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42674eda4c194d913efb361684c8b8c6" category="paragraph">Per configurare una SVM con la propria policy QoS e monitorare il gruppo di policy, esegui i seguenti comandi sul tuo cluster ONTAP:</block>
  <block id="2398ac10b8f12f8d175464af41b6cc27" category="summary">Informazioni sulla distribuzione di Microsoft Windows Nano Server</block>
  <block id="60aa20a9330bfedece833eb6496e61dc" category="doc">Distribuire Nano Server</block>
  <block id="751f4ae88fb7c0e83c557b594f24f467" category="paragraph">Informazioni sulla distribuzione di Microsoft Windows Nano Server.</block>
  <block id="ffd8df9c68fc3e1710ed9dc15dec9225" category="paragraph">Per distribuire un Nano Server come host Hyper-V, attenersi alla seguente procedura:</block>
  <block id="2c8cf6c7616e7bf4d627844c10ef6914" category="list-text">Copiare la cartella NanoServerImageGenerator dalla cartella \NanoServer nell'ISO di Windows Server sul disco rigido locale.</block>
  <block id="e93afc2a7bab8945ac834e9f955ab2c8" category="list-text">Per creare un Nano Server VHD/VHDX, attenersi alla seguente procedura:</block>
  <block id="f0b4451826a1b48587dce5ccbdf7a1e7" category="list-text">Avviare Windows PowerShell come amministratore, accedere alla cartella NanoServerImageGenerator copiata sul disco rigido locale ed eseguire il seguente cmdlet:</block>
  <block id="3b515a3daeec18784951623c4ef02332" category="list-text">Creare un VHD per Nano Server come host Hyper-V eseguendo il seguente cmdlet PowerShell. Questo comando richiede una password di amministratore per il nuovo VHD.</block>
  <block id="2ef6d24f20fa6986cbd70ea844d3e16e" category="list-text">Nel seguente esempio viene creato un Nano Server VHD con la funzione host Hyper-V con clustering di failover abilitato. Questo esempio crea un Nano Server VHD da un ISO montato in f:\. Il VHD appena creato viene inserito in una cartella denominata NanoServer nella cartella da cui viene eseguito il cmdlet. Il nome del computer è NanoServer e il VHD risultante contiene l'edizione standard di Windows Server.</block>
  <block id="7f165cd40e3ab8b56d69cfdf799ebb23" category="list-text">Con il cmdlet New-NanoServerImage, configurare i parametri che impostano l'indirizzo IP, la subnet mask, il gateway predefinito, il server DNS, il nome del dominio, e così via.</block>
  <block id="9ba9f17628c7c8e123a1c4d0b154e1e0" category="list-text">Utilizzare il VHD in una macchina virtuale o in un host fisico per implementare Nano Server come host Hyper-V:</block>
  <block id="7482916c1c66ae16c274920ca01eda80" category="list-text">Per l'implementazione su una macchina virtuale, creare una nuova macchina virtuale in Hyper-V Manager e utilizzare il VHD creato al passaggio 3.</block>
  <block id="8a1f197a1a3903636fe46d151b55f1a4" category="list-text">Per la distribuzione su un host fisico, copiare il VHD sul computer fisico e configurarlo per l'avvio da questo nuovo VHD. Per prima cosa, montare il VHD, eseguire bcdboot e:\Windows (dove il VHD è montato sotto e:\), smontare il VHD, riavviare il computer fisico e avviare il Nano Server.</block>
  <block id="1a2fbb26db89a11f849f5a17170449b5" category="list-text">Unire il Nano Server a un dominio (opzionale):</block>
  <block id="fa966a71fb7e787a036cc8ae2df719c2" category="list-text">Accedere a un qualsiasi computer del dominio e creare un BLOB di dati eseguendo il seguente cmdlet PowerShell:</block>
  <block id="5e83141959914643e6e309d32cb02675" category="list-text">Copiare il file odjblob nel Nano Server eseguendo i seguenti cmdlet PowerShell su un computer remoto:</block>
  <block id="9493ca9bfebee08582b48c95f6ad1768" category="list-text">Riavviare Nano Server.</block>
  <block id="24d48ec9863eca883370d9e471e7dec1" category="section-title">Connettersi a Nano Server</block>
  <block id="11e7dceca10309920a26c38df3c5f421" category="paragraph">Per connettersi a Nano Server in remoto utilizzando PowerShell, attenersi alla seguente procedura:</block>
  <block id="08d7b9e67b4bbd447b1fa3d9103976e8" category="list-text">Aggiungere Nano Server come host attendibile sul computer remoto eseguendo il seguente cmdlet sul server remoto:</block>
  <block id="0b1f1a420d35761f550f4a9f3b9e2ecb" category="list-text">Se l'ambiente è sicuro e si desidera impostare tutti gli host da aggiungere come host attendibili su un server, eseguire il comando seguente:</block>
  <block id="06879aa989dffc1c877a92441f72d474" category="list-text">Avviare la sessione remota eseguendo il seguente cmdlet sul server remoto. Fornire la password per Nano Server quando richiesto.</block>
  <block id="c5363e6f2cab660a02c04316d65097b5" category="paragraph">Per connettersi a Nano Server in modalità remota utilizzando gli strumenti di gestione GUI da un Windows Server remoto, completare i seguenti comandi:</block>
  <block id="d97c0d550aa0ad1af548a89c27d9f7ea" category="list-text">Accedere a Windows Server come membro del gruppo di amministratori.</block>
  <block id="ff621b1b3a7bcf389fc4c97a55bf9505" category="list-text">Per gestire un Nano Server in remoto da Server Manager, fare clic con il pulsante destro del mouse su tutti i server, fare clic su Aggiungi server, fornire le informazioni del Nano Server e aggiungerle. A questo punto è possibile visualizzare il Nano Server nell'elenco dei server. Selezionare il Nano Server, fare clic con il pulsante destro del mouse e iniziare a gestirlo con le varie opzioni fornite.</block>
  <block id="2343c80f9e6b008ea95cc15026c9c094" category="list-text">Per gestire i servizi in remoto su un Nano Server, attenersi alla seguente procedura:</block>
  <block id="1430c8ff3134db821cc65ac53e010d4d" category="list-text">Aprire servizi dalla sezione Strumenti di Server Manager.</block>
  <block id="358fe30f1157bd64dad7a3aba4e40f94" category="list-text">Fare clic con il pulsante destro del mouse su servizi (locale).</block>
  <block id="72fa515e487f796b536e03179e63e7db" category="list-text">Fare clic su Connetti al server.</block>
  <block id="50ec7cc625733992673123275ff834d6" category="list-text">Fornire i dettagli di Nano Server per visualizzare e gestire i servizi su Nano Server.</block>
  <block id="f322fcdc841439901a45a176928f80e0" category="list-text">Se il ruolo Hyper-V è abilitato su Nano Server, completare i seguenti passaggi per gestirlo in remoto da Hyper-V Manager:</block>
  <block id="14994643f0c569708527514d0405c1e5" category="list-text">Fare clic con il pulsante destro del mouse su Hyper-V Manager.</block>
  <block id="8e0877f5a8a5d540837664b9de1070ca" category="list-text">Fare clic su Connetti al server e fornire i dettagli del Nano Server. Ora Nano Server può essere gestito come server Hyper-V per creare e gestire macchine virtuali.</block>
  <block id="b2c5e9024429f1b7f8581d1747d25fd6" category="list-text">Se il ruolo di clustering di failover è abilitato su Nano Server, completare i seguenti passaggi per gestirlo in remoto dal failover cluster manager:</block>
  <block id="31b3efaeee0b35b5bde4f1353f947b93" category="list-text">Aprire failover Cluster Manager dalla sezione Strumenti di Server Manager.</block>
  <block id="2cb85a898a7a975600dcc1bea85df531" category="list-text">Eseguire operazioni relative al clustering con Nano Server.</block>
  <block id="2810ba8ba9d5e4319af85df66ddf2286" category="summary">Sicurezza dello storage ONTAP con Hyper-V.</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="doc">Sicurezza</block>
  <block id="6ca21561032e8c064bc8514ab2e92740" category="paragraph">ONTAP fornisce un sistema di storage sicuro per il sistema operativo Windows.</block>
  <block id="615e826f5576798f024d7959ccefc794" category="section-title">Windows Defender Antivirus</block>
  <block id="2861d3b5f4351fd51979bf98547a050b" category="paragraph">Windows Defender è un software antimalware installato e attivato in Windows Server per impostazione predefinita. Questo software protegge attivamente Windows Server da malware noti e può aggiornare regolarmente le definizioni antimalware tramite Windows Update. I LUN di NetApp e le condivisioni SMB possono essere sottoposti a scansione utilizzando Windows Defender.</block>
  <block id="a86f08bae2bbd68aa81b64f748f3ccb8" category="inline-link">Panoramica di Windows Defender</block>
  <block id="4b51dd417e2be3fdc9a793c3290e3a63" category="paragraph">Per ulteriori informazioni, consultare la<block ref="d66127569e4d44a2d0a35bc9d20b1ea7" category="inline-link-rx"></block>.</block>
  <block id="ce71fc775b37c52dabd938808de8d0f9" category="section-title">BitLocker</block>
  <block id="8d9091beebb755bb6e68a4f04d3288f6" category="paragraph">La crittografia dell'unità BitLocker è una funzione di protezione dei dati continua da Windows Server 2012. Questa crittografia protegge dischi fisici, LUN e CSV.</block>
  <block id="0494cad48bf6f5dd2105391f0426af1a" category="paragraph">Prima di attivare BitLocker, il file CSV deve essere impostato sulla modalità di manutenzione. Pertanto, NetApp consiglia di prendere decisioni relative alla protezione basata su BitLocker prima di creare le macchine virtuali sul CSV per evitare tempi di inattività.</block>
  <block id="e2e4ca1a6c3bcca61ed5ec3ea10c90c0" category="summary">Scopri come distribuire e configurare la replica di Hyper-V con il cluster di failover di Windows Server.</block>
  <block id="5674fdbee301f444dd0ca3836c682957" category="list-text">Se si utilizzano siti separati, è necessario configurare il firewall in ciascun sito per consentire la comunicazione tra i cluster primario e di replica.</block>
  <block id="6cc66ed27b17f9c380f924d533e633d6" category="list-text">Il cluster di replica deve disporre di spazio sufficiente per archiviare i workload replicati.</block>
  <block id="ff71768b9e039ee5012c181eb29bdc39" category="list-text">Attivare le regole firewall su tutti i nodi di un cluster. Eseguire il seguente cmdlet PowerShell con privilegi di amministratore su tutti i nodi sia nel cluster primario che di replica.</block>
  <block id="ac005fe375c3903e88ed3801a8646b0a" category="list-text">Configurare il cluster di replica.</block>
  <block id="3a57da55cdc319b0580af329b8776df6" category="list-text">Configurare il broker replica Hyper-V con un nome NetBIOS e un indirizzo IP da utilizzare come punto di connessione al cluster utilizzato come cluster di replica.</block>
  <block id="643ce0b9206c6c138b36b79315a468f2" category="list-text">Aprire failover Cluster Manager.</block>
  <block id="52243c461a19e74a8e4b64d801979142" category="list-text">Espandere il cluster, fare clic su ruoli e fare clic sul riquadro Configura ruolo dal riquadro azioni.</block>
  <block id="f87ee1c8e6945b31ba45ee813ea7c124" category="list-text">Selezionare Broker replica Hyper-V nella pagina Seleziona ruolo.</block>
  <block id="fdbea454936dca227734d3f978334254" category="list-text">Fornire il nome NetBIOS e l'indirizzo IP da utilizzare come punto di connessione al cluster (punto di accesso client).</block>
  <block id="bb8627cc57d25f02546b85f38d97ae04" category="list-text">Questo processo crea un ruolo di broker replica Hyper-V. Verificare che sia online correttamente.</block>
  <block id="9b11f91c42607554f82ca0c4a5739d14" category="list-text">Configurare le impostazioni di replica.</block>
  <block id="662af7cfca9243c46223a416df05d774" category="list-text">Fare clic con il pulsante destro del mouse sul broker di replica creato nei passaggi precedenti e fare clic su Impostazioni di replica.</block>
  <block id="45375ee44c681920240b13f25bf53d9e" category="list-text">Selezionare attiva questo cluster come server di replica.</block>
  <block id="88aeceb8128e3b94092a3e66ac2236db" category="list-text">Nella sezione autorizzazione e archiviazione, selezionare i server autorizzati a replicare le VM in questo cluster. Inoltre, specificare la posizione predefinita in cui sono memorizzate le VM replicate.</block>
  <block id="3d9241b7079c08f25c850a7d8ac5eebd" category="inline-link-macro">Replica al di fuori di un ambiente cluster</block>
  <block id="3077be518a570235f65497aa5b227e9b" category="paragraph">La replica è simile al processo descritto nella sezione <block ref="85d27647a4d4ffb042b0371e9654ea4c" category="inline-link-macro-rx"></block>.</block>
  <block id="f8b7d7bb25e13b6b771e58da1fa078cb" category="summary">Provisioning dello storage ONTAP per Windows e Hyper-V in ambienti SAN</block>
  <block id="24294828f9d26e2b73b5b1e0eda7a2d0" category="paragraph">Le SVM di ONTAP supportano i protocolli di blocco iSCSI ed FC. Quando viene creata una SVM con protocollo a blocchi iSCSI o FC, la SVM ottiene rispettivamente un iSCSI Qualified Name (IQN) o un FC Worldwide Name (WWN). Questo identificatore presenta una destinazione SCSI per gli host che accedono allo storage a blocchi NetApp.</block>
  <block id="7f33f1b99e752967fce41fe3dec9f051" category="section-title">Provisioning del LUN NetApp su server Windows</block>
  <block id="025d3d39bb1937ffe40a12b1917e28b6" category="paragraph">L'utilizzo dello storage NetApp in ambienti SAN in Windows Server presenta i seguenti requisiti:</block>
  <block id="3e306b32d1acc6cfcca681b93d8d57cd" category="list-text">Un cluster NetApp è configurato con uno o più storage controller NetApp.</block>
  <block id="3e0ea625c6f590606b5242be6455347c" category="list-text">Il cluster NetApp o gli storage controller dispongono di una licenza iSCSI valida.</block>
  <block id="5bf7c7c03ed76506f8822badb526f0a8" category="list-text">Sono disponibili porte configurate iSCSI e/o FC.</block>
  <block id="46434438c1896350bc085c1a67785198" category="list-text">Lo zoning FC viene eseguito su uno switch FC per la connettività FC.</block>
  <block id="1e704db41d570618bd723b41d0db395e" category="list-text">Una SVM deve avere una LIF per rete Ethernet o fabric Fibre Channel su ogni storage controller che fornirà dati tramite iSCSI o Fibre Channel.</block>
  <block id="daa700de515c2e157d34b0e12c154478" category="list-text">Crea una nuova SVM con protocollo a blocchi iSCSI e/o FC abilitato. È possibile creare una nuova SVM utilizzando uno dei seguenti metodi:</block>
  <block id="ec642b047305fbfe6db973f313768eae" category="list-text">Comandi CLI sullo storage NetApp</block>
  <block id="43736124eda42b8dec979b188b9d891b" category="list-text">Configurare il protocollo iSCSI e/o FC.</block>
  <block id="51dbb9050f89d2c5cbfda6a46bb48963" category="list-text">Avviare il servizio iSCSI e/o FC sulla SVM.</block>
  <block id="5058f1af8388633f609cadb75a75dc9d" category="paragraph">.</block>
  <block id="80967cdacf7a48c49276c07097765c46" category="list-text">Creare set di porte iSCSI e/o FC usando i LIF SVM.</block>
  <block id="2d59cbd9d3169fc27e47164a0bf60c42" category="list-text">Creare un gruppo iniziatore iSCSI e/o FC per Windows utilizzando il set di porte creato.</block>
  <block id="b6efc79e22c0381d9fcc8c3f40ff674f" category="list-text">Aggiungere un iniziatore al gruppo iniziatore. L'iniziatore è l'IQN per iSCSI e WWPN per FC. È possibile eseguire una query da Windows Server eseguendo il cmdlet Get-InitatorPort di PowerShell.</block>
  <block id="ab39c1b30c8045ee5b2419b682b64e5c" category="paragraph">IQN per iSCSI su Windows Server può anche essere controllato nella configurazione delle proprietà dell'iniziatore iSCSI.</block>
  <block id="83f0120a854049de17bd46bb97e5c5fa" category="list-text">Creare una LUN mediante la procedura guidata Crea LUN e associarla al gruppo iniziatore creato.</block>
  <block id="186c31b1cbf72f8c54f9c6a0edca1cfe" category="paragraph">Windows Server utilizza l'estensione MPIO ALUA (Asymmetric Logical Unit Access) per determinare i percorsi diretti e indiretti verso i LUN. Anche se ogni LIF di proprietà di una SVM accetta richieste di lettura/scrittura per le proprie LUN, solo uno dei nodi del cluster è effettivamente proprietario dei dischi che supportano tale LUN in un dato momento. In questo modo i percorsi disponibili per un LUN vengono suddivisi in due tipi, diretto o indiretto, come illustrato nella figura seguente.</block>
  <block id="7dc177b120da05827161978955c8104e" category="paragraph">Un percorso diretto per una LUN è un percorso su cui le LIF di una SVM e la LUN a cui si accede risiedono nello stesso nodo. Per passare da una porta di destinazione fisica a un disco, non è necessario attraversare la rete cluster.</block>
  <block id="b456728920702bd70bc705a1af06be72" category="paragraph">I percorsi indiretti sono percorsi di dati su cui si trovano le LIF di una SVM e la LUN a cui si accede su nodi diversi. I dati devono attraversare la rete cluster per passare da una porta di destinazione fisica al disco.</block>
  <block id="6b08a0deb0bef5f6429e5fb7bab4da29" category="inline-image-macro">Percorsi multipli in ambiente SAN, larghezza=624, altezza=232</block>
  <block id="e5106eaf1ca3b8ff0d6a4555b38845de" category="paragraph"><block ref="e5106eaf1ca3b8ff0d6a4555b38845de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e6c7f4878b6fa562299bd45be030c4d" category="section-title">MPIO</block>
  <block id="90881f9a41c6c14a994dd6d410b5eae3" category="section-title">Attiva MPIO</block>
  <block id="1f4614ecf24e855792cb4a72e2ca4a86" category="paragraph">Per attivare MPIO su Windows Server, attenersi alla seguente procedura:</block>
  <block id="bb35cb72ffe2e8dd1a02cf65b86c6cd3" category="list-text">Avviare Server Manager.</block>
  <block id="d580309cd21fec5dd6a0fc9e095dacbe" category="list-text">Nella sezione Gestione, fare clic su Aggiungi ruoli e funzioni.</block>
  <block id="19c0c759d805032bc93817553dbc8ef9" category="list-text">Nella pagina Select Features (Seleziona funzioni), selezionare Multipath i/O.</block>
  <block id="63c2082592ff76eac0541130a24e7670" category="section-title">Configurare MPIO</block>
  <block id="655995aa16b525227f20b4e6b55a22cf" category="paragraph">Quando si utilizza il protocollo iSCSI, è necessario indicare a Windows Server di applicare il supporto multipath ai dispositivi iSCSI nelle proprietà MPIO.</block>
  <block id="3cdb8cf9c5fe85e070ceba959169e83f" category="paragraph">Per configurare MPIO su Windows Server, attenersi alla procedura illustrata di seguito:</block>
  <block id="bd27f39c0a288d0682b789a806d1eec7" category="list-text">Accedere a Windows Server come membro del gruppo di amministratori.</block>
  <block id="a267872bfc142a132ea159cb0904930f" category="list-text">Nella sezione Tools (Strumenti), fare clic su MPIO.</block>
  <block id="46205f4b1d4b254565cae2fd6970a3a6" category="list-text">In Proprietà MPIO su rileva percorsi multipli, selezionare Aggiungi supporto per dispositivi iSCSI e fare clic su Aggiungi. Viene quindi richiesto di riavviare il computer.</block>
  <block id="8c372bcf6ff4084f9e072d698d449b18" category="list-text">Riavviare Windows Server per vedere il dispositivo MPIO elencato nella sezione MPIO Devices (dispositivi MPIO) delle proprietà MPIO.</block>
  <block id="28f21ae88e9953ac3d80686cfb49832b" category="section-title">Configurare iSCSI</block>
  <block id="a12e2e6108a8b8cb032c190ebe798d79" category="paragraph">Per rilevare lo storage a blocchi iSCSI su Windows Server, attenersi alla seguente procedura:</block>
  <block id="623f636e32ba5729ab907ad3eeeb5adb" category="list-text">Nella sezione Strumenti, fare clic su iSCSI Initiator.</block>
  <block id="d259349ad54c81b69ffb57d045a7c135" category="list-text">Nella scheda rilevamento, fare clic su rileva portale.</block>
  <block id="9055f8c4230cf1268018d9b81d1c30e0" category="list-text">Fornisci l'indirizzo IP delle LIF associate alla SVM creata per lo storage NetApp per il protocollo SAN. Fare clic su Avanzate, configurare le informazioni nella scheda Generale, quindi fare clic su OK.</block>
  <block id="56fe767f1eb1a3401bb37455b6e1c804" category="list-text">L'iniziatore iSCSI rileva automaticamente la destinazione iSCSI e la elenca nella scheda Destinazioni.</block>
  <block id="f6357f1aad932cb8ef210a786e72e1e9" category="list-text">Selezionare la destinazione iSCSI nelle destinazioni rilevate. Fare clic su Connect (Connetti) per aprire la finestra Connect to Target (Connetti a destinazione).</block>
  <block id="28d26404caba20cb28577f61c51a7e1f" category="list-text">È necessario creare sessioni multiple dall'host Windows Server alle LIF iSCSI di destinazione sul cluster storage NetApp. A tale scopo, attenersi alla seguente procedura:</block>
  <block id="3aef6deb3c61c368bc66313781c8e351" category="list-text">Nella finestra connessione a destinazione, selezionare Enable MPIO (attiva MPIO) e fare clic su Advanced (Avanzate).</block>
  <block id="d754cac9ca73d1113c5fa5908ca2dc97" category="list-text">In Impostazioni avanzate nella scheda Generale, selezionare la scheda locale come Microsoft iSCSI Initiator e selezionare l'IP iniziatore e l'IP del portale di destinazione.</block>
  <block id="fdcb9587e9c4d393ea337f94fb0e1f5f" category="list-text">È inoltre necessario effettuare la connessione utilizzando il secondo percorso. Pertanto, ripetere i passi da 5 a 8, ma questa volta selezionare l'IP iniziatore e l'IP del portale di destinazione per il secondo percorso.</block>
  <block id="cb35c153406b8cdeb5963bd9a0ceb501" category="list-text">Selezionare la destinazione iSCSI nelle destinazioni rilevate nella finestra principale di iSCSI Properties e fare clic su Properties.</block>
  <block id="2a3977b58760a2b4c9e557175a5e494e" category="list-text">La finestra Proprietà mostra che sono state rilevate più sessioni. Selezionare la sessione, fare clic su Devices (periferiche), quindi fare clic sul pulsante MPIO per configurare il criterio di bilanciamento del carico. Vengono visualizzati tutti i percorsi configurati per il dispositivo e tutti i criteri di bilanciamento del carico sono supportati. In genere, NetApp consiglia di eseguire il round robin con il sottoinsieme e questa impostazione è quella predefinita per gli array con ALUA attivato. Round robin è l'impostazione predefinita per gli array Active-Active che non supportano ALUA.</block>
  <block id="7b7b8262c038321869fc17ba522bbe07" category="paragraph">Per rilevare lo storage a blocchi iSCSI o FC su Windows Server, attenersi alla seguente procedura:</block>
  <block id="7554b29976a023cca6089775e3a7fd73" category="list-text">Fare clic su Gestione computer nella sezione Strumenti di Gestione server.</block>
  <block id="b7e726cedaa814db32dbfe4395773cc4" category="list-text">In Gestione computer, fare clic sulla sezione Gestione disco in archiviazione, quindi fare clic su altre azioni e ripetere la scansione dei dischi. In questo modo vengono visualizzati i LUN iSCSI raw.</block>
  <block id="8fd13d2e47a19c784864b40dc7e4621f" category="list-text">Fare clic sul LUN rilevato e renderlo online. Quindi selezionare Initialize Disk (Inizializza disco) utilizzando la partizione MBR o GPT. Creare un nuovo volume semplice fornendo le dimensioni del volume e la lettera dell'unità e formattarlo utilizzando FAT, FAT32, NTFS o il file system resiliente (Refs).</block>
  <block id="31ef353687ab7c0fb280206b2eba67d0" category="list-text">NetApp consiglia di attivare il thin provisioning sui volumi che ospitano le LUN.</block>
  <block id="de065768c0f0b724b1926b25d92fdcef" category="list-text">Per evitare problemi di multipathing, NetApp consiglia di utilizzare tutte le 10Gb sessioni o tutte le 1Gb sessioni a un determinato LUN.</block>
  <block id="ed4eb5407c23e138e99781446b4170d8" category="list-text">NetApp consiglia di confermare l'abilitazione di ALUA nel sistema storage. ALUA è attivato per impostazione predefinita su ONTAP.</block>
  <block id="df0f70c4f2bca2f5f0216ab40982d08a" category="list-text">Nell'host del server Windows a cui è mappata la LUN NetApp, attivare il servizio iSCSI (TCP-in) per il servizio in entrata e il servizio iSCSI (TCP-out) per il servizio in uscita nelle impostazioni del firewall. Queste impostazioni consentono il passaggio del traffico iSCSI da e verso l'host Hyper-V e il controller NetApp.</block>
  <block id="defe090ca065bb89790c1a0b2d533ad0" category="section-title">Provisioning delle LUN NetApp sul server Nano</block>
  <block id="a7b1fc24d300b03d303a4e66fd5eaf19" category="inline-link-macro">Distribuire Nano Server.</block>
  <block id="c56e09ae358fe6206c8e4059eb76252b" category="paragraph">Oltre ai prerequisiti menzionati nella sezione precedente, il ruolo di archiviazione deve essere abilitato dal lato server Nano. Ad esempio, Nano Server deve essere distribuito utilizzando l'opzione -Storage. Per distribuire Nano Server, vedere la sezione "<block ref="00a4a5119b1e43564baa188fc895d5ff" category="inline-link-macro-rx"></block>"</block>
  <block id="152dbede177bc5347922fdc2b306adf2" category="paragraph">Per eseguire il provisioning dei LUN NetApp su un server nano, attenersi alla seguente procedura:</block>
  <block id="fe02f402a046a8784957e096b11835e3" category="list-text">Connettersi al Nano Server in modalità remota seguendo le istruzioni riportate nella sezione "<block ref="60e7ef5a283935545371795472ceb490" category="inline-link-macro-rx"></block>."</block>
  <block id="1b3c1a51c3603283ec4f7ab199a89ad3" category="list-text">Per configurare iSCSI, eseguire i seguenti cmdlet PowerShell sul Nano Server:</block>
  <block id="5e885af04f617a09b29600bd064e0a82" category="list-text">Aggiungere un iniziatore al gruppo iniziatore.</block>
  <block id="8a73c7acbdf9fc31a87cebe8de47a176" category="list-text">Configurare MPIO.</block>
  <block id="8e08d5639ddc5bf9f71aeea2f9df6706" category="list-text">Rileva lo storage a blocchi.</block>
  <block id="ad04ba98fa2a26c6e2a4f71314b1c4c7" category="section-title">Avvio da SAN</block>
  <block id="e29512aa6180bca309f145289f08337c" category="paragraph">Un host fisico (server) o una macchina virtuale Hyper-V può avviare il sistema operativo Windows Server direttamente da una LUN NetApp invece del disco rigido interno. Nell'approccio all'avvio da SAN, l'immagine del sistema operativo da cui eseguire l'avvio risiede su una LUN NetApp collegata a un host fisico o a una VM. Per un host fisico, l'HBA dell'host fisico è configurato per utilizzare il LUN NetApp per l'avvio. Per una VM, la LUN NetApp è collegata come disco pass-through per l'avvio.</block>
  <block id="2cf07cb81d5366158ac32b0d02e3bf39" category="paragraph">Grazie alla tecnologia NetApp FlexClone, è possibile clonare immediatamente le LUN di avvio con un'immagine del sistema operativo e allegarle ai server e alle macchine virtuali per fornire rapidamente immagini del sistema operativo pulite, come illustrato nella figura seguente.</block>
  <block id="e60c0a021a1a11ca0fd66050c818b441" category="inline-image-macro">Avviare le LUN con FlexClone NetApp, width=561, height=357</block>
  <block id="79f4f54e05eb2f1c2084e0542e66f182" category="paragraph"><block ref="79f4f54e05eb2f1c2084e0542e66f182" category="inline-image-macro-rx" type="image"></block></block>
  <block id="738e6a96e2bf795b59ac62d4827a779e" category="list-text">L'host fisico (server) dispone di un HBA iSCSI o FC appropriato.</block>
  <block id="7957c1b3b06b3ca5c17a05da5e59c9ec" category="list-text">È stato scaricato un driver di periferica HBA adatto per il server che supporta Windows Server.</block>
  <block id="1810f78aa22a9972644e65ac2cdad107" category="list-text">Il server dispone di un'unità CD/DVD o di un supporto virtuale adatto per inserire l'immagine ISO di Windows Server ed è stato scaricato il driver del dispositivo HBA.</block>
  <block id="0af744e0f07c6b198e478b2ba83aca3a" category="list-text">Viene eseguito il provisioning di una LUN iSCSI o FC NetApp sullo storage controller del NetApp.</block>
  <block id="30e2bee2ccadbae82d2d5aeddd5b4078" category="paragraph">Per configurare l'avvio da SAN per un host fisico, attenersi alla seguente procedura:</block>
  <block id="7d90eb9f56cbfbfe2930a2d651f51f3a" category="list-text">Attivare BootBIOS sull'HBA del server.</block>
  <block id="034cb1858f7a3762e67e18bff38aa62a" category="list-text">Per gli HBA iSCSI, configurare l'IP iniziatore, il nome del nodo iSCSI e la modalità di avvio della scheda nelle impostazioni del BIOS di avvio.</block>
  <block id="aeae1f3a4453e2d3e333de58d3f28c4a" category="list-text">Quando si crea un gruppo iniziatore per iSCSI e/o FC su un controller di storage NetApp, aggiungere l'iniziatore HBA del server al gruppo. L'iniziatore HBA del server è il WWPN per l'HBA FC o il nome del nodo iSCSI per l'HBA iSCSI.</block>
  <block id="1ec419dd357b1eacb28eec8cfd657908" category="list-text">Creare un LUN sullo storage controller NetApp con un ID LUN di 0 e associarlo al gruppo iniziatore creato nella fase precedente. Questo LUN serve come LUN di boot.</block>
  <block id="52ec2612ed3c17b60d5c662122410366" category="list-text">Limitare l'HBA a un singolo percorso verso il LUN di avvio. È possibile aggiungere altri percorsi dopo l'installazione di Windows Server sul LUN di avvio per sfruttare la funzione multipathing.</block>
  <block id="0fa69ac9076a9031393e6f5d4aa909d5" category="list-text">Utilizzare l'utilità BootBIOS dell'HBA per configurare il LUN come dispositivo di avvio.</block>
  <block id="58347d33bbc0409dce93e92c5983619a" category="list-text">Riavviare l'host e accedere all'utilità BIOS host.</block>
  <block id="1b9013d7a416c62e05336b3791451d0d" category="list-text">Configurare il BIOS host in modo che il LUN di avvio sia il primo dispositivo nell'ordine di avvio.</block>
  <block id="3472e7b0e2c4389366cf3e0f09f6376d" category="list-text">Dall'ISO di Windows Server, avviare il programma di installazione.</block>
  <block id="8423662d97649ae1012d665b6594f514" category="list-text">Quando l'installazione richiede "dove installare Windows?", fare clic su carica driver nella parte inferiore della schermata di installazione per avviare la pagina Seleziona driver da installare. Fornire il percorso del driver di periferica HBA scaricato in precedenza e completare l'installazione del driver.</block>
  <block id="4d0de28cb0fe5a517374a0c7fdaaff27" category="list-text">Ora il LUN di avvio creato in precedenza deve essere visibile nella pagina di installazione di Windows. Selezionare il LUN di avvio per l'installazione di Windows Server sul LUN di avvio e terminare l'installazione.</block>
  <block id="0dbc8e7afe6136a3b34471c047b28f83" category="paragraph">Per configurare l'avvio da SAN per una VM, attenersi alla seguente procedura:</block>
  <block id="6af97eac32eef9a62687eac41262ae48" category="list-text">Quando si crea un gruppo iniziatore per iSCSI o FC su un controller di storage NetApp, aggiungere al controller il codice IQN per iSCSI o il codice WWN per FC del server Hyper-V.</block>
  <block id="c18de5a7c8558c6b9b749ea9d61336da" category="list-text">Creare LUN o cloni LUN sullo storage controller NetApp e associarli al gruppo iniziatore creato nella fase precedente. Queste LUN fungono da LUN di boot per le macchine virtuali.</block>
  <block id="dac33c93e3d9b5c90a34c39aa579711a" category="list-text">Rilevare le LUN sul server Hyper-V, portarle online e inizializzarle.</block>
  <block id="441d10873880501fa764914d0bf1f044" category="list-text">Portare i LUN offline.</block>
  <block id="0490d2908eb59e831010f6c50ebdf6ea" category="list-text">Creare le macchine virtuali con l'opzione Allega un disco rigido virtuale in un secondo momento nella pagina Connetti disco rigido virtuale.</block>
  <block id="2b2b3b281225dec976273bad7f4dacf0" category="list-text">Aggiunta di un LUN come disco pass-through a una macchina virtuale.</block>
  <block id="ab82d3a85d9187f45c1cac0bd2922647" category="list-text">Aprire le impostazioni VM.</block>
  <block id="d2e03542bea91031de7772d6cb0b7b13" category="list-text">Fare clic su Controller IDE 0, selezionare disco rigido e fare clic su Aggiungi. Selezionando IDE Controller 0 questo disco diventa il primo dispositivo di avvio per la VM.</block>
  <block id="1904d13d92aac636b46007dec34eb357" category="list-text">Selezionare disco rigido fisico nelle opzioni disco rigido e selezionare un disco dall'elenco come disco pass-through. I dischi sono i LUN configurati nelle fasi precedenti.</block>
  <block id="19e47f17e14687afa5f6c07833dbd7aa" category="list-text">Installare Windows Server sul disco pass-through.</block>
  <block id="30f837081d56a5f1605e52592a38d5f4" category="list-text">Verificare che i LUN siano offline. In caso contrario, il disco non può essere aggiunto come disco pass-through a una VM.</block>
  <block id="9865f9e3af02eaca8b480229a22515f4" category="list-text">Quando esistono più LUN, annotare il numero del disco del LUN nella gestione del disco. Questa operazione è necessaria perché i dischi elencati per la VM sono elencati con il numero del disco. Inoltre, la selezione del disco come disco pass-through per la VM si basa su questo numero di disco.</block>
  <block id="15b11e66e58b25dffc74ff36f6529d4d" category="list-text">NetApp consiglia di utilizzare ONTAP MPIO configurato sull'host a scopo di storage.</block>
  <block id="154e178d8f948264ecf34dcfd8ad3112" category="summary">Questa appendice descrive come utilizzare la migrazione live di Hyper-V al di fuori di un ambiente in cluster</block>
  <block id="3a37015d23bf5b95b8aaeeb60e7149f6" category="paragraph">Questa sezione descrive l'implementazione della migrazione live di Hyper-V all'esterno di un ambiente in cluster.</block>
  <block id="34076d85579973b175bda646666488f5" category="list-text">Server Hyper-V standalone con storage indipendente o storage SMB condiviso.</block>
  <block id="6d3867adf71fde2bd2e28c3530f980e2" category="list-text">Il ruolo Hyper-V installato sui server di origine e di destinazione.</block>
  <block id="860a24a5665c79d337512cf7091c1f27" category="list-text">Entrambi i server Hyper-V appartengono allo stesso dominio o a domini che si fidano l'uno dell'altro.</block>
  <block id="599b01a5eeab6af8dcd5d22203b25b3b" category="paragraph">Per eseguire la migrazione live in un ambiente non in cluster, configurare i server Hyper-V di origine e di destinazione in modo che possano inviare e ricevere operazioni di migrazione live. Su entrambi i server Hyper-V, completare la seguente procedura:</block>
  <block id="5c8aa736f4d71f22237d67e44338e090" category="list-text">In azioni, fare clic su Impostazioni Hyper-V.</block>
  <block id="146cc3da35b3cb4807f19e5c342f3d0b" category="list-text">Fare clic su Live Migration e selezionare Enable Incoming and Outgoing Live Migrations (Abilita migrazioni Live in entrata e in uscita).</block>
  <block id="000104d6631c201d8476c728987584e9" category="list-text">Scegliere se consentire il traffico di migrazione live su qualsiasi rete disponibile o solo su reti specifiche.</block>
  <block id="bbba185068a3a5aa887f5064ee5fc3de" category="list-text">In alternativa, è possibile configurare il protocollo di autenticazione e le opzioni relative alle prestazioni dalla sezione Advanced (Avanzate) di Live Migrations (migrazioni in tempo reale).</block>
  <block id="0d91ef025d958a7706b6abf25f2160a5" category="list-text">Se si utilizza CredSSP come protocollo di autenticazione, assicurarsi di accedere al server Hyper-V di origine dal server Hyper-V di destinazione prima di spostare la macchina virtuale.</block>
  <block id="4671ab6d9ed8f69134f49812ab7a7c35" category="list-text">Se Kerberos viene utilizzato come protocollo di autenticazione, configurare la delega vincolata. Questa operazione richiede l'accesso al controller di dominio Active Directory. Per configurare la delega, attenersi alla seguente procedura:</block>
  <block id="3c3a519ac45fd3a37ae321645897af94" category="list-text">Accedere al controller di dominio Active Directory come amministratore.</block>
  <block id="15be526c72b91c88e16f64f6c832eb6b" category="list-text">Nella sezione Strumenti, fare clic su utenti e computer di Active Directory.</block>
  <block id="444f95dff8ac9b4c8c6335d66d6ae4a7" category="list-text">Espandere il dominio e fare clic su computer.</block>
  <block id="a07ecc7f9ab368b241540687975a30aa" category="list-text">Selezionare il server Hyper-V di origine dall'elenco, fare clic con il pulsante destro del mouse su di esso e scegliere Proprietà.</block>
  <block id="a3a23c7b6ce827c11b3cdb698108c307" category="list-text">Nella scheda delega, selezionare considera attendibile il computer per la delega solo ai servizi specificati.</block>
  <block id="4070350eb1a20fec8173f5ee230b8566" category="list-text">Selezionare utilizza solo Kerberos.</block>
  <block id="36d92877123542287dffc5912e198436" category="list-text">Fare clic su Aggiungi per aprire la procedura guidata Aggiungi servizi.</block>
  <block id="2a206fdec4cfdbdd63ff3dd2265bbb34" category="list-text">In Aggiungi servizi, fare clic su utenti e computer, che apre Seleziona utenti o computer**.**</block>
  <block id="6fb0c1f70349caf1f37bdb1c7b73efe4" category="list-text">Specificare il nome del server Hyper-V di destinazione e fare clic su OK.</block>
  <block id="261db7be66ebd6db420e928cb4b402f7" category="list-text">Per spostare lo storage delle macchine virtuali, selezionare CIFS.</block>
  <block id="f4288db12d8f66e52ec2ac189f491e82" category="list-text">Per spostare le macchine virtuali, selezionare il servizio Microsoft Virtual System Migration.</block>
  <block id="9149d965e2ccf728685f671fb1046ab9" category="list-text">Nella scheda delega, fare clic su OK.</block>
  <block id="9bc766cbcc4911cf673963ca303576bc" category="list-text">Dalla cartella computer, selezionare il server Hyper-V di destinazione dall'elenco e ripetere il processo. In Seleziona utenti o computer, fornire il nome del server Hyper-V.</block>
  <block id="5868e6c6d4568bb2c1245c731ab1f681" category="list-text">Spostare la macchina virtuale.</block>
  <block id="ab102f10122268c6b0663d464d3192da" category="list-text">Scegliere Sposta macchina virtuale.</block>
  <block id="8b95cb0524fdc80c99bdf8cb976556d2" category="list-text">Specificare il server Hyper-V di destinazione per la macchina virtuale.</block>
  <block id="25b70b154b120ba061f03c292637a9a4" category="list-text">Scegliere le opzioni di spostamento. Per Shared Live Migration, scegliere Sposta solo la macchina virtuale. Per Shared Nothing Live Migration, scegli una delle altre due opzioni in base alle tue preferenze.</block>
  <block id="8c60fc97ae35b3af22d644ab2b9186e7" category="list-text">Fornire la posizione della macchina virtuale sul server Hyper-V di destinazione in base alle proprie preferenze.</block>
  <block id="dd714dbbaab89194e2aefdf439089cff" category="list-text">Rivedere il riepilogo e fare clic su OK per spostare la VM.</block>
  <block id="8ab11353f8fda3f130084c6ff3c1f32e" category="summary">Panoramica della virtualizzazione Microsoft Windows e Hyper-V con ONTAP</block>
  <block id="e905fd86484ea1bf5b665b34fc9e24b4" category="paragraph">Microsoft Windows Server è un sistema operativo di classe Enterprise che copre networking, sicurezza, virtualizzazione, cloud privato, cloud ibrido, infrastruttura desktop virtuale, protezione degli accessi, protezione delle informazioni, servizi web, infrastruttura della piattaforma applicativa, e molto altro ancora.</block>
  <block id="16b5970810caafa8d6f89bee6e0398f2" category="admonition">*Questa documentazione sostituisce i report tecnici pubblicati in precedenza _TR-4568: Linee guida per la distribuzione di NetApp e Best practice per lo storage in Windows Server_*</block>
  <block id="dbf037f8e99a1d5b52fe58af78568561" category="list-text">Un'architettura unificata che supporta protocolli di file, oggetti e blocchi. In questo modo, gli storage controller fungono da dispositivi NAS e SAN e da archivi di oggetti</block>
  <block id="23748de0bc860150d3c6b27a4d472042" category="list-text">Un array All SAN (ASA) incentrato solo sui protocolli a blocchi e che ottimizza i tempi di ripresa dell'i/o (IORT) aggiungendo multipathing Active-Active simmetrico per gli host di connessione</block>
  <block id="d0114359083804284c542907b2f8cd60" category="list-text">Un'architettura unificata software-defined</block>
  <block id="30063e1e8c837a5b52057909e747b2d8" category="list-text">ONTAP Select in esecuzione su VMware vSphere o KVM</block>
  <block id="0f76eddbf2cd8ceb8e89447591876ab9" category="list-text">Cloud Volumes ONTAP in esecuzione come istanza cloud nativa</block>
  <block id="f7d26dbdc8e2b21b211abf2157e73536" category="list-text">Offerte di first party degli hyperscale cloud provider</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="list-text">Amazon FSX per NetApp ONTAP</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="list-text">Google Cloud NetApp Volumes</block>
  <block id="7ad18871bdb08a3899a3f7ed4e463284" category="paragraph">ONTAP offre funzionalità di efficienza dello storage NetApp come la tecnologia Snapshot(R) di NetApp, il cloning, la deduplica, il thin provisioning, la replica con risorse limitate, compressione, virtual storage tiering e molto altro ancora con performance ed efficienza migliorate.</block>
  <block id="538a662f2ecbeba6af56e41386484f67" category="paragraph">Insieme, Windows Server e ONTAP sono in grado di operare in ambienti di grandi dimensioni e offrire un valore immenso al consolidamento dei data center e alle implementazioni di cloud privato o ibrido. Questa combinazione offre anche carichi di lavoro senza interruzioni in modo efficiente e supporta una scalabilità perfetta.</block>
  <block id="8f0442ea7c58fe8ab4000f5aaeac415b" category="paragraph">Il presente documento è destinato agli architetti di sistema e di storage che progettano soluzioni di storage NetApp per server Windows.</block>
  <block id="f6f27d1607ed17a4b610676f16f68357" category="paragraph">Nel presente documento si presuppone quanto segue:</block>
  <block id="e9d690b9eb25093e460ea369baa55496" category="inline-link">Guida all'amministrazione di sistema per gli amministratori di cluster</block>
  <block id="d54e01b4234443b582b1d0cc44ce1c19" category="list-text">Il lettore ha una conoscenza generale delle soluzioni hardware e software NetApp. Vedere<block ref="87244016000a25428f0fcae2d3732d46" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="c501659fe58b766ec2ead9a0c974e530" category="inline-link">Gestione DELLE SAN di Clustered Data ONTAP</block>
  <block id="75ac79ee68c2245f6d8b8cc32a3eae9e" category="inline-link">Gestione NAS</block>
  <block id="48fa880bcded409e494bd8e2e8c64a97" category="list-text">Il lettore vanta una conoscenza generale dei protocolli di accesso ai blocchi, quali iSCSI, FC e il protocollo di accesso ai file SMB/CIFS. Vedere<block ref="123a6e61ead9566ba44616c8f29f1ba3" category="inline-link-rx"></block> Per informazioni relative alle SAN. Vedere<block ref="9933d9f07fd1633df051103d1b03340e" category="inline-link-rx"></block> Per informazioni relative a CIFS/SMB.</block>
  <block id="02279515531a2de57bfdffa958d40813" category="list-text">Il lettore possiede una conoscenza generale del sistema operativo Windows Server e di Hyper-V.</block>
  <block id="e1e99607c6efe5e3439e886c50500015" category="paragraph">Per una matrice completa e aggiornata regolarmente di configurazioni SAN e NAS testate e supportate, consultare il<block ref="5555d80b97794db0ba7e8564a4b85ca4" category="inline-link-rx"></block> Sul sito del supporto NetApp. Con IMT, è possibile determinare le versioni esatte dei prodotti e delle funzionalità supportate per il proprio ambiente specifico. NetApp IMT definisce i componenti e le versioni del prodotto compatibili con le configurazioni supportate da NetApp. I risultati specifici dipendono dall'installazione di ciascun cliente in conformità alle specifiche pubblicate.</block>
  <block id="3eb0aeddd8b10d858bd2028c6f983308" category="summary">Best practice operative per lo storage SRM e ONTAP di VMware</block>
  <block id="35d022831f6b84d57c0d19770bd37b82" category="list-text">ONTAP 9 può essere configurato in modo da rimuovere automaticamente le istantanee per preservare l'uptime in caso di esaurimento dello spazio quando il dimensionamento automatico non è in grado di fornire una capacità di emergenza sufficiente. L'impostazione predefinita di questa funzionalità non elimina automaticamente le snapshot create da SnapMirror. Se le snapshot SnapMirror vengono eliminate, il servizio SRA di NetApp non può invertire e risincronizzare la replica per il volume interessato. Per impedire a ONTAP di eliminare snapshot di SnapMirror, configurare la funzionalità di eliminazione automatica Snapshot in modo da provare.</block>
  <block id="70ca1a895029f273d425b715900ff37a" category="inline-image-macro">Replica vVol</block>
  <block id="0c1274faebf0b61ccee15ede78b00b55" category="paragraph"><block ref="0c1274faebf0b61ccee15ede78b00b55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c5aade1021a3c4cd296db5e8cca90b" category="inline-image-macro">Pianificazioni di SnapMirror</block>
  <block id="a1066290411892a896db86292d410eb3" category="paragraph"><block ref="a1066290411892a896db86292d410eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1079afba0a1986bf5bb313da40d31a49" category="inline-image-macro">mappatura dei criteri</block>
  <block id="32e0e862ac943abe75cff3d58b3e5d2b" category="paragraph"><block ref="32e0e862ac943abe75cff3d58b3e5d2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dd63afe980253ca98d9e32784c2f1fc" category="paragraph">Questo viene fornito con un nuovo requisito per conto dell'amministratore di vSphere. Poiché i volumi vengono creati al di fuori dell'ambito degli strumenti di ONTAP, non è a conoscenza delle modifiche apportate dall'amministratore di ONTAP fino al periodo di riscoperta regolarmente pianificato. Per questo motivo, è consigliabile eseguire sempre la risDiscovery ogni volta che si crea un volume o una relazione SnapMirror da utilizzare con i vVol. È sufficiente fare clic con il pulsante destro del mouse sull'host o sul cluster e selezionare ONTAP tools &gt; Update host and Storage Data (Strumenti &gt; Aggiorna dati host e archiviazione), come illustrato nella seguente schermata.</block>
  <block id="2802aa9f39078d087d6ee0f565b18e51" category="inline-image-macro">Aggiornamento dei dati host e di archiviazione</block>
  <block id="416223ee42c638c719e40efc871fe8a1" category="paragraph"><block ref="416223ee42c638c719e40efc871fe8a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06b2d4b91b5c9eaa8c20a1c270f95b3c" category="inline-image-macro">cluster</block>
  <block id="6c0893d9a45aaff00c1ef0daf0867ada" category="paragraph"><block ref="6c0893d9a45aaff00c1ef0daf0867ada" category="inline-image-macro-rx" type="image"></block></block>
  <block id="820b71b9a8a55fe48690a5f973c5480e" category="paragraph">La progettazione software con strumenti ONTAP per VMware vSphere si avvale delle seguenti attività di sviluppo sicure:</block>
  <block id="ecdc76c84c9674a3148f3d464298469c" category="paragraph">I tool ONTAP per VMware vSphere includono le seguenti funzionalità di sicurezza in ciascuna release.</block>
  <block id="0785fa6b3221e7345916be824259dc2f" category="paragraph">Quando si utilizzano DSP con strumenti ONTAP per VMware vSphere, è necessario prima creare un datastore con il plug-in, utilizzare vCenter per creare il cluster di datastore e quindi aggiungere il datastore. Una volta creato il cluster di datastore, è possibile aggiungere ulteriori datastore al cluster di datastore direttamente dalla procedura guidata di provisioning nella pagina Dettagli.</block>
  <block id="043d75b2a25cf6f38bccaf9211c5bcc5" category="summary">In questa pagina sono descritte le Best practice per l'implementazione di una soluzione di storage ONTAP in un ambiente VMware vSphere.</block>
  <block id="760f70bd45ae12af9fa6bee90f402eeb" category="cell">Fare riferimento a NFS.MaxQueueDefelse in <block ref="1f38ac07598dbb4b06912539aafa4211" category="inline-link-macro-rx"></block>.</block>
  <block id="647fe6e64f77a1f54f9bb61154ab2a4f" category="summary">Altre risorse vVol</block>
  <block id="852ee2d26adc87d2379ffeb9287f7642" category="inline-image-macro">Tool ONTAP per la dashboard VMware vSphere 9,8 vVol</block>
  <block id="12947c7ceaf237f27fd206edb07cc0c1" category="paragraph"><block ref="12947c7ceaf237f27fd206edb07cc0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2c48e84c0d02dd4e236da05038bd9a" category="paragraph">ONTAP supporta gli archivi dati VMFS e NFS vVol. L'utilizzo di vVol con datastore SAN offre alcuni dei vantaggi di NFS, come la granularità a livello di macchine virtuali. Di seguito sono riportate alcune Best practice da prendere in considerazione e ulteriori informazioni sono disponibili in <block ref="7be3ce63e842612697a6d91b19b8afcd" category="inline-link-macro-rx"></block>:</block>
  <block id="436b5d96360742275889cb237fe2ab70" category="inline-image-macro">Componenti vVol</block>
  <block id="1706c14e85f152d61bab2f65d32810a1" category="paragraph"><block ref="1706c14e85f152d61bab2f65d32810a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f38d7beb04aa98b65d2317c2f1659f" category="inline-image-macro">Tool ONTAP per vSphere</block>
  <block id="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="paragraph"><block ref="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0e8af5e898d44e394489b0c629abb" category="image-alt">Gruppi di host VM e regole di affinità</block>
  <block id="9a2f41e25337439aa55e14c7e16bf211" category="summary">La soluzione ONTAP per SRM (Site Recovery Manager) di VMware</block>
  <block id="a2fca395a283b61cb3e85ebc206c6274" category="paragraph">Sin dall'introduzione nel moderno data center nel 2002, ONTAP è una soluzione storage leader per gli ambienti VMware vSphere e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi.</block>
  <block id="f98dd9d12416a648450df8c99d10878a" category="summary">Questa è una panoramica dei volumi virtuali di VMware vSphere (vVol) con ONTAP</block>
  <block id="674c41ba00ec77fc9d294abbba7e7b7d" category="paragraph">ONTAP è stata una soluzione storage leader per gli ambienti VMware vSphere da oltre vent'anni e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi.</block>
  <block id="ae7454da5e20b82b7fe67eb1ff88c923" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4400: Volumi virtuali VMware vSphere (vVol) con ONTAP_</block>
  <block id="ee82b7a98212a75a2397dd9c5f9b1ab4" category="paragraph">ONTAP ha supportato la specifica VASA dalla sua versione iniziale nel 2012. Sebbene altri sistemi storage NetApp possano supportare VASA, questo documento si concentra sulle versioni attualmente supportate di ONTAP 9.</block>
  <block id="669b30b7e6d5ef1d862fe65880b816a8" category="paragraph">Oltre a ONTAP 9 su sistemi AFF, ASA e FAS, NetApp supporta i carichi di lavoro VMware su ONTAP Select, Amazon FSX per NetApp con VMware Cloud su AWS, la soluzione Azure NetApp Files con Azure VMware, Cloud Volumes Service con Google Cloud VMware Engine e NetApp Private Storage in Equinix, tuttavia, le funzionalità specifiche possono variare in base al provider di servizi e alla connettività di rete disponibile. È inoltre disponibile l'accesso dai guest vSphere ai dati memorizzati in tali configurazioni e a Cloud Volumes ONTAP.</block>
  <block id="afd715f07b1ec06fe77bf23a2d7bf185" category="paragraph">_Per ulteriori informazioni sulle Best practice di ONTAP e VMware vSphere, vedere <block ref="5dbb4949ffa7cb97fe4eaffc517a1111" category="inline-link-macro-rx"></block>_</block>
  <block id="bfdc61fd18bd1a23d9660561bc8999b7" category="list-text">*Cloud Volumes ONTAP.* il software per la gestione dei dati NetApp Cloud Volumes ONTAP offre controllo, protezione, flessibilità ed efficienza ai tuoi dati sul cloud di tua scelta. Cloud Volumes ONTAP è un software di gestione dei dati nativo del cloud basato sullo storage ONTAP. Utilizzare insieme a Cloud Manager per implementare e gestire le istanze di Cloud Volumes ONTAP insieme ai sistemi ONTAP on-premise. Sfrutta le funzionalità NAS e SAN iSCSI avanzate insieme a una gestione dei dati unificata, incluse le snapshot e la replica SnapMirror.</block>
  <block id="e88c947a5d8f4c0daec271a8595604a7" category="inline-image-macro">Vista macchine virtuali Active IQ Unified Manager</block>
  <block id="9078040b61fc8a9bd0215e8f35ff788c" category="paragraph"><block ref="9078040b61fc8a9bd0215e8f35ff788c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ef2f850d3f17cacfbd404bade7eed5b" category="inline-image-macro">Topologia espansa AIQUM</block>
  <block id="75817aa97084cb93e0292a1f0549551f" category="paragraph"><block ref="75817aa97084cb93e0292a1f0549551f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbd6cdb70073007e002f1ae45c2f7e4a" category="summary">Topologie di replica con ONTAP con SnapMirror e VMware SRM.</block>
  <block id="4e749568996a3331860532ac7a470fdb" category="inline-image-macro">Layout della relazione di SnapMirror</block>
  <block id="3d2c169d59a49a498b2d7e714c5a6ce2" category="paragraph"><block ref="3d2c169d59a49a498b2d7e714c5a6ce2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706bdd824ec69e00026180eaf2801d2e" category="paragraph"><block ref="706bdd824ec69e00026180eaf2801d2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba1aebb9b3c7be6b408863c12bbc2844" category="paragraph"><block ref="ba1aebb9b3c7be6b408863c12bbc2844" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea07c4b81c3f00ae8bbef49ac8562d1c" category="paragraph"><block ref="ea07c4b81c3f00ae8bbef49ac8562d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a757dd793cbe082927530094a72d26" category="inline-image-macro">coppie di array</block>
  <block id="263506cdbbc7c35e461fc5f1044b9c79" category="paragraph"><block ref="263506cdbbc7c35e461fc5f1044b9c79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b26873df0260bdc332a7511f6823cf63" category="inline-image-macro">Configurazioni non supportate</block>
  <block id="120528a3f7d5a39fdd0d67fb0e2b94a4" category="paragraph"><block ref="120528a3f7d5a39fdd0d67fb0e2b94a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="160a69c7a04198d870353b06dbf714a9" category="paragraph"><block ref="160a69c7a04198d870353b06dbf714a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="742a3ab0c9a97e5a438c8edfb1b271d2" category="paragraph"><block ref="742a3ab0c9a97e5a438c8edfb1b271d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0a05359b36f0932509cfa007b46e853" category="inline-image-macro">Cascata di relazioni di SnapMirror</block>
  <block id="2057708d80974a7573d92b3e0d8a9258" category="paragraph"><block ref="2057708d80974a7573d92b3e0d8a9258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd92dffb12f75e4b81ad67d8668ae698" category="inline-image-macro">SnapMirror a cascata SnapVault</block>
  <block id="13ece5df0d16f65585acbfb9ebad113c" category="paragraph"><block ref="13ece5df0d16f65585acbfb9ebad113c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c74d71595c83ecb05581a89554ca8bb2" category="inline-image-macro">Inverso di SnapMirror a SnapVault</block>
  <block id="5bb35c000e450925b37eff3feca75a24" category="paragraph"><block ref="5bb35c000e450925b37eff3feca75a24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ab367df5e87b988bc086e5ee534793e" category="summary">In questa pagina sono descritte le Best practice per l'implementazione di VMware vSphere con ONTAP e datastore connessi a NFS.</block>
  <block id="0e768c8183bcbfc87718f59d9dfd61eb" category="inline-link-macro">datastore</block>
  <block id="e6a172fa04a2b585ad34762a7e8991da" category="list-text">Fare riferimento alle note della tabella di interoperabilità NFS v4.1 nella <block ref="6a9c495bd8eb9d28b9471f77a4372a63" category="inline-link-macro-rx"></block> Per i livelli di patch ESXi specifici richiesti per il supporto.</block>
  <block id="622b235a9123d972c612737c81eb55a1" category="inline-link-macro">Funzione NFSv3 nConnect con NetApp e VMware</block>
  <block id="d94a770977f68948a4930f4a2edbabb9" category="image-alt">Nuovo cluster</block>
  <block id="f5c7047b98efcb8c7eef2db6ef31faf4" category="image-alt">Attivare l'opzione monitoraggio host</block>
  <block id="239aaf78fcb42b02d3709057d2a7978a" category="image-alt">Monitoraggio VM</block>
  <block id="a7765f8868404f7c3cb890ce051f7de4" category="image-alt">Controllo ammissione</block>
  <block id="e5bd6e5564d38885fef18a28e48861b4" category="image-alt">Cluster HA</block>
  <block id="8e00c91ecf143f76c94e3aa1668fc92b" category="inline-image-macro">Cloning ONTAP</block>
  <block id="9c7295440be885852a164f5880627146" category="paragraph"><block ref="9c7295440be885852a164f5880627146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eed6756a7834e04fb7716ee8d830425" category="inline-link-macro"><block ref="1eed6756a7834e04fb7716ee8d830425" category="inline-link-rx"></block></block>
  <block id="0e4a75553a081fffff029a37e55f5d71" category="inline-link-macro"><block ref="0e4a75553a081fffff029a37e55f5d71" category="inline-link-rx"></block></block>
  <block id="32fd58743bd2ce579949a47db1b95ca8" category="summary">La replica vVol con VASA offre funzionalità uniche rispetto a SRA e ai datastore tradizionali.</block>
  <block id="570bfadf5783125790b6c87f55842fb2" category="inline-image-macro">Implementazione SnapCenter</block>
  <block id="71ca4878111d253f9883f471e5de9594" category="paragraph"><block ref="71ca4878111d253f9883f471e5de9594" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd90e11d4c9fc73f37adda8029276215" category="summary">In questa pagina sono descritte le Best practice per l'implementazione di una soluzione di storage ONTAP in un ambiente VMware vSphere.</block>
  <block id="ab906277df9ce070b1e11724f8ccf589" category="list-text">Utilizzare una singola interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP. Le raccomandazioni precedenti di un LIF per datastore non sono più necessarie. Benché l'accesso diretto (LIF e datastore nello stesso nodo) sia migliore, non preoccuparti dell'accesso indiretto perché l'effetto sulle performance è generalmente minimo (microsecondi).</block>
  <block id="8dc90de75c19a4114217f443b0ca2866" category="inline-image-macro">Connettività da un host vSphere a un datastore NFS ONTAP</block>
  <block id="36b9a8da16a1d2fad06b788e662b7c4a" category="paragraph"><block ref="36b9a8da16a1d2fad06b788e662b7c4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb6d2d52dfe07f9662232c444256aece" category="paragraph">Un host che utilizza iSCSI o NVMe/TCP può essere collegato direttamente a un sistema storage e funzionare normalmente. La ragione è la pedata. Le connessioni dirette a due storage controller differenti offrono due percorsi indipendenti per il flusso di dati. La perdita di percorso, porta o controller non impedisce l'utilizzo dell'altro percorso.</block>
  <block id="0d761ccb2787bad60b77ac971f6d3914" category="summary">In questa pagina sono descritte le Best practice per l'implementazione dei volumi ONTAP FlexGroup in un ambiente VMware vSphere.</block>
  <block id="adc6ae60e2ce9c7497e70727d5232a2d" category="paragraph">Utilizza volumi ONTAP e FlexGroup con VMware vSphere per datastore semplici e scalabili che sfruttano tutta la potenza di un intero cluster ONTAP.</block>
  <block id="53c3353b925071c58c705888c2ba7f14" category="paragraph">ONTAP 9,8, insieme ai tool ONTAP per VMware vSphere 9,8 e al plug-in SnapCenter per VMware 4,4, ha aggiunto il supporto per i datastore basati su volumi FlexGroup in vSphere. I volumi FlexGroup semplificano la creazione di datastore di grandi dimensioni e creano automaticamente i volumi costituenti distribuiti necessari nel cluster ONTAP, per ottenere le massime performance da un sistema ONTAP.</block>
  <block id="3f004d1e872dca374feb3f23565997c6" category="paragraph">Utilizza i volumi FlexGroup con vSphere se desideri un singolo datastore vSphere scalabile con la potenza di un cluster ONTAP completo o se disponi di carichi di lavoro di cloning molto grandi che possono sfruttare il nuovo meccanismo di cloning di FlexGroup.</block>
  <block id="55e0e7799b68cd76cf68be0ee82fef7b" category="section-title">Offload delle copie</block>
  <block id="6dda3ca3c4d8fee4a726d8e72402d30a" category="paragraph">Oltre agli estesi test di sistema con i carichi di lavoro vSphere, ONTAP 9,8 ha aggiunto un nuovo meccanismo di offload delle copie per i datastore FlexGroup. Questo nuovo sistema utilizza un motore di copia migliorato per replicare i file tra i componenti in background consentendo l'accesso sia all'origine che alla destinazione. La cache locale viene quindi utilizzata per creare rapidamente istanze dei cloni delle macchine virtuali on-demand.</block>
  <block id="aa27f776099657de8054550adc71803c" category="inline-link">Come configurare ONTAP FlexGroup per consentire l'offload delle copie VAAI</block>
  <block id="52b5c3310b38cd7b3015770aa7de4aa7" category="paragraph">Per attivare l'offload delle copie ottimizzato per FlexGroup, fare riferimento alla sezione<block ref="cbb2bc98314efa36f692ba86393a7074" category="inline-link-rx"></block></block>
  <block id="0db4fc806176bc768d44fa59cf3c36aa" category="paragraph">Potresti accorgerti che se utilizzi il cloning VAAI, ma non quello per mantenere calda la cache, i cloni potrebbero non essere più veloci di una copia basata su host. In questo caso, è possibile regolare il timeout della cache per soddisfare meglio le proprie esigenze.</block>
  <block id="1e8e371d8058e71f2444bc0cd42517eb" category="paragraph">Ogni nuovo processo di clonazione che un volume riceve ripristina il timeout. Se un volume costituente nel FlexGroup di esempio non riceve una richiesta di clone prima del timeout, la cache di quella particolare VM verrà cancellata e il volume dovrà essere popolato di nuovo. Inoltre, se l'origine del clone originale cambia (ad esempio, è stato aggiornato il modello), la cache locale di ciascun componente verrà invalidata per evitare conflitti. Come indicato in precedenza, la cache può essere regolata in base alle esigenze dell'ambiente.</block>
  <block id="6bcf203b609d41b14c06e319cede61d7" category="section-title">Impostazioni QoS</block>
  <block id="9ab9903a16c07ff38214a043719957fd" category="paragraph">È supportata la configurazione della qualità del servizio a livello di FlexGroup utilizzando ONTAP System Manager o la shell del cluster, ma non fornisce consapevolezza delle macchine virtuali o integrazione di vCenter.</block>
  <block id="d9450aaad95d69e8cc75ddc0a69a9026" category="paragraph">La qualità del servizio (IOPS max/min) può essere impostata su singole macchine virtuali o su tutte le macchine virtuali di un datastore in quel momento nell'interfaccia utente di vCenter o tramite API REST utilizzando i tool ONTAP. L'impostazione della QoS su tutte le macchine virtuali sostituisce le impostazioni separate per ogni macchina virtuale. Le impostazioni non si estendono alle macchine virtuali nuove o migrate in futuro; impostare la QoS sulle nuove macchine virtuali o riapplicare la QoS a tutte le macchine virtuali nel datastore.</block>
  <block id="43a70a1e984a991b55dc01f4e4c6bda0" category="paragraph">Si noti che VMware vSphere considera tutti i/o di un datastore NFS come una singola coda per host e la limitazione della QoS su una VM può influire sulle performance per altre VM nello stesso datastore. Questo contrasta con i vVol, che possono mantenere le proprie impostazioni di policy di QoS se migrano in un altro datastore e non influiscono sull'io di altre macchine virtuali quando rallentano.</block>
  <block id="f32c3edaacea72c0ddb30ecf0135c4de" category="section-title">Metriche</block>
  <block id="ed7927d72c6154d79bedf6b19ea8fc83" category="paragraph">ONTAP 9,8 ha inoltre aggiunto nuove metriche di performance basate su file (IOPS, throughput e latenza) per i file FlexGroup, che possono essere visualizzate nei tool ONTAP per la dashboard e i report delle macchine virtuali di VMware vSphere. Il plug-in ONTAP Tools per VMware vSphere consente inoltre di impostare le regole di qualità del servizio (QoS) utilizzando una combinazione di IOPS massimo e/o minimo. Questi possono essere impostati su tutte le macchine virtuali in un datastore o singolarmente per macchine virtuali specifiche.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="section-title">Best practice</block>
  <block id="43fc84d75bb64307120a48d004166174" category="inline-link-macro">Datastore e protocolli: NFS</block>
  <block id="b43cf2a2c13b864c3b2547368e95b2c5" category="list-text">Utilizza i tool ONTAP per creare datastore FlexGroup, per assicurarti che FlexGroup venga creato in modo ottimale e che le policy di esportazione siano configurate in modo da corrispondere al tuo ambiente vSphere. Tuttavia, dopo aver creato il volume FlexGroup con i tool ONTAP, tutti i nodi del cluster vSphere utilizzano un singolo indirizzo IP per montare il datastore. Ciò potrebbe causare un collo di bottiglia sulla porta di rete. Per evitare questo problema, smontare il datastore, quindi rimontarlo utilizzando la procedura guidata standard del datastore vSphere utilizzando un nome DNS round-robin che offre bilanciamento del carico tra le LIF della SVM. Dopo il rimontaggio, gli strumenti ONTAP saranno nuovamente in grado di gestire il datastore. Se gli strumenti ONTAP non sono disponibili, utilizzare i valori predefiniti di FlexGroup e creare il criterio di esportazione seguendo le linee guida riportate in <block ref="1dcda1ccb6404fd747bdfa52cd9e0cc2" category="inline-link-macro-rx"></block>.</block>
  <block id="689367b2abf9b4f7fdef5f8589689dbc" category="list-text">Quando si ridimensiona un datastore FlexGroup, tenere presente che FlexGroup è costituito da più volumi FlexVol più piccoli che creano uno spazio dei nomi più grande. Pertanto, dimensionare il datastore in modo che sia almeno 8x MB (si suppongano i 8 componenti predefiniti) delle dimensioni del file VMDK più il 10-20% di spazio inutilizzato, per garantire flessibilità nel ribilanciamento. Ad esempio, se nell'ambiente è presente un VMDK di 6TB GB, dimensionare il datastore FlexGroup non inferiore a 52,8TB GB (6x8+10%).</block>
  <block id="098d1f2818677f5cc4dd7c08e40b3f41" category="list-text">VMware e NetApp supportano il trunking di sessione NFSv4,1 a partire da ONTAP 9.14.1. Per informazioni dettagliate sulle versioni specifiche, fare riferimento alle note della matrice di interoperabilità NFS 4,1 di NetApp. NFSv3 non supporta percorsi fisici multipli a un volume ma supporta nconnect beginning in vSphere 8.0U2. Ulteriori informazioni su nconnect sono disponibili sul sito <block ref="390300af711b584cff3623a0769fdf9b" category="inline-link-macro-rx"></block>.</block>
  <block id="ac08f555cdca1e9107c33a3e4f5eca2b" category="list-text">Utilizzare il plug-in NFS per VMware VAAI per l'offload delle copie. Si noti che mentre il cloning è migliorato all'interno di un datastore FlexGroup, come menzionato in precedenza, ONTAP non offre significativi vantaggi in termini di performance rispetto alla copia dell'host ESXi quando si copiano le macchine virtuali tra volumi FlexVol e/o FlexGroup. Prendi in considerazione, pertanto, i workload di cloning al momento di decidere di utilizzare VAAI o FlexGroup. La modifica del numero di volumi costituenti è un modo per ottimizzare il cloning basato su FlexGroup. Come per l'ottimizzazione del timeout della cache menzionato in precedenza.</block>
  <block id="0906d77ff43b190c03c912f8e47c3230" category="list-text">Utilizza i tool ONTAP per VMware vSphere 9,8 o versione successiva per monitorare le performance delle macchine virtuali FlexGroup utilizzando le metriche ONTAP (dashboard e report VM) e per gestire la QoS sulle singole macchine virtuali. Queste metriche non sono attualmente disponibili tramite i comandi o le API ONTAP.</block>
  <block id="315f464c64861565200e97577a6eabde" category="list-text">Il plug-in SnapCenter per VMware vSphere versione 4,4 e successive supporta il backup e recovery delle macchine virtuali in un datastore FlexGroup nel sistema storage primario. SCV 4,6 aggiunge il supporto di SnapMirror per datastore basati su FlexGroup. L'utilizzo di snapshot e replica basate su array è il modo più efficiente per proteggere i dati.</block>
  <block id="6c5f0256b71da4e103acbeed0dfcc379" category="summary">Questo documento descrive gli aspetti di sicurezza del plug-in SnapCenter per VMware.</block>
  <block id="3fd4fd8640d78da436f762569919841f" category="list-text">*Attività di risposta agli incidenti di sicurezza dei prodotti.* le vulnerabilità di sicurezza sono scoperte sia internamente che esternamente all'azienda e possono rappresentare un serio rischio per la reputazione di NetApp se non vengono affrontate in modo tempestivo. Per facilitare questo processo, un Product Security Incident Response Team (PSIRT) segnala e tiene traccia delle vulnerabilità.</block>
  <block id="a2132633bc2804871caed9697d50a10d" category="summary">Funzioni, limiti e vVol supportano con gli strumenti ONTAP.</block>
  <block id="2fa76de41291847c8d191ea664c53395" category="summary">Ulteriori informazioni su vSphere Metro Storage Cluster con ONTAP</block>
  <block id="0ecd760f5e697e57a60b2f1597be9d54" category="admonition">Per ulteriori informazioni su VMware vSphere Virtual Volumes, SPBM e ONTAP, vedere <block ref="2e6ec19fbf81081d6cc68364fb2fb656" category="inline-link-macro-rx"></block>.</block>
  <block id="431a88aaf8eee90b865aec0ca23cfc8c" category="paragraph">Sia NMP che ONTAP supportano l'ALUA (Asymmetric Logical Unit Access) per negoziare percorsi ottimizzati e non ottimizzati. In ONTAP, un percorso ottimizzato per ALUA segue un percorso di dati diretto, utilizzando una porta di destinazione sul nodo che ospita il LUN a cui si accede. ALUA è attivato per impostazione predefinita sia in vSphere che in ONTAP. NMP riconosce il cluster ONTAP come ALUA e utilizza il plug-in del tipo di array di storage ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) e seleziona il plug-in di selezione del percorso round robin <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="7dbbfa4d228c6ffe9a64c938bc057b0d" category="inline-image-macro">connettività multipath</block>
  <block id="4525956d57ef52f4b2a4f341fbeec28e" category="paragraph"><block ref="4525956d57ef52f4b2a4f341fbeec28e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8692ff2ea8c35b5c4c7cea90481e416c" category="summary">Questo documento categorizza ed enumera le impostazioni di storage e di rete consigliate.</block>
  <block id="ff6fdc6e7749c69219fc26d54c625bd5" category="paragraph">NetApp ha sviluppato una serie di impostazioni ottimali per l'host ESXi sia per protocolli NFS sia per protocolli a blocchi. Sono inoltre fornite indicazioni specifiche per le impostazioni di multipathing e timeout HBA per un corretto comportamento con ONTAP in base ai test interni di NetApp e VMware.</block>
  <block id="bc25cf0638b9454338db449fa254150f" category="paragraph">Questi valori possono essere impostati facilmente utilizzando gli strumenti ONTAP per VMware vSphere: Dal dashboard Riepilogo, fare clic su Modifica impostazioni nel portlet sistemi host o fare clic con il pulsante destro del mouse sull'host in vCenter, quindi accedere a Strumenti ONTAP &gt; Imposta valori consigliati.</block>
  <block id="baee97fad9d55c529dc7a7eb07fd1ba4" category="cell">VSphere 6,0 o versioni successive, impostare su 256
Tutte le altre configurazioni NFS sono impostate su 64.</block>
  <block id="b3fd5cebc3e5891cccea8f8df97003e0" category="paragraph">Nelle sezioni seguenti vengono illustrate le Best practice per la distribuzione con ONTAP e VMware SRM.</block>
  <block id="c89f9fd1a8019dc4d7a2559a982d3aa8" category="inline-link-macro">Panoramica della configurazione S3</block>
  <block id="f14de37f621abb28f0bf089cae467a29" category="paragraph">In origine, questo approccio unificato ha indicato il supporto dei protocolli NAS e SAN su un unico sistema di storage e ONTAP continua a essere una piattaforma leader per SAN e la sua forza originale nel campo delle NAS. ONTAP ora fornisce anche il supporto del protocollo a oggetti S3. Sebbene S3 non sia utilizzato per i datastore, è possibile utilizzarlo per le applicazioni in-guest. Per ulteriori informazioni sul supporto del protocollo S3 in ONTAP, consultare la sezione <block ref="9a0a48164e4b196191c2134bda6f342d" category="inline-link-macro-rx"></block>.</block>
  <block id="8eb06904cba6440e6130ac3e32b68aba" category="paragraph">*NOTA:* per ulteriori informazioni sulle SVM, sullo storage unificato e sull'accesso dei client, vedere <block ref="9e7286a7ad3ab81fa024704c7a52e505" category="inline-link-macro-rx"></block> Nel centro di documentazione di ONTAP 9.</block>
  <block id="d96a9839a4f7a8d356a868bd23816516" category="summary">ONTAP è da quasi vent'anni una soluzione di storage leader per gli ambienti VMware vSphere e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi. Questo documento presenta la soluzione ONTAP per vSphere, incluse le informazioni più recenti sui prodotti e le Best practice, per ottimizzare l'implementazione, ridurre i rischi e semplificare la gestione.</block>
  <block id="93fbb268e5e551ae95265cfe3b3b6c7a" category="paragraph">PostgreSQL viene fornito con varianti che includono PostgreSQL, PostgreSQL Plus ed EDB Postgres Advanced Server (ECAS). PostgreSQL viene in genere distribuito come database back-end per applicazioni multi-Tier. È supportato da pacchetti middleware comuni (come PHP, Java, Python, Tcl/TK, ODBC, E JDBC) ed è stata storicamente una scelta popolare per i sistemi di gestione di database open-source. ONTAP è una scelta eccellente per l'esecuzione di database PostgreSQL per la sua affidabilità, prestazioni elevate ed efficienza di gestione dei dati.</block>
  <block id="bbc2d665b02dc421c5c756db4b973610" category="sidebar">Microsoft Hyper-V.</block>
  <block id="672553790d8814b967eb8623e754ea84" category="sidebar">Linee guida per l'installazione e Best practice per lo storage</block>
  <block id="c5865855c43d734069987786177edd98" category="sidebar">Hyper-V.</block>
  <block id="230dea8fdf5e53eb32282fb3f8d4d9f6" category="sidebar">Linee guida per l'implementazione e Best practice per lo storage</block>
  <block id="3c0fa9c86e8d92c7a146b2d71467ab2e" category="sidebar">Storage NetApp e ambiente Windows Server</block>
  <block id="1ed211700a6cc31a2b45adb662dcbb8a" category="sidebar">Provisioning negli ambienti SAN</block>
  <block id="41ffc5ff950f2260951b6b6150c36f6b" category="sidebar">Provisioning negli ambienti SMB</block>
  <block id="e5f52b64058cb937fdd114369219d380" category="sidebar">Infrastruttura storage Hyper-V su NetApp</block>
  <block id="4380100fa910735712157068aeec0575" category="sidebar">Distribuire Hyper-V Live Migration in un ambiente in cluster</block>
  <block id="0726f4e9c3c98564af638f1b4cd17a9e" category="sidebar">Implementazione di Hyper-V Live Migration all'esterno di un ambiente in cluster</block>
  <block id="1bbd09497cd931a02f8dc0ee3cfcf19d" category="sidebar">Distribuire la replica Hyper-V all'esterno di un ambiente in cluster</block>
  <block id="832a116d7f9184d8880a539553a0cb52" category="sidebar">Distribuire la replica Hyper-V in un ambiente in cluster</block>
  <block id="1a85c0d242c43eb56cc500e60d323331" category="paragraph">VMFS è un file system in cluster dalle performance elevate che fornisce datastore che sono pool di storage condivisi. Gli archivi dati VMFS possono essere configurati con LUN accessibili tramite FC, iSCSI, FCoE o namespace NVMe accessibili tramite i protocolli NVMe/FC o NVMe/TCP. VMFS consente l'accesso simultaneo allo storage da parte di ogni server ESX in un cluster. Le dimensioni massime del LUN sono generalmente di 128TB GB a partire da ONTAP 9.12.1P2 (e versioni precedenti con i sistemi ASA); pertanto, è possibile creare un datastore VMFS 5 o 6 di 64TB GB di dimensioni massime utilizzando un singolo LUN.</block>
  <block id="8983ee0717807e5385f3c8b2c70a177c" category="list-text">TR-4597: VMware vSphere per ONTAP
<block ref="0bff808225ac084b8184e7670c17aa52" category="inline-link-macro-rx"></block></block>
  <block id="1f7ff87198d4a8563ac0d42354d47052" category="list-text">TR-4400: Volumi virtuali VMware vSphere con ONTAP
<block ref="57ea579fe6c0d333a496008248ad03e2" category="inline-link-macro-rx"></block></block>
  <block id="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-macro"><block ref="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-rx"></block></block>
  <block id="6e5923e0b2d91653ee7dd35aa5f48141" category="list-text">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9
<block ref="6a851721cd10ebeb2f9cfa107f963956" category="inline-link-macro-rx"></block></block>
  <block id="1e626dbc797733633cd43ac045564b36" category="list-text">Creatore utente RBAC per ONTAP
<block ref="51416f5c8b6f7981eb23be678ab313ad" category="inline-link-macro-rx"></block></block>
  <block id="eaef75afe923a97ffd4ccab86876f8da" category="list-text">Strumenti ONTAP per le risorse VMware vSphere
<block ref="9d52dd6d1c195e015d4baef3146522a8" category="inline-link-macro-rx"></block></block>
  <block id="58b39d11ffaef440efc4e3c365487610" category="list-text">Documentazione di VMware Site Recovery Manager
<block ref="18c037ca2f7fe7180f506030fe7e514c" category="inline-link-macro-rx"></block></block>
  <block id="bc11d67bfced1da7778c2cabee9e7615" category="paragraph">Fare riferimento a. <block ref="de89165a46abdf575eb9a1ba0995e131" category="inline-link-macro-rx"></block> Sul sito del supporto NetApp per verificare che le versioni esatte dei prodotti e delle funzionalità descritte in questo documento siano supportate per il tuo ambiente specifico. NetApp IMT definisce i componenti e le versioni dei prodotti che possono essere utilizzati per costruire configurazioni supportate da NetApp. I risultati specifici dipendono dall'installazione di ciascun cliente in conformità alle specifiche pubblicate.</block>
  <block id="e651877073d877e1ee090d986eafc550" category="list-text">Devi avere cluster Hyper-V ubicati nella stessa area geografica o in posizioni separate che fungono da cluster primari e di replica. Revisione <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="8762adae157b34ee542f2e614401603a" category="list-text">Concetti di ONTAP
<block ref="836022e29667128997850a15d18e8759" category="inline-link-rx"></block></block>
  <block id="e7b3912abd11fa36935a211d0189ebc2" category="list-text">Best practice per LE SAN moderne
<block ref="49df8abaa6163afdde37b69f7f59185c" category="inline-link-rx"></block></block>
  <block id="05c54431756e1b1a7114938bc6f4b199" category="list-text">Integrità e disponibilità dei dati degli array NetApp All-SAN con NetApp ASA
<block ref="8f140ecff12b563e3c96a8cff991aedb" category="inline-link-rx"></block></block>
  <block id="bc96f334e3988ce96701a7082c0e23b5" category="list-text">Guida introduttiva a Nano Server +
<block ref="abdd6de84336a7f761fbe384605879e9" category="inline-link-rx"></block></block>
  <block id="0e660b82d6e28b6935041a5223ed1aed" category="paragraph">Per distribuire la migrazione in tempo reale, è necessario che i server Hyper-V siano configurati in un cluster di failover con storage condiviso. Revisione <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="1dd1e97374852e1f244963d9fdb0c414" category="list-text">Verifica del failover pianificato. Sposta le macchine virtuali su un altro nodo utilizzando migrazione live, migrazione rapida o migrazione dello storage (spostamento). Revisione <block ref="ba8afff2d0e4662eeb47d28935e79828" category="inline-link-macro-rx"></block> per ulteriori dettagli.</block>
  <block id="8737a5d2bc43b0eb76ab5674d0fcb094" category="sidebar">Panoramica di SRM con ONTAP</block>
  <block id="76f6daa4bfab6ca8a7350e46d3d6718f" category="sidebar">Informazioni aggiuntive per SRM</block>
  <block id="3ebf71fd7bd7392466a892c2228b2f58" category="section-title">Provisioning delle condivisioni SMB su Windows Server</block>
  <block id="674b9c5bbf2379d6c48343d029972e53" category="section-title">Integrazione host</block>
  <block id="16ce478a465011bacaa6e508063c2648" category="section-title">Cose da ricordare</block>
  <block id="83f04319244758f7531b398c51aa9f38" category="section-title">Provisioning delle condivisioni SMB su Nano Server</block>
  <block id="2323e97f7cf2da464750911f1f3e1af6" category="doc">Distribuire la replica Hyper-V in un ambiente in cluster</block>
  <block id="36b10adb4505559b63b091b53614af1f" category="section-title">Deduplica NetApp</block>
  <block id="1ba5c1747d37a3d7ae84fd1dcac77603" category="section-title">Ulteriori letture</block>
  <block id="50802d3e5a25b93d471686a10da03dd8" category="section-title">Best practice</block>
  <block id="67bd1e9f90c0abcd3fe89dce2e8b6307" category="doc">Implementazione di Hyper-V Live Migration all'esterno di un ambiente in cluster</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Pubblico previsto</block>
  <block id="458ed20ed5d1729b427e233e0e52f797" category="section-title">Provisioning dello storage NetApp per Windows Server</block>
  <block id="e648c74a53b161f90c8e915624ce6135" category="section-title">Gestione dello storage NetApp</block>
  <block id="9292ee6bce21e93911c38cd0a1c2e209" category="section-title">Best practice per il networking</block>
  <block id="381400d1babe5b80783d5e46896d832e" category="doc">Distribuire il server Nano</block>
  <block id="02676c7c18a8d411999242a1f5731de2" category="section-title">Storage Hyper-V su NetApp CIFS</block>
  <block id="00a66fbc09172147ac7be9c85b708a6b" category="section-title">Trasferimento dei dati con offload</block>
  <block id="39d0bfdf27f1fc555ae2f030e21f8818" category="section-title">Clustering Hyper-V: Alta disponibilità e scalabilità per le macchine virtuali</block>
  <block id="10fd9c0040ca7b99a67758c3cd638746" category="section-title">Live Migration in un ambiente in cluster</block>
  <block id="ed7cd01cb26e2db33a36eaa87ac85ff1" category="section-title">Live Migration all'esterno di un ambiente in cluster</block>
  <block id="023196611fee49915adf49422b3289e6" category="section-title">Replica Hyper-V: Disaster recovery per macchine virtuali</block>
  <block id="e78f6d0414a6dde66f4e12a3e218620b" category="section-title">Replica estesa</block>
  <block id="e43f3be13a49d6eeab4304d80790eaa0" category="section-title">Rileva lo storage a blocchi</block>
  <block id="adc95a9707f2f351740aa0d52f08981e" category="section-title">Approccio FlexClone di NetApp</block>
  <block id="0bee1618a00f62535bd1e3f03af6a8f0" category="section-title">Avvio da SAN per l'host fisico</block>
  <block id="68468d5f213be162fe50260787894f8f" category="section-title">Avvio da SAN per macchina virtuale</block>
  <block id="5b6253395cb699e828a4e33bbe3ad99e" category="doc">Implementazione di replica Hyper-V all'esterno di un ambiente in cluster</block>
  <block id="c56bd6d44fe37df3133f12e09059b492" category="doc">Implementa il cluster Hyper-V.</block>
  <block id="284558d4613b1e72103300f1b8973b3b" category="paragraph">Quando viene installato per la prima volta, ESX non dispone di funzionalità preconfigurate, come l'hosting di un sistema operativo guest o il supporto di un'applicazione per l'utente finale. Si tratta di un container vuoto fino a quando non viene definita una macchina virtuale (VM). ONTAP è simile. Quando viene installata per la prima volta, ONTAP non dispone di funzionalità di servizio dati fino a quando non viene creata una SVM. È il linguaggio della SVM che definisce i servizi dati.</block>
  <block id="2737c9012caaebb1cbb9e526400a2345" category="paragraph">In un ambiente multi-tenant, è possibile assegnare a ciascun tenant una SVM dedicata. Il limite per il numero di SVM e LIF per cluster, coppia ha e nodo dipende dal protocollo in uso, dal modello di nodo e dalla versione di ONTAP.  Consultare <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> per questi limiti.</block>
  <block id="50812cc1b8d48579d382b689e4393be6" category="paragraph">Alcuni dati non contengono dati duplicati. Ad esempio, un blocco Oracle contiene un'intestazione univoca a livello globale per il database e un trailer quasi univoco. Di conseguenza, la deduplica di un database Oracle raramente offre un risparmio superiore al 1%. La deduplica con i database MS SQL è leggermente migliore, ma i metadati univoci a livello di blocco rimangono un limite.</block>
  <block id="e237dd01ca20b300861ea50239fefbf9" category="paragraph">Sono incluse misure di pianificazione tipiche, quali la garanzia della presenza di una larghezza di banda sufficiente sulla SAN tra l'host e il sistema di storage, la verifica della presenza di tutti i percorsi SAN tra i dispositivi richiesti, l'utilizzo delle impostazioni della porta FC richieste dal fornitore dello switch FC, evitando conflitti ISL, e utilizzando un adeguato monitoraggio del fabric SAN.</block>
  <block id="bab63c3a8b4ae009c3596c809e27d73b" category="paragraph">La replica MetroCluster si basa sulla tecnologia NetApp SyncMirror, che è progettata per passare in modo efficiente dalla modalità sincrona alla modalità sincrona e viceversa. Questa funzionalità soddisfa i requisiti dei clienti che richiedono una replica sincrona, ma che hanno bisogno anche di un'alta disponibilità per i propri servizi dati. Ad esempio, se la connettività a un sito remoto viene interrotta, è generalmente preferibile che il sistema di archiviazione continui a funzionare in uno stato non replicato.</block>
  <block id="bf4d44f407dab4b746f1eaeb06e897af" category="paragraph">Molte soluzioni di replica sincrona sono in grado di funzionare solo in modalità sincrona. Questo tipo di replica "tutto o niente" viene talvolta chiamato modalità domino. Tali sistemi storage smettono di fornire i dati piuttosto che permettere che le copie locali e remote dei dati diventino non sincronizzate. Se la replica viene forzata, la risincronizzazione può richiedere molto tempo e lasciare un cliente esposto a una perdita di dati completa durante il tempo in cui il mirroring viene ristabilita.</block>
  <block id="8f076395fe8f8f46c03efb655db313e6" category="section-title">Connessione diretta FC</block>
  <block id="722830ffc5e46dbe206670f85cd1d889" category="paragraph">ONTAP e alcuni altri prodotti NetApp supportano ora l'autenticazione a più fattori (MFA) utilizzando una vasta gamma di metodi. Il risultato è un nome utente/password compromesso da solo non è un thread di sicurezza senza i dati del secondo fattore, come un FOB o un'applicazione per smartphone.</block>
  <block id="37c43820ab88f1340855c30955eec330" category="section-title">Verifica multi-admin (MAV)</block>
  <block id="1910dc5a02cb649cc24df5670c631e34" category="paragraph"><block ref="1910dc5a02cb649cc24df5670c631e34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="416d0d3efc5f3919abcdaaa2364738d9" category="paragraph"><block ref="416d0d3efc5f3919abcdaaa2364738d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28c6217e46797f76e427c591070cf50c" category="paragraph"><block ref="28c6217e46797f76e427c591070cf50c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d03e09c345dd723011486de3855c13b2" category="list-text">Documentazione SMB
<block ref="409ef354547d1e3428907ed7fdd2dc6e" category="inline-link-rx"></block></block>
  <block id="834873443aaaf2c09b851c8b0f7b2497" category="section-title">Compressione dei database</block>
  <block id="2ee3c7318caa2523e9c749e4e2152266" category="paragraph">Un punto comune di confusione tra i clienti che non conoscono ONTAP è l'utilizzo di FlexVol, comunemente denominati semplicemente "volumi".</block>
  <block id="ff2dabe8a40c84d01b0584c50319a79e" category="paragraph">Un volume non è un LUN. Questi termini vengono utilizzati in maniera anonima con molti prodotti di altri vendor, inclusi i cloud provider. ONTAP Volumes sono semplicemente container di gestione. Non forniscono dati da soli, né occupano spazio. Sono container per file o LUN e esistono per migliorare e semplificare la gestibilità, in particolare su larga scala.</block>
  <block id="92a5781e05d0d9b7044f44e2ef7bff84" category="section-title">Volumi e LUN</block>
  <block id="faf1e8eebcac2d18d4ac10e75f416a3f" category="paragraph">I LUN correlati sono normalmente collocati in una stessa posizione in un singolo volume. Ad esempio, un database che richiede 10 LUN solitamente conterrà tutte le 10 LUN dello stesso volume.</block>
  <block id="3a5bf2895b95fa2b89fce4dcf94fd2f9" category="list-text">L'utilizzo di un rapporto di 1:1:1 tra LUN e volumi, vale a dire un LUN per volume, non è * una Best practice formale.</block>
  <block id="1886f4ac4aa2f64bf8224f178a36ba92" category="list-text">I volumi dovrebbero invece essere visti come container per i carichi di lavoro o i set di dati. È possibile che sia presente un singolo LUN per volume o che ve ne siano molti. La risposta giusta dipende dai requisiti di gestibilità.</block>
  <block id="0de05608a70e8ec5863afc41ba150178" category="list-text">La dispersione dei LUN in un numero non necessario di volumi può causare overhead e problemi di pianificazione aggiuntivi per operazioni quali operazioni di snapshot, un numero eccessivo di oggetti visualizzati nell'interfaccia utente e il raggiungimento dei limiti di volume della piattaforma prima del raggiungimento del limite LUN.</block>
  <block id="0955dbd01a9f8194cad5a6876b931f5a" category="section-title">Volumi, LUN e snapshot</block>
  <block id="9bbd4f2fca3a1e1aaa76abf8cb43351c" category="paragraph">I criteri e le pianificazioni degli Snapshot vengono posizionati sul volume, non sul LUN. Un set di dati composto da 10 LUN richiederebbe una singola policy di snapshot quando le LUN sono collocate contemporaneamente nello stesso volume.</block>
  <block id="f34f28bb7a1701ded173c2ab504f5c20" category="paragraph">Inoltre, la co-localizzazione di tutti i LUN correlati per un dato dataset in un singolo volume consente di eseguire operazioni di snapshot atomiche. Ad esempio, un database di 10 LUN o un ambiente applicativo basato su VMware composto da 10 diversi sistemi operativi possono essere protetti come un singolo oggetto coerente se le LUN sottostanti vengono tutte collocate in un singolo volume. Se vengono posizionati su volumi diversi, gli snapshot possono essere o meno sincronizzati al 100%, anche se pianificati allo stesso tempo.</block>
  <block id="fe7797cb1dbe36223357d4c25ff30c9e" category="paragraph">In alcuni casi, potrebbe essere necessario suddividere una serie di LUN correlata in due volumi diversi a causa dei requisiti di recovery. Ad esempio, un database potrebbe avere quattro LUN per i file di dati e due LUN per i log. In questo caso, un volume di file dati con 4 LUN e un volume di registro con 2 LUN potrebbe essere l'opzione migliore. Il motivo è la possibilità di recupero indipendente. Ad esempio, è possibile ripristinare in maniera selettiva il volume di file dati a uno stato precedente, vale a dire che le quattro LUN vengono riportate allo stato della snapshot, senza influire sul volume di log con i dati critici.</block>
  <block id="66383d632fe33f1b7c20af9c1c142028" category="section-title">Volumi, LUN e SnapMirror</block>
  <block id="8fb29c5f40886ece62abcd994f1aa202" category="paragraph">Le policy e le operazioni di SnapMirror, come le operazioni di Snapshot, vengono eseguite sul volume, non sul LUN.</block>
  <block id="7d8d0afc8d9998a7e6457c6251b4defc" category="paragraph">La co-localizzazione dei LUN correlati in un singolo volume consente di creare una singola relazione di SnapMirror e di aggiornare tutti i dati contenuti con un singolo update. Come per gli snapshot, l'aggiornamento sarà anche un'operazione atomica. La destinazione SnapMirror avrà una replica point-in-time singola delle LUN di origine. Se le LUN sono state distribuite su più volumi, le repliche possono essere o meno coerenti l'una con l'altra.</block>
  <block id="e45ffde45b5f4090fe8c92a49d38bcb2" category="section-title">Volumi, LUN e QoS</block>
  <block id="756a4c619fb81eafd00bc072334a5877" category="paragraph">Mentre la qualità del servizio può essere applicata in modo selettivo alle singole LUN, in genere è più semplice impostarla a livello di volume. Ad esempio, tutte le LUN utilizzate dai guest di un determinato server ESX possono essere collocate su un singolo volume e successivamente può essere applicata una policy di QoS adattiva di ONTAP. In questo modo si ottiene un limite di IOPS per TB autoscalabile valido per tutte le LUN.</block>
  <block id="fb219ca81e7a635609b70d290a7a3aa2" category="paragraph">Analogamente, se un database richiedeva 100K IOPS e occupava 10 LUN, sarebbe più semplice impostare un singolo limite di 100K IOPS su un singolo volume piuttosto che impostare 10 limiti individuali di 10K IOPS, uno per ogni LUN.</block>
  <block id="56739402ea66bd29b7303b69ee165d5b" category="section-title">Layout a più volumi</block>
  <block id="c509cb5f7def30cc77b15b0e91ab39a4" category="paragraph">Vi sono alcuni casi in cui la distribuzione delle LUN su più volumi può essere vantaggiosa. Il motivo principale è lo striping dei controller. Ad esempio, un sistema storage ha potrebbe ospitare un singolo database in cui è richiesto il potenziale completo di elaborazione e caching di ogni controller. In questo caso, una progettazione tipica sarebbe quella di collocare metà dei LUN in un singolo volume sul controller 1, e l'altra metà dei LUN in un singolo volume sul controller 2.</block>
  <block id="ad328d1793d6c3621e91d83556548a01" category="paragraph">Analogamente, lo striping dei controller potrebbe essere utilizzato per il bilanciamento del carico. Un sistema ha che ospitava 100 database da 10 LUN ciascuno potrebbe essere progettato dove ogni database riceve un volume da 5 LUN su ciascuno dei due controller. Il risultato è garantito il caricamento simmetrico di ogni controller quando vengono forniti database aggiuntivi.</block>
  <block id="4cd2d5d8d873ad1f707d88334324153a" category="paragraph">Tuttavia, nessuno di questi esempi riguarda un rapporto volume-LUN di 1:1:1. L'obiettivo resta quello di ottimizzare la gestibilità mediante la co-localizzazione dei LUN correlati in volumi.</block>
  <block id="a9fd7be1f3363701ad1b35b16af02c9e" category="paragraph">Un esempio se un rapporto da 1:1 LUN a volume è sensato è la containerizzazione, laddove ogni LUN potrebbe rappresentare davvero un singolo carico di lavoro e deve essere gestita singolarmente. In questi casi, un rapporto 1:1:1 può essere ottimale.</block>
  <block id="64e5a77897fe6326f14436eaaaf5432b" category="section-title">Spazio libero e allocazione di spazio LVM</block>
  <block id="702db8f3db66a0eec35817fe5d2e4544" category="inline-link-macro">ASMRU</block>
  <block id="096ca5ad0b3774fee4699e2da1bfa884" category="paragraph">L'efficienza del thin provisioning delle LUN attive in un ambiente di file system può andare persa nel tempo quando i dati vengono eliminati. A meno che i dati eliminati non vengano sovrascritti con zero (vedere anche <block ref="5b58c4ec517e475a59d0a785f87cabdc" category="inline-link-macro-rx"></block> Oppure lo spazio viene liberato con il recupero dello spazio TRIM/UNMAP, i dati "cancellati" occupano sempre più spazi vuoti non allocati nel file system. Inoltre, in molti ambienti di database il thin provisioning delle LUN attive è limitato, in quanto i file di dati vengono inizializzati alle dimensioni massime al momento della creazione.</block>
  <block id="ceb8ec6ec593174c2c6f33be2ca966eb" category="summary">Posizionamento di volumi e LUN di Oracle e ONTAP</block>
  <block id="0724b56ced27e0a66fb4692a57fb1436" category="doc">Posizionamento delle LUN dei database Oracle</block>
  <block id="f595bf3bf71ab0c91a5503ba4efb8ea4" category="paragraph">Il posizionamento ottimale delle LUN del database all'interno dei volumi ONTAP dipende principalmente dalle diverse funzionalità di ONTAP.</block>
  <block id="05a1ffdb277b8c7ac1dca78adae0017e" category="sidebar">Posizionamento delle LUN</block>
  <block id="9d5c13d45bbf74999764cfe8d4798562" category="summary">Security Hardening Guide for ONTAP tools for VMware vSphere, gestione dei certificati HTTPS.</block>
  <block id="d6a1787b51b08315bfcc44f3a9bb4b2f" category="paragraph">Per impostazione predefinita, gli strumenti ONTAP utilizzano un certificato autofirmato creato automaticamente durante l'installazione per proteggere l'accesso HTTPS all'interfaccia utente Web. Gli strumenti ONTAP offrono le seguenti funzionalità:</block>
  <block id="1eddd0f3479da31541c39e5ddddfa930" category="list-text">Rigenerare il certificato HTTPS</block>
  <block id="61bf3033b18d202012951f5bf7be4fa9" category="paragraph">Durante l'installazione degli strumenti ONTAP, viene installato un certificato CA HTTPS e il certificato viene memorizzato nell'archivio chiavi. L'utente può rigenerare il certificato HTTPS tramite la console principale.</block>
  <block id="b363a018e3596ec66080579ce5bd4c2d" category="paragraph">È possibile accedere alle opzioni sopra riportate nella console _maint_ accedendo a _'Configurazione applicazione' → 'rigenerare certificati'._</block>
  <block id="43d609906e5ac2fd9406eddd67d6f82a" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere, punti di accesso utente.</block>
  <block id="3562b87b566382dc56e8b6fb2b849126" category="doc">Tool ONTAP per access point VMware vSphere (utenti)</block>
  <block id="c015e2af845448c5e88873c4e51c8cac" category="paragraph">L'installazione di ONTAP Tools per VMware vSphere consente di creare e utilizzare tre tipi di utenti:</block>
  <block id="6399e228248ba3e1f084750197938b67" category="list-text">System User (utente di sistema): L'account utente root</block>
  <block id="2a408bd40a0a3130a390340955a699ef" category="list-text">Utente dell'applicazione: Gli account utente amministratore, utente principale e utente di database</block>
  <block id="5d212a60c02bc59306c8863b31342276" category="list-text">Support user: L'account utente diag</block>
  <block id="3c2b7b0ce42bb5eb8141643a9729f4ee" category="section-title">1. Utente di sistema</block>
  <block id="b277c4882e7365ab0ac88d56cd6154b3" category="paragraph">L'utente System(root) viene creato dall'installazione degli strumenti ONTAP sul sistema operativo sottostante (Debian).</block>
  <block id="155b9191864da17a7eaaf07b64d596d8" category="list-text">Un utente di sistema predefinito "root" viene creato su Debian tramite l'installazione degli strumenti ONTAP. L'impostazione predefinita è disattivata e può essere attivata ad hoc tramite la console 'Maint'.</block>
  <block id="159efbffccd1957bc8c4c78b2a74c085" category="section-title">2. Utente dell'applicazione</block>
  <block id="170cab8b15d5b37a17e43144afe7308d" category="paragraph">L'utente dell'applicazione viene denominato come utente locale negli strumenti di ONTAP. Si tratta di utenti creati nell'applicazione ONTAP Tools. Nella tabella seguente sono elencati i tipi di utenti dell'applicazione:</block>
  <block id="e01ca242f9b1bef82800de4c209149c7" category="cell">*Utente*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Descrizione*</block>
  <block id="9eb92414db7b53ac16645af9b0f64e58" category="cell">Administrator User (utente amministratore)</block>
  <block id="ccf6887baccb4288ae3579b56fac8d2a" category="cell">Viene creato durante l'installazione degli strumenti di ONTAP e l'utente fornisce le credenziali durante la distribuzione degli strumenti di ONTAP. Gli utenti hanno la possibilità di modificare la 'password' nella console 'Mainta'. La password scadrà tra 90 giorni e gli utenti saranno tenuti a cambiarla.</block>
  <block id="55df75b800db0f96de770b3c38f676b4" category="cell">Utente manutenzione</block>
  <block id="a2bc121b09cae43d6c478870f5298ae5" category="cell">Viene creato durante l'installazione degli strumenti di ONTAP e l'utente fornisce le credenziali durante la distribuzione degli strumenti di ONTAP. Gli utenti hanno la possibilità di modificare la 'password' nella console 'Mainta'. Si tratta di un utente addetto alla manutenzione che viene creato per eseguire le operazioni della console di manutenzione.</block>
  <block id="b124032a093d41b9efbb43f40c538bcb" category="cell">Utente database</block>
  <block id="86a670227d3e81e8fa34eb4aede3129a" category="section-title">3. Utente di assistenza (utente diag)</block>
  <block id="e482d8f0e37161e7916c7a78d2cf7210" category="paragraph">Durante l'installazione di ONTAP Tools, viene creato un utente di supporto. Questo utente può essere utilizzato per accedere agli strumenti ONTAP in caso di problemi o interruzioni del server e per raccogliere i registri. Per impostazione predefinita, questo utente è disattivato, ma può essere attivato su base adhoc tramite la console 'Maint'. È importante notare che l'utente verrà disattivato automaticamente dopo un determinato periodo di tempo.</block>
  <block id="562596399deefc1e2a6cc32eb489976c" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere.</block>
  <block id="80dd7fd00106118cf9c10abf911b7111" category="paragraph">Di seguito sono elencate le porte e i protocolli necessari per consentire la comunicazione tra gli strumenti ONTAP per il server VMware vSphere e altre entità come i sistemi di storage gestito, i server e altri componenti.</block>
  <block id="d40dfcfdaecc4e8015535acd5de00398" category="section-title">Porte in entrata e in uscita richieste per OTV</block>
  <block id="834b74ce890c61455ad330759d44eff2" category="paragraph">Tenere presente la tabella riportata di seguito che elenca le porte in entrata e in uscita necessarie per il corretto funzionamento degli strumenti ONTAP. È importante assicurarsi che solo le porte menzionate nella tabella siano aperte per i collegamenti da macchine remote, mentre tutte le altre porte devono essere bloccate per i collegamenti da macchine remote. In questo modo si garantisce la sicurezza e la sicurezza del sistema.</block>
  <block id="5732d3577c35dfcce968ba967a9a6149" category="cell">*Porta TCP v4/V6 #*</block>
  <block id="e71a4b7488a97c0e5d8b3ab3efe619e4" category="cell">*Direzione*</block>
  <block id="bc437eb0df24b836c84a74f47b391093" category="cell">*Funzione*</block>
  <block id="576fe92cf4e45714b61ed10e5c856aa5" category="cell">Connessioni HTTPS +
Utilizzato per connessioni SOAP su HTTPS +
Questa porta deve essere aperta per consentire a un client di connettersi al server API degli strumenti ONTAP.</block>
  <block id="4e31bd5bdc8239bb7c98471d3500d951" category="cell">Connessioni HTTPS - VP e SRA +
Utilizzato per le connessioni SOAP su HTTPS</block>
  <block id="7e6b20d014d1c659e4eaf20dc2dcd7eb" category="cell">8443</block>
  <block id="aaa2d7fe63bee55de8ffca52cb61fbd5" category="cell">Plugin remoto</block>
  <block id="25fa62922a9b3c1c2763bbf88014e217" category="cell">Porta del database Derby, solo tra questo computer e se stesso, connessioni esterne non accettate — solo connessioni interne</block>
  <block id="c68bd9055776bf38d8fc43c0ed283678" category="cell">8150</block>
  <block id="b482bc4bf0e383b0858c5d9eb0e96ba9" category="cell">Il servizio integrità registro viene eseguito sulla porta</block>
  <block id="9956361dfa33899fc0efed6ee3946512" category="section-title">Controllo dell'accesso remoto al database Derby</block>
  <block id="58b7326b56820f4b18dfd73dc9707831" category="paragraph">Gli amministratori possono accedere al database derby con i seguenti comandi. È possibile accedervi tramite la VM locale degli strumenti ONTAP e un server remoto con i seguenti passaggi:</block>
  <block id="296068c08046bbf197300e38c4e851cb" category="paragraph">*[.underline]#esempio:#*</block>
  <block id="10046bc1eb8463e6ca6ae51bd3b7a574" category="inline-image-macro">Derby, larghezza=468, altezza=136</block>
  <block id="36434da35edb72a1f85cbbcc1ff2b197" category="paragraph"><block ref="36434da35edb72a1f85cbbcc1ff2b197" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f21dd7ffc271f1301878c3078a59692d" category="summary">Security Hardening Guide for ONTAP tools for VMware vSphere, banner di accesso.</block>
  <block id="67f78f0bab8fe81a2b6971543c716d3d" category="paragraph">Il seguente banner di accesso viene visualizzato dopo che l'utente ha immesso un nome utente nel prompt di accesso. Tenere presente che SSH è disattivato per impostazione predefinita e consente l'accesso una tantum solo se attivato dalla console VM.</block>
  <block id="ae20daf991a940f9de7033ff0a1af410" category="paragraph">Una volta completato l'accesso tramite il canale SSH, viene visualizzato il seguente testo:</block>
  <block id="8f1b6f904292913013b1f6e578d7b074" category="summary">Security Hardening Guide for ONTAP tools for VMware vSphere, verifica dell'integrità.</block>
  <block id="cedd87fff2ad5101cd8565e33950e1fb" category="doc">Verifica dell'integrità dei tool ONTAP per i pacchetti di installazione di VMware vSphere</block>
  <block id="aeeb9f5277554716592480db544d25f3" category="paragraph">Sono disponibili due metodi per verificare l'integrità dei pacchetti di installazione degli strumenti ONTAP.</block>
  <block id="126ba7383e25522e071a963ddd6f220f" category="list-text">Verifica dei checksum</block>
  <block id="deccc645a0c8869a44e645f2f4247dbd" category="list-text">Verifica della firma</block>
  <block id="e5f3970dd7fabab1726b53d58d636de2" category="paragraph">I checksum sono disponibili nelle pagine di download dei pacchetti di installazione di OTV. Gli utenti devono verificare i checksum dei pacchetti scaricati in base al checksum fornito nella pagina di download.</block>
  <block id="7452fe022f94726684aeea655673eb0f" category="section-title">Verifica della firma degli strumenti ONTAP OVA</block>
  <block id="373d060b52f94a014177952dcca0c4e9" category="paragraph">Il pacchetto di installazione vApp viene fornito sotto forma di tarball. Questo tarball contiene certificati intermedi e root per l'appliance virtuale insieme a un file README e un pacchetto OVA. Il file README guida gli utenti su come verificare l'integrità del pacchetto vApp OVA.</block>
  <block id="48fefdb76906b256f183e6f68b23eba1" category="paragraph">I clienti devono inoltre caricare il certificato root e intermedio fornito su vCenter versione 7.0U3E e successive.  Per le versioni vCenter comprese tra 7.0.1 e 7,0.U3E, la funzionalità di verifica del certificato non è supportata da VMware. I clienti non devono caricare alcun certificato per le versioni 6.x. di vCenter</block>
  <block id="84a005842347a9560b170cfcd79c5203" category="section-title">Caricamento del certificato root attendibile in vCenter</block>
  <block id="57f60da4817dc5d71c45890bb182781e" category="list-text">Accedere con il client VMware vSphere a vCenter Server.</block>
  <block id="72282f16a7aca6b61acfc6fe27ce55c7" category="list-text">Specificare il nome utente e la password per adminutator@vsphere.local o un altro membro del gruppo vCenter Single Sign-on Administrators. Se durante l'installazione è stato specificato un dominio diverso, accedere come Administrator@mydomain.</block>
  <block id="9470c9e64c285d5b66a039ab668ab64a" category="list-text">Accedere all'interfaccia utente di Gestione certificati: a. Dal menu principale, selezionare Amministrazione. b. Nella sezione certificati, fare clic su Gestione certificati.</block>
  <block id="43a75b176810226695d2db6f52c87b73" category="list-text">Se richiesto dal sistema, immettere le credenziali di vCenter Server.</block>
  <block id="5f51c5b3cb2f48fd1d670bf384d1006d" category="list-text">In certificati principali attendibili, fare clic su Aggiungi.</block>
  <block id="55c3b759c54a437c7ced6432f1c62de0" category="list-text">Fare clic su Sfoglia e selezionare la posizione del file .pem del certificato (OTV_OVA_INTER_ROOT_CERT_CHAIN.pem).</block>
  <block id="8acdedaaa4134bb6ae49472b4bc268a7" category="list-text">Fare clic su Aggiungi. Il certificato viene aggiunto al negozio.</block>
  <block id="e2200da08ea15bdea0f97dbfc4e9f1c7" category="inline-link-macro">Aggiungere un certificato radice attendibile all'archivio certificati</block>
  <block id="6eeecddd909e7e017ba2732e46dc739c" category="paragraph">Fare riferimento a. <block ref="b8e45b03638af10d852f253eba7e63e3" category="inline-link-macro-rx"></block> per ulteriori informazioni. Durante la distribuzione di una vApp (utilizzando il file OVA), la firma digitale per il pacchetto vApp può essere verificata nella pagina "Dettagli revisione". Se il pacchetto vApp scaricato è originale, nella colonna 'Publisher' viene visualizzato 'Trusted Certificate' (certificato attendibile) (come nella seguente schermata).</block>
  <block id="a13b63a149750821fb588cd3cb41c209" category="inline-image-macro">Certificato attendibile</block>
  <block id="a83d8109f7a0cf9c4a04c65c40ecd354" category="paragraph"><block ref="a83d8109f7a0cf9c4a04c65c40ecd354" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61dc5ac976a8bd4a8744d8890305d26e" category="section-title">Verifica della firma degli attrezzi ONTAP ISO e SRA tar.gz</block>
  <block id="d4f26c1c073b64ba200e3fa71762c256" category="paragraph">NetApp condivide il proprio certificato di firma del codice con i clienti nella pagina di download del prodotto, insieme ai file zip del prodotto per OTV-ISO e SRA.tgz.</block>
  <block id="a7ac1e7561da5cc70126cfea891de159" category="paragraph">Dal certificato di firma del codice, gli utenti possono estrarre la chiave pubblica nel modo seguente:</block>
  <block id="5f4345a6f62f7a3926b2c3d92f5574f6" category="paragraph">Quindi, utilizzare la chiave pubblica per verificare la firma per il prodotto zip iso e tgz come indicato di seguito:</block>
  <block id="81eeab9506186e2dca8faefa78d54067" category="paragraph">Esempio:</block>
  <block id="c6666237b03fcb86e315a0a06e73b6ef" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere, crittografia TLS reciproca per le connessioni di gestione dello storage.</block>
  <block id="53893182b7e17fb2da37935ee3ffda55" category="paragraph">Le versioni ONTAP 9,7 e successive supportano la comunicazione mutua TLS. A partire dai tool ONTAP per VMware e vSphere 9,12, il TLS reciproco viene utilizzato per la comunicazione con i cluster appena aggiunti (in base alla versione di ONTAP).</block>
  <block id="1be712dee4c47804142318ffb739e46b" category="paragraph">Per tutti i sistemi storage aggiunti in precedenza: Durante un aggiornamento, tutti i sistemi storage aggiunti diventeranno automaticamente attendibili e verranno configurati i meccanismi di autenticazione basati su certificato.</block>
  <block id="d39adf53eaace0fbba30d4e13760a974" category="paragraph">Come nella schermata riportata di seguito, nella pagina di configurazione del cluster viene visualizzato lo stato di Mutual TLS (autenticazione basata su certificato), configurato per ciascun cluster.</block>
  <block id="c036889d83926f57571c8b12e4f7fb6f" category="inline-image-macro">image2,larghezza=468,altezza=158</block>
  <block id="095064767a4b9cadb4016dfc2788237c" category="paragraph"><block ref="095064767a4b9cadb4016dfc2788237c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53f061d401dd80027634ccca2a19cd8d" category="section-title">*Aggiunta cluster*</block>
  <block id="7ce4b2757e70979f49bcf8f64ba36363" category="paragraph">Durante il flusso di lavoro di aggiunta del cluster, se il cluster che viene aggiunto supporta MTLS, MTLS verrà configurato per impostazione predefinita. L'utente non deve eseguire alcuna configurazione per questo. La schermata riportata di seguito mostra la schermata presentata all'utente durante l'aggiunta del cluster.</block>
  <block id="3c1556a297200019d3a0b8045c0956b9" category="inline-image-macro">Add Storage System,width=450,height=400</block>
  <block id="3a225aabc3c5c25670ad0b4d131da24f" category="paragraph"><block ref="3a225aabc3c5c25670ad0b4d131da24f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="987de6e025f6af1fc4451710295ca76f" category="inline-image-macro">Add Storage System,width=468,height=416</block>
  <block id="576a9128888c73fc82869b3ae173c7d2" category="paragraph"><block ref="576a9128888c73fc82869b3ae173c7d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="307eba22b8070bb93e642827620f8588" category="paragraph"><block ref="307eba22b8070bb93e642827620f8588" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71cfed326a2cabd3b505c6580123a459" category="inline-image-macro">Add Storage System,width=468,height=516</block>
  <block id="a3a8f9da50b3f15d69f3186129f159f6" category="paragraph"><block ref="a3a8f9da50b3f15d69f3186129f159f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b3ebbeea272602ddec07bb77e34668a" category="section-title">Cluster Edit (Modifica cluster)</block>
  <block id="d2562e450657937f981a45d9d18ff4ec" category="paragraph">Durante l'operazione di modifica del cluster, esistono due scenari:</block>
  <block id="500bcb89776517849e2e07073aad4eca" category="list-text">Se il certificato ONTAP scade, l'utente dovrà ottenere il nuovo certificato e caricarlo.</block>
  <block id="edf2227e3378b5b0864ef73e58d39d77" category="list-text">Se il certificato OTV scade, l'utente può rigenerarlo selezionando la casella di controllo.</block>
  <block id="6db8cdf80049c7cf629fe6f8f6e3a9c0" category="list-text">_Genera un nuovo certificato client per ONTAP._</block>
  <block id="acba923a9524c642724d6ff34f5dac93" category="inline-image-macro">Modify Storage System,width=468,height=461</block>
  <block id="6a59df9970674c274e20b1d91be2df8a" category="paragraph"><block ref="6a59df9970674c274e20b1d91be2df8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75545011d3e6abe8a2cd8cd5bc21c6fd" category="paragraph"><block ref="75545011d3e6abe8a2cd8cd5bc21c6fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14a73da2f5fe352620bed1b49a3319ed" category="summary">Security Hardening Guide for ONTAP tools for VMware vSphere, protezione della sicurezza della rete contro gli attacchi DOS.</block>
  <block id="8f7e7bd942f453f0550dc4f907e88810" category="paragraph">Per impostazione predefinita, il numero massimo di richieste simultanee per utente è 48. L'utente root negli strumenti ONTAP può modificare questo valore in base ai requisiti del proprio ambiente. *Questo valore non deve essere impostato su un valore molto alto in quanto fornisce un meccanismo contro gli attacchi DOS (Denial of Service).*</block>
  <block id="99c1088ea27d16b42c6b45d794f59d3f" category="paragraph">Gli utenti possono modificare il numero massimo di sessioni simultanee e altri parametri supportati nel file *_/opt/netapp/vscserver/etc/dosfilterParams.json_*.</block>
  <block id="5e7c907630f5a432ac6b39f0b8c04c28" category="paragraph">Possiamo configurare il filtro con i seguenti parametri :</block>
  <block id="a35f2f4ccb228969a85b8719ea25b047" category="list-text">*_delayMS_*: Il ritardo in millisecondi dato a tutte le richieste oltre il limite di velocità prima che vengano prese in considerazione. Dare -1 per respingere la richiesta.</block>
  <block id="f1b9d5fde713093a3a80f140d1439d37" category="list-text">*_throttleMS_*: Per quanto tempo attendere il semaforo in modalità asincrona.</block>
  <block id="aa363bec6acd7600aedeee5377470bde" category="list-text">*_maxRequestMS_*: Per quanto tempo consentire l'esecuzione di questa richiesta.</block>
  <block id="351b695725caafd647abb749c50a7e6f" category="list-text">*_ipWhitelist_*: Un elenco separato da virgole di indirizzi IP che non saranno limitati dalla velocità. (Possono essere indirizzi IP vCenter, ESXi e SRA)</block>
  <block id="058e1fe7e6afcd3bcff86482a583976b" category="list-text">*_maxRequestsPerSec_*: Il numero massimo di richieste da una connessione al secondo.</block>
  <block id="1c1496a21f967d57b50fe5ebb0e62125" category="paragraph">*Valori predefiniti nel file _dosfilterParams_:*</block>
  <block id="9afb15056a8bc8b4402d55eba2274dad" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere, configurazione NTP.</block>
  <block id="48edbd8a951efb0ad617f7868b27a6c0" category="paragraph">A volte, possono verificarsi problemi di protezione dovuti a discrepanze nelle configurazioni dell'ora di rete. È importante assicurarsi che tutti i dispositivi all'interno di una rete dispongano di impostazioni dell'ora precise per evitare tali problemi.</block>
  <block id="a55d703ea2930e8e72e94ce11c3297ab" category="section-title">*Virtual appliance*</block>
  <block id="5a65f4c9ca6d99f573528348d36914fa" category="paragraph">È possibile configurare i server NTP dalla console di manutenzione dell'appliance virtuale.  Gli utenti possono aggiungere i dettagli del server NTP in _System Configuration_ =&gt; _Add new NTP Server_ option</block>
  <block id="90ab4fc7a1c530bceac36bda71efbc5f" category="paragraph">Per impostazione predefinita, il servizio per NTP è ntpd. Si tratta di un servizio legacy che in alcuni casi non funziona bene per le macchine virtuali.</block>
  <block id="6801ecdb823d018c7370042d27b5ee2c" category="section-title">*Debian*</block>
  <block id="dc3bb5166d38d2aec53765aca7c0d24c" category="paragraph">Su Debian, l'utente può accedere al file /etc/ntp.conf per i dettagli del server ntp.</block>
  <block id="fec65f0c33739368ce5845fadb6cb880" category="paragraph">Queste guide si applicano sia alle applicazioni che al sistema operativo guest dell'appliance stessa.</block>
  <block id="5aaf8fc9424d7872cf500fb7adcb3b97" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere, configurazione dei criteri password.</block>
  <block id="53477738359cebc12d4e01727ee8b5e7" category="paragraph">Gli utenti che distribuiscono gli strumenti ONTAP per la prima volta o che eseguono l'aggiornamento alla versione 9,12 o successiva dovranno seguire il criterio password complessa sia per gli utenti dell'amministratore che per quelli del database. Durante il processo di distribuzione, ai nuovi utenti verrà richiesto di immettere le password. Per gli utenti di brownfield che effettuano l'aggiornamento alla versione 9,12 o successiva, l'opzione per seguire il criterio password complessa sarà disponibile nella console di manutenzione.</block>
  <block id="7afd9be20a239f83f98bdbc7f90512ef" category="list-text">Una volta che l'utente accede alla console principale, le password verranno controllate in base al set di regole complesso e, se risulta non essere seguite, all'utente verrà chiesto di reimpostare lo stesso.</block>
  <block id="1e048d74f3d9375186833526a00f4309" category="list-text">La validità predefinita della password è di 90 giorni e dopo 75 giorni l'utente inizierà a ricevere la notifica di modifica della password.</block>
  <block id="dbb73ef3f8e9b61d387a809281a654cc" category="list-text">È necessario impostare una nuova password ad ogni ciclo; il sistema non utilizzerà l'ultima password come nuova password.</block>
  <block id="210b05d5e7375bcb02bcf09a873bbda6" category="list-text">Ogni volta che un utente accede alla console principale, prima di caricare il menu principale controlla i criteri delle password, come le schermate seguenti:</block>
  <block id="bc66b4fce20ef49b05e4a54f053e65a6" category="inline-image-macro">Menu principale,larghezza=468,altezza=116</block>
  <block id="4661acb75237098be364b3c05d7d9b7c" category="paragraph"><block ref="4661acb75237098be364b3c05d7d9b7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f09c69f731d4d6f2e8d6135082aa8e4" category="list-text">Se non viene rilevato seguendo il criterio password o la relativa configurazione di aggiornamento da ONTAP Tools 9,11 o precedenti. L'utente visualizzerà quindi la seguente schermata per reimpostare la password:</block>
  <block id="4499d4bfb9610056781e2e61956dd0ca" category="inline-image-macro">Schermata di reimpostazione della password,larghezza=468,altezza=116</block>
  <block id="a84278f7bf3ee281e39e467fca1fe454" category="paragraph"><block ref="a84278f7bf3ee281e39e467fca1fe454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47e6664ac0a72e1d719cfc288383b4f8" category="list-text">Se l'utente tenta di impostare una password debole o restituisce l'ultima password, viene visualizzato il seguente errore:</block>
  <block id="fe04952c38b6a9a7db1a75bbb4905232" category="inline-image-macro">Errore password debole,width=468,height=101</block>
  <block id="2c59de9ea5183e73d5fa6382fa7f3fc1" category="paragraph"><block ref="2c59de9ea5183e73d5fa6382fa7f3fc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8463a61dd94ff5934036d4c8a8936e32" category="doc">Timeout di inattività</block>
  <block id="704c7fc6c4d40b9af6aafb7cf9b44022" category="paragraph">Per impedire l'accesso non autorizzato, viene impostato un timeout di inattività che disconnette automaticamente gli utenti inattivi per un determinato periodo di tempo durante l'utilizzo di risorse autorizzate. In questo modo, solo gli utenti autorizzati possono accedere alle risorse e mantenere la sicurezza.</block>
  <block id="80f9ebebc8f94450338d28bcb4a2164d" category="inline-link">Configurare il valore di timeout del client vSphere</block>
  <block id="3748702da26b5718f1f7c769ce58b009" category="list-text">Per impostazione predefinita, le sessioni del client vSphere si chiudono dopo 120 minuti di inattività, richiedendo all'utente di accedere nuovamente per riprendere a utilizzare il client. È possibile modificare il valore di timeout modificando il file webclient.properties. È possibile configurare il timeout del client vSphere<block ref="ec8715bde1a929a6f64160d5372f4574" category="inline-link-rx"></block></block>
  <block id="e4306c4cf124046d8f90518752cd5021" category="list-text">Gli strumenti ONTAP hanno un tempo di disconnessione della sessione Web-cli di 30 minuti.</block>
  <block id="7fb0cadcdae6feac05c7b8274b97b3c7" category="sidebar">Panoramica sulla protezione avanzata degli strumenti ONTAP</block>
  <block id="10b486896b1a91f5d38214dfb30c4263" category="sidebar">Verifica dell'integrità dei pacchetti di installazione degli strumenti ONTAP</block>
  <block id="7c7c4cc4771d6114aa8b4d38f5817a85" category="sidebar">Porte e protocolli</block>
  <block id="919e26ea009ce7fa2dcc499a27ccc6aa" category="sidebar">Punti di accesso (utenti)</block>
  <block id="333dd505db0523536c6885f47456518c" category="sidebar">TLS reciproco</block>
  <block id="6a3f3799bc264d32568bb7169ddd515a" category="sidebar">Certificato HTTPS</block>
  <block id="4b7ad38343c4b2010cf81e6b2933e186" category="sidebar">Banner di accesso</block>
  <block id="bfdb89134acf30ff5da790924cefa0ac" category="sidebar">Timeout di inattività</block>
  <block id="cb197b06aa92a742d01e256d58d3e34b" category="sidebar">Attacco DOS</block>
  <block id="d870a4bd29f74339732a958574d2c4eb" category="sidebar">Configurazione NTP</block>
  <block id="339ce1d4220ba7045e3a35ef35279ad3" category="sidebar">Criteri password</block>
  <block id="3698338a95ad1801e25ed154adaf1a70" category="summary">Guida alla protezione avanzata per gli strumenti ONTAP per VMware vSphere, panoramica e introduzione.</block>
  <block id="47d29daaa26fbfa9c9a069d4cd023ac1" category="doc">Guida alla protezione avanzata per gli strumenti ONTAP per VMware vSphere</block>
  <block id="fe0e23a929284a636c245a362ada6472" category="paragraph">La guida alla protezione avanzata per gli strumenti ONTAP per VMware vSphere fornisce una serie completa di istruzioni per la configurazione delle impostazioni più sicure.</block>
  <block id="bc86ce4caa57368f9094a93dd72ffd28" category="paragraph">Quando è richiesta la modalità domino, NetApp offre SnapMirror Synchronous (SM-S). Esistono anche opzioni a livello di applicazione, come Oracle DataGuard o SQL Server Always on Availability Groups. Il mirroring del disco a livello del sistema operativo può essere opzionale. Per ulteriori informazioni e opzioni, consulta il tuo NetApp o il partner account team.</block>
  <block id="8059304404c995bd8a349056e7d40e32" category="inline-link">_Soluzioni NetApp per la virtualizzazione con VMware di Broadcom_</block>
  <block id="cc5363f91541e771ebd890b2330cb8ba" category="paragraph"><block ref="cc5363f91541e771ebd890b2330cb8ba" category="inline-link-rx"></block></block>
  <block id="c90946faf2ed37e17d936e0b3acde7a7" category="summary">C'è un'crescente domanda di crittografia dei dati a riposo, che si estende oltre i dati tradizionali a tutti i tipi di dati memorizzati.</block>
  <block id="b1e1676a19b222da72a55b95aa86d3e9" category="paragraph">Per un'analisi approfondita di altri argomenti relativi alla sicurezza, fare riferimento alle seguenti risorse.</block>
  <block id="e6bd708199eed7d8bf33ef8308be0b3e" category="inline-link-macro">Report tecnici sulla sicurezza</block>
  <block id="fb7f6edb08c080e81bd91a922a9d08f8" category="list-text"><block ref="fb7f6edb08c080e81bd91a922a9d08f8" category="inline-link-macro-rx"></block></block>
  <block id="ff8c9f0959eb84d21416835c3f9c89d6" category="inline-link-macro">Guide per la protezione avanzata</block>
  <block id="589b1ebfaed268e1548717208be6131f" category="list-text"><block ref="589b1ebfaed268e1548717208be6131f" category="inline-link-macro-rx"></block></block>
  <block id="e44de13cc4b452eccde9961bbe9da42b" category="inline-link-macro">Documentazione del prodotto di sicurezza e crittografia dei dati ONTAP</block>
  <block id="c76e848365d3a2199dfced47ddbf8690" category="list-text"><block ref="c76e848365d3a2199dfced47ddbf8690" category="inline-link-macro-rx"></block></block>
  <block id="0e8f1228bcea37dc870b3c00ddfebb6b" category="list-text">*Offerte di prime parti.* Amazon FSX per NetApp ONTAP, Google Cloud NetApp Volumes e Azure NetApp Files per ANF offrono servizi di storage gestito multiprotocollo dalle performance elevate negli ambienti di cloud pubblico leader. Possono essere utilizzati direttamente da VMware Cloud su AWS (VMC on AWS), Azure VMware Solution (AVS) e Google Cloud VMware Engine (GCVE) come datastore o storage per sistemi operativi guest (GOS) e istanze di calcolo.</block>
  <block id="2c95b4b56070479502ffc85344c7d8b2" category="list-text">*Servizi cloud*. Utilizza il backup e recovery di BlueXP o SnapMirror Cloud per proteggere i dati dai sistemi on-premise utilizzando il cloud storage pubblico. Cloud Sync consente di migrare e mantenere sincronizzati i dati tra NAS, archivi di oggetti e storage Cloud Volumes Service. Il disaster recovery di BlueXP è una soluzione conveniente ed efficiente per sfruttare le tecnologie NetApp come base per una soluzione di disaster recovery solida e capace per disaster recovery su cloud, DR on-premise e on-premise.</block>
  <block id="1a523ba4ece9125275b92ebb41e3cf23" category="inline-link-macro">Documentazione Cloud Volumes ONTAP</block>
  <block id="e4501a9ef639002a658af0113906add9" category="list-text"><block ref="e4501a9ef639002a658af0113906add9" category="inline-link-macro-rx"></block></block>
  <block id="7436b418bed093768e360d32105591d2" category="inline-link-macro">Documentazione ONTAP Select</block>
  <block id="82fe32c89de73116e2188701ca735c39" category="list-text"><block ref="82fe32c89de73116e2188701ca735c39" category="inline-link-macro-rx"></block></block>
  <block id="c756b6b1ba6b752239a8d49eda5ad2a4" category="inline-link-macro">Documentazione di backup e ripristino BlueXP</block>
  <block id="f99b2e5828a20fe99efc9b8c25b42d83" category="list-text"><block ref="f99b2e5828a20fe99efc9b8c25b42d83" category="inline-link-macro-rx"></block></block>
  <block id="b044111e167403664c9e3432eca1f25a" category="inline-link-macro">Documentazione di disaster recovery di BlueXP</block>
  <block id="ec39a9c8e559c87efc4a1ac3c8dfd136" category="list-text"><block ref="ec39a9c8e559c87efc4a1ac3c8dfd136" category="inline-link-macro-rx"></block></block>
  <block id="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="list-text"><block ref="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="inline-link-macro-rx"></block></block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">VMware Cloud su AWS</block>
  <block id="560d5b2cd40977bd7b77b31d7088f657" category="list-text"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block></block>
  <block id="e6aa20b5d3923ee0466f5d7e7bfed821" category="inline-link-macro">Che cos'è Azure NetApp Files?
</block>
  <block id="810dc5c2e801b56b11325dd2aca0775c" category="list-text"><block ref="810dc5c2e801b56b11325dd2aca0775c" category="inline-link-macro-rx"></block></block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="inline-link-macro">Soluzione VMware Azure</block>
  <block id="f068ad668d317d445bc0da61125c318f" category="list-text"><block ref="f068ad668d317d445bc0da61125c318f" category="inline-link-macro-rx"></block></block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="inline-link-macro">Motore VMware Google Cloud</block>
  <block id="dadb2f85467c159b9d8387744cdd0ce6" category="list-text"><block ref="dadb2f85467c159b9d8387744cdd0ce6" category="inline-link-macro-rx"></block></block>
  <block id="e6288bb2b93ca74537fbff66317f01d9" category="inline-link-macro">Che cos'è Google Cloud NetApp Volumes?</block>
  <block id="e19aa8cca2f701dba5fc123376bebdb5" category="list-text"><block ref="e19aa8cca2f701dba5fc123376bebdb5" category="inline-link-macro-rx"></block></block>
  <block id="b44c4aa4ed40a2c01a89549bc8746cbd" category="cell">Impostato su 512 MB per la maggior parte delle release di vSphere 6.X.
Impostare sul valore predefinito (1024MB) per 6.5U3, 6.7U3 e 7,0 o versioni successive.</block>
  <block id="f3c4f211a4831f8f7c223705b0fccd5d" category="paragraph">I limiti di throughput sono utili per controllare i livelli di servizio, gestire carichi di lavoro sconosciuti o testare le applicazioni prima della distribuzione per assicurarsi che non influiscano su altri carichi di lavoro in produzione. Possono anche essere utilizzati per limitare un carico di lavoro ingombrante dopo l'identificazione.</block>
  <block id="5ab12aefceb83851b73081a686bd30ab" category="section-title">Supporto della policy QoS di ONTAP</block>
  <block id="8aa45e69fd8330d5e4d2f6e16309ff41" category="paragraph">Sono supportati anche i livelli minimi di servizio basati sugli IOPS per fornire performance costanti per gli oggetti SAN in ONTAP 9.2 e per gli oggetti NAS in ONTAP 9.3.</block>
  <block id="98d229565d14d4d286f57a588a784c1e" category="inline-link-macro">Panoramica sulla gestione e sul monitoraggio delle performance</block>
  <block id="b7629a90716592b8dcae7480ad66d224" category="paragraph">Fare riferimento a. <block ref="de4b907e949a377b72cd0f0b0595d155" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="81eba6b819a671b6c8962061afd13a78" category="section-title">Datastore NFS non vVol</block>
  <block id="5bafceb9f14cf4b07086992cd31326a5" category="paragraph">È possibile applicare una policy di QoS ONTAP all'intero datastore o ai singoli file VMDK al suo interno. Tuttavia, è importante comprendere che tutte le macchine virtuali di un datastore NFS tradizionale (non vVol) condividono una coda i/o comune da un determinato host. Se una macchina virtuale viene rallentata da una policy di QoS ONTAP, in pratica tutto l'i/o del datastore sembrerà rallentato per quell'host.</block>
  <block id="1520a4910ffa6efc27379931cc307d0b" category="paragraph">*Esempio:*
* È stato configurato un limite QoS su VM1.vmdk per un volume montato come datastore NFS tradizionale dall'host esxi-01.
* Lo stesso host (esxi-01) utilizza VM2.vmdk e si trova sullo stesso volume.
* Se VM1.vmdk viene rallentato, allora anche VM2.vmdk sembrerà essere rallentato poiché condivide la stessa coda io con VM1.vmdk.</block>
  <block id="caf18b31d986fc095c3c0cd6a1f19f9e" category="paragraph">A partire da vSphere 6,5 è possibile gestire limiti granulari dei file sui datastore non vVol sfruttando la gestione basata su criteri dello storage (SPBM, Storage Policy-Based Management) con Storage i/o Control (SIOC) v2.</block>
  <block id="c28029445f9803e209550517678387a9" category="paragraph">Fare riferimento ai link seguenti per ulteriori informazioni sulla gestione delle prestazioni con i criteri SIOC e SPBM.</block>
  <block id="8bef032522908e987555b77fb50dbb85" category="inline-link-macro">Regole basate su host SPBM: SIOC v2</block>
  <block id="98a7507b3e8be801707c07e336bc5506" category="inline-link-macro">Gestisci le risorse i/o di storage con vSphere</block>
  <block id="37b0c263c77e85e59d9f00438e870fa4" category="paragraph"><block ref="ea373db41b8c05446b96b46f4bbe1141" category="inline-link-macro-rx"></block>
<block ref="c5badf4fd27434d786395fe52801b533" category="inline-link-macro-rx"></block></block>
  <block id="cd6af799ac31b0fbf81bcbba1d3d6bf1" category="list-text">La policy deve essere applicata a<block ref="3b9aef0680339707b430261c2f800255" prefix=" " category="inline-code"></block> che contiene l'immagine effettiva del disco virtuale, non il<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (file di descrizione del disco virtuale) o.<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (File descrittore VM).</block>
  <block id="9aa28dc739b66a86d9f73ba24b9dd4c2" category="paragraph">Gli archivi dati FlexGroup offrono funzionalità QoS avanzate quando si utilizzano gli strumenti ONTAP per VMware vSphere 9.8 e versioni successive. È possibile impostare facilmente la QoS su tutte le macchine virtuali di un datastore o su macchine virtuali specifiche. Per ulteriori informazioni, consultare la sezione FlexGroup di questo report. Tieni presente che si applicano ancora le limitazioni di qualità del servizio menzionate in precedenza per i datastore NFS tradizionali.</block>
  <block id="b5380e34617914719b059f6d55b97b66" category="section-title">Datastore VMFS</block>
  <block id="b74c42e3de8c5b901769e263bf236711" category="paragraph">Utilizzando le LUN di ONTAP, le policy di QoS possono essere applicate al volume FlexVol che contiene le LUN o le singole LUN, ma non ai singoli file VMDK perché ONTAP non conosce il file system VMFS.</block>
  <block id="e122a7a507ac1f580cc5b9f2632a851c" category="section-title">Datastore vVol</block>
  <block id="be1ca5bcad3b34c08e2b2d7bfc8a95e3" category="paragraph">È possibile impostare facilmente una qualità del servizio minima e/o massima su singole macchine virtuali o VMDK senza impatti su altre macchine virtuali o VMDK grazie alla gestione basata su policy di storage e ai vVol.</block>
  <block id="f5ac983ee93a7017d283971566bc828e" category="paragraph">Durante la creazione di un profilo di capacità storage per il container vVol, specifica un valore IOPS max e/o min in termini di performance, quindi fai riferimento a questo SCP con la policy storage delle macchine virtuali. Utilizzare questo criterio quando si crea la macchina virtuale o si applica il criterio a una macchina virtuale esistente.</block>
  <block id="1f23e960871a0a77a49731a6b47646c5" category="inline-link-macro">Volumi virtuali di VMware vSphere (vVol) con ONTAP</block>
  <block id="8743b08c4d707cd145a4e7acce189480" category="cell">Sì (il datastore può essere rallentato)</block>
  <block id="b2891bc898f2a418aa349b623568299e" category="summary">Active IQ Unified Manager permette il monitoraggio e la risoluzione dei problemi relativi allo storage e alle performance NetApp nel tuo ambiente VMware vSphere.</block>
  <block id="b7ce758ec5c25cb23edfa4ead0d0097e" category="admonition">*NetApp consiglia* almeno il 15% di spazio libero quando si utilizzano unità rotanti. Ciò comprende tutto lo spazio inutilizzato, compreso lo spazio libero all'interno dell'aggregato o di un volume ed eventuale spazio libero allocato a causa dell'utilizzo del provisioning completo, ma non utilizzato dai dati effettivi. Le prestazioni saranno influenzate dall'avvicinarsi del 10% dello spazio libero.</block>
  <block id="5a7f49be424e282d22b4c3889f5cd341" category="paragraph">MetroCluster è una funzionalità di ONTAP in grado di proteggere i database Oracle con RPO=0 mirroring sincrono tra i siti, per poi scalare in verticale e supportare centinaia di database su un singolo sistema MetroCluster.</block>
  <block id="30160293c6cf2d26d13cbd294af7fb4c" category="paragraph">È anche semplice da usare. L'utilizzo di MetroCluster non aggiunge o modifica necessariamente i migliori percorsi per la gestione di applicazioni e database aziendali.</block>
  <block id="c77924ff430fa98df17795d4f5c5885f" category="doc">Certificato HTTPS degli strumenti ONTAP</block>
  <block id="641cc5f60c71fe9f9a2e15c5cc680ec3" category="summary">Guida al rafforzamento della protezione per gli strumenti ONTAP per VMware vSphere, porte e protocolli TCP</block>
  <block id="872cba2a662a784946eb48675276dee2" category="doc">Mutual TLS (autenticazione basata su certificato)</block>
  <block id="5a4857ad48868097d482a4a448f48bd9" category="doc">Numero massimo di richieste simultanee per utente (protezione di rete/attacco DOS)</block>
  <block id="0af211d5cda5cc4bb17dd7751e741595" category="doc">Configurazione NTP (Network Time Protocol)</block>
  <block id="273eb98a312e607888044e87e0210015" category="section-title">Supporto vVol NetApp</block>
  <block id="551e3b0a48f99995daac658b17a1de62" category="list-text">*Migliore gestione della capacità.* Gli strumenti VASA e ONTAP consentono di vedere la capacità dello storage fino al singolo livello di aggregato, se necessario, e fornire più livelli di avviso in caso di esaurimento della capacità.</block>
  <block id="38653f1dd04b13c5276f4f4a82e8506f" category="admonition">Il termine connettività si riferisce alla connessione cluster utilizzata per la replica tra siti. Non si riferisce ai protocolli host. Tutti i protocolli lato host sono supportati come di consueto in una configurazione MetroCluster indipendentemente dal tipo di connessione utilizzata per la comunicazione tra cluster.</block>
  <block id="6f343e6c5daed91ac953577dd5e1e06e" category="doc">Interruzione della connettività di replica</block>
  <block id="6f04ca443b44ef3da2adedd7c0cf36fa" category="paragraph">Per gli esempi seguenti, si supponga che il sito A sia configurato come sito preferito.</block>
  <block id="f553ed0b13f8b38932589ba34432ab5a" category="paragraph">Se la replica SM-AS viene interrotta, non è possibile completare la scrittura io perché sarebbe impossibile per un cluster replicare le modifiche al sito opposto.</block>
  <block id="2ef1646841c5728f668289819e837437" category="section-title">Sito A (sito preferito)</block>
  <block id="47d7b1b43310c2ce615be2e71aed414d" category="paragraph">Il risultato dell'errore del collegamento di replica sul sito preferito sarà una pausa di circa 15 secondi nell'elaborazione io in scrittura, poiché ONTAP ritenta le operazioni di scrittura replicate prima di determinare che il collegamento di replica è veramente irraggiungibile. Trascorsi i 15 secondi, il sistema del sito A riprende l'elaborazione io in lettura e scrittura. I percorsi SAN non vengono modificati e i LUN rimangono online.</block>
  <block id="bb713afeab82bcb45a45d3cc1411e3eb" category="section-title">Sito B</block>
  <block id="dc68c1abbc392a93905ce712c45999eb" category="paragraph">Poiché il sito B non è il sito preferito di sincronizzazione attiva SnapMirror, i relativi percorsi LUN non saranno più disponibili dopo circa 15 secondi.</block>
  <block id="3784559d5087e35dc7372b1c51cf920e" category="section-title">Errore del sistema di storage</block>
  <block id="901afcf3108cffc70b3209e8613babf0" category="paragraph">Il risultato di un errore del sistema di storage è quasi identico al risultato della perdita del collegamento di replica. Il sito sopravvissuto dovrebbe subire una pausa io di circa 15 secondi. Trascorso questo periodo di 15 secondi, io riprenderà sul sito come di consueto.</block>
  <block id="0ce6f0c843cdd28d3ff7284039730959" category="section-title">Perdita del mediatore</block>
  <block id="6b9600f6a35d60a0773b02ff771e5be1" category="paragraph">Il servizio di mediazione non controlla direttamente le operazioni di storage. Funziona come un percorso di controllo alternativo tra cluster. Esiste principalmente per automatizzare il failover senza il rischio di uno scenario split-brain. Durante l'utilizzo normale, ogni cluster replica le modifiche al partner e pertanto ogni cluster può verificare che il cluster partner sia online e fornisca i dati. Se il collegamento di replica non è riuscito, la replica viene interrotta.</block>
  <block id="878273b0ad33bf4f330480ad6262d08c" category="paragraph">Il motivo per cui è necessario un mediatore per il failover automatizzato sicuro è perché altrimenti sarebbe impossibile per un cluster di storage determinare se la perdita di comunicazione bidirezionale fosse il risultato di un'interruzione della rete o di un errore effettivo dello storage.</block>
  <block id="7bccc28ee4a5fac4fa93b691ca9733bc" category="paragraph">Il mediatore fornisce un percorso alternativo per ciascun cluster per verificare lo stato di salute del partner. Gli scenari sono i seguenti:</block>
  <block id="7ba0268be94dd09db527214e2f2862b4" category="list-text">Se un cluster può contattare direttamente il partner, i servizi di replica sono operativi. Non è richiesta alcuna azione.</block>
  <block id="5c3163ce1d24869bf6e6594bcd37901d" category="list-text">Se un sito preferito non può contattare direttamente il proprio partner o tramite il mediatore, presuppone che il partner sia effettivamente non disponibile oppure è stato isolato e ha portato i percorsi LUN offline. Il sito preferito procede quindi al rilascio dello stato RPO=0 e continua l'elaborazione dell'io in lettura e in scrittura.</block>
  <block id="e2c06d8468f627e9f8fdc9380204f00f" category="list-text">Se un sito non preferito non può contattare direttamente il proprio partner, ma può contattarlo tramite il mediatore, prenderà i suoi percorsi offline e attenderà il ritorno della connessione di replica.</block>
  <block id="f7fd4567c8be042fc3f9be5b45124d76" category="list-text">Se un sito non preferito non può contattare direttamente il proprio partner o tramite un mediatore operativo, supporterà che il partner sia effettivamente non disponibile, oppure che sia stato isolato e che abbia portato i percorsi LUN offline. Il sito non preferito procede quindi al rilascio dello stato RPO=0 e continua l'elaborazione dell'i/o in lettura e scrittura. Assumerà il ruolo dell'origine della replica e diventerà il nuovo sito preferito.</block>
  <block id="1286d22222876588b31270c148d8c480" category="paragraph">Se il mediatore non è completamente disponibile:</block>
  <block id="3cc95aae492aaec45753d6e6b7d91c12" category="list-text">In caso di guasto dei servizi di replica per qualsiasi motivo, incluso un guasto del sito o del sistema storage non preferito, il sito preferito rilascerà lo stato RPO=0 e riprenderà l'elaborazione i/o in lettura e scrittura. Il sito non preferito prenderà i suoi percorsi offline.</block>
  <block id="92395625e4bc805c933a9b4f52c5c594" category="list-text">Il guasto del sito preferito causerà un'interruzione poiché il sito non preferito non sarà in grado di verificare che il sito opposto sia effettivamente offline e quindi non sarebbe sicuro per il sito non preferito riprendere i servizi.</block>
  <block id="3450c1f3c1166bb5f38dd42c45eb1b70" category="section-title">Ripristino dei servizi in corso</block>
  <block id="5a0a7b8380bda809ef1b210c3bb41b93" category="paragraph">Dopo aver risolto un errore, come il ripristino della connettività da sito a sito o l'accensione di un sistema guasto, gli endpoint di sincronizzazione attivi di SnapMirror rilevano automaticamente la presenza di una relazione di replica difettosa e la riportano allo stato RPO=0. Una volta ristabilita la replica sincrona, i percorsi non riusciti torneranno in linea.</block>
  <block id="8f3219fa36fad5d789373fdf883d28b1" category="paragraph">In molti casi, le applicazioni in cluster rilevano automaticamente la restituzione dei percorsi non riusciti e tali applicazioni tornano online. In altri casi, potrebbe essere necessaria una scansione SAN a livello di host oppure potrebbe essere necessario riportare le applicazioni online manualmente. Dipende dall'applicazione e dal modo in cui è configurata, e in generale tali attività possono essere facilmente automatizzate. ONTAP si sta auto-riparando e non deve richiedere alcun intervento da parte dell'utente per riprendere le operazioni di storage RPO = 0 KB.</block>
  <block id="52ec8762530eb85c0734309b6747a861" category="section-title">Failover manuale</block>
  <block id="afe62727c9717a186ce014753f902c8a" category="paragraph">La modifica del sito preferito richiede un'operazione semplice. I/o si fermeranno per un secondo o due come autorità sugli switch del comportamento di replica tra i cluster, ma in caso contrario i/o non vengono influenzati.</block>
  <block id="2d430e41b39275608ed6816ee435f2c4" category="paragraph">Il mediatore non è realmente un tiebreaker, anche se quella è effettivamente la funzione che fornisce. Non esegue alcuna azione, ma fornisce un canale di comunicazione alternativo per la comunicazione tra cluster e cluster.</block>
  <block id="caeb8c810d4965bfc8ad369332977e54" category="inline-image-macro">Diagramma di sincronizzazione attivo SnapMirror con mediatore</block>
  <block id="4c67fbe8dcb303fbb7a06384a1e166ff" category="paragraph"><block ref="4c67fbe8dcb303fbb7a06384a1e166ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2767cf2bbeaf5540c1e615745cfead81" category="paragraph">La sfida #1 con il failover automatizzato è il problema split-brain, e questo problema sorge se i due siti perdono la connettività tra loro. Che cosa dovrebbe accadere? Non si desidera che due siti diversi si designino come copie sopravvissute dei dati, ma in che modo un singolo sito può distinguere tra la perdita effettiva del sito opposto e l'impossibilità di comunicare con il sito opposto?</block>
  <block id="661d0a9679d7d1af0f76f646c941e5cc" category="paragraph">Qui entra il mediatore nell'immagine. Se si trova in un sito 3rd e ciascun sito dispone di una connessione di rete separata per tale sito, è disponibile un percorso aggiuntivo per ciascun sito per convalidare lo stato dell'altro. Esaminare nuovamente l'immagine sopra riportata e considerare i seguenti scenari.</block>
  <block id="d0c23d9c3fc0a960d3362e7ba10243f5" category="list-text">Cosa succede se il mediatore non riesce o è irraggiungibile da uno o entrambi i siti?</block>
  <block id="123c024944e0a1dd3f71661e6d0e5005" category="list-text">I due cluster possono ancora comunicare tra loro sullo stesso link utilizzato per i servizi di replica.</block>
  <block id="00a2d2948ebb25dba32d9366b8655dfc" category="list-text">I dati sono ancora serviti con protezione RPO=0/7</block>
  <block id="7ac2e4e468f2c732023f530f71ac9dbb" category="list-text">Cosa succede se il sito A non funziona?</block>
  <block id="ce89434a9a13b39dccbbded97d674de0" category="list-text">Il sito B vedrà che entrambi i canali di comunicazione si interrompono.</block>
  <block id="0a22d4bfa3bb021654f02d82cdbb9422" category="list-text">Il sito B sostituirà i servizi dati, ma senza RPO = mirroring 0:1</block>
  <block id="2a7681a43b5e9647d24566f342ab0b27" category="list-text">Cosa succede se il sito B non funziona?</block>
  <block id="1c8ff8325f78bcc084c3c197606b5482" category="list-text">Il sito A vedrà che entrambi i canali di comunicazione si interrompono.</block>
  <block id="8a8e5bd62b16753898cefd37bdf7ccb4" category="list-text">Il sito A sostituirà i servizi dati, ma senza RPO = mirroring 0:1</block>
  <block id="11b1ce76911fece428e0edd5c9e7682f" category="paragraph">Esiste un altro scenario da considerare: La perdita del collegamento di replica dei dati. In caso di perdita del link di replica tra i siti, RPO=0 Mirroring sarà ovviamente impossibile. Che cosa dovrebbe accadere allora?</block>
  <block id="3e2a78d8ed8be1e5b40ff81cc9e2a2d6" category="paragraph">Questo è controllato dallo stato del sito preferito. In una relazione SM-AS, uno dei siti è secondario all'altro. Questo non ha alcun effetto sulle normali operazioni e tutto l'accesso ai dati è simmetrico, ma se la replica viene interrotta, il legame dovrà essere interrotto per riprendere le operazioni. Ne risulta che il sito preferito continuerà le operazioni senza mirroring e il sito secondario interromperà l'elaborazione io fino al ripristino della comunicazione di replica.</block>
  <block id="225caaa9ecf3ac7dfb141c808a1c1651" category="paragraph">La sincronizzazione attiva di SnapMirror (in precedenza nota come SnapMirror Business Continuity o SM-bc) permette a singoli database e applicazioni SQL Server di continuare il servizio in caso di interruzioni, con il failover trasparente dello storage senza interventi manuali.</block>
  <block id="700cb79deb6ef819c0aacbb228c5a16b" category="paragraph">La sincronizzazione attiva SnapMirror (SM-AS) si basa sulla sincronizzazione SnapMirror. Entrambi possono fornire una replica sincrona dei dati RPO=0, ma SM-as porta la soluzione ulteriormente offrendo una disponibilità RTO quasi pari a zero per i dati SAN. Questo avviene attraverso l'automazione che gestisce i percorsi SAN per mantenere disponibili i dati. Gli errori relativi a siti, controller e comunicazioni sono tutti gestiti automaticamente da ONTAP.</block>
  <block id="c159224eea5fb4a30b3cc9be6e90cd6c" category="paragraph">SnapMirror Active Sync offre LUN che esistono su due siti diversi. Durante il normale funzionamento, non è presente alcuna "sorgente" o "destinazione". La direzione è bidirezionale. Tutti gli io in lettura diretti contro un determinato percorso LUN saranno gestiti dal controller locale utilizzando la propria copia locale dei dati. Tutte le scritture verranno replicate sul partner remoto e scritte localmente prima di essere riconosciute.</block>
  <block id="4a85397e66688e4e619ffe832e627548" category="inline-image-macro">Panoramica su SnapMirror Active Sync</block>
  <block id="773253d9f54d4d8d3d596bef999303fa" category="paragraph"><block ref="773253d9f54d4d8d3d596bef999303fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ddc1e5dc440806435445e7a532ad1198" category="paragraph">A livello logico, il comportamento è simile a un singolo set di LUN. È possibile indirizzare l'io a queste LUN logiche attraverso percorsi SAN esistenti su due cluster diversi, ma i dati sono sempre gli stessi. Il comportamento io è simmetrico, aspetto critico per molte configurazioni di applicazioni Active-Active.</block>
  <block id="ddc5ca7c74db522011a3b2ddccda5b40" category="inline-image-macro">Design logico di sincronizzazione attiva SnapMirror</block>
  <block id="a91ae760520ff89a08c2f2db6a6c2ebd" category="paragraph"><block ref="a91ae760520ff89a08c2f2db6a6c2ebd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="daadd24f5163a10f9a2f016019883886" category="section-title">Gestione del percorso</block>
  <block id="9bb9bee58b329761e36c7d9bf8900d6f" category="paragraph">Esistono due approcci alla topologia di rete sincrona SnapMirror, uniforme e non uniforme. La considerazione chiave per la scelta tra accesso uniforme e non uniforme è se è possibile o necessario estendere la SAN tra i vari siti. La sincronizzazione attiva di SnapMirror può essere utilizzata in entrambe le situazioni.</block>
  <block id="1f46c4a6c97a8add22ae7c23181c23d8" category="paragraph">ONTAP Mediator è un'applicazione software che viene scaricata dal sito di assistenza di NetApp e che in genere viene distribuita su una macchina virtuale.</block>
  <block id="91e17573d84d7d626cc27e989a3957bc" category="inline-link-macro">Documentazione di ONTAP sulla sincronizzazione attiva di SnapMirror</block>
  <block id="ae81dd17263728532627374843ee0ff8" category="paragraph">Per le fasi di pianificazione e configurazione, fare riferimento a <block ref="44f5d8051247437425911d96f84db248" category="inline-link-macro-rx"></block> .</block>
  <block id="5abea2d56204d1c15aa063dc90ccfb4f" category="paragraph">La sincronizzazione attiva di SnapMirror considererà un sito la "fonte" e l'altro la "destinazione". Ciò implica una relazione di replica unidirezionale, ma ciò non si applica al comportamento io. La replica è bidirezionale e simmetrica, mentre i tempi di risposta io sono identici su entrambi i lati del mirror.</block>
  <block id="e5086daa5843466ff5f04f20d4c19d74" category="paragraph">La<block ref="36cd38f49b9afa08222c0dc9ebfe35eb" prefix=" " category="inline-code"></block> designazione è controlla il sito preferito. In caso di perdita del link di replica, i percorsi delle LUN nella copia di origine continueranno a fornire i dati mentre i percorsi delle LUN nella copia di destinazione non saranno disponibili finché la replica non viene ristabilita e SnapMirror ritorna allo stato sincrono. I percorsi riprenderanno a fornire i dati.</block>
  <block id="a0bbe7bd1e93252f1267d98703905552" category="paragraph">La configurazione di origine/destinazione può essere visualizzata tramite SystemManager:</block>
  <block id="13d0a54956b2dd09d5e909acadfb1694" category="inline-image-macro">SM screenshot di SM-as source</block>
  <block id="70547bc22a604012e7d30f238d3ab5c8" category="paragraph"><block ref="70547bc22a604012e7d30f238d3ab5c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b53b7d18b58af25bcf47dc21678038f" category="paragraph">O all'interfaccia CLI:</block>
  <block id="498b1bbe0e017f1ad405fe4c77fb8ea1" category="paragraph">La chiave è che source è l'SVM su cluster1. Come menzionato sopra, i termini "origine" e "destinazione" non descrivono il flusso di dati replicati. Entrambi i siti possono elaborare una scrittura e replicarla nel sito opposto. In effetti, entrambi i cluster sono origini e destinazioni. L'effetto della designazione di un cluster come origine controlla semplicemente quale cluster sopravvive come sistema di storage in lettura e scrittura in caso di perdita del link di replica.</block>
  <block id="18a07170e14f5cbc26533f0a136dfdd0" category="inline-image-macro">Rete non uniforme con sincronizzazione attiva SnapMirror</block>
  <block id="9347dda18b33bf2c717916c013eb47bc" category="paragraph"><block ref="9347dda18b33bf2c717916c013eb47bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9532c9e7afcd43c7d9bb5740695fc259" category="paragraph">Il vantaggio principale di questo approccio è la semplicità DELLE SAN, eliminando l'esigenza di stretching di una SAN via rete. Alcuni clienti non dispongono di connettività a latenza sufficientemente bassa tra i siti o non dispongono dell'infrastruttura per il tunnel del traffico FC SAN su una rete intersito.</block>
  <block id="439caacb19fa16f2c21563703ed645d7" category="paragraph">Lo svantaggio legato all'accesso non uniforme è che alcuni scenari di errore, inclusa la perdita del collegamento di replica, provocheranno la perdita dell'accesso allo storage da parte di alcuni host. In caso di interruzione della connettività dello storage locale, le applicazioni eseguite come istanze singole, come ad esempio i database non in cluster, eseguiti in maniera intrinseca solo su un singolo host in uno qualsiasi dei supporti di montaggio, si guasterebbero. I dati sarebbero comunque protetti, ma il server di database non avrebbe più accesso. Dovrebbe essere riavviato su un sito remoto, preferibilmente tramite un processo automatizzato. Ad esempio, VMware ha è in grado di rilevare una situazione di tutti i percorsi verso l'esterno su un server e di riavviare una macchina virtuale su un altro server in cui sono disponibili i percorsi.</block>
  <block id="5a2e2e33df9734d8ef57bcb93643d89a" category="paragraph">Al contrario, un'applicazione in cluster come Oracle RAC può offrire un servizio disponibile contemporaneamente in due siti diversi. Perdere un sito non significa perdere il servizio dell'applicazione nel suo complesso. Le istanze sono ancora disponibili e in esecuzione nel sito sopravvissuto.</block>
  <block id="9fad44ede04fb95c16ea64be5e51836c" category="paragraph">In molti casi, l'overhead della latenza aggiuntivo di un'applicazione che accede allo storage attraverso un collegamento da sito a sito sarebbe inaccettabile. Ciò significa che la migliore disponibilità di una rete uniforme è minima, poiché la perdita di storage su un sito comporterebbe comunque la necessità di arrestare i servizi sul sito in cui si è verificato l'errore.</block>
  <block id="15da96ce40136a3259e04ae0dc25fc95" category="paragraph">Esistono percorsi ridondanti attraverso il cluster locale non mostrati in questi diagrammi per semplicità. I sistemi di storage ONTAP sono ad alta disponibilità, pertanto un guasto a un controller non dovrebbe causare guasti nel sito. Ciò dovrebbe comportare solo una modifica dei percorsi locali utilizzati nel sito interessato.</block>
  <block id="bb12626aefb7c36f9b13694d35dadd5d" category="paragraph">Una caratteristica importante di SM-AS è la capacità di configurare i sistemi storage per sapere dove si trovano gli host. Quando si mappano i LUN a un determinato host, è possibile indicare se sono prossimali o meno a un determinato sistema di archiviazione.</block>
  <block id="4590bab77464ba1a9c8ee6b8095eef60" category="inline-image-macro">Rete uniforme AFF con sincronizzazione attiva SnapMirror</block>
  <block id="988f5836c7a60d1374a4804da23d51e4" category="paragraph"><block ref="988f5836c7a60d1374a4804da23d51e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b2fdfa824f1319cc47992b1277faa78" category="paragraph">Durante le normali operazioni, tutti i io sono i/o locali. Le letture e le scritture sono gestite dallo storage array locale. Gli io in scrittura, naturalmente, dovranno anche essere replicati dal controller locale sul sistema remoto prima di essere riconosciuti, ma tutti gli io in lettura saranno serviti localmente e non subiranno una latenza aggiuntiva attraverso il collegamento SAN tra i siti.</block>
  <block id="97b2bb0cfbae3fe49433caf537e819ec" category="paragraph">L'unica volta in cui verranno utilizzati i percorsi non ottimizzati è quando tutti i percorsi attivi/ottimizzati vengono persi. Ad esempio, se l'intero array sul sito A perde energia, gli host sul sito A sarebbero comunque in grado di accedere ai percorsi dell'array sul sito B e di rimanere quindi operativi, anche se sperimenterebbero una latenza più elevata.</block>
  <block id="5ab085bf88338486e590861594d3947a" category="paragraph">I sistemi NetApp ASA offrono multipathing Active-Active su tutti i percorsi di un cluster. Questo vale anche per le configurazioni SM-AS.</block>
  <block id="6511f0e2589c08e82bc8dd3e9bc93185" category="inline-image-macro">Rete uniforme ASA con sincronizzazione attiva SnapMirror</block>
  <block id="1d818a68fead665559afc9e582394a7d" category="paragraph"><block ref="1d818a68fead665559afc9e582394a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3fe6771b27ffcb15a75ae88f6d57c4b" category="paragraph">Una configurazione ASA con accesso non uniforme funzionerebbe in gran parte allo stesso modo di AFF. Con un accesso uniforme, io attraverserebbe la WAN. Ciò può essere o non può essere desiderabile.</block>
  <block id="498a9faf271a73dcf026b1041b66ef2a" category="paragraph">Se i due siti fossero a una distanza di 100 metri con connettività in fibra non dovrebbe esserci una latenza aggiuntiva rilevabile che attraversa la WAN, ma se i siti fossero a lunga distanza gli uni dagli altri, le performance in lettura risulterebbero compromesse su entrambi i siti. Al contrario, con AFF questi percorsi WAN sarebbero utilizzati solo se non ci fossero percorsi locali disponibili e le performance quotidiane sarebbero migliori, perché tutti i io sarebbero io locali. ASA con rete di accesso non uniforme sarebbe un'opzione per ottenere i vantaggi in termini di costi e funzionalità di ASA senza incorrere in penalizzazioni per l'accesso alla latenza tra siti.</block>
  <block id="15ab92b8042738f6acc912e2d98ae17a" category="paragraph">ASA con SM-as in una configurazione a bassa latenza offre due benefici interessanti. In primo luogo, essenzialmente *raddoppia* le prestazioni per ogni singolo host perché io può essere gestito dal doppio dei controller utilizzando il doppio dei percorsi. In secondo luogo, in un ambiente a sito singolo offre una disponibilità estrema, perché è possibile perdere un intero sistema storage senza interrompere l'accesso degli host.</block>
  <block id="41c719032afe187deaf4b4b2af41aa36" category="paragraph">L'efficienza di stoccaggio sensibile alla temperatura (TSSE) è disponibile in ONTAP 9.8 e versioni successive. Si affida alle mappe termiche di accesso ai blocchi per identificare i blocchi a cui si accede raramente e comprimerli con una maggiore efficienza.</block>
  <block id="8284eb5a9d9bef8f0f1ece257656d0fe" category="summary">Informazioni aggiuntive per Epic su ONTAP</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="inline-link-macro">Documentazione sui prodotti NetApp</block>
  <block id="0897605072547ea93ef25a4b355ac5f6" category="list-text"><block ref="0897605072547ea93ef25a4b355ac5f6" category="inline-link-macro-rx"></block></block>
  <block id="5358757de9216cc29d688612a3d72fe1" category="inline-link-macro">Documentazione di ONTAP 9</block>
  <block id="3973235e869d719328cf4b37e59562e5" category="list-text"><block ref="3973235e869d719328cf4b37e59562e5" category="inline-link-macro-rx"></block></block>
  <block id="c9cefb6ed873a418f8c8232dca6879d2" category="inline-link-macro">Gruppi di coerenza</block>
  <block id="10d6aff3e86ebe3712a2616b45008fb3" category="list-text"><block ref="10d6aff3e86ebe3712a2616b45008fb3" category="inline-link-macro-rx"></block></block>
  <block id="0d3cc094235677831b5697c5bab76394" category="inline-link-macro">Risorse per la documentazione di ONTAP e ONTAP System Manager</block>
  <block id="3b2c8ae1d985c88d539bf7851e067922" category="list-text"><block ref="3b2c8ae1d985c88d539bf7851e067922" category="inline-link-macro-rx"></block></block>
  <block id="e9bf68ed54b6d1ff63e8bda8c0b6a70f" category="inline-link-macro">TR-3930i: Linee guida per il dimensionamento degli NetApp per Epic</block>
  <block id="920aa6d447930899ad56517c79fd12fc" category="list-text"><block ref="b6ff45309a811037a92ca1e6262c74a8" category="inline-link-macro-rx"></block> (Accesso NetApp richiesto)</block>
  <block id="840f4016fe968750d45ea4545f2f1893" category="section-title">Documenti di orientamento epici per i clienti</block>
  <block id="a839c9787ec80291f4b34dc5451786a5" category="paragraph">EPIC fornisce ai clienti i seguenti documenti per la guida su server, storage e rete. Questi documenti sono citati in questo report tecnico.</block>
  <block id="67bab37630accce3ea259fb1601fca2e" category="list-text">Considerazioni sulla Storage Area Network</block>
  <block id="0fe2c5f32f45114c27e3b7a7ca0ba0ad" category="list-text">Business Continuity Guida alle soluzioni tecniche</block>
  <block id="2163e1881d92ff554d8969998a7d618f" category="list-text">All-Flash - Manuale della strategia per l'architettura di riferimento</block>
  <block id="b332ca8d59cd86adb52c28aef982cc69" category="list-text">Stato dei prodotti di storage e della tecnologia</block>
  <block id="a0107bedc201b2df3694df573f65ae32" category="list-text">Considerazioni epiche sul cloud</block>
  <block id="0cf7d14c360e7f8755d749057b348718" category="list-text">Guida alla configurazione dell'hardware (specifica del cliente)</block>
  <block id="50923dab9020d1e069418763d0bd15a3" category="list-text">Consigli sul layout dello storage per il database (specifici del cliente)</block>
  <block id="4e1249f2da2104e56555dec5d4d51e6a" category="summary">Architettura EPIC a quattro nodi</block>
  <block id="7baf69c8e83ff08e0583426d011bc650" category="paragraph">Le figure qui sotto mostrano il layout dello storage per un'architettura a quattro nodi: Una coppia ha in produzione e una coppia ha in disaster recovery. La dimensione dei controller e il numero di dischi si basano su quest'ultima immagine di dimensionamento.</block>
  <block id="70ccc987c3596ca363e7b8d980858220" category="paragraph">NetApp garantisce prestazioni di livello minimo accettando le policy AQoS consigliate da SLM. EPIC supporta il consolidamento dei pool di storage su ONTAP su hardware notevolmente inferiore. Per ulteriori informazioni, consulta il documento Epic Quarterly SPATS. Fondamentalmente, i sistemi pool1, pool2 e NAS1 (elencati nella Epic hardware Configuration Guide) possono essere eseguiti su una singola coppia ha, con i carichi di lavoro distribuiti in modo uniforme sui due controller. Nelle operazioni di disaster recovery, anche il pool Epic 3 e la NAS 3 sono divisi tra i due controller nella coppia ha.</block>
  <block id="34557edb2bf88cd4f837f2384ead1830" category="paragraph">Gli ambienti di copia completa di test (come SUP, REL e PJX) sono clonati da Epic Production, Epic Report o Epic Disaster Recovery. Per informazioni su backup e refresh Epic, consulta la sezione intitolata, "Gestione dei dati".</block>
  <block id="5c8423bf649a8a50f33626549581cce9" category="section-title">Architettura a quattro nodi</block>
  <block id="f42ac2802f367c372897f3fb06218d2d" category="inline-image-macro">Architettura EPIC a 4 nodi</block>
  <block id="848f13dbd455e0190684bb8052ef94d6" category="paragraph"><block ref="848f13dbd455e0190684bb8052ef94d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b8013c3961c3eb9f2d01aff2c9d430" category="section-title">Posizionamento dei carichi di lavoro a quattro nodi</block>
  <block id="8e576f920186d1c7001b6f1da66f2359" category="inline-image-macro">Posizionamento EPIC a 4 nodi</block>
  <block id="34594b0fc43be2425a0a68f14928bc8d" category="paragraph"><block ref="34594b0fc43be2425a0a68f14928bc8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="145a177f694025424b761a3b22ca2f6b" category="summary">Architettura EPIC a sei nodi</block>
  <block id="7682e26e53b5af35c13c22f5034f788a" category="paragraph">I clienti potrebbero voler iniziare con un design a sei nodi oppure scalare in orizzontale in maniera perfetta da quattro a sei nodi in base alla crescita della domanda. Con lo scale-out è possibile spostare senza interruzioni i carichi di lavoro tra i nodi e ribilanciare nell'intero cluster.</block>
  <block id="121ec45abd57b78d2c63e13a01970fbf" category="paragraph">Questa architettura offre il miglior bilanciamento di performance e capacità nel cluster. Produzione di EPIC, Epic Report ed Epic Test vengono eseguiti tutti sulla prima coppia ha. La seconda coppia ha è utilizzata per Clarity, Hyperspace, VMware, NAS1 e i restanti workload Epic. Il disaster recovery corrisponde all'architettura a quattro nodi descritta nella sezione precedente.</block>
  <block id="628e6fdb5831f5144730fdfb620a1a2a" category="section-title">Architettura a sei nodi</block>
  <block id="5d28884b83f218379ec90c789e2e382b" category="inline-image-macro">Architettura EPIC a 6 nodi</block>
  <block id="a5cf77b4851a534d4e7f8cbfc10e7734" category="paragraph"><block ref="a5cf77b4851a534d4e7f8cbfc10e7734" category="inline-image-macro-rx" type="image"></block></block>
  <block id="214d949b6d12c893a63f49d862292640" category="section-title">Posizionamento dei carichi di lavoro a sei nodi</block>
  <block id="65ea1ebb7d9c2d858f8701fcbecd438d" category="inline-image-macro">Posizionamento EPIC a 6 nodi</block>
  <block id="77e8933cdf526d7670fcd797f57f81a7" category="paragraph"><block ref="77e8933cdf526d7670fcd797f57f81a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3ab98b5217808d71238c069623fa0ff" category="summary">Architettura EPIC a otto nodi</block>
  <block id="ab4e8eb50674d5d1bee79a6682b49325" category="paragraph">Le figure qui sotto mostrano l'architettura scale-out a otto nodi. Ancora una volta, puoi iniziare con quattro nodi e scalare fino a sei nodi e continuare con la scalabilità fino a otto nodi e oltre. Questa architettura offre il miglior equilibrio di performance e capacità sui sei nodi di produzione.</block>
  <block id="0ef10ffde0c0ebd21feabe96ec890f72" category="paragraph">Gli ambienti di test vengono clonati da Report anziché dalla produzione in questa progettazione. Questo alleggerisce il carico degli ambienti di test e dei controlli dell'integrità dalla produzione.</block>
  <block id="211891edb616b1a6e25c469a73cd07c9" category="section-title">Architettura a otto nodi</block>
  <block id="3b31cb391c5fb328f6bcf768909f68a2" category="paragraph"><block ref="3b31cb391c5fb328f6bcf768909f68a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c344a01a287e43ab2ef2793cf550435a" category="section-title">Posizionamento dei carichi di lavoro a otto nodi</block>
  <block id="80a544c0b0187e121e581e019d0902a9" category="inline-image-macro">Posizionamento EPIC a 8 nodi</block>
  <block id="e374fdf5079d6709ca8206b4c77be000" category="paragraph"><block ref="e374fdf5079d6709ca8206b4c77be000" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17e9ce8e967d60724d7f53d467470a10" category="summary">Architettura epica</block>
  <block id="b1830ae1e99adb346ce1da353cd6c089" category="paragraph">Questa sezione descrive l'ambiente software Epic e i componenti chiave che richiedono lo storage. Fornisce importanti considerazioni per guidare la progettazione dello storage.</block>
  <block id="4db273f137d059bd4ffd23818c367214" category="paragraph">EPIC, che ha sede a Verona, Wisconsin, produce software per gruppi medici, ospedali e organizzazioni sanitarie integrate di medie e grandi dimensioni. I clienti includono anche ospedali comunitari, strutture accademiche, organizzazioni per bambini, fornitori di reti di sicurezza e sistemi multi-ospedalieri. Il software integrato di livello epico comprende funzioni cliniche, di accesso e di guadagno e si estende a casa.</block>
  <block id="27cd823999704d6e14cdee1e83bef7f0" category="paragraph">Non rientra nello scopo di questo documento descrivere l'ampia gamma di funzioni supportate dal software Epic. Dal punto di vista del sistema storage, tuttavia, tutto il software Epic condivide un singolo database incentrato sul paziente per ogni implementazione. EPIC sta passando dal database InterSystems Caché al nuovo database InterSystems Iris. Poiché i requisiti di storage sono gli stessi per Caché e Iris, nel resto del documento faremo riferimento al database come Iris. Iris è disponibile per i sistemi operativi AIX e Linux.</block>
  <block id="4e25ab2bd75f003927aabf72608c3610" category="section-title">IRIS intersistemi</block>
  <block id="0af82ac784148ef3818d2fe5b04763fa" category="paragraph">InterSystems Iris è il database utilizzato dall'applicazione Epic. In questo database, il server dati è il punto di accesso per i dati memorizzati in modo permanente. Il server applicazioni gestisce le query del database ed esegue le richieste di dati al server dati. Per la maggior parte degli ambienti software Epic, l'utilizzo dell'architettura SMP (Symmetric Multiprocessor) in un unico server di database è sufficiente per soddisfare le richieste di database delle applicazioni Epic. Nelle distribuzioni di grandi dimensioni, è possibile supportare un modello distribuito utilizzando il protocollo ECP (Enterprise Caché Protocol) di InterSystems.</block>
  <block id="8dfea4e602a85bafff792b879b2d056b" category="paragraph">L'utilizzo di hardware in cluster abilitato per il failover consente a un server dati in standby di accedere allo stesso storage del server dati primario. Consente inoltre al server dati di standby di assumersi le responsabilità di elaborazione durante un guasto hardware.</block>
  <block id="c77ab217583518f1b67702b591baf929" category="paragraph">Inoltre, fornisce tecnologie in grado di soddisfare i requisiti di replica dei dati, disaster recovery e alta disponibilità (ha). La tecnologia di replica di InterSystems viene utilizzata per replicare un database Iris in modo sincrono o asincrono da un server dati primario a uno o più server dati secondari. NetApp SnapMirror viene utilizzato per replicare lo storage WebBLOB o per il backup e il disaster recovery.</block>
  <block id="df2e58f9c6f746010ccdd5cf07673500" category="paragraph">Il database Iris aggiornato presenta numerosi vantaggi:</block>
  <block id="f8ffd660138274e3b7b31f900153e4b6" category="list-text">Maggiore scalabilità e possibilità per le organizzazioni più grandi con diverse istanze Epic di consolidarsi in un'unica istanza più ampia.</block>
  <block id="242ef58734fef1421d6cc1e1154bd041" category="list-text">Un periodo di validità delle licenze in cui i clienti possono ora passare da AIX a Red Hat Enterprise Linux (RHEL) senza dover pagare una nuova licenza per la piattaforma.</block>
  <block id="08a78b85487809e2116574e4ff97dec5" category="section-title">Utilizzo dello storage e dei server del database Caché</block>
  <block id="4cc33a0396ddd5a29816a3a40d01a6b5" category="list-text">*Produzione* negli ambienti software Epic viene implementato un singolo database incentrato sul paziente. Nei requisiti hardware di Epic, il server fisico che ospita il server primario dei dati IRIS di lettura/scrittura è chiamato server di database di produzione. Questo server richiede uno storage all-flash dalle performance elevate per i file appartenenti all'istanza del database primario. Per l'alta disponibilità, Epic supporta l'utilizzo di un server di database di failover che ha accesso agli stessi file. Iris utilizza Epic Mirror per la replica nel report di sola lettura, il disaster recovery e il supporto delle copie di sola lettura. Ogni tipo di server di database può essere impostato sulla modalità di lettura/scrittura per motivi di continuità aziendale.</block>
  <block id="cdbcd4cba3ac1d1b15d302df69df1198" category="list-text">*Report* Un server di database mirror per la creazione di report fornisce l'accesso in sola lettura ai dati di produzione. Ospita un server di dati Iris configurato come mirror di backup del server di dati Iris di produzione. Il server del database di reporting ha gli stessi requisiti di capacità di archiviazione del server del database di produzione. Reporting delle performance di scrittura è lo stesso della produzione, ma le caratteristiche del carico di lavoro in lettura sono diverse e dimensionate in modo diverso.</block>
  <block id="10938a446d1d37c3afcad8aac850f514" category="list-text">*Supporta la sola lettura* questo server database è opzionale e non è mostrato nella figura seguente. È inoltre possibile implementare un server database mirror per supportare Epic supporta funzionalità di sola lettura, in cui viene fornito l'accesso a una copia di produzione in modalità di sola lettura. Questo tipo di server di database può essere impostato sulla modalità di lettura/scrittura per motivi di continuità aziendale.</block>
  <block id="32042e6794444e49e092cad346b66b28" category="list-text">*Disaster Recovery* per soddisfare gli obiettivi di business continuity e disaster recovery, un server di database mirror per il disaster recovery viene comunemente installato in un sito geograficamente separato dai server di database mirror per la produzione e/o la creazione di rapporti. Un server di database mirror per il disaster recovery ospita anche un server di dati Iris configurato come mirror di backup del server di dati Iris di produzione. Se il sito di produzione non è più disponibile per un lungo periodo di tempo, è possibile configurare questo server di database mirror per fungere da istanza di lettura/scrittura speculare (SRW). Il server del database mirror di backup ha gli stessi requisiti di archiviazione dei file del server del database di produzione. Al contrario, lo storage del database del mirroring del backup è dimensionato allo stesso modo dello storage di produzione, dal punto di vista delle prestazioni per la business continuity.</block>
  <block id="d05c7e253f48b314f8488aba0e85b3b4" category="inline-image-macro">EPIC IRIS ODB</block>
  <block id="90cb7e5b029ac3a1b754d9f0d75bfbb9" category="paragraph"><block ref="90cb7e5b029ac3a1b754d9f0d75bfbb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b101ffd23847579c0cf3cb028fc314ee" category="list-text">*Test* le organizzazioni sanitarie spesso distribuiscono ambienti di sviluppo, test e staging. Anche i server di dati IRIS aggiuntivi per questi ambienti richiedono uno storage che può essere gestito dallo stesso sistema di storage. EPIC ha requisiti e vincoli specifici per fornire storage aggiuntivo da un sistema storage condiviso. Questi requisiti specifici sono affrontati genericamente dalle Best practice contenute in questo documento.</block>
  <block id="5c52f2993ead7ce33b4600c9955d9657" category="paragraph">Oltre ai server di dati ODB Iris, gli ambienti software Epic includono in genere altri componenti, come quelli seguenti e come mostrato nella figura seguente:</block>
  <block id="c352fde153a95627d87a161b60e9e211" category="list-text">Un server di database Oracle o Microsoft SQL Server come back-end degli strumenti di reporting aziendale di Epic Clarity</block>
  <block id="72e364f0316ce75144d3bcbc76627977" category="admonition">Clarity viene utilizzato per generare rapporti sui dati estratti giornalmente dal database Iris di reporting.</block>
  <block id="9c7d7e54119a875f7f730fac34d86939" category="list-text">Server WebBLOB (SMB)</block>
  <block id="7f140c68d528349ef23a9adde829618a" category="list-text">Server database multifunzione</block>
  <block id="db670b036ce103ccc68fe4a2f746bcbb" category="list-text">Macchine virtuali polivalenti (VM)</block>
  <block id="46f49acf82ce78d08668061bb78e679a" category="list-text">Spazio ipertestuale per accesso client</block>
  <block id="847ce339c80d3a544fdd1e3ea23f89ed" category="inline-image-macro">Database EPIC</block>
  <block id="ddc0ff60fb0cba83974547cb2fd7a40e" category="paragraph"><block ref="ddc0ff60fb0cba83974547cb2fd7a40e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="300c335aaf3a97bb6020a19be0b8ca96" category="paragraph">I requisiti di storage di tutti questi workload, pool, protocolli NAS e SAN multipli possono essere consolidati e ospitati da un singolo cluster ONTAP. Questo consolidamento consente alle organizzazioni del settore sanitario di disporre di una singola strategia di gestione dei dati per tutti i workload Epic e non Epic.</block>
  <block id="4a7de8a55a290fb3a0a4efd490ec781b" category="section-title">Carichi di lavoro del database operativi</block>
  <block id="a627911d38337b81dddab9711a61842c" category="paragraph">Ogni server di database Epic esegue l'i/o sui seguenti tipi di file:</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="list-text">File di database</block>
  <block id="07599d3aee2c26c36cae1cb305a0d120" category="list-text">File journal</block>
  <block id="b9c807a9cbbe80f3b710d64a47334ecf" category="list-text">File dell'applicazione</block>
  <block id="4b11d0da3422be079767b9c81ea967cb" category="paragraph">Il carico di lavoro di un singolo server di database dipende dal suo ruolo nell'ambiente software Epic. Ad esempio, i file di database di produzione sono in genere interessati ai carichi di lavoro più impegnativi, costituiti al 100% da richieste i/o casuali. Il carico di lavoro di qualsiasi database mirror è generalmente meno impegnativo e presenta meno richieste di lettura. I carichi di lavoro dei file di giornale sono principalmente sequenziali.</block>
  <block id="6908d08a516bc86d102ccafa6c2ece9d" category="paragraph">EPIC mantiene un modello di carico di lavoro per il benchmark delle performance dello storage e i carichi di lavoro del cliente. Per ulteriori informazioni sul modello di workload Epic, sui risultati dei benchmark e sulle linee guida sull'utilizzo dei tool di dimensionamento NetApp per dimensionare correttamente lo storage per gli ambienti Epic, consulta<block ref="81c36a9e6d224e9d42c9630dffaa9434" category="inline-link-rx"></block> (è richiesto l'accesso NetApp).</block>
  <block id="f71d6b15e61746171efc106f495b60cd" category="paragraph">EPIC offre inoltre a ciascun cliente una guida alla configurazione dell'hardware customizzata che contiene le proiezioni di i/o e i requisiti della capacità dello storage. I requisiti di storage finali possono includere ambienti di sviluppo, test e/o staging, nonché tutti gli altri carichi di lavoro secondari che potrebbero essere consolidati. I clienti possono utilizzare la guida alla configurazione hardware per comunicare a NetApp i requisiti totali di storage. Questa guida contiene tutti i dati necessari per dimensionare un'implementazione Epic.</block>
  <block id="c7a0b1a5f7a146b9b72947b2bba045ed" category="paragraph">Durante la fase di implementazione, Epic mette a disposizione una Database Storage Layout Guide, che fornisce dettagli più granulari a livello di LUN, da utilizzare per una progettazione dello storage avanzata. Tenere presente che la Guida al layout dello storage del database è una soluzione di archiviazione generica e non specifica per NetApp. Utilizza questa guida per determinare il miglior layout di storage su NetApp.</block>
  <block id="ab3b24e1e2a3f9784a9c6cad8db20a76" category="summary">Dimensioni epiche</block>
  <block id="706a0ec5dbae849750639964dc6b852f" category="paragraph">Una delle principali considerazioni sull'architettura per il dimensionamento di un ambiente storage Epic è la dimensione del database ODB.</block>
  <block id="abe227b9b306ed7c0527800b44a2f1d0" category="paragraph">È possibile selezionare un'architettura storage Epic di piccole-medie-grandi dimensioni seguendo il diagramma riportato di seguito. Questi progetti includono l'esecuzione di tutti i carichi di lavoro elencati nella Guida alla configurazione dell'hardware. L'albero di dimensionamento si basa sui dati di oltre 100 guide alla configurazione hardware e dovrebbe essere una stima accurata.</block>
  <block id="be0322041cc582d91f5f470df1ef2ba4" category="paragraph">È importante notare che si tratta solo di un punto di partenza. Devi collaborare con il nostro Alliance team Epic per confermare eventuali design Epic. Il team può essere raggiunto a EPIC@NetApp.com. Ogni implementazione deve soddisfare le richieste dei clienti, rispettando al contempo le Best practice consigliate da Epic e NetApp.</block>
  <block id="20e8e833e31ffb5776ac701658144bd3" category="list-text">Piccola architettura Epic con un database Epic inferiore a 10TB</block>
  <block id="5d8ee21ec144a04a8287c0171b9a8527" category="list-text">Architettura Epic media con un database Epic dal 10TB al 50TB</block>
  <block id="79ac7005a81d3ad4f64a1a5f5db00c7e" category="list-text">Architettura Epic di grandi dimensioni con un database Epic da oltre 50TB TB</block>
  <block id="650c96055e8747d8b8a4c503b32aea8d" category="inline-image-macro">EPIC guide sul dimensionamento</block>
  <block id="1c2004236bc67ea5f8fcc53a967ce698" category="paragraph"><block ref="1c2004236bc67ea5f8fcc53a967ce698" category="inline-image-macro-rx" type="image"></block></block>
  <block id="431d999c23fb9c149586aa971425928e" category="summary">Requisiti di storage EPIC</block>
  <block id="8afb3f2b206e0239313a484fe51999d7" category="paragraph">Vengono generalmente fornite risorse di storage dedicate per il database di produzione, mentre le istanze dei database mirrorati condividono risorse di storage secondarie con altri componenti software Epic, come i tool di reporting Clarity.</block>
  <block id="d31081e8762bd0903adf5d3f0b769e73" category="paragraph">Altre risorse di storage di software, ad esempio quelle utilizzate per file di sistema e applicazioni, vengono fornite anche dalle risorse di storage secondario.</block>
  <block id="ed879cdc9a77683dfbe5be59441dec43" category="paragraph">Oltre alle considerazioni sul dimensionamento, Epic prevede le seguenti regole aggiuntive sul layout dello storage e considerazioni chiave:</block>
  <block id="ba76cf08b10101b5fee8e2e6d0da268e" category="list-text">A partire dal 2020, tutti i carichi di lavoro del database operativo (ODB) devono trovarsi su array all-flash.</block>
  <block id="542f0f7c69fde2bd55b5a36854a84fa3" category="list-text">EPIC consiglia di collocare ciascun pool di storage su hardware fisico separato, inclusi pool1, pool2, pool3, NAS1 ed NAS2.</block>
  <block id="919d67cad73121e6af0b2b20169d947b" category="admonition">Un nodo in un cluster può essere considerato come un pool di storage. Con ONTAP 9.4 o versioni successive e AQoS, è possibile creare pool protetti utilizzando criteri.</block>
  <block id="4449a7b5d2b5dfb4b1bad2ed2f86b5fd" category="list-text">Nuovi suggerimenti per il backup su Epic 3-2-1.</block>
  <block id="b560499317ab0447790f01d7acd5401b" category="list-text">Copia situata nel sito remoto (disaster recovery)</block>
  <block id="09d6c5f51239ea513e80e433549993f4" category="list-text">Una delle copie deve trovarsi su una piattaforma di storage diversa rispetto alla copia primaria</block>
  <block id="df5be706f042b26557014aa77c608eb6" category="list-text">Copie dei dati</block>
  <block id="47311b53e9ae798223e097c4249a0668" category="admonition">I clienti che utilizzano NetApp SnapMirror per eseguire il backup di NetApp non soddisfano i consigli 3-2-1-5. Il motivo è che ONTAP to ONTAP non soddisfa il secondo requisito sopra elencato. Puoi utilizzare SnapMirror direttamente da ONTAP per lo storage a oggetti on-premise (ad esempio tramite StorageGRID) o nel cloud per soddisfare i requisiti Epic.</block>
  <block id="fef74abf89ce7520dbdabb6ae983ee4b" category="paragraph">Per ulteriori informazioni sugli obblighi di storage, consultare le seguenti guide Epic disponibili in Galaxy:</block>
  <block id="bed1a6db332388739ca169835c6c3425" category="list-text">Considerazioni sulla SAN</block>
  <block id="9080906c2106e0567c91717cc003d027" category="list-text">Stato dei prodotti di storage e della tecnologia (SPATS)</block>
  <block id="81b560a1124b6edc7fe2858e332661b6" category="list-text">Guida alla configurazione dell'hardware</block>
  <block id="db11e37a9250a9db4d48618851771913" category="summary">Configurazione delle istantanee dello storage EPIC</block>
  <block id="4cbb03cae0c07fb5c8e5d5e6df97064e" category="doc">Configurazione straordinaria dell'efficienza dello storage</block>
  <block id="bc9c71d0bf41f8b2c8bde032eb1d97d0" category="paragraph">Le applicazioni con storage distribuito su più di un volume con una o più LUN di quantità appropriate per il carico di lavoro richiedono un backup dei contenuti, garantendo una protezione dei dati coerente.</block>
  <block id="d43039551f875a24f15f154306be2586" category="paragraph">I gruppi di coerenza (in breve CGS) offrono queste funzionalità e molto altro ancora. Possono essere utilizzate di notte per creare snapshot coerenti on-demand o pianificate utilizzando una policy. Tutto questo è utile per ripristinare, clonare e persino replicare i dati.</block>
  <block id="cbe00f2bdd9a3c8aaaf5f8159a8750c1" category="paragraph">Per ulteriori informazioni sul CGS, fare riferimento alla <block ref="acc09d7e0c59ae3310cafae5d547383a" category="inline-link-macro-rx"></block></block>
  <block id="e62f16b222adc7aecc70ff7b56e652dc" category="paragraph">Una volta eseguito il provisioning di volumi e LUN come descritto nelle precedenti sezioni di questo documento, è possibile configurarli in un set di CGS. La procedura consigliata consiste nel configurarli come illustrato nella figura seguente:</block>
  <block id="7dd784e39903a42471f96a6d0d6ae420" category="inline-image-macro">Layout del gruppo di coerenza EPIC</block>
  <block id="909e3795441b963b86fcad387196919f" category="paragraph"><block ref="909e3795441b963b86fcad387196919f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45dbe5c870e6de731da235aab8c51046" category="paragraph">È necessario impostare una pianificazione degli snapshot del CG notturno su ciascuno dei CGS figlio associati ai volumi che forniscono spazio di archiviazione per il database di produzione. Ciò comporterà una nuova serie di backup coerenti di questi CGS ogni notte. Questi possono essere utilizzati per il cloning del database di produzione per l'utilizzo in ambienti non di produzione, come test e sviluppo. NetApp ha sviluppato workflow Ansible automatizzati basati su CG proprietari per Epic per automatizzare il backup dei database di produzione, il refresh e gli ambienti di test.</block>
  <block id="a93362f9de0aff40adccba50a939a6fa" category="paragraph">Gli snapshot CG possono essere utilizzati per supportare le operazioni di ripristino del database in produzione di Epic.</block>
  <block id="4bf6f09e67952b918985533c270b0668" category="paragraph">Per i volumi SAN, disattiva la policy di snapshot predefinita su ciascun volume utilizzato per CGS. Questi snapshot sono generalmente gestiti dall'applicazione di backup in uso o dal servizio di automazione Ansible Epic di NetApp.</block>
  <block id="7082753514151e011ff039e6fe23eba2" category="paragraph">Per volumi SAN, disattivare la policy di snapshot predefinita su ogni volume. Questi snapshot vengono in genere gestiti da un'applicazione di backup o dall'automazione Epic Ansible.[NS2]</block>
  <block id="669d2da75a76d767cc8259b5f37cacc3" category="paragraph">I set di dati WebBLOB e VMware devono essere configurati come soli volumi, non associati a CGS. Puoi utilizzare SnapMirror per mantenere le snapshot su sistemi storage separati dalla produzione.</block>
  <block id="5a6fb6753e1c4f748d223c8e329133fb" category="paragraph">Al termine, la configurazione sarà la seguente:</block>
  <block id="926ce6c3b85cb26b415b6fc7e43f2879" category="inline-image-macro">EPIC con snapshot CG</block>
  <block id="a578d209aa95904cf62330de918a003d" category="paragraph"><block ref="a578d209aa95904cf62330de918a003d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193e03aa51a18f1e5d72b6a9dd240ed7" category="paragraph">Le efficienze inline di ONTAP sono attive per impostazione predefinita e funzionano indipendentemente dal protocollo storage, dall'applicazione o dal Tier storage.</block>
  <block id="f900dc6292f9bf9dcf98291ad5846d4b" category="paragraph">L'efficienza riduce la quantità di dati scritti sul costoso storage flash e limita il numero di dischi richiesti. ONTAP preserva l'efficienza con la replica. Ognuna di queste efficienze ha poco o nessun effetto sulle performance, anche per un'applicazione sensibile alla latenza come Epic.</block>
  <block id="936d07f32ce5afcd55e98c4a8cbce642" category="paragraph">*NetApp consiglia* di attivare tutte le impostazioni di efficienza per ottimizzare l'utilizzo del disco. Queste impostazioni sono attivate per impostazione predefinita nei sistemi basati su AFF e ASA.</block>
  <block id="d4a551eeebb2992a4ffff1ad1083479a" category="paragraph">Le seguenti caratteristiche rendono possibile questa efficienza dello storage:</block>
  <block id="cc0df1dcdfa0541f9c5dde8e0b570a36" category="list-text">La deduplica consente di risparmiare spazio sullo storage primario rimuovendo copie ridondanti dei blocchi di un volume che ospita le LUN. Questa opzione consigliata è attivata per impostazione predefinita.</block>
  <block id="db37fd6533f852997b6ae076ae5e86e0" category="list-text">La compressione inline riduce la quantità di dati da scrivere su disco e con i workload Epic vengono realizzati considerevoli risparmi di spazio. Questa opzione consigliata è attivata per impostazione predefinita.</block>
  <block id="c8afff3d362092825c7eda5b0b6b39af" category="list-text">La inline compaction impiega blocchi da 4K KB e li combina in un singolo blocco. Questa opzione consigliata è attivata per impostazione predefinita.</block>
  <block id="b158d6ac5a43e19d1be67d7ba849494d" category="list-text">La replica con risorse limitate è al centro del portfolio di software per la protezione dei dati di NetApp, che include il software NetApp SnapMirror. La thin Replication SnapMirror protegge i dati business-critical riducendo i requisiti di capacità dello storage. *NetApp consiglia* di attivare questa opzione.</block>
  <block id="13fb0a52e16b7b3839f151b0847cd0d1" category="list-text">Deduplica aggregata. La deduplica è sempre stata a livello di volume. Con ONTAP 9.2, è stata resa disponibile la deduplica aggregata, che offre ulteriori risparmi in termini di riduzione dei dischi. La deduplica dell'aggregato post-processo è stata aggiunta con ONTAP 9.3. *NetApp consiglia* di attivare questa opzione.</block>
  <block id="46269eefafcbb08ab4667022c6491767" category="summary">Protocolli EPIC e file</block>
  <block id="73a17ad0a24141989f242b5b099eec4f" category="paragraph">È supportata la combinazione di NAS e SAN sullo stesso array all-flash.</block>
  <block id="688ffca27fb85bfb71c8a7632a871ec1" category="paragraph">*NetApp consiglia* l'utilizzo di volumi FlexGroup per condivisioni NAS, ad esempio WebBLOB (se disponibile).</block>
  <block id="55449fd175613962d882ab450cfc5f3c" category="inline-link-macro">FabricPool</block>
  <block id="1cd6516d7f54730b868069e2db63b528" category="paragraph">WebBLOB offre fino al 95% di dati cold. Puoi facoltativamente liberare spazio sul tuo array all-flash e sfruttare il tiering dei backup e dei dati cold nello storage a oggetti on-premise o nel cloud utilizzando la <block ref="e722be9b80fb0aa9c356c4300710e630" category="inline-link-macro-rx"></block> funzionalità di ONTAP. Tutto ciò può essere realizzato senza alcun effetto significativo sulle prestazioni. FabricPool è una funzione inclusa in ONTAP. I clienti possono generare un report di dati cold (o inattivi) per esaminare quanti benefici possono essere realizzati abilitando FabricPool. Puoi impostare l'età dei dati da Tier tramite le policy. I clienti EPIC hanno ottenuto risparmi significativi grazie a questa funzionalità.</block>
  <block id="fc3145f7fe85a0cdfffb31f4034ada3b" category="summary">EPIC su ONTAP - Utilità host</block>
  <block id="f2f8d65f0baeae6d15c1016784ddadbf" category="paragraph">Le utilità host NetApp sono pacchetti software per vari sistemi operativi che contengono utility di gestione come il<block ref="3a8e4afa851609127d534b04e7d29c08" prefix=" " category="inline-code"></block> binario CLI, i driver multipath e altri file importanti necessari per le operazioni SAN corrette.</block>
  <block id="23cfb87b0ff3960aab8099cbbb63b50b" category="inline-link-macro">Host SAN</block>
  <block id="b0a8af1d81527bdd65ec0e8fb2a4b4e0" category="paragraph">*NetApp consiglia* di installare le utilità host NetApp sugli host connessi ai sistemi di archiviazione NetApp e che accedono ad essi. Per ulteriori informazioni, vedere <block ref="b2445b429f9784426e3dc1158e67c70d" category="inline-link-macro-rx"></block> e <block ref="7d7a0f71ed9bf2fe94a10fa9e1aeb381" category="inline-link-macro-rx"></block> la documentazione.</block>
  <block id="54ed29e411552372c5b6b9e2e1617e6d" category="admonition">Con AIX, è particolarmente importante che le utilità host siano installate prima di rilevare i LUN. In questo modo si garantisce che il comportamento del multipathing LUN sia configurato correttamente. Se il rilevamento è stato eseguito senza le utilità host, è necessario deconfigurare i LUN dal sistema utilizzando il<block ref="9442434081221d63eaaa2c4799062866" prefix=" " category="inline-code"></block> comando e quindi eseguire nuovamente il rilevamento tramite<block ref="fe54d1c30028417038a4ffe0fc5eb503" prefix=" " category="inline-code"></block> o un riavvio.</block>
  <block id="e7a8be60cff2fec7b8ed793c4d2dddfe" category="summary">Configurazione EPIC di LUN e volume</block>
  <block id="acdbb325faec5e3e2d86b3dbbaf90c54" category="paragraph">Il documento Epic Database Storage Layout Recommendations fornisce indicazioni sulle dimensioni e sul numero di LUN per ogni database.</block>
  <block id="a620ecf0a73eb209a145eb913a29bc5a" category="paragraph">È importante rivedere questo documento con il supporto degli Epic DBA e Epic così come finalizzare il numero di LUN e le dimensioni delle LUN che potrebbero essere necessarie una modifica. Questi consigli relativi allo storage sono importanti in termini di profondità della coda degli HBA, prestazioni dello storage, facilità di funzionamento e facilità di espansione.</block>
  <block id="21ebeea1f14a138dfebb1b9599a4c3dd" category="paragraph">Per massimizzare le performance di un carico di lavoro, ad esempio Epic ODB o Clarity, ogni layout funziona al meglio anche per lo storage NetApp. Utilizzando otto volumi, l'io in scrittura viene distribuito in modo uniforme tra i controller, massimizzando l'utilizzo della CPU. Per la replica e il backup, è consigliabile limitare il numero di volumi a otto per semplificare le operazioni.</block>
  <block id="90adf331b7868c7af46ad6e035e93844" category="section-title">Opzioni di scalabilità</block>
  <block id="b323bb297a66afc2eea7b89dd4019798" category="section-title">Volume e layout di 8 LUN</block>
  <block id="66d125e77a6185ef5cf43b2a6bffea80" category="inline-image-macro">Layout EPIC a 8 LUN</block>
  <block id="99a54ac1eaa5bd57b4c4c29d6a63f1ac" category="paragraph"><block ref="99a54ac1eaa5bd57b4c4c29d6a63f1ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad4d79343f04d8b64999875ad328086" category="list-text">Bilancia i carichi di lavoro nella coppia ha per massimizzare performance ed efficienza.</block>
  <block id="26b591a32a8a235db7f742995589a455" category="list-text">USA volumi e LUN con thin provisioning.</block>
  <block id="9fb0aaeb125238e83485971ae6b7e2fc" category="list-text">Utilizzare un minimo di otto LUN del database, due LUN di journal e due LUN delle applicazioni. Questa configurazione massimizza le prestazioni dello storage e la profondità della coda del sistema operativo. Se necessario, è possibile utilizzarne di più per motivi di capacità o di altro tipo.</block>
  <block id="ba5e00554d1ba1b8ca0fc2eaeda44672" category="list-text">Se non è necessario aggiungere LUN ai gruppi di volumi, aggiungere otto LUN alla volta.</block>
  <block id="08c8ec6a9fefcf9c5c7dff1258aacf67" category="list-text">I gruppi di coerenza (CGS) sono necessari per il gruppo di volumi e LUN di cui eseguire il backup insieme.</block>
  <block id="f513b81222a1b44f552ae172aeb697c9" category="list-text">Non utilizzare la QoS durante Genio o le prestazioni i/O.</block>
  <block id="b77a34499937c829a2c5c5a1cdc17f05" category="list-text">Dopo il test genio o Clarity, NetApp consiglia di eliminare lo storage e di eseguire nuovamente il provisioning prima di caricare i dati di produzione.</block>
  <block id="186bc47646aec5e2abf40b2605a16461" category="list-text">È importante che<block ref="54645d7349dcc4fe9d7d19985a40c2c9" prefix=" " category="inline-code"></block> l'opzione abilitato sia impostata sui LUN. In caso contrario, i dati eliminati sulle LUN non verranno rilevati da ONTAP e potrebbero causare problemi di capacità. Per ulteriori informazioni, consulta la Epic Storage Configuration Quick Reference Guide.</block>
  <block id="153c47e1653d87804319da1fe347f29b" category="summary">Gestione epica delle performance</block>
  <block id="912975539030067a6f1874223cda9b75" category="paragraph">La maggior parte degli array all-flash offre le performance richieste per i workload Epic. Il fattore di differenziazione di NetApp è la sua capacità di impostare policy sulle performance a livello minimo e garantire performance coerenti per ogni applicazione.</block>
  <block id="edfc4c86589e31546a8fb2d8b085b8c9" category="section-title">Qualità del servizio (QoS)</block>
  <block id="8080e6f80ff76b571829265ee2917e87" category="paragraph">NetApp consiglia di utilizzare la qualità del servizio. Il beneficio della qualità del servizio è la capacità di consolidare tutti i workload Epic. Tutti i protocolli e i pool di storage possono risiedere su meno hardware. Non hai bisogno di separare pool di storage.</block>
  <block id="44c2f7cd7c41efaae67916780bf96079" category="list-text">NetApp consiglia di assegnare tutti i workload nel cluster a una policy di qualità del servizio per una migliore gestione dello spazio nel cluster.</block>
  <block id="d90d7fd828646173964451dadbe758c1" category="list-text">NetApp consiglia di eseguire un bilanciamento uniforme dei workload nella coppia ha.</block>
  <block id="a77412a540f86bfc443abfcef22db414" category="list-text">Non utilizzare i criteri QoS durante l'esecuzione di test di i/o; in caso contrario, il test Genio non riuscirà. Analizza i diversi workload di produzione per 2-4 settimane prima di assegnare qualsiasi policy QoS.</block>
  <block id="c36c006dced61f1e460ff43516fa7294" category="summary">EPIC su ONTAP - protocolli</block>
  <block id="0f079f7da3a6e5c8a52a3aca113fd3e6" category="paragraph">FCP è il protocollo preferito per la presentazione dei LUN.</block>
  <block id="97ec588f063ba0f25df2b93eda2639c8" category="paragraph">*NetApp Recommended* Single Initiator zoning: Un iniziatore per zona con tutte le porte di destinazione richieste sullo storage utilizzando nomi di porte internazionali (WWPN). La presenza di più di un iniziatore in una singola zona può causare un crosstalk intermittente dell'HBA, che causa un'interruzione significativa.</block>
  <block id="880bc24c60e1d6eb559f57440c27f955" category="paragraph">Dopo aver creato il LUN, associare il LUN al gruppo iniziatore (igroup) contenente i WWPN dell'host per abilitare l'accesso.</block>
  <block id="d8609b6e37acaad082fff919da3c6691" category="paragraph">NetApp supporta anche l'utilizzo di NVMe/FC (se disponi di versioni dei sistemi operativi AIX e RHEL che sono capaci) e migliora le performance. FCP e NVMe/FC possono coesistere sullo stesso fabric.</block>
  <block id="2586e87005565fe66fa19a3af50f632c" category="summary">Dimensionamento dello storage per Epic</block>
  <block id="5e3e8694114d62a133f86c691b0d1d68" category="paragraph">Devi collaborare con il nostro Alliance team Epic per confermare eventuali design Epic. Il team può essere raggiunto a EPIC@NetApp.com. Ogni implementazione deve soddisfare le richieste dei clienti, rispettando al contempo le Best practice consigliate da Epic e NetApp.</block>
  <block id="c77c62342c6d144df81571fee8e8a4e8" category="paragraph">Per informazioni su come utilizzare i tool di dimensionamento NetApp per determinare le dimensioni e il numero corretti dei gruppi RAID per le esigenze di storage dell'ambiente software Epic, consulta <block ref="b6ff45309a811037a92ca1e6262c74a8" category="inline-link-macro-rx"></block> (è richiesto l'accesso a NetApp).</block>
  <block id="6fff8a4d9dc5db1aefc3e3a86c26dbd7" category="admonition">È richiesto l'accesso al Field Portal di NetApp.</block>
  <block id="1484157a851d4053990c9bf55fb59e58" category="summary">Esempio di implementazione EPIC su ONTAP: Aggregati</block>
  <block id="e8f3d574ecc3fdf160285a0c9a5a7046" category="paragraph">Per la documentazione più recente sugli aggregati di provisioning, fare clic su <block ref="a20b867e80db6cfd4fb8336d84c1fcc5" category="inline-link-macro-rx"></block>.</block>
  <block id="f2871c08962452bb98a23ee83880a7dd" category="admonition">Le impostazioni predefinite ottimizzano prestazioni e capacità. Viene creato un unico aggregato di grandi dimensioni per nodo.</block>
  <block id="46b67d0e3c5baea52f318c392862983a" category="summary">EPIC su ONTAP esempio di distribuzione - filesystem</block>
  <block id="ff902a0a262960f8bf9189923c1ff7d9" category="paragraph">Per informazioni su come montare i LUN, creare gruppi di volumi e volumi logici e configurare i file system, consulta la Epic Storage Configuration Quick Reference Guide. Utilizzare i seguenti comandi di esempio per configurare i server di produzione Epic per RHEL.</block>
  <block id="f54e4ad7066826fa3c18dcb8a62ddd03" category="section-title">File system e opzioni di montaggio</block>
  <block id="ca487f2e3d336dbbead8ef7ce6f1dc6c" category="paragraph">Una volta creati e mappati i LUN e completata la suddivisione in zone, attenersi alla seguente procedura per collegare lo storage al server.</block>
  <block id="232aac42537fa2491071068a6dacfe10" category="admonition">In questo esempio abbiamo utilizzato 8x 1024Gb LUN per il database, 2x 1024Gb LUN per i diari e 2x 1024Gb LUN per le installazioni delle applicazioni.</block>
  <block id="cdf658da371089bb06d8dc79b4ae2e2e" category="section-title">I/o asincrono</block>
  <block id="86c5811d8dc490e1467aed33484d89f2" category="paragraph">Una copia del white paper Epic SAN Considerations e del documento di riferimento rapido sulla configurazione dello storage fornisce dettagli su come configurare gli host e connettersi allo storage. In questa sezione viene descritto come configurare un host Red Hat Enterprise Linux. I dettagli di AIX sono disponibili nei documenti referenziati.</block>
  <block id="81cba0a3715b5297330ade2beaa9dc7d" category="summary">Esempio di implementazione EPIC su ONTAP - LUN</block>
  <block id="30baf86157b500051493cda4ff1be0c3" category="paragraph">&gt;&gt;&gt; segnaposto per la frase descrittiva o paragrafo</block>
  <block id="6aa18085c59b7b34360d5dff15bf6e84" category="paragraph">Creare il LUN</block>
  <block id="6a761ce5c1cf1122b1aaea2aec3cfc85" category="paragraph">Per creare un LUN:<block ref="18244093c882fe4e65acdec6d61f9f95" category="inline-link-rx"></block></block>
  <block id="8ede5bcd129cb7b52add8d233c5e5867" category="paragraph">Aggiungere volumi a CG</block>
  <block id="4bd3faeb169131a1ecbf00026f146a6f" category="paragraph">Per creare o modificare i gruppi di coerenza:<block ref="52ad8c1ba289849e0c6ebe85b916c91a" category="inline-link-rx"></block></block>
  <block id="1093fcc785c9f0e59ff32142b73ff3a5" category="paragraph">LUN della mappa</block>
  <block id="9e5dabcfb97ff08290166a6dd001c95e" category="paragraph">Per mappare il LUN:<block ref="8b5a6c46b302a4299b28e891d262657f" category="inline-link-rx"></block></block>
  <block id="73a228bbb9b14b5f966f329a201b115d" category="paragraph">A seconda della versione di ONTAP, l'impostazione predefinita per Riserva frazionaria sul volume può essere 100%. Questa configurazione deve essere impostata su 0.</block>
  <block id="b13aace07f0445cf1ff16be054bcc01e" category="summary">Esempio di implementazione EPIC su ONTAP</block>
  <block id="cca1d6e8ff542fcd4d1315f7f9033467" category="paragraph">Questa sezione illustra una configurazione avanzata completa di un cluster ONTAP, un provisioning e una presentazione dello storage su un server Epic.</block>
  <block id="df8f0aad2b90e887efba35ecbc7e6546" category="paragraph">Allo scopo di acquisire i dettagli e per semplificare la documentazione, viene utilizzata la riga di comando. Se si preferisce la GUI, è possibile eseguire il provisioning di tutte le impostazioni in System Manager.</block>
  <block id="d706ffe8745cb55ce7b7d1c7dfa458dd" category="paragraph">Storicamente, la configurazione iniziale in blocco per progetti di grandi dimensioni è in genere più veloce utilizzando i comandi elencati nella Tabella 1, soprattutto se si concatenano i comandi in un foglio di lavoro. Questo elenco di comandi serve anche come eccellente documentazione di compilazione.</block>
  <block id="12c8172fde8f9b3f81c3ed0d2805f3d4" category="paragraph">Un'altra opzione di provisioning utilizza gli script di automazione del giorno 0 e del giorno 1 utilizzando Ansible. NetApp mette a disposizione per il download centinaia di playbook Ansible, tra cui la raccolta Ansible Galaxy tramite il comando di installazione NetApp.ONTAP della raccolta ansible-Galaxy.</block>
  <block id="80455b40cdd7b477184d76f23f747af1" category="paragraph">Inoltre, la GUI funziona benissimo con un semplice LUN a una pagina e provisioning condiviso. La GUI è ideale per le operazioni di aggiunta, modifica o eliminazione dello storage. Entrambe le opzioni sono valide se si applicano le impostazioni di archiviazione di Best practice riportate nella Tabella 1.</block>
  <block id="d7441f24bee2c1922760ce27f5e978ec" category="paragraph">L'installazione completa del cluster e il provisioning dello storage/host non devono richiedere più di un'ora durante lo staging.</block>
  <block id="3924c8a2656c72cc0c7d6a27f9ad08ea" category="paragraph">*Procedure consigliate per le impostazioni di archiviazione*</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Impostazione</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valore</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregato</block>
  <block id="ae6bd8a277455ba774ffc217a2f8a539" category="cell">Provisioning automatico predefinito, un aggregato ADP per nodo con RAID DEP</block>
  <block id="63555da25f96be027cd722d9f281cffa" category="cell">Due SVM quando si utilizza multiprocol (SVM a blocchi e SMB/NFS). Utilizza Epic e la convenzione di naming dei protocolli. Utilizzare uno stile di sicurezza appropriato</block>
  <block id="aec0819ab194aee8aab8a5e40aad8343" category="cell">Garanzia di spazio per volumi</block>
  <block id="334c4a4c42fdb79d7ebc3e73b517e6f8" category="cell">nessuno</block>
  <block id="d374cbba7f603e6be8e6450a6b3feb45" category="cell">Policy di snapshot dei volumi</block>
  <block id="8285885018fdba6d87edc774237f0e24" category="cell">Dimensionamento automatico del volume</block>
  <block id="4d200fce73a8e1cc965cfc2c43343824" category="cell">crescere</block>
  <block id="948111f101cd4e13c4a1e21775e9742d" category="cell">Dimensionamento automatico volume max</block>
  <block id="fde7826aacd46b7610beed2b0ef8d81e" category="cell">2T o 2 LUN</block>
  <block id="ca714a7089246aff7f85bbda97ba660b" category="cell">Eliminazione automatica dello snapshot di un volume</block>
  <block id="a10311459433adf322f2590a4987c423" category="cell">attivato</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Dimensione del volume</block>
  <block id="9bba382221ce257d09f3f50492803815" category="cell">1,5 x LUN</block>
  <block id="dc85eb20ed6dd71700df76a7f9acd32b" category="cell">Layout del volume</block>
  <block id="370e47099244ee43c575d91449bb7e36" category="cell">Distribuito anche tra i controller</block>
  <block id="ca301c828c76b7b6b1a9b621ba37f603" category="cell">tipo igroup</block>
  <block id="d6c56de514a4a8fe23f54d6b42dd23af" category="cell">Sistema operativo se utilizzato con server fisici, tipo VMware se utilizzato con ESX.</block>
  <block id="bbd68bf55ab562da30e73449f1b87424" category="summary">Esempio di implementazione EPIC su ONTAP - protocolli</block>
  <block id="589b83bd3c7696acc0086c7f233e64e3" category="doc">Esempio di implementazione EPIC su ONTAP: Piattaforme</block>
  <block id="05f72896244a448167caa4a410eb4ecf" category="paragraph">Per i database Epic ODB, i carichi di lavoro di journal e applicativi, Epic consiglia di presentare lo storage ai server come LUN FCP.</block>
  <block id="d2ec366dff0b7a3eda35e6acf91f6898" category="paragraph">I clienti NetApp hanno eseguito con successo tutti i workload Epic nel cloud Azure. AWS è anche in grado di eseguire workload Epic. Grazie a NetApp Cloud Volumes ONTAP e NetApp Cloud Volumes Services, NetApp offre le funzionalità Enterprise e le performance richieste per eseguire Epic in modo efficace nel cloud. Le opzioni cloud di NetApp offrono blocchi su iSCSI e file su NFS o SMB.</block>
  <block id="a3a5d01a736b2f5bc994d2ff7b0da8c5" category="summary">Esempio di implementazione EPIC su ONTAP - protocollo FCP</block>
  <block id="dc0e595680f18844673c0930ecf1ca6b" category="paragraph">Una volta creata la SVM, è necessario aggiungervi dei protocolli.</block>
  <block id="263a628397d3f78e3b61f40863b0868f" category="paragraph">Per creare LIF dati FCP, fare clic su <block ref="8f46d074b2d46f416cb36dce6f8bd76d" category="inline-link-macro-rx"></block>.</block>
  <block id="663c2decd75c93fbad53179b6016c0d1" category="paragraph">I gruppi iniziatori vengono utilizzati per consentire l'accesso del server ai LUN. Per creare un iGroup, fare clic su <block ref="c6345eebd77187b1723cf47095ffbd0f" category="inline-link-macro-rx"></block>.</block>
  <block id="93f7209bec244568b95ac2f8f50896d7" category="summary">Esempio di implementazione EPIC su ONTAP: SVM</block>
  <block id="39ce7fcbb7e39843ad7e81e460901359" category="paragraph">NetApp virtualizza lo storage e l'accesso utente è fornito dalla SVM.</block>
  <block id="8c22ab38f47a2a116e19714defb5f005" category="paragraph">Per Epic, utilizziamo una SVM FCP e una SVM SMB. In base a come si desidera gestire lo storage ed eventualmente la multi-tenancy, è possibile utilizzare più SVM.</block>
  <block id="99889a411324e95bb7313521d10d972b" category="paragraph">Per configurare una SVM, fare clic su <block ref="cb8e547e3f29ee63864aeed75c724bf1" category="inline-link-macro-rx"></block></block>
  <block id="abf025601df70d9ba931fe67b1cc4a79" category="summary">EPIC su ONTAP esempio di implementazione: Volumi</block>
  <block id="02594c71ca915876e2512e474d8b462d" category="paragraph">Per creare volumi, vedere<block ref="b6546da834bc505016791ad9e7ec9d1e" category="inline-link-rx"></block></block>
  <block id="36e2bc00e48fbcfe5ae35a8a6056788c" category="admonition">A partire da ONTAP 9.7, la crittografia dell'aggregato e del volume è abilitata per impostazione predefinita quando si dispone di una licenza NVE e gestione delle chiavi integrata o esterna. Per abilitare la deduplica a livello di volume, imposta l'errore add -crypt al comando di creazione/modifica del volume (se disponi di una licenza NVE).</block>
  <block id="7a112f92e38a30129ab13d18331e21ce" category="section-title">Eliminazione automatica degli snapshot</block>
  <block id="f118801694edca90b5e446d3fe39cda0" category="paragraph">Per eliminare automaticamente le istantanee:<block ref="ecea59d033fb2dad1d38e75fbdc1c820" category="inline-link-rx"></block></block>
  <block id="e324e68086bb9c9e930b9d1168f1de5d" category="summary">Disponibilità EPIC su ONTAP</block>
  <block id="8339b88fddad3cfe433f684a83da04eb" category="paragraph">Al cuore di ONTAP troviamo operazioni senza interruzioni che consentono di evitare costose interruzioni delle operazioni di business.</block>
  <block id="ca7972f1caf7a478b4f931e986112b62" category="paragraph">NetApp offre una disponibilità di oltre il 99,999999% in base ai dati di produzione, che vengono chiamati "a casa" tramite NetApp Active IQ. Ogni coppia ha nel cluster non ha single point of failure. ONTAP risale al 1992 e rappresenta il software per la gestione dei dati più diffuso al mondo, con una storia eccezionale di fornitura di storage affidabile. Ora, grazie al monitoring proattivo e alla risoluzione automatica del 97% dei problemi da parte di Active IQ, la disponibilità è maggiore e i casi di supporto sono notevolmente inferiori.</block>
  <block id="43a21754b069ee170b1858e00c4072df" category="paragraph">EPIC consiglia l'utilizzo di sistemi storage ha per ridurre i guasti dei componenti hardware. Questo suggerimento va dall'hardware di base (ad esempio gli alimentatori ridondanti) al networking (ad esempio il collegamento in rete multipercorso).</block>
  <block id="58992d12f27d940ad0ced78080987a44" category="paragraph">Quando è necessario aggiornare lo storage, scalare in verticale, scalare in orizzontale o ribilanciare i carichi di lavoro nel cluster, non ci sono effetti per la cura del paziente. È possibile spostare i dati, ma non interrompere mai più l'attenzione dei pazienti grazie a migrazioni o aggiornamenti integrali. Passa alla tecnologia di prossima generazione, a prova di futuro ed evita il lock-in hardware. NetApp offre anche una garanzia di disponibilità scritta del 100%.</block>
  <block id="071a41c2bfc6123073746c5459501089" category="inline-link-macro">Affidabilità, disponibilità, serviceability e sicurezza di NetApp ONTAP</block>
  <block id="c38a90bcf1a9aa5905c0c4e6fbac331b" category="paragraph">Ulteriori informazioni sulle funzionalità di affidabilità, disponibilità, manutenzione e sicurezza di NetApp sono disponibili nel <block ref="c4f5dec030b0bd57318efbed2e25e7a7" category="inline-link-macro-rx"></block>white paper.</block>
  <block id="12a3215a6e17b2d4e547b8c9ddb4db59" category="summary">Data Protection EPIC</block>
  <block id="e2f4ffd17d85ea8c667a8fa10eaa81bd" category="doc">Clonazione epica</block>
  <block id="d777ff146845d0c5a59b451dcdd63eff" category="paragraph">EPIC riconosce che la tecnologia NetApp Snapshot basata su nodi storage non ha alcun effetto sulle performance sui carichi di lavoro di produzione rispetto ai backup tradizionali basati su file. Quando i backup Snapshot vengono utilizzati come origine di ripristino per il database di produzione, il metodo di backup deve essere implementato tenendo presente la coerenza del database.</block>
  <block id="7952c7481879c42a618f85cfab77dc0b" category="paragraph">Uno snapshot è una copia di backup di sola lettura point-in-time di un volume. NetApp FlexClone® scatta un'istantanea e la legge e la scrive istantaneamente. I volumi FlexClone offrono un enorme valore, acquisendo snapshot di sola lettura e coerenti con l'applicazione e creando volumi FlexClone scrivibili da dati di produzione. Questa funzionalità nativa ha un impatto significativo sul risparmio in termini di storage, sul tempo delle operazioni e sulle funzionalità di automazione.</block>
  <block id="dd12a5170cc960b0ed4afe4f23fd727b" category="paragraph">Per il processo di refresh vengono utilizzati i volumi FlexClone.</block>
  <block id="198010d8bf8a3ff0f084ffd059a9a1da" category="section-title">Gestione dei dati</block>
  <block id="31949f92a027681e10fa0ae809d62bcd" category="paragraph">Nell'ambito della soluzione, NetApp fornisce una soluzione di backup e test refresh completamente automatizzata, utilizzando strumenti ONTAP nativi. Questa soluzione è stata progettata per semplificare la gestione dei dati Epic in particolare per la grande comunità degli amministratori dei database Epic (DBA):</block>
  <block id="bde282ad1e62a3d8d64bcbebfd99918c" category="list-text">EPIC Mirror viene utilizzato per replicare i dati su report e disaster recovery (indicato con il verde).</block>
  <block id="89c4ed523f61f9d3446182d80a53c8b6" category="list-text">Dump di dati giornalieri da Report a Clarity.</block>
  <block id="c3d37da5ec71148ab4d2292c5fc62181" category="list-text">Backup automatici NetApp (indicati con giallo).</block>
  <block id="f417d841f910f45d16ac64fccd850be8" category="list-text">NetApp aggiornamento automatico dei test di SUP, REP e altro (indicato in blu).</block>
  <block id="2a7a6372892435f5d284e730df618c35" category="list-text">Gli ambienti di test sono adatti ad ambienti di copia completa, non a copie squash di piccole dimensioni.</block>
  <block id="88b2dcefc205727508d4017aacafaafd" category="paragraph">Per ulteriori informazioni, contatta i servizi NetApp per le applicazioni Epic.</block>
  <block id="4e3e281c19bf41f436de9fe363daa25c" category="paragraph">I gruppi di coerenza (CGS in breve) offrono questa funzionalità e molto altro ancora. Possono essere utilizzate di notte per creare snapshot coerenti on-demand o pianificate utilizzando una policy. Tutto questo è utile per ripristinare, clonare e persino replicare i dati.</block>
  <block id="f5de57234e68f27cbd82acfc80f2d5cb" category="inline-link-macro">Documentazione NetApp sui gruppi di coerenza</block>
  <block id="f7e43fe614bf53ff9721f7494c0caf16" category="paragraph">Per ulteriori informazioni sul CGS, fare riferimento a. <block ref="0efc681e89d66f1c589ad00a8ae67afa" category="inline-link-macro-rx"></block></block>
  <block id="9f42082fda47a6a26e6c6e6bcc14526e" category="section-title">Configurazione dei gruppi di coerenza per Epic</block>
  <block id="7d381e222258ec55bcf215684ae70097" category="inline-image-macro">Gruppi EPIC e di coerenza</block>
  <block id="4eb8f91ee432a8e69615314961db4f88" category="paragraph"><block ref="4eb8f91ee432a8e69615314961db4f88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4294e0bf4b67190ddcb91a01b3c4356c" category="section-title">Snapshot del gruppo di coerenza</block>
  <block id="86cfb45aaa741215d8d8d58223948dcc" category="paragraph">I dataset WebBLOB e VMare devono essere configurati come soli volumi, non associati a CGS. Puoi utilizzare la tecnologia SnapMirror o SnapVault per conservare le copie Snapshot su sistemi storage separati dalla produzione.</block>
  <block id="f5445123331a1b74a34fd1f392e9e946" category="inline-image-macro">Istantanee CG epiche</block>
  <block id="92aabd14a16803d9fa65ca4f94488322" category="paragraph"><block ref="92aabd14a16803d9fa65ca4f94488322" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c71026f6349a81cd2a3cfcfa8ea9ceb" category="summary">EPIC su ONTAP Consolidation</block>
  <block id="569a30a99d3744f0871a7c36162f469c" category="paragraph">Una delle principali sfide nel settore sanitario è l'inefficienza degli ambienti a silos.</block>
  <block id="87b522a84cee7651eb3ea5c59d4c9a35" category="paragraph">Le soluzioni a più punti vengono create da vari gruppi che impediscono il progresso. Disporre di una strategia unificata per la gestione dei dati offre efficienza per accelerare la trasformazione. Tecnologie dirompenti come la digitalizzazione delle cartelle cliniche dei pazienti, il ransomware e l'ai generativa, favoriscono tutto ciò che è necessario consolidare.</block>
  <block id="882f36b3d76e4e5b9ac08850c1e7a15a" category="paragraph">Con ONTAP puoi consolidare file/blocchi/oggetti e ciascuno dei tuoi workload di Tier 0/1/2/3, on-premise e nel cloud, il tutto in esecuzione su ONTAP.</block>
  <block id="0b153e0d191221abe8c325950ab9a03b" category="summary">EPIC su ONTAP Efficiency</block>
  <block id="12ca553efec3e73a9120d8c050d405a9" category="paragraph">EPIC viene eseguito su array all-flash in cui la maggior parte del costo è costituita dal disco. Pertanto, l'efficienza dello storage è fondamentale per il risparmio sui costi.</block>
  <block id="aac466a460fe672b45d2e43b476f772e" category="paragraph">L'efficienza dello storage inline di NetApp ottiene risparmi leader del settore sullo storage senza effetti sulle performance e offriamo persino una garanzia di efficienza scritta con gli array all-flash.</block>
  <block id="436525ee58a117eefbde96bb2f0cae02" category="paragraph">Nel calcolo dell'efficienza dello storage, è importante misurare la capacità da raw a utilizzabile su quella effettiva.</block>
  <block id="bbf547b93564824fe00f04646269a56e" category="list-text">*Capacità nativa* prima di applicare qualsiasi RAID, la dimensione del disco in base al numero di dischi.</block>
  <block id="29cabda6c17d251ab3bba7feb41646fc" category="list-text">*Capacità utilizzabile* dopo l'applicazione del RAID, quanto spazio di archiviazione utilizzabile è disponibile.</block>
  <block id="9edb4e889ca40d3881217c9433ecb376" category="list-text">*Capacità effettiva* quantità di storage fornita e presentata all'host o al client.</block>
  <block id="21e10a177fbffc69f63f5dcdb44175f5" category="paragraph">La figura riportata di seguito rappresenta un calcolo dell'efficienza di esempio di un'implementazione Epic tipica, che include tutti i carichi di lavoro che richiedono 852TB TB di storage effettivo e con un'efficienza di 5,2:1 che fornisce 1,32PB TB di dati effettivi totali.</block>
  <block id="c8c2fd097c28062ec912ad0d2f9bbe11" category="admonition">In base al numero di dischi, la capacità da raw a utilizzabile varia leggermente.</block>
  <block id="f0a0c9b18011b122c315d8970dbcce49" category="inline-image-macro">Straordinaria efficienza dello storage</block>
  <block id="d145883b21ccbccb471abc3a5dac40f3" category="paragraph"><block ref="d145883b21ccbccb471abc3a5dac40f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8acecf163b9e71e2e9331bc87c5e90" category="admonition">NetApp non utilizza la tecnologia Snapshot di NetApp o il thin provisioning per calcolare l'efficienza nel programma di garanzia. In questo modo è possibile ottenere efficienze non realistiche pari a 30 o 100:1, cosa che non significa nulla per il dimensionamento della capacità dello storage reale.</block>
  <block id="f4f81a0ab85224d234bc465988b5b871" category="summary">Panoramica di EPIC su ONTAP</block>
  <block id="35b4c598dd74c59e91d978c12210cc03" category="doc">EPIC su ONTAP</block>
  <block id="52aaae321a4b3f69eaf3448c22d2d55c" category="paragraph">EPIC è più facile con ONTAP.</block>
  <block id="76d68daeac9b3e7a8cfb0c3d904ac7de" category="paragraph">ONTAP è una piattaforma per la gestione dei dati che ti consente di consolidare i workload Epic e soddisfare al contempo tutti i tuoi requisiti in termini di performance, data Protection e gestione dei dati.</block>
  <block id="85e6f9f2e3539043a3a60b16af5a654f" category="paragraph">Solo NetApp ti consente di standardizzare tutti i carichi di lavoro del settore sanitario per SAN, NAS e oggetti su una singola piattaforma per la gestione dei dati ad alta disponibilità. ONTAP è la piattaforma software di storage più diffusa al mondo e viene fornita con quasi 30 anni di innovazione costante. Puoi affrontare tutte le sfide Epic con strumenti nativi per la gestione dei dati ONTAP e integrazione applicativa. Non è necessario acquistare numerosi strumenti di terze parti per colmare le lacune della soluzione.</block>
  <block id="54fed3d17b1233bcc7ab7b0d3f6eddca" category="paragraph">Molti vendor di soluzioni storage offrono uno storage a blocchi tradizionale, affidabile e veloce. Funzionano bene, ma di norma sono implementate in silos per eseguire un singolo workload come produzione, report, Clarity, VDI, VMware e NAS. Ciascuna di queste unità utilizza hardware e strumenti di gestione diversi e generalmente vengono gestite da diversi gruppi IT. Questo approccio tradizionale aggiunge al problema più grande con l'assistenza sanitaria oggi - la complessità.</block>
  <block id="58ad32957aed88a3c14ef81e5f254bd3" category="paragraph">NetApp rende la gestione dei dati più semplice ed efficiente. Invece di sprecare denaro nel caso di silos di dimensioni eccessive, ONTAP utilizza l'innovazione e la tecnologia per offrire SLA coerenti e garantiti per ogni carico di lavoro su una singola piattaforma, su qualsiasi protocollo con la protezione integrata dei dati. Queste funzionalità e questi strumenti si estendono anche al cloud di tua scelta, come illustrato di seguito.</block>
  <block id="0d9c98d3832defc892b59655abcfacfc" category="inline-image-macro">Scalabilità e semplicità per il settore sanitario con ONTAP</block>
  <block id="4277ed476100dc05b0a4e0e837c3d9b9" category="paragraph"><block ref="4277ed476100dc05b0a4e0e837c3d9b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63cc4e5664cd9022b0fc1580682f9995" category="summary">Prestazioni epiche su ONTAP</block>
  <block id="6762c0b102338c245945f7d09da83fa4" category="paragraph">ONTAP ha introdotto le tecnologie flash nel 2009 e ha supportato i dischi a stato solido dal 2010. Questa lunga esperienza con lo storage flash consente a NetApp di mettere a punto le funzionalità ONTAP per ottimizzare le performance SSD e aumentare la resistenza dei supporti flash mantenendo al contempo le funzionalità ricche di funzionalità di ONTAP.</block>
  <block id="8e0c14b7c96a8748c07c3916510ebd8b" category="paragraph">A partire dall'anno 2020, tutti i workload Epic ODB devono trovarsi su storage all-flash. I carichi di lavoro EPIC operano tipicamente a circa 1.000-2.000 IOPS per terabyte di storage (blocco da 8k KB, rapporto di lettura e scrittura 75%/25% e 100% di random). EPIC è molto sensibile alla latenza e l'elevata latenza ha un effetto visibile sull'esperienza dell'utente finale, oltre che su task operativi come l'esecuzione di report, backup, controlli di integrità e tempi di refresh dell'ambiente.</block>
  <block id="4a9928f04affb2a4fe321fb9e2b003fd" category="list-text">Il fattore limitante per gli array all-flash non è i dischi, ma piuttosto l'utilizzo sui controller.</block>
  <block id="11a9dfbe9a015ca567ecd5f77959dc1f" category="list-text">ONTAP utilizza un'architettura Active-Active. Per ottenere performance elevate, entrambi i nodi nella coppia ha scrivono sui dischi.</block>
  <block id="3a5c5db6ac361794af4c29a626c584f5" category="list-text">Questo risultato è un utilizzo massimizzato della CPU, il singolo fattore più importante che consente a NetApp di pubblicare le migliori performance Epic nel settore.</block>
  <block id="2f6b137b593d6a732992bc619827ee36" category="list-text">Le tecnologie NetApp RAID DP, ADP (Advanced Disk Partitioning) e WAFL soddisfano tutti i requisiti Epic. Tutti i carichi di lavoro distribuiscono i/o su tutti i dischi. Nessun collo di bottiglia.</block>
  <block id="0ce3d3de991180e05a5a0818efc312ef" category="list-text">ONTAP è ottimizzato in funzione della scrittura; le scritture vengono riconosciute una volta scritte sulla NVRAM mirrorata prima di essere scritte su disco a una velocità della memoria inline.</block>
  <block id="ca65639a4e206f319202179e1d9a4ff4" category="list-text">WAFL, NVRAM e l'architettura modulare consentono a NetApp di utilizzare il software per innovare con efficienze inline, crittografia e performance. Consentono inoltre a NetApp di introdurre nuove caratteristiche e funzionalità senza influire sulle prestazioni.</block>
  <block id="f13349f1404495d87711104e964b1cef" category="list-text">Storicamente, ogni nuova versione di ONTAP aumenta le prestazioni e l'efficienza del 30-50%. Le prestazioni sono ottimali con ONTAP.</block>
  <block id="70d9e3c68d42d6ec42ab792e06c44357" category="section-title">NVMe</block>
  <block id="42fa4afed0f941a60ea00e82671c421d" category="paragraph">Quando le performance sono di primaria importanza, NetApp supporta anche NVMe/FC, il protocollo FC SAN di nuova generazione.</block>
  <block id="1e4d4890d3f90b04841095b53183f782" category="paragraph">Come si può notare nella figura sotto, i nostri test Genio hanno raggiunto un numero molto maggiore di IOPS utilizzando il protocollo NVMe/FC rispetto al protocollo FC. La soluzione connessa NVMe/FC ha raggiunto oltre 700k IOPS prima di superare la soglia del ciclo di scrittura di 45 secondi. Sostituendo i comandi SCSI con NVMe, puoi anche ridurre significativamente l'utilizzo sull'host.</block>
  <block id="0b336e7e203efd55d17ecfaa03c134f5" category="inline-image-macro">Grafico genio epico</block>
  <block id="293e47073bb00e514b986ef28fbbb2e1" category="paragraph"><block ref="293e47073bb00e514b986ef28fbbb2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ff8735576a58daba5ba20974f92a584" category="summary">EPIC su scalabilità ONTAP</block>
  <block id="1027782bab261904e6adf43f2b137951" category="paragraph">La Epic hardware Configuration Guide registra una crescita annua di circa il 20% per 3 anni. Tuttavia, anche gli ambienti possono crescere inaspettatamente.</block>
  <block id="39e52e339ff39b5620d48036812e09ec" category="paragraph">NetApp può scalare perfettamente performance e capacità fino a 12 nodi per cluster NAS, SAN e a oggetti. Potrai quindi scalare in verticale e in orizzontale senza interruzioni seguendo la crescita del tuo business.</block>
  <block id="49c5cdfe08202e574deefaa3d26c332a" category="inline-link-macro">Epic sull'architettura verificata NetApp su SAN moderna</block>
  <block id="12cb4beeba752f647712c749e3076fbf" category="paragraph">EPIC Iris offre ulteriori funzionalità di scalabilità. Consente ai clienti più grandi con diverse istanze Epic di consolidarsi in una singola istanza. Il <block ref="5d13d58e489e8fe43bb727515c1d9ff2" category="inline-link-macro-rx"></block> documento dimostra che Epic è in grado di scalare perfettamente i workload consolidati fino a 720K milioni di IOPS su una singola ha e di scalare in orizzontale fino a oltre 4M milioni di IOPS in un cluster. Puoi scalare in verticale senza interruzioni aggiornando i controller o aggiungendo dischi ai cluster esistenti.</block>
  <block id="196097993185ddccf60443ac3f86e89f" category="paragraph">Inoltre, è possibile spostare i dati NAS, SAN e a oggetti senza interruzioni tra i nodi del cluster. Ogni coppia ha nel cluster può essere qualsiasi combinazione di tipi e dimensioni di sistemi ONTAP FAS e AFF. Puoi bilanciare i carichi di lavoro in un singolo cluster per massimizzare l'investimento storage.</block>
  <block id="6abd4957b4615c500bd2a32425316211" category="paragraph">ONTAP offre anche la possibilità di utilizzare lo storage a oggetti su StorageGRID o nel cloud come destinazione di backup e/o destinazione del tiering automatico del cold storage. Questa funzionalità ti consente di liberare automaticamente sugli oggetti i costosi dischi all-flash, le snapshot di Tier e i dati cold.</block>
  <block id="8d3f76f475a5e81f188f700429c71a9e" category="paragraph">Il risultato è che Epic funziona semplicemente meglio con il portfolio di prodotti NetApp, sfruttando ONTAP, diversi protocolli, StorageGRID e il cloud di tua scelta. Questi prodotti offrono opzioni di disaster recovery, archiviazione, analisi, tiering e altro ancora.</block>
  <block id="1e3ccee88df9552e4751ba4ad173de96" category="summary">EPIC su ONTAP Security</block>
  <block id="32e1bf49ff775c9283c882fe7f3ec873" category="paragraph">Oggi la sicurezza è la preoccupazione principale per le organizzazioni e i dirigenti del settore sanitario. Non è mai stato così difficile da gestire e le organizzazioni devono affrontare problemi come compliance, governance dei dati, protezione antivirus e ransomware.</block>
  <block id="0d6ce08690a300cb8ce00d77e1c31a5e" category="inline-link-macro">Guida alla protezione per ONTAP</block>
  <block id="40e97866feb53c48881b34e5f97ca61f" category="paragraph">Una guida completa a Epic e alla sicurezza dello storage esulano dall'ambito di questo documento; tuttavia, <block ref="471b0f2cfbad0f2ec4e54df06500d580" category="inline-link-macro-rx"></block> elenca tutte le funzionalità di sicurezza estese e avanzate disponibili con ONTAP.</block>
  <block id="1408f921f799efe0e585aeba5fa9ed58" category="inline-link-macro">TR-4569</block>
  <block id="f87d3f3c7c3e6e9ab1153c53d78b40b1" category="paragraph">NetApp Active IQ Unified Manager monitora le violazioni di sicurezza in base alle informazioni incluse nel <block ref="1b2ca6a48e0bf52cc6351680c5ee6170" category="inline-link-macro-rx"></block> e le segnala nella dashboard per semplificare la gestione della sicurezza. Questi strumenti possono aiutare la vostra organizzazione a raggiungere gli obiettivi di sicurezza per proteggere, rilevare e risolvere gli attacchi.</block>
  <block id="a1fbc1f9fe3c77416c96f491ba933c4a" category="inline-link-macro">FPolicy di NetApp</block>
  <block id="96f76ddccc0adcaf0fc9a2fc6c834374" category="inline-link-macro">Autenticazione multifattore (MFA)</block>
  <block id="a754af2f708573321f76c2d36bea9f02" category="paragraph">NetApp ha inoltre collaborato con i vendor di sicurezza per fornire l'integrazione tramite <block ref="48fae993b7aeb9944f39dadc4618e2b6" category="inline-link-macro-rx"></block> software per migliorare la tua offerta di sicurezza. Inoltre, <block ref="b5ae90d3a2df9b77f2db834fe0dc7b7d" category="inline-link-macro-rx"></block> può essere aggiunto per proteggere l'ambiente Epic da accessi non autorizzati con credenziali trapelate.</block>
  <block id="91d998bab304adb0fd27858a4295dcac" category="inline-link-macro">Cyber vault di ONTAP</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link-macro">La soluzione NetApp per ransomware</block>
  <block id="63ab8aaa1f35361bdf5c84b3d1dd4765" category="inline-link-macro">NetApp e zero trust</block>
  <block id="a67fe844bc4d3e5cf5ebac11dea00b01" category="paragraph">Infine, le copie snapshot native di ONTAP e le tecnologie immutabili SnapLock con <block ref="79305a8b61b53acc892506e6bcd6f49f" category="inline-link-macro-rx"></block>, offrono un'esclusiva funzionalità air gap per proteggere le cartelle cliniche dei pazienti dal ransomware. Consultare la documentazione NetApp a <block ref="910d0617bba4ff1a9d41b4b330096d85" category="inline-link-macro-rx"></block>. Per un approccio più strategico alla protezione, vedere <block ref="aaf21a490837c9b392e59c6c9110165d" category="inline-link-macro-rx"></block>.</block>
  <block id="28caba838e7a7ff7ff218bae8235208a" category="summary">Snapshot e cloning epici</block>
  <block id="8ad0c394ef79d2b18983fabe84f658fc" category="paragraph">Uno snapshot è una copia point-in-time di un volume di sola lettura.</block>
  <block id="568043eed0b44992a4b4a1cc21f8b633" category="paragraph">Uno snapshot inserisce un blocco logico in tutti i blocchi del file system attivo. Le copie Snapshot di NetApp ONTAP sono near-Instant e non utilizzano storage aggiuntivo.</block>
  <block id="04a00b93a2db41946dc3d263cf6c294c" category="paragraph">Write ANHERE file Layout, o WAFL, è un file system di sola scrittura; non esegue io aggiuntivi, come la copia dei dati in un blocco protetto da snapshot prima di essere sovrascritti. Non viene mai spostato i dati; pertanto, le snapshot non hanno alcun effetto sulla capacità o sulle performance dello storage. Le snapshot consentono enormi risparmi in termini di storage, migliorando al tempo stesso la soluzione di backup.</block>
  <block id="a701f5d044348085ee4f97fef6636845" category="section-title">FlexClone</block>
  <block id="16f57611d3d44b74ce1c1b134cb8e798" category="paragraph">Un volume NetApp ONTAP FlexClone è un clone di un volume esistente o di uno Snapshot di un volume esistente. Si tratta di un volume ONTAP come qualsiasi altro e può essere esso stesso clonato, protetto con Snapshot e configurato con una policy di QoS.</block>
  <block id="e0c3236990160654182a79c89baab29f" category="paragraph">Come per le Snapshot, un volume FlexClone non richiede spazio aggiuntivo al momento della creazione. Solo le modifiche al clone richiedono capacità aggiuntiva.</block>
  <block id="9a9ff90c24c36543bf54b1f2136fd9e0" category="paragraph">EPIC richiede da 10 a 30 copie dei database di produzione per vari requisiti operativi, come backup in streaming, controlli dell'integrità e ambienti di aggiornamento dello staging. L'esigenza di una soluzione costruita su FlexClone Volumes è aumentata con il passaggio ad aggiornamenti più frequenti.</block>
  <block id="dad816f366caa0b8cae67daaeb85deb0" category="admonition">Una soluzione di backup Epic completamente automatizzata e una soluzione di refresh Epic sono fornite da NetApp come parte della soluzione utilizzando Ansible e i tool NetApp nativi.</block>
  <block id="53f102b306ab1aba43e9e20701dc32f2" category="doc">EPIC su ONTAP</block>
  <block id="3bfc8ddd725eed5b674d1a480bc650d2" category="paragraph">La chiave della digital transformation sta facendo di più con i tuoi dati.</block>
  <block id="2b82426bc0bfa4ea3efb779d165629a4" category="admonition">Questa documentazione sostituisce questo report tecnico precedentemente pubblicato _TR-3923: Best practice NetApp per Epic_.</block>
  <block id="fdf0f3f3a2bae0d66ca5ecb45e1f3d85" category="paragraph">Gli ospedali richiedono grandi quantità di dati per iniziare il viaggio della digital transformation. Parte del processo di trattamento dei pazienti, gestione degli orari del personale e delle risorse mediche è che le informazioni vengono raccolte ed elaborate. Tuttavia, molte azioni vengono ancora eseguite manualmente o tramite sistemi obsoleti. L'unica costante è che la quantità di dati continua a crescere in modo esponenziale e quindi diventa sempre più difficile da gestire.</block>
  <block id="74090662bfdb94e49dfc286a6946cc5c" category="paragraph">La causa principale di questo problema è che i dati ospedalieri vengono spesso archiviati in silos di dati. Troppo tempo viene impiegato per le immissioni manuali e gli aggiornamenti che portano a burnout ed errori. Il presente documento riguarda una parte dei dati del settore sanitario, la Epic Electronic Health Records (EHR). Tuttavia, la strategia di gestione dei dati qui trattata può e deve essere applicata a tutti i dati sanitari. NetApp vanta una lunga storia di modernizzazione e semplificazione dell'infrastruttura digitale. La nostra infrastruttura dati intelligente costituisce la base della digital transformation.</block>
  <block id="b68a1112138fe0c0c1beafc2aea18949" category="paragraph">NetApp offre una singola soluzione di gestione dei dati per tutte le esigenze del settore sanitario e possiamo guidare gli ospedali nel loro percorso verso la digital transformation. Costruendo una base con strutture e soluzioni intelligenti, l'assistenza sanitaria può trarre il pieno valore di queste preziose informazioni. Questo quadro può aiutare i medici a diagnosticare le malattie più velocemente e sviluppare piani di trattamento personalizzati per supportare meglio i processi decisionali in situazioni di emergenza. Inoltre, sarà possibile creare una propria infrastruttura dati intelligente e consentire all'ospedale di sbloccare i silos di dati, agevolare l'interoperabilità dei dati e proteggere le informazioni sensibili dei pazienti.</block>
  <block id="6b5a360f7d15046cfd935db963e3da66" category="paragraph">Utilizza questo documento come guida per costruire e implementare con successo Epic EHR. Invece di costruire diversi silos Epic, crea una singola infrastruttura dati Epic e trasforma il tuo ospedale.</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="section-title">Scopo</block>
  <block id="b8954f46b76dae4370058c7bd9ae0c97" category="paragraph">Questo documento descrive le Best practice per l'integrazione dello storage NetApp in un ambiente software Epic. Contiene le seguenti sezioni:</block>
  <block id="6c5022fa1197168f37c42e56f80d36aa" category="list-text">Una conoscenza tecnica dell'ambiente software Epic e dei relativi requisiti di storage in diverse configurazioni.</block>
  <block id="a9da176a5abe5a618e8ed6a88bdbf21b" category="list-text">Considerazioni epiche sullo storage che descrivono importanti fattori decisionali per le soluzioni Epic.</block>
  <block id="8b3f0902644adbb7e0435ae9c9a284e2" category="list-text">Consigli sullo storage NetApp, descrivendo le Best practice di configurazione dello storage NetApp per soddisfare i requisiti di storage Epic.</block>
  <block id="5d113f2038d289f391614c39043629e8" category="section-title">Scopo</block>
  <block id="217eb7cf1ad7503a42f61ad3cffb47fb" category="paragraph">Questo documento non tratta i seguenti argomenti:</block>
  <block id="f900b8ede5ddf3a0471176dab052001d" category="list-text">Requisiti quantitativi delle prestazioni e linee guida sul dimensionamento, risolti in<block ref="81c36a9e6d224e9d42c9630dffaa9434" category="inline-link-rx"></block> (è richiesto l'accesso NetApp)</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Pubblico</block>
  <block id="2f215f5ba67ae7978ce4846a4a1cdc08" category="paragraph">NetApp presuppone che il lettore disponga delle seguenti conoscenze di base:</block>
  <block id="6cfde17644914efa6d0a4d0c21a8f9db" category="list-text">Una solida comprensione dei concetti SAN e NAS</block>
  <block id="c86456e4299d4b0ad43e030d0fdd0af5" category="list-text">Familiarità tecnica con i sistemi di storage ONTAP</block>
  <block id="59eba43c04b655e21f087af920398a2a" category="list-text">Familiarità tecnica con la configurazione e l'amministrazione di ONTAP</block>
  <block id="b7c45da218d2e29ec939a31cdd81f2be" category="paragraph">Uno storage controller NetApp che esegue ONTAP può supportare i seguenti carichi di lavoro in un ambiente Windows Server:</block>
  <block id="ba0a81fc95587bfae3e0ac0bf44e562a" category="paragraph">Il NetApp PowerShell Toolkit (PSTK) è un modulo PowerShell che offre automazione end-to-end e consente l'amministrazione dello storage di ONTAP. Il modulo ONTAP contiene oltre 2.000 cmdlet e aiuta nell'amministrazione di FAS, NetApp All Flash FAS (AFF), commodity hardware e risorse cloud.</block>
  <block id="f43e8d35e63b48bc73d5dc074df829ae" category="paragraph">Microsoft ODX, noto anche come offload delle copie, permette trasferimenti dei dati diretti all'interno di un dispositivo di storage o tra dispositivi di storage compatibili senza trasferire i dati attraverso il computer host. ONTAP supporta la funzionalità ODX per i protocolli CIFS e SAN. ODX può potenzialmente migliorare le performance se le copie si trovano all'interno dello stesso volume, ridurre l'utilizzo della CPU e della memoria sul client e ridurre l'utilizzo della larghezza di banda i/o di rete.</block>
  <block id="e033e4d03ff089011c11d7d2fa80d475" category="paragraph">I server in cluster Hyper-V (detti nodi) sono connessi dalla rete fisica e da un software cluster. Questi nodi utilizzano lo storage condiviso per memorizzare i file delle macchine virtuali, tra cui configurazione, file dell'hard disk virtuale (VHD) e copie Snapshot. Lo storage condiviso può essere una condivisione SMB/CIFS di NetApp o un CSV posto sopra una LUN NetApp, come illustrato di seguito. Si tratta di uno storage condiviso che offre un namespace coerente e distribuito, a cui tutti i nodi del cluster possono accedere contemporaneamente. Pertanto, se un nodo si guasta nel cluster, l'altro nodo fornisce il servizio mediante un processo chiamato failover. I cluster di failover possono essere gestiti utilizzando lo snap-in failover Cluster Manager e i cmdlet Windows PowerShell per il clustering di failover.</block>
  <block id="72960f8df48c0debc035454921c1b5d3" category="list-text">In una migrazione live condivisa, la macchina virtuale viene memorizzata in una condivisione SMB. Pertanto, quando si effettua la migrazione live di una macchina virtuale, lo storage della macchina virtuale rimane sulla condivisione SMB centrale per l'accesso istantaneo da parte dell'altro nodo, come illustrato di seguito.</block>
  <block id="5a002cf26db634ca1b1fff75461d2427" category="list-title">ONTAP viene eseguito sugli storage controller NetApp. È disponibile in più formati.</block>
  <block id="6011d6a859985e0b6d7c13b0907896ca" category="paragraph">ONTAP offre uno storage ad alta disponibilità in cui possono esistere più percorsi dallo storage controller a Windows Server. Il multipathing consente di utilizzare più percorsi dei dati da un server a uno storage array. Il multipathing protegge da guasti hardware (rottura dei cavi, guasto di switch e HBA (host Bus Adapter) e così via) e può offrire limiti di performance più elevati utilizzando le prestazioni aggregate di più connessioni. Quando un percorso o una connessione non è disponibile, il software multipathing sposta automaticamente il carico su uno degli altri percorsi disponibili. La funzione MPIO unisce i diversi percorsi fisici allo storage come unico percorso logico utilizzato per l'accesso ai dati allo scopo di garantire la resilienza dello storage e il bilanciamento del carico. Per utilizzare questa funzione, la funzione MPIO deve essere attivata su Windows Server.</block>
  <block id="8bbfb9edfb90853f3f9439d77ce59441" category="list-text">Comandi CLI su ONTAP</block>
  <block id="e72f4a4f5fcfab964176e743af1f3196" category="paragraph">Il protocollo NAS CIFS è integrato in modo nativo in ONTAP. Pertanto, Windows Server non richiede alcun software client aggiuntivo per accedere ai dati su ONTAP. Uno storage controller NetApp viene visualizzato sulla rete come file server nativo e supporta l'autenticazione Microsoft Active Directory.</block>
  <block id="ab2d1dd1b024fd7be648c22c4a43997b" category="list-text">È possibile eseguire determinate attività di gestione CIFS utilizzando Microsoft Management Console (MMC). Prima di eseguire queste attività, è necessario collegare MMC all'archiviazione ONTAP utilizzando i comandi di menu MMC.</block>
  <block id="1d5ba6202d85466a95188b58c37dccc8" category="list-text">NetApp consiglia di collegare gli host Hyper-V e lo storage ONTAP con una rete 10GB, se disponibile. Nel caso della connettività di rete 1GB, NetApp consiglia di creare un gruppo di interfacce composto da più porte 1GB.</block>
  <block id="79d467fa842b9015f2f12ada4fa1c7fc" category="paragraph">Le prestazioni di SQL Server dipendono in modo multiplo dalla CPU e dalla configurazione di base.</block>
  <block id="dcfe06c0ddbb3b395286872a95182eb3" category="paragraph">L'hyperthreading si riferisce all'implementazione simultanea di multithreading (SMT), che migliora la parallelizzazione dei calcoli eseguiti su processori x86. SMT è disponibile sia sui processori Intel che AMD.</block>
  <block id="2e84c18998d7c7a831a62718e10a98c5" category="paragraph">L'hyperthreading produce CPU logiche che appaiono come CPU fisiche nel sistema operativo. SQL Server vede quindi le CPU aggiuntive e le utilizza come se vi fossero più core di quelli fisicamente presenti. Questo può migliorare notevolmente le prestazioni aumentando la parallelizzazione.</block>
  <block id="4403546c5938500562a9d8677deb1c38" category="section-title">Core e licenze</block>
  <block id="c325fde2d51a1ea2ddd8c9dd51cfdf9c" category="paragraph">L'immagine seguente mostra il messaggio di registro di SQL Server dopo l'avvio che indica l'imposizione del limite principale.</block>
  <block id="e59dc8056170cddb696ba9bff812c325" category="paragraph">SQL Server utilizza tutte le CPU disponibili dal sistema operativo (se si sceglie la licenza core per processore). Inoltre, crea degli scheduler f0r per ogni CPU per utilizzare al meglio le risorse per qualsiasi carico di lavoro. Durante il multitasking, il sistema operativo o altre applicazioni sul server possono passare da un processore all'altro. SQL Server è un'applicazione che richiede molte risorse e in tal caso le prestazioni possono risentirne. Per ridurre al minimo l'impatto, è possibile configurare i processori in modo che tutto il carico di SQL Server venga indirizzato a un gruppo preselezionato di processori. Ciò si ottiene utilizzando la maschera di affinità della CPU.</block>
  <block id="e40a45aed8142e74026f5aa7a6ee1122" category="paragraph">L'opzione maschera i/o affinità associa l'i/o del disco di SQL Server a un sottoinsieme di CPU. Negli ambienti OLTP di SQL Server, questa estensione può migliorare significativamente le prestazioni dei thread di SQL Server che emettono operazioni i/O.</block>
  <block id="a58930419c1b1a276791665c876f8f80" category="paragraph">Sebbene sia utile per query di grandi dimensioni, può causare problemi di prestazioni e limitare la concorrenza. Un approccio migliore consiste nel limitare il parallelismo al numero di core fisici in un singolo socket CPU. Ad esempio, su un server con due socket CPU fisici con 12 core per socket, indipendentemente dall'hyperthreading,<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> deve essere impostato su 12.<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> Non è possibile limitare o dettare quale CPU utilizzare. Limita invece il numero di CPU che possono essere utilizzate da una singola query batch.</block>
  <block id="16dce493fdad96fe48148f47dc552bfb" category="admonition">*NetApp consiglia* per DSS, ad esempio data warehouse, iniziare con<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> 50 ed esplorare la messa a punto su o giù, se necessario. Assicurarsi di misurare le query critiche nell'applicazione quando si apportano modifiche.</block>
  <block id="0add8d6e7be42a854cd7e0161c7f9bcc" category="paragraph">In genere, per ogni query viene creato un thread del sistema operativo separato. Se vengono effettuate centinaia di connessioni simultanee a SQL Server, la configurazione con un solo thread per query può consumare troppe risorse di sistema. L'<block ref="a9233738c364090bbc418d8a0e08a79e" prefix=" " category="inline-code"></block>opzione consente di migliorare le prestazioni consentendo a SQL Server di creare un pool di thread di lavoro in grado di gestire collettivamente un maggior numero di richieste di query.</block>
  <block id="29daf9697a41a463dbe76855a2053a87" category="paragraph">Nell'esempio seguente viene illustrato come configurare l'opzione numero massimo di thread di lavoro utilizzando T-SQL.</block>
  <block id="7039e99a0fdcc0d3ef80074ed42bf4e4" category="paragraph">Le strategie di backup dei database devono basarsi su requisiti aziendali identificati, non su capacità teoriche. Combinando la tecnologia Snapshot di ONTAP e sfruttando le API di Microsoft SQL Server, è possibile eseguire rapidamente un backup coerente delle applicazioni indipendentemente dalle dimensioni dei database utente. Per requisiti di gestione dei dati più avanzati o scale-out, NetApp offre SnapCenter.</block>
  <block id="4cd6720df070a1784bae9c6f525f483d" category="admonition">*NetApp recommended* Using SnapCenter to create Snapshot copy. Anche il metodo T-SQL descritto di seguito funziona, ma SnapCenter offre un'automazione completa sul processo di backup, ripristino e cloning. Esegue inoltre il rilevamento per garantire che vengano creati gli snapshot corretti. Non è necessaria alcuna pre-configurazione.</block>
  <block id="97e73fdb42ddecb63ed519a484ff3c9b" category="paragraph">SQL Server richiede inoltre un coordinamento tra il sistema operativo e lo storage per garantire che i dati corretti siano presenti negli snapshot al momento della creazione. Nella maggior parte dei casi, l'unico metodo sicuro per eseguire questa operazione è SnapCenter o T-SQL. Gli snapshot creati senza questo coordinamento aggiuntivo potrebbero non essere recuperabili in modo affidabile.</block>
  <block id="9d831cc4c73b8a2915ce6d8928d55915" category="paragraph">La funzionalità di replica del gruppo di disponibilità always-on di SQL Server può essere un'opzione eccellente e NetApp offre opzioni per integrare la protezione dei dati con Always-on. In alcuni casi, tuttavia, è consigliabile prendere in considerazione la tecnologia di replica ONTAP. Sono disponibili tre opzioni di base.</block>
  <block id="dd432f8769e4d3db8acf8bf9df94680a" category="paragraph">La tecnologia SnapMirror offre una soluzione aziendale rapida e flessibile per la replica dei dati su LAN e WAN. La tecnologia SnapMirror trasferisce solo i blocchi di dati modificati a destinazione dopo la creazione del mirror iniziale, riducendo in modo significativo i requisiti di larghezza di banda della rete. Può essere configurato in modalità sincrona o asincrona.</block>
  <block id="fce5f84d02dbd5c9e3cfedf18e809644" category="summary">Microsoft SQL Server e NetApp MetroCluster</block>
  <block id="41900c1c2eb669e401e4abee9091b40b" category="paragraph">La distribuzione di Microsoft SQL Server con ambiente MetroCluster richiede alcune spiegazioni sulla progettazione fisica di un sistema MetroCluster.</block>
  <block id="60359402d81f6673550c3df489efb034" category="paragraph">MetroCluster esegue il mirroring sincrono di dati e configurazione tra due cluster ONTAP in posizioni separate o domini di errore. MetroCluster offre storage sempre disponibile per le applicazioni gestendo automaticamente due obiettivi:</block>
  <block id="abf0aedf685f58c3cf3abe3e41ca549c" category="list-text">RPO (Zero Recovery Point Objective) eseguendo il mirroring sincrono dei dati scritti nel cluster.</block>
  <block id="1194ac032fc54dbcf779ac23fbc73dd5" category="list-text">RTO (Recovery Time Objective) quasi nullo attraverso la configurazione del mirroring e l'automazione dell'accesso ai dati del secondo sito.</block>
  <block id="9aa45379205d52916f2958359e92c1c8" category="paragraph">MetroCluster offre semplicità con mirroring automatico dei dati e configurazione tra i due cluster indipendenti situati nei due siti. Poiché lo storage viene fornito all'interno di un cluster, viene automaticamente eseguito il mirroring nel secondo cluster del secondo sito. NetApp SyncMirror® fornisce una copia completa di tutti i dati con RPO pari a zero. Ciò significa che i carichi di lavoro da un sito possono passare in qualsiasi momento al sito opposto e continuare a fornire i dati senza perdita di dati. MetroCluster gestisce il processo di switchover per fornire accesso ai dati forniti da NAS e SAN al secondo sito. La progettazione di MetroCluster come soluzione validata contiene dimensionamento e configurazione che consente di eseguire uno switchover entro i periodi di timeout del protocollo (generalmente inferiori a 120 secondi). Questo consente un RPO prossimo allo zero e le applicazioni possono continuare ad accedere ai dati senza incorrere in guasti. Il MetroCluster è disponibile in diverse variazioni definite dal fabric dello storage back-end.</block>
  <block id="47985b72c36de8197de21d06517f1a03" category="paragraph">La protezione per SQL Server con MetroCluster si basa su SyncMirror, che offre una tecnologia di mirroring sincrono scale-out dalle performance massime.</block>
  <block id="96a36329b3e96b1619b1d635a806bb3f" category="summary">Microsoft SQL Server con NetApp MetroCluster</block>
  <block id="9fcf1f7a4c16b536048dc5875b61d4b1" category="paragraph">Un'opzione per la protezione dei database di SQL Server con RPO pari a zero è MetroCluster. MetroCluster è una semplice tecnologia di replica RPO=0 dalle performance elevate che consente di replicare un'intera infrastruttura tra i siti in modo semplice.</block>
  <block id="8a7f9ca86b522c62318d9b1eb5b51625" category="paragraph">SQL Server è in grado di scalare fino a migliaia di database su un unico sistema MetroCluster. Potrebbero esistere istanze standalone di SQL Server o istanze cluster di failover, MetroCluster System non aggiunge o modifica necessariamente le Best practice per la gestione di un database.</block>
  <block id="43135677cc98d0d6872d9ec24bef82e4" category="paragraph">Una spiegazione completa di MetroCluster esula dall'ambito di questo documento, ma i principi sono semplici. MetroCluster può offrire una soluzione di replica con RPO=0 e failover rapido. Ciò che costruite su questa base dipende dalle vostre esigenze.</block>
  <block id="046797023ebbfe8b6dd24d4fc7cab0be" category="paragraph">Ad esempio, una procedura di DR rapida di base dopo una perdita improvvisa del sito potrebbe utilizzare la seguente procedura di base:</block>
  <block id="f8b79e7c0c5914411ccfda1cbaa25414" category="list-text">Forzare uno switchover MetroCluster</block>
  <block id="740d5da1ae0060ef63f290d3aed64929" category="list-text">Rilevamento di LUN FC/iSCSI (solo SAN)</block>
  <block id="89c617c4ed9cac275e572a67b1c52b29" category="list-text">Montare i file system</block>
  <block id="f08329445e69fa49a8223bf365f09e47" category="list-text">Avviare SQL Services</block>
  <block id="b7aabeea5e06b7371d4372fd7f698f88" category="paragraph">Il requisito principale di questo approccio è rappresentato da un sistema operativo in esecuzione sul sito remoto. Deve essere preconfigurato con l'installazione di SQL Server e deve essere aggiornato con una versione di build equivalente. È inoltre possibile eseguire il mirroring dei database di sistema di SQL Server nel sito remoto e montarli se viene dichiarata un'emergenza.</block>
  <block id="a61003199d91214045b9d3344f527cbd" category="paragraph">Se i volumi, i file system e il datastore che ospitano database virtualizzati non vengono utilizzati nel sito di disaster recovery prima dello switchover, non è necessario impostare i<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> volumi associati.</block>
  <block id="2b963bb5f627aa0ffda026b4d97b6474" category="summary">Microsoft SQL Server e SM-as scenari di failover</block>
  <block id="bdd8b094b65ec8544e0ad9724a1984ad" category="doc">Failover di sincronizzazione attiva di Microsoft SQL Server e SnapMirror</block>
  <block id="b0bb805a1ea68ad43ceacf65954b4b4b" category="paragraph">La pianificazione di un'architettura completa dell'applicazione SnapMirror Active Sync richiede la comprensione del modo in cui SM-AS risponderà in vari scenari di failover pianificati e non pianificati.</block>
  <block id="3fc36a3b35bb877723ed17d69c3d57fb" category="summary">Microsoft SQL Server e ONTAP mediator</block>
  <block id="511d40fa1b50f901027391480dff9c67" category="paragraph">Il mediatore è necessario per automatizzare in modo sicuro il failover. Idealmente, sarebbe posizionato su un sito 3rd indipendente, ma può comunque funzionare per la maggior parte delle esigenze se colocated con uno dei cluster che partecipano alla replica.</block>
  <block id="cef962a099d3ff2b834420d0c97f5bc1" category="summary">Microsoft SQL Server e SM: Accesso non uniforme</block>
  <block id="3ef2650b3e4d89df6ea0248f432e6c2c" category="paragraph">Una rete di accesso non uniforme significa che ogni host ha solo accesso alle porte sul sistema di storage locale. LA SAN non è estesa a più siti (o presenta errori nei domini dello stesso sito).</block>
  <block id="7c58b14cf1e27ff24a5b6a0656848380" category="summary">Sincronizzazione attiva di Microsoft SQL Server e SnapMirror</block>
  <block id="a87e788e43169f3df56a7eee4e9bd79c" category="doc">Sincronizzazione attiva di SQL Server e SnapMirror</block>
  <block id="64affc06244780af1f97a68438460989" category="paragraph">La sincronizzazione attiva di SnapMirror consente a singoli database e applicazioni SQL Server di continuare le operazioni durante interruzioni di rete e storage, con failover trasparente dello storage senza interventi manuali.</block>
  <block id="0a19f1ca74616d0d4972b2c02c3f7fee" category="paragraph">A partire da ONTAP 9.15,1, SnapMirror Active Sync supporta l'architettura Active/Active simmetrica oltre alla configurazione asimmetrica esistente. La funzionalità Active/Active simmetrica offre replica bidirezionale sincrona per la business continuity e il disaster recovery. Protegge l'accesso ai dati per carichi di lavoro critici SAN con accesso simultaneo in lettura e scrittura ai dati in diversi domini di errore, garantendo operazioni senza interruzioni e riducendo al minimo i downtime in caso di disastri o errori di sistema.</block>
  <block id="d17dae030927ab027095c1e44df8fbf1" category="paragraph">Gli host SQL Server accedono allo storage utilizzando LUN Fiber Channel (FC) o iSCSI. Replica tra ciascun cluster in cui risiede una copia dei dati replicati. Poiché questa funzionalità è la replica a livello di storage, le istanze di SQL Server in esecuzione su istanze di cluster di failover o host standalone possono eseguire operazioni di lettura/scrittura in entrambi i cluster. Per le fasi di pianificazione e configurazione, fare riferimento a <block ref="44f5d8051247437425911d96f84db248" category="inline-link-macro-rx"></block> .</block>
  <block id="3fa280b2a8840046be265109ff9f0696" category="section-title">Architettura di SnapMirror Active con Active/Active simmetrico</block>
  <block id="a93a13dd139e6bb0629cd0ace446c595" category="paragraph"><block ref="a93a13dd139e6bb0629cd0ace446c595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f689709f901a51858096aaf9637eb4" category="paragraph">**Replica sincrona**</block>
  <block id="71ed2e619a97a27f6fe533714a412725" category="paragraph">Durante l'utilizzo normale, ciascuna copia è una replica sincrona con RPO=0/7, con un'unica eccezione. Se i dati non possono essere replicati, ONTAP rilascerà il requisito di replicare i dati e riprendere la distribuzione io su un sito mentre le LUN dell'altro sito vengono portate offline.</block>
  <block id="331b5c7e8c01ec1e37b60de5a5efba6c" category="paragraph">**Hardware di archiviazione**</block>
  <block id="c2048364072b2c53688aeb273047e068" category="paragraph">**ONTAP mediatore**</block>
  <block id="588068838f06fe39dec548e2210ddf2f" category="paragraph">ONTAP Mediator è un'applicazione software che viene scaricata dal supporto NetApp e che viene in genere distribuita su una piccola macchina virtuale. Il ONTAP Mediator non è un tiebreaker. È un canale di comunicazione alternativo per i due cluster che partecipano alla replica sincrona attiva SnapMirror. Le operazioni automatizzate sono gestite da ONTAP in base alle risposte ricevute dal partner tramite connessioni dirette e tramite il mediatore.</block>
  <block id="6fda40460e9cbbefd704b9c01ea2c18c" category="summary">Microsoft SQL Server e SM, come sito preferito</block>
  <block id="ac420a2d1b21182a80148191683bc9f7" category="paragraph">Il comportamento di sincronizzazione attiva di SnapMirror è simmetrico, con una eccezione importante: Configurazione del sito preferita.</block>
  <block id="309d61d5c343d8fd53c2c585c64587b6" category="doc">Microsoft SQL Server con sincronizzazione attiva SnapMirror</block>
  <block id="3ccf31c781c6df95109107d66199a8f6" category="section-title">Istanza standalone di SQL Server</block>
  <block id="bd53ef250bf6f7a012cc7ed01c62f8cd" category="inline-link-macro">Server SQL su ONTAP</block>
  <block id="d0d5aa4f66a3624a91ad4b11bbc2250f" category="paragraph">Le procedure consigliate per il layout dei file e la configurazione del server sono identiche a quelle consigliate nella <block ref="c89905de54b32eb552c83786b7590df9" category="inline-link-macro-rx"></block> documentazione.</block>
  <block id="a489ffed938ef1b9e86889bc413501ee" category="inline-link-macro">uniforme</block>
  <block id="ee289d07b4c3d14dcc9cc162df065f99" category="paragraph">Con una configurazione standalone, SQL Server potrebbe essere eseguito solo in un sito. Presumibilmente <block ref="b88135502d93a28469d0c520f73e7e7d" category="inline-link-macro-rx"></block>si userebbe l'accesso.</block>
  <block id="50c137c2af8db8930fd9881b4ece5d99" category="inline-image-macro">Host singolo con accesso uniforme</block>
  <block id="60ee5124219a8203e5bacd7d5a1f38fa" category="paragraph"><block ref="60ee5124219a8203e5bacd7d5a1f38fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="327efeeabe7ad30552ef39a61284b93b" category="paragraph">Grazie a un accesso uniforme, un guasto dello storage in uno dei siti non interromperebbe le operazioni di database. Un errore completo del sito che includeva il server di database comporterebbe, ovviamente, un'interruzione del servizio.</block>
  <block id="5bc465d840f8a329d264340f938ab253" category="paragraph">Alcuni clienti potrebbero configurare un sistema operativo in esecuzione nel sito remoto con un'installazione di SQL Server preconfigurata, aggiornata con una versione di build equivalente a quella dell'istanza di produzione. Il failover richiede l'attivazione dell'istanza standalone di SQL Server nel sito alternativo, il rilevamento dei LUN e l'avvio del database. È possibile automatizzare il processo completo con il cmdlet di Windows PowerShell, in quanto non sono richieste operazioni dal lato storage.</block>
  <block id="ea7bbefe18f9ad7af62904dd6da19c33" category="inline-link-macro">Non uniforme</block>
  <block id="b53a3ef75c6e33a4f8945589cbe8beee" category="paragraph"><block ref="56d4a3cb11d7ad2b0e560d2cc8afde2c" category="inline-link-macro-rx"></block> è possibile utilizzare anche l'accesso, ma il risultato sarebbe un'interruzione del database se il sistema storage in cui si trovava il server del database non avesse avuto esito positivo, perché il database non avrebbe percorsi disponibili per lo storage. In alcuni casi ciò può ancora essere accettabile. La sincronizzazione attiva di SnapMirror garantirebbe comunque una data Protection con RPO=0 e, in caso di guasto del sito, la copia restante sarebbe attiva e pronta a riprendere le operazioni seguendo la stessa procedura utilizzata con un accesso uniforme descritta sopra.</block>
  <block id="a2e30e760061ab42fd5030c552306712" category="paragraph">Un processo di failover semplice e automatizzato può essere configurato più facilmente con l'uso di un host virtualizzato. Ad esempio, se i file di dati di SQL Server vengono replicati in modo sincrono su storage secondario insieme a un VMDK di avvio, in caso di disastro è possibile attivare l'ambiente completo nel sito alternativo. Un amministratore può attivare manualmente l'host nel sito rimasto o automatizzare il processo tramite un servizio come VMware ha.</block>
  <block id="f04055c72ba32a95b9830308e4508cb1" category="section-title">Istanza del cluster di failover di SQL Server</block>
  <block id="21fd4631916f5c0e63ef67f98d413d6a" category="paragraph">Le istanze di failover di SQL Server possono essere ospitate anche in un cluster di failover di Windows in esecuzione su un server fisico o virtuale come sistema operativo guest. Questa architettura multi-host offre un'istanza di SQL Server e la resilienza dello storage. Tale implementazione è utile in ambienti a domanda elevata che richiedono solidi processi di failover senza rinunciare a prestazioni avanzate. In una configurazione del cluster di failover, quando un host o uno storage primario viene colpito, SQL Services eseguirà il failover sull'host secondario e, allo stesso tempo, lo storage secondario sarà disponibile per servire io. Non è richiesto alcuno script di automazione o intervento dell'amministratore.</block>
  <block id="58daef667c5e83ded89d712a683c532b" category="summary">Microsoft SQL Server e SM: Accesso uniforme</block>
  <block id="b8c5c455d22a62b43bd58615af0a569e" category="paragraph">Una rete ad accesso uniforme significa che gli host sono in grado di accedere ai percorsi su entrambi i siti (o ai domini di errore all'interno dello stesso sito).</block>
  <block id="b7986b8213ecdd63004689cc2dedb163" category="doc">Disaster recovery per Microsoft SQL Server con SnapMirror</block>
  <block id="fdbd6bb11fa9bf15b9e53c8f359e821c" category="list-text">In caso di utilizzo di SMB, la SVM di destinazione deve appartenere allo stesso dominio Active Directory del quale fa parte la SVM di origine, in modo da non interrompere le liste per il controllo degli accessi (ACL) archiviate nei file NAS durante il ripristino in caso di disastro.</block>
  <block id="d5a7d81e3f495111d65621aede2e26a4" category="list-text">L'utilizzo di nomi di volumi di destinazione identici ai nomi di volumi di origine non è necessario, ma può semplificare la gestione del processo di montaggio dei volumi di destinazione nella destinazione. Se viene utilizzato SMB, occorre rendere identico il namespace NAS di destinazione nei percorsi e nella struttura delle directory al namespace di origine.</block>
  <block id="4dd0779e2b7f46c37eb5ec38cdde3bb6" category="list-text">Utilizza la replica sincrona in cui la richiesta di un rapido data recovery è maggiore e soluzioni asincrone per la flessibilità negli RPO.</block>
  <block id="829f5bea960b53b5f1e50e8288a740d4" category="paragraph">La separazione tra il posizionamento degli oggetti logici nei filegroup e i file di database fisici consente di ottimizzare il layout dei file di database, ottenendo il massimo dal sottosistema di storage. Il numero di file di dati che supportano un carico di lavoro può essere variato in base alle necessità per supportare i requisiti di i/o e la capacità prevista, senza influire sull'applicazione. Queste variazioni nel layout del database sono trasparenti per gli sviluppatori di applicazioni, che posizionano gli oggetti del database nei filegroup piuttosto che nei file di database.</block>
  <block id="df42f2a843e18c9b5f6adccba2ffcbf9" category="paragraph">L'attività Esegui manutenzione volume è semplificata in SQL Server 2016 e viene fornita come opzione durante il processo di installazione. In questa figura viene visualizzata l'opzione per concedere al servizio del motore di database di SQL Server il privilegio di eseguire l'attività di manutenzione del volume.</block>
  <block id="8c0ea2438ef8ec6eede8f5ae6996c5a0" category="paragraph">Un'altra importante opzione del database che controlla le dimensioni dei file di database è l'autohrink. Quando questa opzione è attivata, SQL Server riduce regolarmente i file di database, ne riduce le dimensioni e rilascia spazio al sistema operativo. Questa operazione richiede molte risorse ed è raramente utile perché i file di database crescono di nuovo dopo un certo periodo di tempo quando nuovi dati entrano nel sistema. Il collegamento automatico non deve essere attivato nel database.</block>
  <block id="58083df92a650a52d9ea6e4d544ffbd8" category="list-text">Creare la directory di registro dell'host su un volume dedicato in cui SnapCenter copia i registri delle transazioni.</block>
  <block id="42ad46ab967ef7af8287ca8a5c12f2d1" category="paragraph">La sezione seguente illustra le impostazioni della memoria di SQL Server necessarie per ottimizzare le prestazioni del database.</block>
  <block id="4e6b5a65dde214f8e25b7adbac9c9583" category="paragraph">L'opzione memoria massima del server imposta la quantità massima di memoria che l'istanza di SQL Server può utilizzare. Viene generalmente utilizzata se più applicazioni vengono eseguite sullo stesso server in cui SQL Server è in esecuzione e si desidera garantire che queste applicazioni dispongano di memoria sufficiente per funzionare correttamente.</block>
  <block id="fb182faf8ee092092118e8cbb568ae0d" category="paragraph">Alcune applicazioni utilizzano solo la memoria disponibile all'avvio e non richiedono memoria aggiuntiva, anche se sono sotto pressione della memoria. È qui che entra in gioco l'impostazione della memoria massima del server.</block>
  <block id="c7af956e7765f16c090e0eab836fb42a" category="paragraph">L'utilizzo di SQL Server Management Studio per regolare la memoria minima o massima del server richiede il riavvio del servizio SQL Server. È inoltre possibile regolare la memoria del server utilizzando Transact SQL (T-SQL) utilizzando il seguente codice:</block>
  <block id="0abaf38d5c4f997a2507fe6e57682b0b" category="paragraph">L'accesso alla memoria non uniforme (NUMA, non Uniform Memory Access) è una tecnologia di ottimizzazione dell'accesso alla memoria che consente di evitare un carico extra sul bus del processore.</block>
  <block id="87dfe44a851d25873ee6bd0691ac0c6e" category="paragraph">Se NUMA è configurato su un server in cui è installato SQL Server, non è necessaria alcuna configurazione aggiuntiva, in quanto SQL Server è compatibile con NUMA e funziona bene sull'hardware NUMA.</block>
  <block id="7cf384150f5c5317f48125af9bf68c31" category="paragraph">L'opzione di creazione della memoria di indice è un'altra opzione avanzata che non dovrebbe normalmente essere modificata dai valori predefiniti.</block>
  <block id="64e199b7fb089ffb63f4c4396bac2cd1" category="paragraph">Per impostazione predefinita, l'impostazione memoria minima per query assegna &gt;= a 1024KB per ogni query da eseguire. È consigliabile lasciare questa impostazione al valore predefinito per consentire a SQL Server di gestire dinamicamente la quantità di memoria allocata per le operazioni di creazione dell'indice. Tuttavia, se SQL Server dispone di una quantità di RAM superiore a quella necessaria per un'esecuzione efficiente, le prestazioni di alcune query possono essere migliorate se si aumenta questa impostazione. Pertanto, se sul server non viene utilizzata SQL Server, altre applicazioni o il sistema operativo è disponibile memoria, il miglioramento di questa impostazione può contribuire alle prestazioni complessive di SQL Server. Se non è disponibile memoria libera, l'aumento di questa impostazione potrebbe compromettere le prestazioni complessive.</block>
  <block id="d4b44030b0eb9280a0e984cd6565e3b3" category="list-text">Software di backup SnapCenter, inclusi i seguenti componenti:</block>
  <block id="95a3a11e77f5071b2a97b611548b866c" category="paragraph">L'ambito di questa sezione sulle Best practice è limitato alla progettazione tecnica, basata su principi e standard preferenziali che NetApp consiglia per l'infrastruttura di storage. L'implementazione end-to-end non rientra nell'ambito di applicazione.</block>
  <block id="133dcf168b09b98ab4e6c6f77a743a14" category="paragraph">Per informazioni sulla compatibilità tra i prodotti NetApp, vedere <block ref="18e7fcfe606d6d0912191de7fd9eb56a" category="inline-link-macro-rx"></block>.</block>
  <block id="961963c19132b001c6c7289519292be5" category="paragraph">Prima di distribuire SQL Server, è necessario comprendere i requisiti dei carichi di lavoro delle applicazioni supportate dalle istanze dei database di SQL Server. Ogni applicazione ha requisiti differenti in termini di capacità, performance e disponibilità, per cui ogni database dovrebbe essere progettato per supportare al meglio tali requisiti. Molte organizzazioni classificano i database in più Tier di gestione, utilizzando i requisiti delle applicazioni per definire gli SLA. I carichi di lavoro di SQL Server sono spesso classificati come descritto di seguito:</block>
  <block id="d748a2050ea9de15020c9f22e1c8a802" category="list-text">OLTP, che è spesso i database più critici di un'organizzazione. In genere, questi database supportano le applicazioni rivolte ai clienti e sono considerati essenziali per le operazioni chiave dell'azienda. I database OLTP mission-critical e le applicazioni che questi supportano spesso hanno SLA che richiedono performance elevate, sono sensibili al peggioramento delle performance e richiedono la massima disponibilità. Potrebbero anche essere candidati per cluster di failover sempre attivi o gruppi di disponibilità sempre attivi. La combinazione di i/o di questi tipi di database è in genere caratterizzata da una percentuale compresa tra il 75% e il 90% di random Read e tra il 25% e il 10% di scrittura.</block>
  <block id="542d0aad1735dc536565c8a1ec4b579f" category="list-text">Database DSS (Decision Support System), talvolta denominati data warehouse. Questi database sono mission-critical per molte organizzazioni che si affidano alle analytics per il loro business. Questi database sono sensibili all'utilizzo della CPU e alle operazioni di lettura dal disco quando vengono eseguite query. In molte organizzazioni, i database DSS sono i più critici durante la fine di mese, trimestre e anno Questo carico di lavoro ha in genere una combinazione di i/o di lettura quasi del 100% e il throughput io è spesso più importante degli IOPS.</block>
  <block id="af2a7a153f6f4904cc7384604809cf3c" category="paragraph">SQL Server può essere configurato come singola istanza per server o come istanze multiple. La decisione giusta dipende in genere da fattori quali l'utilizzo del server per la produzione o lo sviluppo, indipendentemente dal fatto che l'istanza sia considerata di importanza critica per le operazioni aziendali e gli obiettivi prestazionali.</block>
  <block id="8f66f557400d1222f6352dbc8811ec03" category="paragraph">Le configurazioni delle istanze condivise possono essere inizialmente più semplici da configurare, ma possono causare problemi in cui le risorse vengono divise o bloccate, il che a sua volta causa problemi di prestazioni per altre applicazioni che hanno database ospitati nell'istanza condivisa di SQL Server.</block>
  <block id="40d6bdd2be551c4046e5ad632c4dfe71" category="paragraph">La combinazione delle soluzioni storage ONTAP e Microsoft SQL Server genera design di storage per database di livello Enterprise in grado di soddisfare le più esigenti esigenze applicative odierne.</block>
  <block id="9e020f08745f560c049f43a1b5ead190" category="paragraph">L'ottimizzazione di una soluzione SQL Server su ONTAP richiede la comprensione del modello e delle caratteristiche di i/o di SQL Server. Un layout di storage ben progettato per un database SQL Server deve supportare i requisiti relativi alle performance di SQL Server, offrendo al contempo la massima capacità di gestione dell'infrastruttura nel suo complesso. Un buon layout dello storage permette inoltre di avere successo nell'implementazione iniziale e di far crescere l'ambiente senza problemi nel tempo, con il crescere dell'azienda.</block>
  <block id="9eb2f26da39e165d9e3a1c48b5798690" category="paragraph">i volumi vengono creati e risiedono all'interno degli aggregati. Questo termine talvolta causa confusione perché un volume ONTAP non è un LUN. Un volume ONTAP è un container di gestione per i dati. Un volume può contenere file, LUN o persino oggetti S3. Un volume non occupa spazio, ma viene utilizzato solo per la gestione dei dati contenuti.</block>
  <block id="64999620676d7bc615f88fabe256272f" category="list-text">Se si installa SQL Server su una condivisione SMB, assicurarsi che Unicode sia attivato sui volumi SMB per la creazione delle cartelle.</block>
  <block id="b0874893f6e3e7030833ec488dc9da90" category="list-text">Collocare i file di dati utente <block ref="937f38432beb92fdba3d47780720bdf7" prefix="(" category="inline-code"></block>) su volumi separati perché si tratta di carichi di lavoro di lettura/scrittura casuali. È comune creare backup del log delle transazioni con maggiore frequenza rispetto ai backup del database. Per questo motivo, inserire i file di log delle transazioni <block ref="cb15b9539ae0d984ff8740c68b52561c" prefix="(" category="inline-code"></block>) in un volume separato o VMDK dai file di dati in modo che sia possibile creare pianificazioni di backup indipendenti per ciascuno di essi. Questa separazione isola inoltre l'i/o di scrittura sequenziale dei file di log dall'i/o di lettura/scrittura casuale dei file di dati e migliora significativamente le prestazioni di SQL Server.</block>
  <block id="f7f1cb17ab4960f1a8e4c28a7fbccb0d" category="list-text">Non combinare file di database e non di database, come file di ricerca full-text, sullo stesso LUN.</block>
  <block id="58ccb3e2006ffa82c78944061df94b30" category="paragraph">L'efficienza dello storage di ONTAP è ottimizzata per memorizzare e gestire i dati di SQL Server in modo che utilizzino la minore quantità di spazio di storage senza impatti sulle performance.</block>
  <block id="f250d23ef016c3e48436a679c5dab1df" category="list-text">Non abilitare la deduplica su volumi contenenti file di dati di SQL Server a meno che non si sappia che il volume contiene più copie degli stessi dati, come ad esempio il ripristino del database dai backup su un singolo volume.</block>
  <block id="6f80e9146e2184b9ec3c46b6d7dd903f" category="paragraph">Il conflitto di pagina può verificarsi nelle pagine GAM (Global allocation map), SGAM (Shared Global allocation map) o PFS (page free space) quando SQL Server deve scrivere in pagine di sistema speciali per allocare nuovi oggetti. I fermi bloccano queste pagine in memoria. In un'istanza SQL Server occupata, può essere necessario molto tempo per ottenere un blocco in una pagina di sistema in tempdb. Ciò si traduce in tempi di esecuzione delle query più lenti ed è noto come conflitto di latch. Per la creazione di file di dati tempdb, vedere le procedure consigliate riportate di seguito:</block>
  <block id="255bd5c00b8de4b2f998369f766b2b5e" category="paragraph">Questa sezione riguarda la protezione dei dati remoti, per la quale i dati vengono replicati in un sito remoto ai fini di uno storage offsite sicuro e di un disaster recovery. Si noti che queste tabelle non riguardano la protezione dei dati di mirroring sincrono. Per questo requisito, consultare la documentazione di NetApp MetroCluster tra cui <block ref="06d0604733fc7f7e3f9befaa1239278d" category="inline-link-macro-rx"></block> e. <block ref="87f167af2516b222ddeec7405581e8b8" category="inline-link-macro-rx"></block></block>
  <block id="ad8d77efdce72d372a83929b50a127d1" category="paragraph">Un backup coerente con i crash di un set di dati si riferisce all'acquisizione dell'intera struttura di set di dati in un singolo point-in-time. Se il set di dati è memorizzato in un singolo volume, il processo è semplice ed è possibile creare una Snapshot in qualsiasi momento. Se un set di dati si estende tra i volumi, è necessario creare uno snapshot del gruppo di coerenza (CG). Esistono diverse opzioni per la creazione di snapshot CG, tra cui il software NetApp SnapCenter, le funzionalità native del gruppo di coerenza ONTAP e gli script gestiti dagli utenti.</block>
  <block id="3c27a8d13352bda1e272615270d5faba" category="paragraph">Un backup coerente con i crash di un database si riferisce all'acquisizione dell'intera struttura del database, inclusi i file di dati, i log di ripristino e i file di controllo, in un singolo momento. Se il database è memorizzato in un singolo volume, il processo è semplice ed è possibile creare una Snapshot in qualsiasi momento. Se un database si estende su volumi, è necessario creare uno snapshot del gruppo di coerenza (CG). Esistono diverse opzioni per la creazione di snapshot CG, tra cui il software NetApp SnapCenter, le funzionalità native del gruppo di coerenza ONTAP e gli script gestiti dagli utenti.</block>
  <block id="7589d3d0b42e170fc0a459aba0b87fd6" category="paragraph">VBSR è preferibile quando un database è molto grande o quando deve essere recuperato il più rapidamente possibile, e l'uso di VBSR richiede l'isolamento dei file di dati. In un ambiente NFS, i file di dati di un dato database devono essere archiviati in volumi dedicati che non sono contaminati da alcun altro tipo di file. In un ambiente SAN, i file di dati devono essere memorizzati in LUN dedicate su volumi dedicati. Se viene utilizzato un volume manager (incluso Oracle Automatic Storage Management [ASM]), il gruppo di dischi deve essere dedicato anche ai file di dati.</block>
  <block id="d8c4de538bee7abe14d3527c343afee7" category="paragraph">Se è richiesto un RAC esteso Active-Active, la sincronizzazione attiva di SnapMirror deve essere presa in considerazione al posto di MetroCluster. La replica SM-As consente di preferire una replica specifica dei dati. Pertanto, può essere integrato un cluster RAC esteso in cui tutte le letture avvengono localmente. Gli i/o in lettura non attraversano mai i siti, offrendo la minore latenza possibile. Tutte le attività di scrittura devono comunque transito sulla connessione tra siti, ma tale traffico è inevitabile con qualsiasi soluzione di mirroring sincrono.</block>
  <block id="be6001fc2ab5bfaacf123c0267e58a0a" category="admonition">Se con Oracle RAC vengono utilizzate LUN di avvio, compresi i dischi di avvio virtualizzati,<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> potrebbe essere necessario modificare il parametro. Per ulteriori informazioni sui parametri di timeout RAC, vedere <block ref="1d616ba7dc3776fc2ecabd1cd20f420f" category="inline-link-macro-rx"></block>.</block>
  <block id="2bd32004298994cdcbc5a1672f2b8c95" category="summary">Istanza singola Oracle con sincronizzazione attiva SnapMirror</block>
  <block id="b704207e8ec8f6bbae1764da78cb5232" category="doc">Oracle con sincronizzazione attiva SnapMirror</block>
  <block id="93c480a0b6f335159bf44fcf2e2bec93" category="paragraph">L'utilizzo della sincronizzazione attiva di SnapMirror non aggiunge o modifica necessariamente le procedure consigliate per il funzionamento di un database.</block>
  <block id="30bca7463d8c7b2108be553aabb70549" category="paragraph">La migliore architettura dipende dai requisiti di business. Ad esempio, se l'obiettivo è ottenere una protezione RPO=0:1 contro la perdita di dati, ma l'RTO non è più così semplice, utilizzare i database Oracle Single Instance e replicare le LUN con SM, potrebbe essere sufficiente così come meno costoso da un approccio basato su licenze Oracle. Un guasto del sito remoto non interromperebbe le operazioni e, di conseguenza, la perdita del sito primario porterebbe all'utilizzo di LUN online e pronte per l'uso nel sito rimasto.</block>
  <block id="34ff499afe445b877410a8ae3527a84f" category="paragraph">Se l'RTO fosse più rigoroso, l'automazione Active-passive di base tramite script o cluster come Pacemaker o Ansible migliorerebbe i tempi di failover. Ad esempio, VMware ha può essere configurato in modo da rilevare un guasto della VM nel sito primario e rendere attiva la VM nel sito remoto.</block>
  <block id="63cededd737a118049828e08a2a7e8c7" category="paragraph">Infine, per un failover estremamente rapido, Oracle RAC può essere implementato su più siti. L'RTO sarebbe praticamente pari a zero perché il database sarebbe sempre online e disponibile su entrambi i siti.</block>
  <block id="5d0f4a1c768b6f8fc0a38580e17ef62b" category="summary">Oracle Extended RAC con sincronizzazione attiva SnapMirror</block>
  <block id="596d088e9c01a0ceec54de24c763f7c4" category="paragraph">Molti clienti ottimizzano il proprio RTO estendendo un cluster Oracle RAC tra i vari siti, ottenendo una configurazione completamente Active-Active. La progettazione complessiva diventa più complicata perché deve includere la gestione del quorum di Oracle RAC.</block>
  <block id="c128a5dcb6cee18ff198d2c48937cea1" category="paragraph">Il cluster RAC esteso tradizionale si basava sul mirroring ASM per garantire la protezione dei dati. Questo approccio funziona, ma richiede anche molti passaggi di configurazione manuale e impone un overhead all'infrastruttura di rete. Al contrario, consentendo alla sincronizzazione attiva di SnapMirror di assumersi la responsabilità della replica dei dati, la soluzione risulta notevolmente semplificata. Operazioni quali sincronizzazione, risincronizzazione dopo interruzioni, failover e gestione del quorum sono più semplici, inoltre la SAN non deve essere distribuita tra i siti, semplificando la progettazione e la gestione della SAN.</block>
  <block id="74f82d1e2ecf05353775ddaeb38bcddd" category="paragraph">La chiave per comprendere le funzionalità RAC nella sincronizzazione attiva di SnapMirror è la visualizzazione dello storage come singolo set di LUN che si trovano sullo storage con mirroring. Ad esempio:</block>
  <block id="68dcade92edf97d052fd54be2dc6b60c" category="inline-image-macro">Accesso logico Oracle</block>
  <block id="9c4d005ebe3fb148615bd62837da8194" category="paragraph"><block ref="9c4d005ebe3fb148615bd62837da8194" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b88e2c412773438221951df1b45aa00c" category="paragraph">Nessuna copia primaria o copia speculare. A livello logico, esiste una sola copia di ogni LUN e tale LUN è disponibile nei percorsi SAN che si trovano su due sistemi di storage differenti. Dal punto di vista dell'host, non ci sono failover dello storage e modifiche del percorso. Diversi eventi di errore potrebbero causare la perdita di determinati percorsi verso la LUN, mentre gli altri percorsi rimangono online. La sincronizzazione attiva di SnapMirror garantisce la disponibilità degli stessi dati su tutti i percorsi operativi.</block>
  <block id="31c1d5c6e07b5b3d11e0585af763dc13" category="paragraph">In questa configurazione di esempio, i dischi ASM sono configurati come in qualsiasi configurazione RAC a sito singolo sullo storage Enterprise. Poiché il sistema di storage garantisce la protezione dei dati, viene utilizzata la ridondanza esterna ASM.</block>
  <block id="f016e2bef75fc762898fb65f21fb9836" category="section-title">Accesso uniforme e non privo di informazioni</block>
  <block id="c70bc2caf8d25b4a91254d72909c7e75" category="paragraph">La considerazione più importante con Oracle RAC sulla sincronizzazione attiva di SnapMirror è se utilizzare un accesso uniforme o non uniforme.</block>
  <block id="7cb7fcd446ee1d35aa27d2af5532e2ea" category="paragraph">Un accesso uniforme significa che ogni host può vedere i percorsi su entrambi i cluster. Accesso non uniforme significa che gli host possono vedere solo i percorsi verso il cluster locale.</block>
  <block id="53934f78a11bd68da05d52b4f83ec9fc" category="paragraph">Nessuna delle due opzioni è specificamente consigliata o scoraggiata. Alcuni clienti dispongono prontamente di fibra ottica spenta per la connessione ai siti, altri non dispongono di tale connettività oppure la loro infrastruttura SAN non supporta un ISL a lunga distanza.</block>
  <block id="53772793c4bb5f4dac1c6c0eade7403c" category="section-title">Accesso non uniforme</block>
  <block id="68f708ec0a3f5091f6e432be351bf3cc" category="paragraph">L'accesso non uniforme è più semplice da configurare dal punto di vista della SAN.</block>
  <block id="b923541ce3d0d3feae5be9fb6199f770" category="inline-image-macro">Accesso non uniforme a Oracle RAC</block>
  <block id="b7d64dea0436c64fbd1652575479aa68" category="paragraph"><block ref="b7d64dea0436c64fbd1652575479aa68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58dcba3041e7c7c3352e2c7f9f497eb5" category="inline-link-macro">accesso non uniforme</block>
  <block id="52aa3a00cda7a8077552683f88c13e20" category="paragraph">L'aspetto negativo principale <block ref="56ad9440d84c5145567c05e340b22f93" category="inline-link-macro-rx"></block>dell'approccio è rappresentato dalla perdita della connettività ONTAP sito-sito o dalla perdita di un sistema di storage che causa la perdita delle istanze di database in un singolo sito. Questo ovviamente non è desiderabile, ma potrebbe essere un rischio accettabile in cambio di una configurazione SAN più semplice.</block>
  <block id="4f7fff29e362cc56706e5fe5d34884b6" category="section-title">Accesso uniforme</block>
  <block id="df51b4c411cdf825abbf60c345b2886c" category="paragraph">Un accesso uniforme richiede l'estensione della SAN tra i siti. Il vantaggio principale consiste nel fatto che la perdita di un sistema di storage non provocherà la perdita di un'istanza del database. Al contrario, si otterrebbe una modifica multipathing in cui i percorsi sono attualmente in uso.</block>
  <block id="bb79831252d74e631b0f64224932d6e6" category="paragraph">Esistono diversi modi per configurare l'accesso non uniforme.</block>
  <block id="8ce82023c8f26832db1e79b32f2f7171" category="admonition">Nei diagrammi di seguito sono presenti anche percorsi attivi ma non ottimizzati che sarebbero utilizzati durante semplici guasti del controller, ma tali percorsi non sono mostrati nell'interesse di semplificare i diagrammi.</block>
  <block id="15670c5b41a372b781730d1a2677ed57" category="section-title">AFF con impostazioni di prossimità</block>
  <block id="e2b2f6d768064f58804cd8cb2f295266" category="paragraph">In presenza di una latenza significativa tra i siti, è possibile configurare i sistemi AFF con le impostazioni di prossimità dell'host. In questo modo, ciascun sistema storage può conoscere gli host locali e remoti e assegnare in maniera appropriata le priorità del percorso.</block>
  <block id="5ffb901a29d38d4d4f7c462ffbd0ad7f" category="inline-image-macro">RAC con accesso uniforme</block>
  <block id="efdefb56bfdac6f3b9194f8ce94b9ae9" category="paragraph"><block ref="efdefb56bfdac6f3b9194f8ce94b9ae9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e106da7d1088531e38324a9d76b9a988" category="paragraph">Durante il normale funzionamento, ogni istanza Oracle utilizzerebbe preferenzialmente i percorsi locali attivi/ottimizzati. Il risultato è che tutte le letture saranno gestite dalla copia locale dei blocchi. In questo modo, si ottiene la minore latenza possibile. L'io in scrittura viene analogamente inviato ai percorsi al controller locale. L'io deve ancora essere replicato prima di essere riconosciuto e quindi sarebbe comunque soggetto alla latenza aggiuntiva che attraversa la rete site-to-site, ma ciò non può essere evitato in una soluzione di replica sincrona.</block>
  <block id="889ea87800d5947e36cda77f7d1b16b4" category="section-title">ASA / AFF senza impostazioni di prossimità</block>
  <block id="a92e6cf0c610f6072564d047ffa516be" category="paragraph">In assenza di una latenza significativa tra i siti, è possibile configurare i sistemi AFF senza le impostazioni di prossimità dell'host oppure utilizzare ASA.</block>
  <block id="7760495be1250342ca752bb9cdc684ee" category="paragraph"><block ref="7760495be1250342ca752bb9cdc684ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bad71277bac94b02b8ad4267095b9e1" category="paragraph">Ciascun host sarà in grado di utilizzare tutti i percorsi operativi su entrambi i sistemi storage. Questo consente di migliorare potenzialmente le prestazioni consentendo a ciascun host di sfruttare il potenziale in termini di prestazioni di due cluster, non di uno solo.</block>
  <block id="56473d7f95c121dd938752e3ee76807e" category="paragraph">Con ASA, non solo tutti i percorsi verso entrambi i cluster sono considerati attivi e ottimizzati, ma anche i percorsi sui partner controller sarebbero attivi. Ne risulterebbero percorsi SAN all-Active sull'intero cluster, in qualsiasi momento.</block>
  <block id="22ede275964a6c559bc3f8f6d60e47ff" category="admonition">I sistemi ASA possono anche essere utilizzati in una configurazione di accesso non uniforme. Poiché non esistono percorsi tra siti, non vi sarebbe alcun impatto sulle performance risultanti dall'io che attraversa l'ISL.</block>
  <block id="263e6bb36868a481a8831ae728712452" category="summary">Sincronizzazione attiva di Oracle SnapMirror</block>
  <block id="d1864442faf9b87db487ba86c72892a9" category="paragraph">Gli esempi illustrati di seguito mostrano alcune delle numerose opzioni per la distribuzione dei database Oracle Single Instance con la replica di sincronizzazione attiva SnapMirror.</block>
  <block id="1bd45bc28deaa95af95dd782d94963fa" category="inline-image-macro">Oracle si con accesso non uniforme</block>
  <block id="c94bc93663b0f709f6a6885553fe9153" category="paragraph"><block ref="c94bc93663b0f709f6a6885553fe9153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b29b2b92ebd168fbb013ea878c5c1075" category="paragraph">La sincronizzazione attiva SnapMirror fornisce una copia sincrona dei dati nel sito di disaster recovery, ma la loro disponibilità richiede un sistema operativo e le applicazioni associate. L'automazione di base può migliorare notevolmente il tempo di failover dell'ambiente complessivo. I prodotti Clusterware come Pacemaker vengono spesso utilizzati per creare un cluster in tutti i siti, e in molti casi il processo di failover può essere guidato con semplici script.</block>
  <block id="1e953e50c45ead229eae67ed609a3a1e" category="paragraph">In caso di perdita dei nodi primari, il clusterware (o gli script) porterà i database online nel sito alternativo. Un'opzione è creare server di standby preconfigurati per le risorse SAN che compongono il database. Se il sito primario non funziona, il clusterware o l'alternativa con script esegue una sequenza di azioni simile alle seguenti:</block>
  <block id="861373097ad1daff7221c81f1ffb8bd2" category="list-text">Rileva i guasti del sito primario</block>
  <block id="471eb645214523a67e69f308fd203df5" category="list-text">Rilevamento di LUN FC o iSCSI</block>
  <block id="aaae9cdb1dc3caf850c21cbae6cb7dd9" category="paragraph">La procedura di attivazione effettiva è semplice. Comandi come il rilevamento delle LUN richiedono solo pochi comandi per ogni porta FC. Il montaggio del file system non è altro che un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> comando e sia i database che ASM possono essere avviati e arrestati dalla CLI con un unico comando.</block>
  <block id="81760e5cf8ff0457c9927339fe0d7987" category="list-text">Avviare i database manualmente o configurare le macchine virtuali per avviare automaticamente i database.</block>
  <block id="17ad404af9b36204bcadadd073042e1c" category="paragraph">Ad esempio, un cluster ESX può estendersi su diversi siti. In caso di disastro, dopo lo switchover, è possibile portare online le macchine virtuali nel sito di disaster recovery.</block>
  <block id="06c019e625f0595de8528ac88cab1815" category="section-title">Protezione dai guasti dello storage</block>
  <block id="0559887c95614fe388b0dc7f8914a2db" category="paragraph">Il diagramma precedente mostra l'utilizzo di <block ref="56ad9440d84c5145567c05e340b22f93" category="inline-link-macro-rx"></block>, in cui la SAN non è estesa tra i siti. Questa configurazione potrebbe essere più semplice e, in alcuni casi, potrebbe essere l'unica opzione data le attuali funzionalità SAN, ma significa anche che un guasto del sistema di storage primario causerebbe un'interruzione del database fino a quando l'applicazione non è stata sottoposta a failover.</block>
  <block id="5cbfe7798787ccd0e92fcaceca503314" category="inline-link-macro">accesso uniforme</block>
  <block id="38a1b98129ec5892c90cdda2967b957c" category="paragraph">Per una maggiore resilienza, la soluzione potrebbe essere implementata con <block ref="8c3bdda17267bf34dafd546406201d13" category="inline-link-macro-rx"></block>. Ciò consentirebbe alle applicazioni di continuare a funzionare utilizzando i percorsi pubblicizzati dal sito opposto.</block>
  <block id="d77ca8b041bbb54326491bb1aeb6fadf" category="doc">Sincronizzazione attiva di Oracle e SnapMirror: RAC tiebreaker</block>
  <block id="084a4c8d8d6223c9b3c0749a4097bf8f" category="paragraph">Sebbene il RAC esteso che utilizza la sincronizzazione attiva di SnapMirror sia un'architettura simmetrica rispetto all'io, esiste un'eccezione connessa alla gestione split-brain.</block>
  <block id="f0dd83fae83b5ba13b4e8c760578f47f" category="paragraph">Cosa succede se il collegamento di replica viene perso e nessuno dei due siti ha un quorum? Che cosa dovrebbe accadere? Questa domanda è valida sia per Oracle RAC che per il comportamento di ONTAP. Se non è possibile replicare le modifiche tra i siti e si desidera riprendere le operazioni, uno dei siti dovrà sopravvivere e l'altro sito dovrà diventare non disponibile.</block>
  <block id="58dc7db50a2e11a9de9e6cc092c59d4d" category="inline-link-macro">Mediatore ONTAP</block>
  <block id="406abe933a832eefeb56c0390b824200" category="paragraph">La <block ref="6663df057ff17bcadb83516e8fd742b7" category="inline-link-macro-rx"></block> soddisfa questo requisito al livello ONTAP. Esistono diverse opzioni per RAC Tiebreaking.</block>
  <block id="1a7cedbe5066c42f7f901bffc7905f59" category="section-title">Gli Oracle Tiebreaker</block>
  <block id="236ca78f8e5b54033dbbd133abe79e60" category="paragraph">Il metodo migliore per gestire i rischi di Oracle RAC split-brain consiste nell'utilizzare un numero dispari di nodi RAC, preferibilmente utilizzando un Tiebreaker a 3rd siti. Se un sito 3rd non è disponibile, l'istanza di Tiebreaker potrebbe essere posizionata in un sito dei due siti, designando effettivamente un sito di sopravvivenza preferito.</block>
  <block id="af70ccf0217a2356d2bcebb6fab5a25b" category="section-title">Oracle e css_Critical</block>
  <block id="e7c7cde013ca0177a945b339ca49fe1d" category="paragraph">Con un numero pari di nodi, il comportamento predefinito di Oracle RAC è che uno dei nodi nel cluster sarà considerato più importante degli altri nodi. Il sito con tale nodo con priorità più alta sopravviverà all'isolamento del sito, mentre i nodi sull'altro sito verranno eliminati. La priorità si basa su più fattori, ma è anche possibile controllare questo comportamento utilizzando l'<block ref="6124b1cbe711d49d95a1c41d4e2701b4" prefix=" " category="inline-code"></block>impostazione.</block>
  <block id="1a79a4d60de6718e8e5b326e338ae533" category="inline-link-macro">esempio</block>
  <block id="6ae35dd8ffe888ab910de0d5d5e3a45a" category="paragraph">Nell'<block ref="0a286933b98d5160dd3059338d9fd4c7" category="inline-link-macro-rx"></block>architettura, i nomi host per i nodi RAC sono jfs12 e jfs13. Di seguito sono riportate le impostazioni correnti di<block ref="6124b1cbe711d49d95a1c41d4e2701b4" prefix=" " category="inline-code"></block>:</block>
  <block id="d05ceaa3e91a5aa94cbe7a8ac83ad048" category="paragraph">Se si desidera che il sito con jfs12 sia il sito preferito, impostare questo valore su sì su un nodo del sito A e riavviare i servizi.</block>
  <block id="d7e25fc2f6769b17d752bc3cde6d0266" category="summary">Failover Active Sync di Oracle e SnapMirror</block>
  <block id="f0972b46fa5671c4841c63750ccdebb9" category="doc">Sincronizzazione attiva SnapMirror - perdita della replica di Oracle RAC</block>
  <block id="8a6c7e7b423c27776aad808ff121ced3" category="paragraph">La perdita del collegamento di replica di Oracle RAC produrrà un risultato simile alla perdita della connettività SnapMirror, tuttavia i timeout saranno più brevi per impostazione predefinita. Con le impostazioni predefinite, un nodo Oracle RAC attenderà 200 secondi dopo la perdita della connettività di storage prima dell'eliminazione, ma attenderà solo 30 secondi dopo la perdita dell'heartbeat della rete RAC.</block>
  <block id="488bd272072f6a962dc0b8f69fc362b8" category="paragraph">I messaggi CRS sono simili a quelli illustrati di seguito. È possibile visualizzare il timeout di 30 secondi. Poiché css_Critical è stato impostato su jfs12, situato sul sito A, questo sarà il sito per sopravvivere e jfs13 sul sito B sarà espulso.</block>
  <block id="80f8fcffb7c608c6d25e68111eb38b2d" category="summary">Sincronizzazione attiva di Oracle e SnapMirror - failover manuale</block>
  <block id="0d97f4e7841f881ee429033c005d63ef" category="paragraph">Il termine "failover" non si riferisce alla direzione della replica con la sincronizzazione attiva di SnapMirror perché si tratta di una tecnologia di replica bidirezionale. "Failover" si riferisce invece al sistema di storage preferito in caso di guasto.</block>
  <block id="669420d9776c5672f6a1edf3bbf41604" category="paragraph">Ad esempio, è possibile eseguire un failover per modificare il sito preferito prima di chiudere un sito per la manutenzione o prima di eseguire un test di DR.</block>
  <block id="1a5cda38e5f45bb47ad55cae28a62d58" category="paragraph">Esempio di GUI:</block>
  <block id="dd8c4d4a8c7db09b331d019e9ba3a643" category="inline-image-macro">Clip SystemManager di SM-come sito preferito</block>
  <block id="50925d08482582f6a3178736557a9d6c" category="paragraph"><block ref="50925d08482582f6a3178736557a9d6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="beecd91de8185d21ecef9d430e18d4dc" category="paragraph">Esempio di modifica tramite l'interfaccia CLI:</block>
  <block id="3877a64f9dbc63cfbdca7e30e66c42a2" category="summary">Sincronizzazione attiva di Oracle e SnapMirror - errore mediatore</block>
  <block id="9daff60ceba391d4160d5e54f14037d8" category="paragraph">Il servizio di mediazione non controlla direttamente le operazioni di storage. Funziona come un percorso di controllo alternativo tra cluster. Esiste principalmente per automatizzare il failover senza il rischio di uno scenario split-brain.</block>
  <block id="13ce4a149213a3a389210201d2850f7c" category="paragraph">Durante l'utilizzo normale, ogni cluster replica le modifiche al partner e pertanto ogni cluster può verificare che il cluster partner sia online e fornisca i dati. Se il collegamento di replica non è riuscito, la replica viene interrotta.</block>
  <block id="381c63e25d0de40f5be6677aa1346b0e" category="paragraph">Il motivo per cui è necessario un mediatore per operazioni automatizzate sicure è che altrimenti sarebbe impossibile per i cluster di storage determinare se la perdita di comunicazione bidirezionale fosse il risultato di un'interruzione della rete o di un errore effettivo dello storage.</block>
  <block id="e51e3b7c6dff02b4ab76ceab7b000eb8" category="list-text">In caso di guasto dei servizi di replica per qualsiasi motivo, il sito preferito rilascerà lo stato RPO=0 e riprenderà l'elaborazione i/o in lettura e scrittura. Il sito non preferito prenderà i suoi percorsi offline.</block>
  <block id="957e90f10d8268ba74dc866bec3ed2fa" category="doc">SnapMirror Active Sync - perdita totale di connettività</block>
  <block id="4470e5dd55a8a6253ccfd5dca462e193" category="paragraph">Se il collegamento di replica tra i siti viene perso completamente, la sincronizzazione attiva di SnapMirror e la connettività Oracle RAC verranno interrotte.</block>
  <block id="cd48b65842aa3ca6718bf9d05c82a272" category="paragraph">Il rilevamento split-brain di Oracle RAC dipende dall'heartbeat dello storage di Oracle RAC. Se la perdita della connettività da sito a sito determina la perdita simultanea dei servizi di replica dello storage e heartbeat della rete RAC, i siti RAC non saranno in grado di comunicare tra siti tramite RAC Interconnect o i dischi di voto RAC. Il risultato in un insieme di nodi pari-numerati può essere l'esclusione di entrambi i siti nelle impostazioni di default. Il comportamento esatto dipende dalla sequenza degli eventi e dalla tempistica dei sondaggi della rete RAC e degli heartbeat del disco.</block>
  <block id="d76ecbc1eb83c7a69064a5bb857c85c9" category="inline-link-macro">tiebreaker</block>
  <block id="acef32b29f0767a38d288d2517fd82e4" category="paragraph">È possibile risolvere il rischio di un'interruzione dei servizi dei siti 2 in due modi. In primo luogo, è possibile utilizzare una <block ref="5eea39840e87052aa3c632ea60116716" category="inline-link-macro-rx"></block> configurazione.</block>
  <block id="f52f16ab0735aaefebdd18f6be0a1d9a" category="paragraph">Se non è disponibile un sito 3rd, questo rischio può essere risolto regolando il parametro misscount sul cluster RAC. Per impostazione predefinita, il timeout heartbeat della rete RAC è di 30 secondi. Normalmente viene utilizzato dal RAC per identificare i nodi RAC guasti e rimuoverli dal cluster. Ha anche una connessione al disco di voto heartbeat.</block>
  <block id="c2b5462b64e9fc5a5b57a31b233c8857" category="paragraph">Se, ad esempio, il condotto che trasporta il traffico tra i siti per Oracle RAC e i servizi di replica dello storage viene tagliato da un retroescavatore, inizia il conto alla rovescia per gli errori di 30 secondi. Se il nodo del sito preferito RAC non riesce a ristabilire il contatto con il sito opposto entro 30 secondi e non può utilizzare i dischi di voto per confermare che il sito opposto non sia attivo entro la stessa finestra di 30 secondi, anche i nodi del sito preferito verranno eliminati. Il risultato è un'interruzione completa del database.</block>
  <block id="db651e89ed200f74c11c1ae1c5d2b32d" category="paragraph">A seconda di quando si verifica il polling dell'errore scount, 30 secondi potrebbero non essere sufficienti per il timeout della sincronizzazione attiva SnapMirror e consentire allo storage sul sito preferito di riprendere i servizi prima della scadenza della finestra di 30 secondi. Questa finestra di 30 secondi può essere aumentata.</block>
  <block id="dbdaf8435bc0aa414eca4876e6c308d2" category="paragraph">Questo valore consente al sistema di storage sul sito preferito di riprendere le operazioni prima della scadenza del timeout per il conteggio degli errori. Il risultato sarà quindi l'eliminazione solo dei nodi nel sito in cui sono stati rimossi i percorsi LUN. Esempio seguente:</block>
  <block id="e231fb490ed068ec9b23beb7dd95220e" category="paragraph">Oracle Support sconsiglia vivamente di modificare i parametri misscount o disktimeout per risolvere i problemi di configurazione. La modifica di questi parametri può tuttavia essere garantita e inevitabile in molti casi, incluso l'avvio SAN, la virtualizzazione e le configurazioni di replica dello storage. Se, ad esempio, si sono verificati problemi di stabilità con una rete SAN o IP che hanno provocato estrazioni RAC, è necessario risolvere il problema sottostante e non caricare i valori di misscount o disktimeout. La modifica dei timeout per correggere gli errori di configurazione è mascherare un problema, non risolvere un problema. La modifica di questi parametri per configurare correttamente un ambiente RAC in base agli aspetti di progettazione dell'infrastruttura sottostante è diversa ed è coerente con le istruzioni di supporto di Oracle. Con l'avvio SAN, è comune regolare misscount fino a 200 per far corrispondere disktimeout. Per ulteriori informazioni, vedere<block ref="ba774c2123df7855b7691ef15a557a8c" category="inline-link-macro-rx"></block>.</block>
  <block id="cb5f127f654db8aa1847f5e9e6c5118e" category="summary">Sincronizzazione attiva di Oracle e SnapMirror - ripristino del servizio</block>
  <block id="894265e54aece56ce813211a980cdfe2" category="paragraph">SnapMirror è a riparazione automatica. La sincronizzazione attiva di SnapMirror rileva automaticamente la presenza di una relazione di replica difettosa e la riporta allo stato RPO=0. Una volta ristabilita la replica sincrona, i percorsi torneranno online.</block>
  <block id="c512ae64a9e9927a6314fdd926760a72" category="paragraph">In molti casi, le applicazioni in cluster rilevano automaticamente la restituzione dei percorsi non riusciti e tali applicazioni tornano online. In altri casi, potrebbe essere necessaria una scansione SAN a livello di host oppure potrebbe essere necessario riportare le applicazioni online manualmente.</block>
  <block id="c83e8f0dcd2a1773693ac06c752f2ddd" category="paragraph">Dipende dall'applicazione e dal modo in cui è configurata, e in generale tali attività possono essere facilmente automatizzate. La sincronizzazione attiva di SnapMirror stessa risolve automaticamente il problema e non richiede alcun intervento da parte dell'utente per ripristinare l'RPO = 0 operazioni di storage una volta ripristinata l'alimentazione e la connettività.</block>
  <block id="b55bb91b49684d644a2314af260f5584" category="doc">Architettura di esempio Oracle con sincronizzazione attiva SnapMirror</block>
  <block id="8ba2bb4ebd97f28e7d98a180d8b06c1a" category="paragraph">Gli esempi dettagliati di guasto illustrati in questa sezione si basano sull'architettura illustrata di seguito.</block>
  <block id="5d10516d162cd9f09cf5dc249d499836" category="admonition">Questa è solo una delle numerose opzioni per i database Oracle su SnapMirror Active Sync. Questo disegno è stato scelto perché illustra alcuni degli scenari più complicati.</block>
  <block id="ce2a1d07c1660eb99608e2aeb9ffda20" category="inline-link-macro">sito preferito</block>
  <block id="93d235b3b3adb1fcc631cc9720911156" category="paragraph">In questa configurazione, si supponga che il sito A sia impostato su <block ref="0a07e9e6141ed78f0b7013768c76c4a9" category="inline-link-macro-rx"></block>.</block>
  <block id="3f35d87b783da3d0c6ab04c2222e88cc" category="inline-image-macro">Esempio di Oracle su progettazione SM-AS</block>
  <block id="65d5312cbb5d7497db9571af7d19e76d" category="paragraph"><block ref="65d5312cbb5d7497db9571af7d19e76d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af82c537bd0f6778b9916dc78da8c55a" category="paragraph">Il risultato di un errore del sistema di storage o della sede è quasi identico al risultato della perdita del collegamento di replica. Il sito sopravvissuto dovrebbe subire una pausa io di circa 15 secondi sulle scritture. Trascorso questo periodo di 15 secondi, io riprenderà sul sito come di consueto.</block>
  <block id="24f2945a7c742e126cdf5dcdfb08ec89" category="paragraph">Se il problema riguarda solo il sistema storage, il nodo Oracle RAC del sito guasto perderà i servizi di storage e inserirà lo stesso conto alla rovescia di 200 secondi per il disktime, prima dell'eliminazione e del successivo riavvio.</block>
  <block id="0cff2ae5f5c305f11d8d8a333bd1da2c" category="paragraph">Lo stato del percorso SAN sul nodo RAC che ha perso i servizi storage è simile al seguente:</block>
  <block id="e33921fb5e166f433573176882c09294" category="paragraph">L'host linux ha rilevato la perdita dei percorsi molto più velocemente di 200 secondi, ma dal punto di vista del database le connessioni client all'host sul sito guasto saranno ancora bloccate per 200 secondi sotto le impostazioni predefinite di Oracle RAC. Le operazioni complete del database riprenderanno solo dopo che l'eviction è stata completata.</block>
  <block id="db34db4ac9bd7910a9eded83e1ff30f9" category="paragraph">Nel frattempo, il nodo RAC di Oracle sul sito opposto registrerà la perdita dell'altro nodo RAC. In caso contrario, continua a funzionare come di consueto.</block>
  <block id="ad08bdae586fc05e13eff6bd6d9f0ee2" category="paragraph">Se il collegamento di replica sincrona attiva di SnapMirror, l'io in scrittura non può essere completato perché sarebbe impossibile per un cluster replicare le modifiche al sito opposto.</block>
  <block id="564a95e2696af68aa1c3a4953ecd1ce9" category="section-title">Sito A</block>
  <block id="18fe52a46fad1fa4c9873ea81b6e885f" category="paragraph">Il risultato sul sito A di un errore del collegamento di replica sarà una pausa di circa 15 secondi nell'elaborazione io in scrittura, poiché ONTAP tenta di replicare le scritture prima di determinare che il collegamento di replica è veramente inutilizzabile. Trascorsi i 15 secondi, il cluster ONTAP sul sito A riprende l'elaborazione i/o in lettura e scrittura. I percorsi SAN non vengono modificati e i LUN rimangono online.</block>
  <block id="657e60cc43634129c8f9314afdd5c48b" category="paragraph">Il collegamento di replica è stato tagliato alla data e ora 15:19:44. Il primo avviso da Oracle RAC arriva 100 secondi dopo l'avvicinarsi del timeout di 200 secondi (controllato dal disktimeout del parametro di Oracle RAC).</block>
  <block id="f29d4b902de1f9de93b8673047367cb3" category="paragraph">Una volta raggiunto il timeout del disco di voting di 200 secondi, il nodo Oracle RAC verrà rimosso dal cluster e riavviato.</block>
  <block id="b864ca7c3ca6173547e4a66ba059c688" category="summary">Oracle,SM-as,Active Sync,mediatore</block>
  <block id="01682ebdcacbc827e3ef8083e7b4c060" category="summary">Accesso non uniforme a Oracle e SM</block>
  <block id="f6dbb06140585fe45ddeaf49cae9418e" category="summary">Sincronizzazione attiva di Oracle e SnapMirror</block>
  <block id="d6e7dde9799f39cece01cbc4b2728cdf" category="paragraph">SnapMirror Active Sync ti consente di creare ambienti di database Oracle a disponibilità ultra elevata in cui le LUN sono disponibili da due cluster di storage diversi.</block>
  <block id="13645bda5e7e84c7e547caee4c6325b2" category="paragraph">Con la sincronizzazione attiva di SnapMirror, non vi è alcuna copia "primaria" e "secondaria" dei dati. Ogni cluster può fornire i/o in lettura dalla propria copia locale dei dati e ciascun cluster replicherà una scrittura al partner. Il risultato è un comportamento io simmetrico.</block>
  <block id="36b94662a6696bbaee0152aefe40ed13" category="paragraph">Tra le altre opzioni, questo consente di eseguire Oracle RAC come cluster esteso con istanze operative su entrambi i siti. In alternativa, è possibile creare cluster di database attivi-passivi RPO=0 in cui è possibile spostare i database a singola istanza tra i siti durante un'interruzione del sito e questo processo può essere automatizzato tramite prodotti come Pacemaker o VMware ha. La base di queste opzioni è la replica sincrona gestita dalla sincronizzazione attiva di SnapMirror.</block>
  <block id="d1a363496283d60774ff9c9c51ffe653" category="paragraph">Durante il funzionamento normale, la sincronizzazione attiva di SnapMirror fornisce sempre RPO=0 replica sincrona, con un'eccezione. Se i dati non possono essere replicati, ONTAP rilascerà il requisito di replicare i dati e riprendere la distribuzione io su un sito mentre le LUN dell'altro sito vengono portate offline.</block>
  <block id="72f31f711b37dc7ce7b34e00dd56b5ae" category="paragraph">ONTAP Mediator è un'applicazione software che viene scaricata dal supporto NetApp e che viene in genere distribuita su una piccola macchina virtuale. Il ONTAP Mediator non è un Tiebreaker quando viene utilizzato con la sincronizzazione attiva di SnapMirror. È un canale di comunicazione alternativo per i due cluster che partecipano alla replica sincrona attiva SnapMirror. Le operazioni automatizzate sono gestite da ONTAP in base alle risposte ricevute dal partner tramite connessioni dirette e tramite il mediatore.</block>
  <block id="b06e5b68abe4f23a716133f1fa1a4472" category="summary">Oracle e SM-come sito preferito</block>
  <block id="6d14548094c3b2a5b0a69049f8497fa8" category="doc">Oracle e SM: Come accesso uniforme</block>
  <block id="36ba939f32969ddc6751427944e3569d" category="paragraph">Il requisito più importante è l'isolamento dei dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. Il motivo è accertarsi che la replica dei file dati sia completamente indipendente dalla replica di altri tipi di dati, come i registri di archivio. Per ulteriori informazioni sui layout dei file e per informazioni importanti su come garantire che il layout di archiviazione sia intuitivo, vedere <block ref="c87a7212960b8cc2aca49adb1795e291" category="inline-link-macro-rx"></block>.</block>
  <block id="64c93f87be857cf43f66e341a377693a" category="paragraph">Il sistema operativo è in grado di rilevare che<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> e<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> si trovano sullo stesso volume, che è lo stesso file system di origine. Il sistema operativo utilizza quindi lo stesso handle di dispositivo per l'accesso ai dati. In questo modo si migliora l'uso della cache del sistema operativo e di alcune altre operazioni, ma interferisce con DNFS. Se DNFS deve accedere a un file, come ad esempio<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> , on ,<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> potrebbe erroneamente tentare di utilizzare il percorso errato dei dati. Il risultato è un'operazione i/o non riuscita. In queste configurazioni, Aggiungi l'<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>opzione di montaggio a qualsiasi file system NFS che condivide un volume di origine con un altro file system NFS su quell'host. In questo modo, il sistema operativo Linux assegna un handle di dispositivo indipendente al file system.</block>
  <block id="30d0582d4c5a0b280454304dcff9c28f" category="paragraph">Solaris 11 ha introdotto una modifica nel modo in cui elabora operazioni i/o di grandi dimensioni, che può causare gravi problemi di prestazioni sugli array di storage SAN. Il problema è documentato nel rapporto 630173 del bug di monitoraggio di NetApp, "regressione delle prestazioni di Solaris 11 ZFS".</block>
  <block id="c041cd46ed4caba0947ab494ac5bb1d9" category="paragraph">Questo non è un bug di ONTAP. Si tratta di un difetto di Solaris rilevato in Solaris Defects 7199305 e 7082975.</block>
  <block id="a83650b3549679a1591275f0f9cd38e0" category="paragraph">È possibile consultare il supporto Oracle per scoprire se la versione di Solaris 11 in uso è interessata o per verificare la soluzione alternativa, passando<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block> a un valore inferiore.</block>
  <block id="65711e429e82120028dff2df28b4b92d" category="paragraph">È possibile farlo eseguendo il seguente comando come root:</block>
  <block id="f0eff8c4d89b44c0cf8b8c323abeaa20" category="paragraph">Se è necessario un processo offline, ritardare il riscoperta o il riavvio dei servizi finché il comando non<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> indica che la migrazione è stata completata correttamente. È quindi possibile completare il processo di migrazione come descritto in <block ref="bfe85b0236d22bff0d0d13e4e3fecb98" category="inline-link-macro-rx"></block>.</block>
  <block id="dbd3f1a817d137c052ec01ef60940131" category="inline-link">Documentazione per l'importazione dei LUN esteri di ONTAP</block>
  <block id="1e63fd2b99b2fef1f5d2ae61ebd5b4a3" category="paragraph">Le procedure per migrare LE risorse SAN utilizzando FLI sono documentate in NetApp<block ref="3a5bd22edab525577a3f095f01c2551b" category="inline-link-rx"></block> .</block>
  <block id="4fc57ef291a6bc6be0f3f8c81e4f9b44" category="paragraph">Il diagramma di flusso riportato di seguito mostra i tipi di considerazioni sul percorso di migrazione più adatto. È possibile fare clic con il pulsante destro del mouse sull'immagine e aprirla in una nuova scheda per migliorare la leggibilità.</block>
  <block id="17ed98f652bb960b10b3357e44785f38" category="inline-image-macro">Diagramma di flusso della migrazione</block>
  <block id="f420007a3c90420b30780388a0e05dbc" category="paragraph"><block ref="6ee66f70cd2b82e9dd03128a50a38de9" category="inline-image-macro-rx" type="image"></block>.</block>
  <block id="fb3e908ec44ab0657a364e90a649adee" category="admonition">Consultare la nota relativa a<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> in <block ref="6ada863f3548cecdf5d7a06e9c4201cd" category="inline-link-macro-rx"></block> per un problema DNFS specifico di Linux che può produrre risultati insoliti.</block>
  <block id="7dde30333f2f14b8935a6f394318dd19" category="paragraph">Direttiva non risolta in &lt;stdin&gt; - include::lun-alignment.adoc[]</block>
  <block id="baeaebf1ec4083a8b5a2278617a67479" category="paragraph">Vedere anche la discussione sull'allineamento dei blocchi di compressione nella sezione <block ref="936e7f76dd05eeca0e082776361dee38" category="inline-link-macro-rx"></block>. Qualsiasi layout allineato ai limiti del blocco di compressione 8KB è allineato ai limiti 4KB.</block>
  <block id="62cc2062c0bb14fd9ee41267e11b9824" category="paragraph">Direttiva non risolta in &lt;stdin&gt; - include::database-misalignment-warnings.adoc[]</block>
  <block id="779e77f14b9599d3021cc1c978703d8e" category="paragraph">Le piattaforme di gestione dei dati NetApp basate su ONTAP sono alcune delle soluzioni di storage per SRM più ampiamente adottate. I motivi sono molteplici: Una piattaforma per la gestione dei dati sicura, dalle performance elevate e protocollo unificato (NAS e SAN insieme) che offre efficienza dello storage definita dal settore, multitenancy, controlli della qualità del servizio, protezione dei dati con snapshot efficienti in termini di spazio e replica con SnapMirror. Tutto questo sfrutta l'integrazione multi-cloud ibrida nativa per la protezione dei carichi di lavoro VMware e una vasta gamma di strumenti di automazione e orchestrazione a portata di mano.</block>
  <block id="f05beeac7e71de747ac87dd710b5100f" category="list-text">Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia questo plug-in quando si utilizza vSphere con sistemi che eseguono ONTAP.</block>
  <block id="0452707f6213531bbf4f41e5f16cdead" category="paragraph">Il cloning può essere scaricato sui sistemi che eseguono ONTAP attraverso diversi meccanismi, generalmente a livello di VM, vVol o datastore. Questi includono quanto segue:</block>
  <block id="a4ec3dfc79c8493b1e9fcaee6b06b5a8" category="summary">ONTAP dispone di un ampio supporto per il cloud ibrido.</block>
  <block id="14f3c0fa1399e57b5998b528cc5f3515" category="paragraph">ONTAP è, tra l'altro, un array NAS scale-out di livello Enterprise. ONTAP consente a VMware vSphere di accedere contemporaneamente agli archivi dati connessi a NFS da numerosi host ESXi, superando di gran lunga i limiti imposti ai file system VMFS. L'utilizzo di NFS con vSphere offre alcuni vantaggi in termini di facilità di utilizzo e di visibilità dell'efficienza dello storage, come menzionato nella <block ref="72b655a9973dbed02099f5e63762d591" category="inline-link-macro-rx"></block>sezione.</block>
  <block id="8fabf36e54be557b0b3c16cc181ccef7" category="paragraph">SLM limita i nodi che pubblicizzano i percorsi a una determinata LUN. È una Best practice di NetApp avere almeno una LIF per nodo per SVM e utilizzare SLM per limitare i percorsi pubblicizzati al nodo che ospita la LUN e il suo partner ha. Sebbene esistano altri percorsi, essi non vengono pubblicizzati per impostazione predefinita. È possibile modificare i percorsi pubblicizzati con gli argomenti del nodo di reporting add e remove all'interno di SLM. Tenere presente che le LUN create nelle release precedenti alla 8.3 pubblicizzano tutti i percorsi e devono essere modificate solo per pubblicizzare i percorsi alla coppia ha di hosting. Per ulteriori informazioni su SLM, vedere la sezione 5,9 di<block ref="a2bae1e6a9d1ce7703c1f95bb6ec1d6e" category="inline-link-rx"></block>. Il precedente metodo di portset può essere utilizzato anche per ridurre ulteriormente i percorsi disponibili per un LUN. I portset aiutano a ridurre il numero di percorsi visibili attraverso i quali gli iniziatori in un igroup possono vedere le LUN.</block>
  <block id="0783a52eeafbf6085600efe3ac209a9c" category="paragraph">I sistemi che eseguono ONTAP supportano tutti i principali protocolli di storage, consentendo ai clienti di scegliere il miglior ambiente per il proprio ambiente, a seconda dell'infrastruttura di rete esistente e pianificata e delle competenze dello staff. I test di NetApp hanno generalmente mostrato poca differenza tra i protocolli eseguiti a velocità di linea simili, pertanto è meglio concentrarsi sull'infrastruttura di rete e sulle funzionalità del personale rispetto alle performance del protocollo raw.</block>
  <block id="ef7f5a0b4e0866202a92874cc85a2fd2" category="list-text">Le macchine virtuali che richiedono una migrazione più accurata includono database e applicazioni che utilizzano lo storage collegato. In generale, considerare l'utilizzo degli strumenti dell'applicazione per gestire la migrazione. Per Oracle, prendere in considerazione l'utilizzo di strumenti Oracle come RMAN o ASM per migrare i file di database. Per ulteriori informazioni, vedere<block ref="74eec9db95a0d18126c677c2dcc1d6f1" category="inline-link-rx"></block> . Allo stesso modo, per SQL Server, prendere in considerazione l'utilizzo di SQL Server Management Studio o di strumenti NetApp come SnapManager per SQL Server o SnapCenter.</block>
  <block id="4adbfc6cb6ee114e186e01168d24a89b" category="paragraph">La Best practice più importante quando si utilizza vSphere con sistemi che eseguono ONTAP è quella di installare e utilizzare i tool ONTAP per il plug-in VMware vSphere (precedentemente noto come Virtual Storage Console). Questo plug-in vCenter semplifica la gestione dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi di dati e ottimizza le impostazioni degli host ESXi per i timeout multipath e HBA (descritti nell'Appendice B). Poiché si tratta di un plug-in vCenter, è disponibile per tutti i client web vSphere che si connettono al server vCenter.</block>
  <block id="8c796e9ce33123891311630e9843b227" category="paragraph">La configurazione delle impostazioni di rete quando si utilizza vSphere con sistemi che eseguono ONTAP è semplice e simile ad altre configurazioni di rete. Ecco alcuni aspetti da considerare:</block>
  <block id="14089d94b95e85f3c910fdfee996412f" category="list-text">NetApp consiglia di disattivare il controllo del flusso di rete solo sulle porte di rete del cluster all'interno di un cluster ONTAP. NetApp non fornisce altri consigli sulle Best practice per le restanti porte di rete utilizzate per il traffico dati. Attivare o disattivare secondo necessità. Vedere<block ref="3455dc2b3e7cd12a38e508bec690aa67" category="inline-link-rx"></block> per ulteriori informazioni sul controllo di flusso.</block>
  <block id="0ced8c876dd50237bb9d7be301c0041e" category="paragraph">Infine, per il massimo livello di protezione dei dati, prendere in considerazione una configurazione VMware vSphere Metro Storage Cluster (vMSC) che utilizza NetApp MetroCluster. VMSC è una soluzione certificata VMware che combina la replica sincrona con il clustering basato su array, offrendo gli stessi vantaggi di un cluster ad alta disponibilità ma distribuita in siti separati per la protezione contro il disastro del sito. NetApp MetroCluster offre configurazioni convenienti per la replica sincrona con ripristino trasparente da qualsiasi guasto di un componente di storage singolo e ripristino a comando singolo in caso di disastro del sito. VMSC è descritto in maggior dettaglio nella .<block ref="252912db8b98e51588a897ab91b985e0" category="inline-link-rx"></block></block>
  <block id="49dd4c85a332616209949697018e3112" category="paragraph">I sistemi che eseguono ONTAP semplificano la protezione di qualsiasi dato grazie alla crittografia a riposo. NetApp Storage Encryption (NSE) utilizza dischi con crittografia automatica e ONTAP per proteggere i dati SAN e NAS. NetApp offre inoltre NetApp Volume Encryption e NetApp aggregate Encryption come approccio semplice e basato su software per crittografare i volumi su qualsiasi disco. Questa crittografia software non richiede unità disco speciali o gestori di chiavi esterne ed è disponibile per i clienti ONTAP senza costi aggiuntivi. È possibile eseguire l'upgrade e iniziare a utilizzarlo senza alcuna interruzione per i client o le applicazioni e sono validati in base allo standard FIPS 140-2 livello 1, incluso il gestore delle chiavi integrato.</block>
  <block id="66149c951df015fb5f7aa252fa92bf64" category="paragraph">La configurazione delle impostazioni di rete quando si utilizza vSphere con sistemi che eseguono ONTAP è semplice e simile ad altre configurazioni di rete.</block>
  <block id="cd03a9a043676fafd38958ae11e85ca8" category="list-text">NetApp consiglia di disattivare il controllo del flusso di rete solo sulle porte di rete del cluster all'interno di un cluster ONTAP. NetApp non fornisce altri consigli sulle Best practice per le restanti porte di rete utilizzate per il traffico dati. Se necessario, è necessario attivarlo o disattivarlo. Vedere<block ref="3455dc2b3e7cd12a38e508bec690aa67" category="inline-link-rx"></block> per ulteriori informazioni sul controllo di flusso.</block>
  <block id="2fd6bc533dedf28bc2b73262be20ec88" category="list-text">*Archiviazione unificata.* I sistemi che eseguono ONTAP sono unificati in diversi modi significativi. In origine, questo approccio si riferiva ai protocolli NAS e SAN e ONTAP continua a essere una piattaforma leader per SAN insieme alla sua forza originale nel NAS. Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono ONTAP sono di solito meno costosi per VSI rispetto agli array aziendali tradizionali e allo stesso tempo dispongono di funzionalità avanzate per l'efficienza dello storage per gestire l'infrastruttura di desktop virtuale nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un array SATA per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="bfcd75cb17a665212ae0889e787a7330" category="paragraph">I sistemi che eseguono ONTAP possono utilizzare la funzionalità di qualità del servizio di storage per limitare il throughput in Mbps e/o i/o al secondo (IOPS) per diversi oggetti di storage come file, LUN, volumi o intere SVM.</block>
  <block id="5c60617d5730a7a614bfa0383a2affbd" category="admonition">Questo non si applica ai vVol.</block>
  <block id="b78488659ce8aad3288a0ad7f27c84fb" category="admonition">VVol richiede l'utilizzo dei tool ONTAP per VMware vSphere, che funziona come provider VASA per ONTAP. Fare riferimento a <block ref="2486a36e844a24e9d1cf22351b1f1514" category="inline-link-macro-rx"></block> per le procedure consigliate per i vVol.</block>
  <block id="58da89a03db394d8f73b6516f5a75882" category="paragraph">ONTAP QoS e VMware vSphere Storage i/o Control (SIOC) sono tecnologie complementari che gli amministratori di vSphere e dello storage possono utilizzare insieme per gestire le performance delle VM vSphere ospitate in sistemi che eseguono ONTAP. Ogni strumento ha i propri punti di forza, come mostrato nella tabella seguente. A causa dei diversi ambiti di VMware vCenter e ONTAP, alcuni oggetti possono essere visti e gestiti da un sistema e non dall'altro.</block>
  <block id="bf0dee50832ba16a28008161612fd476" category="paragraph">ONTAP unifica lo storage tramite un approccio software-defined semplificato per una gestione sicura ed efficiente, performance migliorate e una perfetta scalabilità. Questo approccio migliora la protezione dei dati e consente un uso efficace delle risorse cloud.</block>
  <block id="4021b205a984157ad20475f3b9a2555c" category="paragraph">Una Storage Virtual Machine (SVM) è l'unità di multi-tenancy sicura in ONTAP. Si tratta di un costrutto logico che consente l'accesso client ai sistemi che eseguono ONTAP. Le SVM possono servire i dati contemporaneamente attraverso più protocolli di accesso ai dati tramite le interfacce logiche (LIF). Le SVM forniscono l'accesso ai dati a livello di file attraverso protocolli NAS, come CIFS e NFS, e l'accesso ai dati a livello di blocco attraverso protocolli SAN, come iSCSI, FC/FCoE e NVMe. Le SVM possono fornire dati ai client SAN e NAS in modo indipendente e con S3.</block>
  <block id="a6848cf51eef6140971685faf5c7a111" category="paragraph">Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono ONTAP sono di solito meno costosi per VSI rispetto agli array aziendali tradizionali e allo stesso tempo dispongono di funzionalità avanzate per l'efficienza dello storage per gestire l'infrastruttura di desktop virtuale nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un array SATA per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="57ee1b10de81b96324fc044045bf301b" category="paragraph">ONTAP Tools per VMware vSphere è un insieme di strumenti per l'utilizzo dello storage ONTAP insieme a vSphere. Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia di utilizzare questi strumenti ONTAP come Best practice quando si utilizza vSphere con sistemi che eseguono ONTAP. Include un'appliance server, estensioni dell'interfaccia utente per vCenter, VASA Provider e Storage Replication Adapter. Quasi tutto ciò che è contenuto negli strumenti ONTAP può essere automatizzato utilizzando semplici API REST, utilizzabili dalla maggior parte dei moderni strumenti di automazione.</block>
  <block id="3a5159fa23e450460f03e5a885a6c51c" category="paragraph">*[NOTA]</block>
  <block id="d235766de3bd77aa4983181862c135d7" category="admonition">In questo scenario non vi sono cambiamenti nel comportamento di MetroCluster e tutti i datastore continuano a essere intatti dai rispettivi siti.</block>
  <block id="14d627875de76f84985b8a3b27c96633" category="list-text">Durante questo periodo, non si verifica alcun impatto sulle operazioni di i/o della macchina virtuale, tuttavia le performance sono peggiorate a causa dell'accesso ai dati dallo shelf di dischi remoto attraverso link ISL.</block>
  <block id="290cbdcb6abb203d45786213f3c43662" category="admonition">Durante questo periodo, le macchine virtuali rimangono in esecuzione e in questo scenario non si verifica alcuna modifica nel comportamento di MetroCluster. Tutti i datastore continuano a essere intatti dai rispettivi siti.</block>
  <block id="9a18dc3c2c9a217a632ca45b5b93a004" category="admonition">Il master ha non avvia i tentativi di riavvio fino a quando il placement manager non trova lo storage appropriato, quindi in caso di un guasto completo del sito, ciò si verificherebbe dopo l'esecuzione dello switchover.</block>
  <block id="e3f530e977d74053c6d70eb84886e756" category="sidebar">EPIC</block>
  <block id="faeaec9eda6bc4c8cb6e1a9156a858be" category="sidebar">Disponibilità</block>
  <block id="4289ad5c614f8037a8810e869b56facd" category="sidebar">Consolidamento</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Scalabilità</block>
  <block id="86a69bd2f501f95ed83bb7014fac7e30" category="sidebar">Snapshot e cloning</block>
  <block id="58bc025e75c4b3fd1adf3ea672dd4424" category="sidebar">Architettura e design epici</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="sidebar">Dimensionamento</block>
  <block id="41b36522e1e1020bad35b072e2f4caeb" category="sidebar">Requisiti di storage</block>
  <block id="ddb04c3c1835c48b34dced1c453450e9" category="sidebar">Configurazione e Best practice</block>
  <block id="3e23b54348b2b8424e24a426570dc9f2" category="sidebar">Utility host</block>
  <block id="6e19e43ad6dccde81e8d288a0c9ce380" category="sidebar">Configurazione del LUN e del volume</block>
  <block id="a2ddb4431dcf2a898d386c1f3b82c926" category="sidebar">Servizi di file</block>
  <block id="9985b4390c40137573e6da05caf85874" category="sidebar">Protocolli</block>
  <block id="894445e8ea6df545bfbc4247797a2162" category="sidebar">Dimensionamento dello storage</block>
  <block id="051c025eb3cc7303bf3116bffdb7e95d" category="sidebar">Architettura MetroCluster</block>
  <block id="a1930436e8ea74adaf54ff76d868829b" category="sidebar">SQL Server con MetroCluster</block>
  <block id="33673f825b847c6610f7c7115da0bbde" category="sidebar">Sito preferito</block>
  <block id="57848b20be1bd330229089d2e136d982" category="sidebar">Topologia di rete</block>
  <block id="3a1c15502275494d5a57fe7f225fa951" category="sidebar">SQL Server con SM-AS</block>
  <block id="e30da740afd1eb5c7fc5ade391ee694d" category="sidebar">Configurazioni Oracle</block>
  <block id="3d9396f3fc3010d09439c0c007a897aa" category="sidebar">Istanza singola Oracle</block>
  <block id="87e1ed5a71c4eb8ff653400f9dd917a0" category="sidebar">Oracle RAC e Tiebreaker</block>
  <block id="4a1483b5d5deb83e67e3184b05202d31" category="sidebar">Architettura di esempio</block>
  <block id="8b7786259860e64596ef2df3349d25e1" category="sidebar">Errore di interconnessione RAC</block>
  <block id="d65b736af70982866f4f95287faab7ac" category="sidebar">Errore di comunicazione SnapMirror</block>
  <block id="9b7da52d3b31b3d0a034473609a069e5" category="sidebar">Errore di interconnessione di rete totale</block>
  <block id="1163a74136e40a05bc320e61f567a4df" category="sidebar">Guasto del sito</block>
  <block id="29a8ec19326654cdf89bb8516725720a" category="sidebar">Errore mediatore</block>
  <block id="38ea1deaf691187fc38ab915566310c5" category="sidebar">Ripristino del servizio in seguito a un guasto</block>
  <block id="9132b772b1437e64c8acac2be79a7a0f" category="sidebar">Failover manuali</block>
  <block id="05b66cacce7105ad4a548ef5054997f0" category="doc">Impostazioni di prossimità</block>
  <block id="eccafd14420b568fff639755b251d1bd" category="paragraph">La prossimità si riferisce a una configurazione per cluster che indica che un determinato WWN host o ID iniziatore iSCSI appartiene a un host locale. Si tratta di un secondo passo opzionale per la configurazione dell'accesso LUN.</block>
  <block id="d99ea4fad7d0a9010283969d9ddf89aa" category="paragraph">Il primo passo è la normale configurazione di igroup. Ogni LUN deve essere mappato a un igroup che contiene gli ID WWN/iSCSI degli host che devono accedere a quel LUN. Controlla quale host ha _accesso_ a un LUN.</block>
  <block id="bba32ce1a7b85dd9ba50c49b1a53fe4c" category="paragraph">Il secondo passo, opzionale, consiste nel configurare la prossimità all'host. Questo non controlla l'accesso, controlla _priority_.</block>
  <block id="98271aec6138a28e374c8f3724a535b6" category="paragraph">Ad esempio, un host del sito A potrebbe essere configurato in modo da accedere a una LUN protetta dalla sincronizzazione attiva di SnapMirror e, poiché la SAN è estesa tra i siti, i percorsi sono disponibili per tale LUN utilizzando lo storage sul sito A o lo storage sul sito B.</block>
  <block id="81959299f52ddb567fd902f3e1ae5311" category="paragraph">Senza impostazioni di prossimità, l'host utilizzerà entrambi i sistemi storage allo stesso modo perché entrambi i sistemi storage pubblicizzeranno i percorsi attivi/ottimizzati. Se la latenza SAN e/o la larghezza di banda tra i siti è limitata, questa operazione potrebbe non essere disattivabile e potrebbe essere necessario assicurarsi che durante il normale funzionamento ogni host utilizzi preferenzialmente i percorsi verso il sistema di storage locale. Viene configurato aggiungendo l'ID WWN/iSCSI dell'host al cluster locale come host prossimale. Questa operazione può essere eseguita dalla CLI o da SystemManager.</block>
  <block id="f08670cf73640d447fb34d01b0f6418f" category="paragraph">Con un sistema AFF, i percorsi vengono visualizzati come mostrato di seguito quando è stata configurata la prossimità dell'host.</block>
  <block id="85a2564342597a065a3926228b7e9fcd" category="paragraph">SQL Server può essere configurato per funzionare con la sincronizzazione attiva di SnapMirror in diversi modi. La risposta giusta dipende dalla connettività di rete disponibile, dai requisiti RPO e dai requisiti di disponibilità.</block>
  <block id="d60999416cfb11e4fa51f3dbe7386d64" category="paragraph">SM-AS e MetroCluster sono simili per quanto riguarda le funzionalità generali, ma esistono importanti differenze nel modo in cui è stata implementata la replica RPO=0 e nel modo in cui viene gestita. Anche se è possibile utilizzare la modalità asincrona e sincrona di SnapMirror come parte di un piano di disaster recovery, non sono progettate come tecnologie di replica ha.</block>
  <block id="e122442a5a5728cd45ffc4ddd170a36f" category="list-text">Una configurazione MetroCluster è più simile a un cluster integrato con nodi distribuiti tra i siti. SM-AS si comporta come due cluster altrimenti indipendenti che stanno cooperando nel servire un RPO selezionato=0 LUN replicati in modo sincrono.</block>
  <block id="dbbbd9519f58f000ae618fd3a3f2f38c" category="list-text">I dati in una configurazione MetroCluster sono accessibili solo da un determinato sito alla volta. Una seconda copia dei dati è presente sul sito opposto, ma i dati sono passivi. Non è possibile accedervi senza un failover del sistema storage.</block>
  <block id="72d2ba33caf4a678d0b02c7a4a562662" category="list-text">MetroCluster e SM-as eseguono il mirroring a diversi livelli. Il mirroring MetroCluster viene eseguito al livello RAID. I dati di basso livello sono memorizzati in un formato di mirroring utilizzando SyncMirror. L'utilizzo del mirroring è praticamente invisibile ai livelli di LUN, volume e protocollo.</block>
  <block id="33613d29368b0b312d33bd204505f12b" category="list-text">Al contrario, il mirroring SM-AS avviene a livello di protocollo. I due cluster sono complessivamente cluster indipendenti. Una volta sincronizzate le due copie di dati, i due cluster devono solo eseguire il mirroring delle scritture. Quando si verifica una scrittura su un cluster, questa viene replicata nell'altro cluster. La scrittura viene riconosciuta all'host solo quando la scrittura è stata completata su entrambi i siti. A parte questo comportamento di suddivisione del protocollo, i due cluster sono altrimenti normali cluster ONTAP.</block>
  <block id="c6ce2d48c3feb0ac105233b1d47d6785" category="list-text">Il ruolo principale di MetroCluster è la replica su larga scala. Puoi replicare un intero array con RPO=0 e RTO prossimo allo zero. Questo semplifica il processo di failover perché esiste un solo "problema" da eseguire e consente una scalabilità perfetta in termini di capacità e IOPS.</block>
  <block id="22c8f7d4250a7117dcec5e795cf01979" category="list-text">Un caso d'utilizzo chiave per SM-AS è la replica granulare. A volte non vuoi replicare tutti i dati come una singola unità oppure devi eseguire il failover selettivo su alcuni carichi di lavoro.</block>
  <block id="466f5e6d5af96a45aba533d742d1f30e" category="list-text">Un altro caso d'utilizzo chiave per SM-AS è per operazioni Active-Active, dove desideri che siano disponibili copie dei dati completamente utilizzabili su due cluster diversi situati in due posizioni diverse con caratteristiche di performance identiche e, se desiderato, non richiedere l'estensione della SAN tra i siti. Le applicazioni possono essere già in esecuzione su entrambi i siti, riducendo così l'RTO complessivo durante le operazioni di failover.</block>
  <block id="3ab2196c18fe1cd72bf252059597387b" category="section-title">Sincronizzazione attiva di NetApp MetroCluster e SnapMirror</block>
  <block id="95da439be4f858e05c58cde4b5946324" category="paragraph">Per molti clienti, il disaster recovery non richiede solo una copia remota dei dati, ma anche la capacità di sfruttarli in maniera rapida. NetApp offre due tecnologie che soddisfano questa esigenza: MetroCluster e SnapMirror Active Sync</block>
  <block id="3e6b18011054436086bb6cf813b0cb23" category="section-title">Confronto SM-AS e MCC</block>
  <block id="4ab72a69aa303ab33d610a6f6e594e68" category="section-title">Checksum</block>
  <block id="0a4a3e3ef29b5fc4ea4e557f166532b4" category="paragraph">La sincronizzazione attiva di SnapMirror (SM-AS) si basa sulla sincronizzazione sincrona di SnapMirror. Con MetroCluster, ogni controller ONTAP è responsabile della replica dei dati dell'unità in una posizione remota. Con la sincronizzazione attiva di SnapMirror, avrai essenzialmente due sistemi ONTAP diversi che mantengono copie indipendenti dei dati LUN, ma cooperano per presentare una singola istanza di tale LUN. Dal punto di vista dell'host, si tratta di una singola entità LUN.</block>
  <block id="2f589372957b08ce09879b8a2ab6e58c" category="section-title">Attivazione di DNFS</block>
  <block id="1a89d30b5bb0e2de334e029001a92f8a" category="paragraph">Oracle DNFS può funzionare con NFSv3 senza necessità di configurazione oltre all'abilitazione della libreria DNFS (vedere la documentazione di Oracle per il comando specifico richiesto) ma se DNFS non è in grado di stabilire la connettività, può tornare automaticamente al client NFS del kernel. In questo caso, le prestazioni possono essere gravemente compromesse.</block>
  <block id="9cb0e5a02b9facf3c0e654f08ceceda4" category="paragraph">Se si desidera utilizzare la multiplazione DNFS su più interfacce, con NFSv4.X, o utilizzare la cifratura, è necessario configurare un file oranfstab. La sintassi è estremamente rigorosa. Piccoli errori nel file possono causare la sospensione dell'avvio o il bypass del file oranfstab.</block>
  <block id="3c04631b254b4b0e971a2c82517f50cb" category="paragraph">L'unico modo per essere certi che DNFS funzioni come previsto è eseguire una query sulle tabelle v$dnfs.</block>
  <block id="21986e459426718105f7dc1a16e88bd0" category="paragraph">Di seguito è riportato un file oranfstab di esempio che si trova in /etc. Questa è una delle posizioni multiple un file oranfstab può essere posizionato.</block>
  <block id="1d4338d2de6e933a6941c8605def3a39" category="paragraph">Il primo passo consiste nel verificare che DNFS sia operativo per i filesystem specificati:</block>
  <block id="75bc8bd82bedf61e91351f8667b97e13" category="paragraph">Questo output indica che DNFS è in uso con questi due filesystem, ma *non* significa che oranfstab è operativo. Se fosse presente un errore, DNFS avrebbe scoperto automaticamente i filesystem NFS dell'host e si potrebbe comunque vedere lo stesso output da questo comando.</block>
  <block id="f4327e73856b2069e10b045605d3fbe9" category="paragraph">Il multipathing può essere controllato come segue:</block>
  <block id="99dc2d8bc11eb27fb0b920ca969e43e1" category="paragraph">Di seguito sono riportate le connessioni utilizzate da DNFS. Per ogni voce SVRNAME sono visibili due percorsi e canali. Ciò significa che il multipathing funziona, il che significa che il file oranfstab è stato riconosciuto ed elaborato.</block>
  <block id="d99de907aa06fa04c7b19ffceff68307" category="admonition">Le sezioni seguenti sono aggiornate a partire da ONTAP 9.15,1, ma il comportamento lease e lock e le opzioni di ottimizzazione possono cambiare da versione a versione. Se è necessario ottimizzare i timeout di lease/lock NFSv4, consultare il supporto NetApp per le ultime informazioni.</block>
  <block id="4bf95f1ea9ecf4f42a7b323970405bb4" category="paragraph">Questo periodo di tolleranza controlla il recupero del leasing durante le modifiche all'interfaccia di rete, ma esiste un secondo periodo di tolleranza che controlla il recupero durante il failover dello storage,<block ref="d75aeb1a8759ea7475fe0ddcd2058ca1" prefix=" " category="inline-code"></block>. Questa è un'opzione a livello di nodo.</block>
  <block id="0ba7c8a7759adb519c715ac93fdee2a6" category="paragraph">Ad esempio, se hai spesso bisogno di eseguire failover LIF ed è necessario ridurre il periodo di tolleranza, cambierai<block ref="b1280b7c6d986647dff33b87ce276327" prefix=" " category="inline-code"></block>. Se si desidera migliorare il tempo di ripresa io durante il failover del controller, è necessario modificare<block ref="d75aeb1a8759ea7475fe0ddcd2058ca1" prefix=" " category="inline-code"></block>.</block>
  <block id="3f3edac1c3ed7bfad53f9d42b9a0c5a7" category="paragraph">Alterare questi valori solo con cautela e dopo aver compreso appieno i rischi e le conseguenze. Le pause io coinvolte nelle operazioni di failover e migrazione con NFSv4.X non possono essere evitate del tutto. I periodi di blocco, leasing e grazia fanno parte della RFC NFS. Per molti clienti, NFSv3 è preferibile perché i tempi di failover sono più rapidi.</block>
  <block id="167503c08e9285f5c4a4a61a0123897b" category="paragraph">Il periodo di tolleranza e il periodo di leasing sono collegati. Come menzionato sopra, il timeout di lease predefinito è di 30 secondi, il che significa che NFSv4 client devono effettuare il check-in con il server almeno ogni 30 secondi o perdere i lease e, a loro volta, i blocchi. Il periodo di tolleranza esiste per consentire a un server NFS di ricostruire i dati di lease/lock e il valore predefinito è 45 secondi. Il periodo di tolleranza deve essere più lungo del periodo di leasing. In questo modo, un ambiente client NFS progettato per rinnovare i lease almeno ogni 30 secondi avrà la possibilità di effettuare il check-in con il server dopo un riavvio. Un periodo di tolleranza di 45 secondi assicura che tutti quei clienti che si aspettano di rinnovare i loro leasing almeno ogni 30 secondi definitivamente hanno l'opportunità di farlo.</block>
  <block id="6be050126f2df5ae7cd944ce446241c2" category="paragraph">Se un timeout di 30 secondi non è accettabile, è possibile scegliere di prolungare il periodo di leasing.</block>
  <block id="38d530634a8d32e8775a37109fc08542" category="paragraph">Se si desidera aumentare il timeout del lease a 60 secondi per resistere a un'interruzione di rete di 60 secondi, sarà necessario aumentare anche il periodo di tolleranza. Ciò significa che si verificheranno pause di i/o più lunghe durante il failover del controller.</block>
  <block id="ac76821692fdb2dae1d98babe804fb8f" category="paragraph">Normalmente questo non dovrebbe essere un problema. Gli utenti tipici aggiornano i controller ONTAP solo una o due volte all'anno e il failover non pianificato dovuto a guasti hardware è estremamente raro. Inoltre, se aveste una rete in cui un'interruzione di rete di 60 secondi fosse una possibilità preoccupante e aveste bisogno di un timeout del leasing di 60 secondi, probabilmente non vi opporreste a un raro failover del sistema storage con una pausa di 61 secondi. Hai già riconosciuto che la tua rete è in pausa per più di 60 secondi piuttosto frequentemente.</block>
  <block id="73f7848a74f8a1b6c78ac0dfbca44874" category="searchtitle">Protezione dei dati Microsoft SQL Server con il software di gestione NetApp</block>
  <block id="3a80e1e29c96d0837b12aef65785a41a" category="doc">Parametri di configurazione</block>
  <block id="4bb9f72180425717a416a5037a100cca" category="searchtitle">Struttura dei file MySQL e InnoDB</block>
  <block id="9a41c04f55c43c1bfac6d1e3fb0992de" category="doc">NFSv3 tavoli con slot</block>
  <block id="dce12836eeccf070f53590dc5d86633d" category="doc">Dimensioni dei blocchi</block>
  <block id="b4aa7c0127688b4c623685cfeed4ab97" category="searchtitle">Timeout di Oracle Real Application Clusters</block>
  <block id="6fae8d228f324e0e0a9c817b746b9bd0" category="doc">Timeout RAC</block>
  <block id="b64e3a0dc81f710f886a442e1a397bb9" category="doc">Tool di gestione e automazione del database</block>
  <block id="87921e5ee2cf87589874871f0d361694" category="doc">Disponibilità del database</block>
  <block id="accd3900cbd3e4d55a38c8518052015c" category="doc">Checksum e integrità dei dati</block>
  <block id="5611150a7a2a706d09d267b466f083d6" category="paragraph">Con un vero storage array, l'integrità dei dati è protetta utilizzando checksum a livelli multipli. Se i dati sono corrotti in una rete basata su IP, il livello TCP (Transmission Control Protocol) rifiuta i dati a pacchetto e richiede la ritrasmissione. Il protocollo FC include i checksum, così come i dati SCSI incapsulati. Dopo essere stato inserito nell'array, ONTAP dispone della protezione RAID e checksum. Il danneggiamento può verificarsi, ma, come nella maggior parte degli array Enterprise, viene rilevato e corretto. In genere, si verifica un guasto di un intero disco, che richiede una ricostruzione RAID e l'integrità del database rimane inalterata. È ancora possibile che i singoli byte su un'unità siano danneggiati dalla radiazione cosmica o da celle flash difettose. In questo caso, il controllo della parità non viene eseguito correttamente, l'unità viene chiusa in errore e viene avviata la ricostruzione RAID. Ancora una volta, l'integrità dei dati non viene influenzata. L'ultima linea di difesa è l'uso di checksum. Se, ad esempio, un errore catastrofico del firmware su un'unità ha danneggiato i dati in un modo che in qualche modo non è stato rilevato da un controllo di parità RAID, il checksum non corrisponderebbe e ONTAP impedirebbe il trasferimento di un blocco danneggiato prima che il database Oracle potesse riceverlo.</block>
  <block id="cd985f59320d95026288fa5ff6dcf58a" category="doc">Backup in linea</block>
  <block id="9c030078e0f444e80ad1c24e215220a4" category="doc">Data Protection con ONTAP</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">Pianificazione della protezione dei dati</block>
  <block id="06db8225d3ec2b43755ddc9358302450" category="doc">RTO, RPO e pianificazione SLA</block>
  <block id="5d827e5d4c92779310224878dc408813" category="summary">Dr dei database Oracle con MetroCluster</block>
  <block id="f0b223afb696335287bc2ed9501b5b33" category="doc">Disaster recovery con MetroCluster</block>
  <block id="67be2475945283126e261087dcc833b7" category="doc">MetroCluster e NVFAIL</block>
  <block id="13262509535baae73d0cc7ab06de1fc6" category="searchtitle">Oracle Extended RAC su MetroCluster</block>
  <block id="7993038617c805a663d50702c4494b68" category="doc">Oracle Extended RAC</block>
  <block id="75b233b87417347976ef489e09961c77" category="doc">Istanza singola di Oracle</block>
  <block id="aa51324dbf5137dc80d29f127e7265f1" category="doc">Istanza singola Oracle</block>
  <block id="254742fbeffe659f98f802792b541c45" category="doc">RAC tiebreaker</block>
  <block id="aeee9c92b22d6f18b8670c9f330ea7c9" category="doc">Errore interconnettività di rete totale</block>
  <block id="0ef819e6ae8a74f9c8ac0158a24b1627" category="doc">Ripristino del servizio</block>
  <block id="8367f9ef79397d7d8f1367cb4392c602" category="summary">Sincronizzazione attiva di Oracle e SnapMirror - errore del sito</block>
  <block id="5c8784e46ac32f6b1c9b78f954c1a473" category="summary">Sincronizzazione attiva SnapMirror - errore di comunicazione SnapMirror</block>
  <block id="7ed82538ab967cd6e2949aa971158dc9" category="searchtitle">Oracle, SnapMirror Active Sync e ONTAP Mediator</block>
  <block id="db2170f38b52c13c31e0572c709b6f8a" category="searchtitle">Panoramica sulla sincronizzazione attiva di Oracle e SnapMirror</block>
  <block id="e9a673980d8df30ed4173e4b7c4ecd2c" category="searchtitle">Sito preferito per la sincronizzazione attiva di Oracle e SnapMirror</block>
  <block id="45d97b0c2ca342ad882153a1245f9897" category="doc">Sito preferito sincronizzazione attiva SnapMirror</block>
  <block id="0bb4536e921f4d96dd701c1afe746457" category="doc">ASMILib/AFD (driver filtro ASM)</block>
  <block id="3ee9e6a595247d1965be0d0c6cd0f22e" category="doc">Migrazione di file dati</block>
  <block id="a9761df551af398a0fc2974288502d8a" category="doc">Copia dei dati dell'host</block>
  <block id="d437e7d8b6513f91bbd58e0b1e08c90b" category="doc">Pianificazione della migrazione</block>
  <block id="4c7e0d612a5f0e09f272083633991979" category="doc">Configurazione TCP/IP ed ethernet</block>
  <block id="9f2dc5f476d250d879dc58a583f93fd1" category="searchtitle">Configurazione FC SAN per database Oracle</block>
  <block id="08f606415b4ad7fb864651eac04fcd8e" category="searchtitle">Ottimizzazione e benchmarking delle performance dei database Oracle</block>
  <block id="b30e3ef968d39d109aea4a92750c9792" category="doc">NFSv3 serrature obsolete</block>
  <block id="1d19e21de0f93b11f5ceb8b535a3afc2" category="doc">Gestione della capacità</block>
  <block id="8d409dbefa8e76403d7adf4cbd315d3d" category="doc">Failover/switchover di ONTAP</block>
  <block id="0f03a4e25b68a1a67d3be8f0d989ef8b" category="doc">Gestione delle performance con QoS ONTAP</block>
  <block id="555472a0fed2f80e0848845e538a08af" category="doc">Oracle Direct NFS (DNFS)</block>
  <block id="92d0288d9e0c6ed5ffd8dcd2e0900101" category="paragraph">Al momento della stesura del presente documento, il multipathing DNFS non funziona con NFSv4,1 con le versioni più recenti di Oracle Database. Un file oranfstab che specifica NFSv4,1 come protocollo può utilizzare solo un'istruzione PATH singola per una determinata esportazione. Il motivo è che ONTAP non supporta il trunking clientID. Le patch dei database Oracle per risolvere questo limite potrebbero essere disponibili in futuro.</block>
  <block id="3fdf18c0210b51691df97c8be74021a3" category="doc">ASM Reclamation Utility (ASMRU)</block>
  <block id="d63f66214ae30c5b9b10653f1e503492" category="doc">Allineamento delle LUN</block>
  <block id="38baeef7dc11ad9438aa5b211745d9f6" category="searchtitle">Ridimensionamento e ridimensionamento delle LUN dei database Oracle</block>
  <block id="f447f8c9180e11bc4219ace93e7431fb" category="doc">Ridimensionamento LUN e ridimensionamento LVM</block>
  <block id="c8d869d733bd5299001f9d90b9f00d90" category="doc">Dimensionamento e numero di LUN</block>
  <block id="4ee97146242ed12473141d7ecad00ee1" category="doc">Tiering del backup</block>
  <block id="e7cba09a05ca3e6ccdd30a1aa0a7d3af" category="doc">Tiering dei log di archivio</block>
  <block id="c1affdf2bd2e606557f2bf12c69af8f8" category="doc">Tiering parziale dei file</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">Criteri di recupero</block>
  <block id="636d94f9e0fb52c5d7560661b059b203" category="doc">Tiering delle Snapshot</block>
  <block id="bf5f70c9080724ef27b09203705b1abc" category="doc">Tiering completo dei file</block>
  <block id="acf5662e9defb6f8df644e0d8b4caa28" category="doc">Parametri di inizializzazione</block>
  <block id="03095e209912bbf8e40f883c88befe49" category="searchtitle">Protezione dei dati nativa di PostgreSQL</block>
  <block id="300e5ea4a0c7d02b8a4efeba5a1f6faf" category="doc">Protezione DDTA nativa</block>
  <block id="1c3ee6977dcad0709502549dd7b111f3" category="sidebar">Dr Oracle con MetroCluster</block>
  <block id="662637dadb14be675de52ed993629bcd" category="paragraph">Per la profondità della coda del sistema operativo del server, utilizzare un minimo di otto LUN (un LUN per volume) per un database. Aumentare il numero di LUN in base al numero di nodi nel cluster ONTAP. Ad esempio, Aggiungi 4 LUN quando utilizzi un cluster da 4 nodi (2 coppie ha). Per gli ambienti più grandi potrebbe essere necessario un numero maggiore di LUN, ovvero utilizzare lo stesso numero di volumi (otto totali distribuiti nel nodo storage) e aggiungere LUN in multipli di due nei nodi e volumi del cluster. Questo approccio ti consente di scalare facilmente il tuo ambiente Epic.</block>
  <block id="f73f987e4ea887ccfd1bf297bad46e22" category="paragraph">*Esempio 1: Cluster ONTAP a 2 nodi*</block>
  <block id="f08ea6531fe21723a28ec9f89ea3e451" category="paragraph">2 nodi, 1 ha Pair 8 volumi, 4 volumi per nodo 8 LUN, una LUN per volume che aggiunge 2 LUN aggiuntive, una su node01 in volume01, una su node02 in volume02.</block>
  <block id="fd52d4fb0b6e3cfb46cae3e012d26c20" category="paragraph">*Esempio 2: Cluster ONTAP a 4 nodi*</block>
  <block id="489d5412107ca7c901de568b7c7dcce3" category="paragraph">4 nodi, 2 ha Pair 8 volumi, 2 volumi per nodo 8 LUN, una LUN per volume che aggiunge 4 LUN aggiuntive, una su node01 in volume01, una su node02 in volume02, una su node03 in volume03, una su node04 in volume04.</block>
  <block id="2feec0f4e37d9566d4cf292116430adb" category="paragraph">Se il server richiede più storage, l'opzione più semplice è aumentare le LUN che contengono volumi. La seconda opzione consiste nell'aggiungere LUN ai gruppi di volumi in multipli di due alla volta (uno per volume per nodo).</block>
  <block id="c338b7a4eb0c6f0bb88b444f6c195b01" category="admonition">Se in un ambiente di grandi dimensioni che richiede più di 4 nodi o 8 LUN, consulta il nostro Alliance team Epic per confermare le progettazioni delle LUN. Il team può essere raggiunto a EPIC@NetApp.com.</block>
  <block id="e9afc81d3b8e2990f966bb247fa75a6b" category="list-text">Utilizzare 8 LUN in volumi 8 per iniziare, aggiungendo 2 LUN alla volta, in tutti i nodi del cluster.</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentazione ONTAP</block>
  <block id="c5432110ad66f4e2e624118b88a48126" category="list-text">Creare LUN delle dimensioni previste per 3 anni di crescita. (Per conoscere le dimensioni massime dei LUN, consulta la<block ref="2a57767dbf71d600f009b2fefab6360d" category="inline-link-macro-rx"></block>).</block>
  <block id="4631d10aa7c8cd31e9dcf52425c327ee" category="paragraph">Per collegare VMware vSphere ai datastore su un sistema che esegue ONTAP sono utilizzati sei protocolli:</block>
  <block id="4dc791031dce7528180b933655b6f73e" category="paragraph">FCP, NVMe/FC, NVMe/TCP e iSCSI sono protocolli a blocchi che utilizzano il VMFS (vSphere Virtual Machine file System) per memorizzare le VM nei LUN di ONTAP o negli namespace NVMe contenuti in un ONTAP FlexVol volume. NFS è un protocollo di file che inserisce le macchine virtuali in datastore (che sono semplicemente volumi ONTAP) senza la necessità di VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS possono essere utilizzati anche direttamente da un sistema operativo guest a ONTAP.</block>
  <block id="6b8f0029ce30f9b4d5fe0def33875511" category="cell">FC</block>
  <block id="81761811d0f769f1e8ab81834167af5c" category="cell">Software di backup abilitato per VADP (VMware vStorage APIs for Data Protection)</block>
  <block id="50f09c99cf03d7efc83cfdc33047b54f" category="cell">Sì ^1^</block>
  <block id="bb3e0b0b29c5930728585f775194c32b" category="cell">No ^2^</block>
  <block id="b42c555e5ddbb6a4354369bbdd6b4513" category="cell">V3 solo ^2^</block>
  <block id="5543e0c19ec8cfcca651874f8d3b3ff7" category="list-text">*NetApp consiglia* l'utilizzo di volumi FlexVol per la maggior parte dei datastore NFS. A partire da ONTAP 9,8, l'utilizzo dei volumi FlexGroup è supportato anche come datastore e generalmente è consigliato per alcuni casi d'utilizzo. Gli altri container di storage ONTAP, come i qtree, non sono generalmente consigliati, in quanto al momento non sono supportati dai tool ONTAP per VMware vSphere o dal plug-in NetApp SnapCenter per VMware vSphere. Ciò detto, implementare datastore come qtree multiple in un singolo volume potrebbe essere utile per ambienti altamente automatizzati, che possono trarre beneficio da quote a livello di datastore o cloni dei file delle macchine virtuali.</block>
  <block id="c411a2d2bb7111e695dcd16998c5bf03" category="list-text">In alternativa, è possibile configurare datastore VMFS con LUN a cui è possibile accedere da FC e iSCSI. VMFS consente l'accesso simultaneo ai LUN da parte di ogni server ESX in un cluster. Gli archivi di dati VMFS possono avere dimensioni fino a 64 TB e sono costituiti da un massimo di 32 LUN da 2 TB (VMFS 3) o un singolo LUN da 64 TB (VMFS 5). Le dimensioni massime del LUN del ONTAP sono di 128TB GB su sistemi AFF, ASA e FAS. NetApp consiglia di utilizzare un singolo LUN di grandi dimensioni per ciascun datastore. Come per NFS, puoi utilizzare più datastore (volumi) per massimizzare le performance su un singolo controller ONTAP.</block>
  <block id="cb928308729506b7eff5e7791a0ce0ba" category="list-text">I sistemi operativi guest precedenti necessitavano di un allineamento con il sistema storage per ottenere le migliori performance ed efficienza dello storage. Tuttavia, i moderni sistemi operativi supportati dai vendor dei distributori Microsoft e Linux come Red Hat non richiedono più modifiche per allineare la partizione del file system con i blocchi del sistema storage sottostante in un ambiente virtuale. Se stai utilizzando un vecchio sistema operativo che potrebbe richiedere un allineamento, cerca nella Knowledge base di supporto NetApp gli articoli che utilizzano "allineamento VM" o richiedi una copia del documento TR-3747 a un contatto commerciale o di un partner NetApp.</block>
  <block id="2d95becf2e726f81e5f2c0c9447ec2ad" category="paragraph">In generale, *NetApp consiglia* di utilizzare gli strumenti ONTAP per l'interfaccia di VMware vSphere all'interno di vCenter per effettuare il provisioning dei datastore tradizionali e vVol per assicurarsi che vengano seguite le Best practice.</block>
  <block id="3405fd91ec611e14ca0464a159e87d21" category="list-text">Quando gli array di storage ESXi e ONTAP sono connessi a reti di storage Ethernet, *NetApp consiglia* di configurare le porte Ethernet a cui questi sistemi si connettono come porte edge Rapid Spanning Tree Protocol (RSTP) o utilizzando la funzione Cisco PortFast. *NetApp consiglia* di abilitare la funzione di trunk PortFast Spanning-Tree in ambienti che utilizzano la funzione PortFast Cisco e che dispongono di trunking VLAN 802,1Q abilitato al server ESXi o agli array di storage ONTAP.</block>
  <block id="96d48caf96811ccfa373aaf5fbe6f862" category="list-text">*NetApp consiglia* le seguenti procedure consigliate per l'aggregazione dei collegamenti:</block>
  <block id="022cc03b844340886b4e892084430269" category="cell">No ^4^</block>
  <block id="57749a8572dd2708f63cdf198026e062" category="cell">No ^3^</block>
  <block id="03cba371c1878a590431cec079c6f4c2" category="paragraph">^3^ le interfacce LIF SVM si connettono a porte, gruppi di interfacce o interfacce VLAN che hanno impostazioni VLAN, MTU e altre. Tuttavia, le impostazioni non vengono gestite a livello di SVM.</block>
  <block id="7b9dbbe3099a486a2a81a7e43267d3af" category="paragraph">^4^ questi dispositivi hanno indirizzi IP propri per la gestione, ma questi indirizzi non vengono utilizzati nel contesto della rete di storage ESXi.</block>
  <block id="d4b27e1b61577e2e3dfeebd3b8129da5" category="list-text">Evitare di condividere i volumi tra gli host. Ad esempio, anche se sarebbe possibile creare 2 LUN in un singolo volume e condividere ogni LUN con un host diverso, questo aspetto dovrebbe essere evitato perché complica la gestione. Se si eseguono più istanze di SQL Server sullo stesso host, a meno che non ci si trovi in prossimità del limite di volume su un nodo, è possibile evitare la condivisione di volumi e utilizzare un volume separato per istanza per host per semplificare la gestione dei dati.</block>
  <block id="e3ea9105e22caf8aa06aee0279a968bb" category="list-text">Se necessario, configurare un criterio di dimensionamento automatico dei volumi per evitare condizioni di spazio insufficiente.</block>
  <block id="72a9733bd5929d30a93ea680e0c3fad1" category="list-text">L'inserimento di file secondari del database (come parte di un filegroup) in volumi separati migliora le prestazioni del database di SQL Server. Questa separazione è valida solo se il file del database<block ref="937f38432beb92fdba3d47780720bdf7" prefix=" " category="inline-code"></block> non condivide il LUN con altri<block ref="937f38432beb92fdba3d47780720bdf7" prefix=" " category="inline-code"></block> file.</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="searchtitle">File tempdb di Microsoft SQL Server</block>
  <block id="82d9655a27436534991360ea4c0dc680" category="paragraph">Il database Tempdb può essere utilizzato in modo intensivo. Oltre al posizionamento ottimale dei file di database degli utenti su ONTAP, anche il posizionamento dei file di dati tempdb è fondamentale per ridurre il conflitto di allocazione. Tempdb deve essere posizionato su un disco separato e non condiviso con i file di dati dell'utente.</block>
  <block id="5c4a7832da0e9f8799089fdc985bb9b3" category="list-text">Il file dati tempdb deve essere creato con le stesse dimensioni</block>
  <block id="20453a1c8627ad0bc536be210636fa41" category="paragraph">Lo script di esempio seguente modifica tempdb creando otto file tempdb di pari dimensioni e spostando tempdb sul punto di montaggio<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> per SQL Server 2012 e versioni successive.</block>
  <block id="3f808654ebfed6aae875b71a402ac91b" category="inline-link-macro">Avviso per ONTAP 9.16.1</block>
  <block id="afb530fcc81b2978f808bd5327a32c87" category="inline-link-macro">Avviso per ONTAP 9.16.0</block>
  <block id="d804afb237a517c556722013a1b8ec73" category="inline-link-macro">Avviso per ONTAP 9.15.1</block>
  <block id="5f016d328522d91c512269e0786e144d" category="inline-link-macro">Avviso per ONTAP 9.15.0</block>
  <block id="98ea16e049d26c017c083e3896766015" category="inline-link-macro">Avviso per ONTAP 9.14.1</block>
  <block id="2a0d0e639657d07a66d55606242f8863" category="inline-link-macro">Avviso per ONTAP 9.14.0</block>
  <block id="d13ca0508189923e4791d61e82518903" category="paragraph"><block ref="ee254fc53b05f67f41ce3314151253c2" category="inline-link-macro-rx"></block> <block ref="83cffbd8d99e434b2f5f3940f69ff8e4" category="inline-link-macro-rx"></block> <block ref="23ce2232a13ec581d8a1f356c5cc2645" category="inline-link-macro-rx"></block> <block ref="4d4f1ffb0dbcd5627ca696d020c34dce" category="inline-link-macro-rx"></block> <block ref="d16c9b11843460f788b4709fb5f6f9c0" category="inline-link-macro-rx"></block> <block ref="5032e7169b10b3f96d6c299a82923a0e" category="inline-link-macro-rx"></block> <block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block> <block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block> <block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block> <block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block> <block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block> <block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block> <block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block> <block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block> <block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block> <block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block> <block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block> <block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block> <block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block> <block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block> <block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="c9e7f99d53af8a795853cdf25af30b41" category="section-title">ONTAP Mediator per configurazioni IP MetroCluster</block>
  <block id="f6cab8e78e70dc1f9720a3ef038776e0" category="inline-link-macro">9.9.1 Avviso per ONTAP Mediator per le configurazioni IP di MetroCluster</block>
  <block id="ebe991cfd03b446bbf8687699ccbd660" category="inline-link-macro">9,8 Avviso per ONTAP Mediator per le configurazioni IP di MetroCluster</block>
  <block id="2db41096b15f25232cba7341c2140448" category="inline-link-macro">9,7 Avviso per ONTAP Mediator per le configurazioni IP di MetroCluster</block>
  <block id="f81cc577527b8b7cad4405edd62a83d4" category="paragraph"><block ref="3e82164cf34143fb60c8ff9df8c41c0a" category="inline-link-macro-rx"></block> <block ref="d53517b81c95b1c10115cf953ff553c1" category="inline-link-macro-rx"></block> <block ref="b1bde49b948d4004f51f0cd5e9a9e990" category="inline-link-macro-rx"></block></block>
  <block id="89a8982c5b7248833ca5b092a530069e" category="admonition">Mentre i sistemi ONTAP permettono di accoppiare le SVM nello stesso cluster per la replica SnapMirror, questo scenario non viene testato e certificato con SRM. Pertanto, si consiglia di utilizzare solo SVM di cluster diversi quando si utilizza SRM.</block>
  <block id="7d90174e2cb3f5e3051541506c8587b4" category="list-text">Utilizza i tool di ONTAP per VMware vSphere per il provisioning dei datastore in quanto semplifica automaticamente la gestione delle policy di esportazione.</block>
  <block id="4ac7ffa40244bc8345591768f8411745" category="list-text">Utilizzare la funzione di montaggio del plug-in per applicare i datastore esistenti ai nuovi server.</block>
  <block id="adf5380025d4004543deef73a471bbd5" category="inline-link-macro">Funzione NFSv3 nconnect con NetApp e VMware</block>
  <block id="f9f508df0fe89d92476e598965812f69" category="list-text">Tutte le versioni di VMware vSphere attualmente supportate possono utilizzare sia NFS v3 che v4,1. Il supporto ufficiale per nconnect è stato aggiunto a vSphere 8,0 update 2 per NFS v3 e all'update 3 per NFS v4,1. Per NFS v4,1, vSphere continua a supportare il trunking della sessione, l'autenticazione Kerberos e l'autenticazione Kerberos con integrità. È importante notare che il trunking della sessione richiede ONTAP 9.14.1 o una versione successiva. È possibile ottenere ulteriori informazioni sulla funzione nconnect e sul modo in cui migliora le prestazioni a <block ref="8bbf9cc2e5403eec56b8cc2f4bd74d68" category="inline-link-macro-rx"></block>.</block>
  <block id="81439479f2f4c0fa8c28668334fa82bd" category="list-text">Il valore massimo per nconnect in vSphere 8 è 4 e il valore predefinito è 1. Il limite massimo di valore in vSphere può essere aumentato in base all'host tramite impostazioni avanzate, tuttavia in genere non è necessario.</block>
  <block id="b279126f58fd7f43a55f5efc8596bcea" category="list-text">Per gli ambienti che richiedono prestazioni superiori a quelle consentite da una singola connessione TCP, si consiglia di utilizzare il valore 4.</block>
  <block id="9d676095b7ff8ea1b1779bc58fb32a92" category="list-text">Tenere presente che ESXi ha un limite di 256 connessioni NFS e ogni connessione nconnect conta per quel totale. Ad esempio, due datastore con nconnect=4 contano come otto connessioni totali.</block>
  <block id="efdc45c7bd15d84f5bcb4df0560d6d3a" category="list-text">È importante verificare l'impatto delle prestazioni di nconnect sull'ambiente prima di implementare cambiamenti su larga scala negli ambienti di produzione.</block>
  <block id="d1801a2d87a0325c6c691a74f5d1ffef" category="list-text">Vale la pena notare che NFSv3 e NFSv4,1 utilizzano meccanismi di bloccaggio diversi. NFSv3 utilizza il blocco lato client, mentre NFSv4,1 utilizza il blocco lato server. Anche se un volume ONTAP può essere esportato tramite entrambi i protocolli, ESXi può montare un datastore solo attraverso un protocollo. Tuttavia, ciò non significa che altri host ESXi non possano montare lo stesso datastore attraverso una versione diversa. Per evitare qualsiasi problema, è essenziale specificare la versione del protocollo da utilizzare durante il montaggio, assicurandosi che tutti gli host utilizzino la stessa versione e, quindi, lo stesso stile di blocco. È fondamentale evitare di mischiare versioni NFS tra gli host. Se possibile, utilizzare i profili host per verificare la conformità.</block>
  <block id="c17658fd7af3bb19a0f047cb1e006186" category="list-text">Regole delle policy di esportazione NFS vengono utilizzate per controllare l'accesso dagli host vSphere. È possibile utilizzare un criterio con più volumi (datastore). Con NFS, ESXi utilizza lo stile di sicurezza sys (UNIX) e richiede l'opzione di montaggio root per eseguire le macchine virtuali. In ONTAP, questa opzione viene definita superutente e, quando viene utilizzata l'opzione superutente, non è necessario specificare l'ID utente anonimo. Tenere presente che le regole delle policy di esportazione con valori diversi per<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> e<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> possono causare problemi di rilevamento SVM con gli strumenti ONTAP. Gli indirizzi IP devono essere un elenco separato da virgole senza spazi degli indirizzi della porta vmkernel che montano gli archivi dati. Ecco un esempio di regola dei criteri:</block>
  <block id="a001b05a0a70d03d708c133c88072a2b" category="list-text">Elenco di nomi host, indirizzi IP, netgroup o domini corrispondenti ai client: 192.168.42.21,192.168.42.22</block>
  <block id="0106a8755025c8789c58f6ca3db3cd93" category="list-text">Regola di accesso RO: Any</block>
  <block id="1c66db8bac919c3f29211badf0369156" category="list-text">Regola di accesso RW: Qualsiasi</block>
  <block id="193fc1ecf90841d52215e705d60caa7b" category="list-text">ID utente a cui sono mappati gli utenti anonimi: 65534</block>
  <block id="f913a13d0c2cb8f8dd45dc1479901025" category="list-text">Tipi di protezione superutente: Qualsiasi</block>
  <block id="e44d8f7f976db169814f15c0e3c91250" category="list-text">Honor setuid bits in SETATTR: True</block>
  <block id="c154c7fcb68e62b069047ccff2521dc0" category="list-text">Consenti la creazione di dispositivi: True</block>
  <block id="71168bd99a960bfb425e723f5750b3fc" category="list-text">Se si utilizza il plug-in NFS NetApp per VMware VAAI, è necessario impostare il protocollo come<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> al momento della creazione o della modifica della regola dei criteri di esportazione. Per il funzionamento dell'offload delle copie VAAI è necessario il protocollo NFSv4, specificando che il protocollo<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> include automaticamente le versioni NFSv3 e NFSv4. Questa operazione è necessaria anche se il tipo di datastore viene creato come NFS v3.</block>
  <block id="dd68c690edda5e0630944465c5950d11" category="list-text">Protocollo di accesso: nfs</block>
  <block id="4d6306be791d29381011bb901e0351d5" category="list-text">Spec. Corrispondenza client: 192.168.42.21,192.168.42.22</block>
  <block id="62297138e048f9159339e4709b23cd2f" category="list-text">Come LUN connessa a iSCSI o namespace connesso a NVMe/TCP, accessibile e controllato da un iniziatore software da un sistema operativo guest di macchine virtuali</block>
  <block id="6bc78ccffdd069cded655f73dc33debc" category="paragraph">ESXi 6 ha aggiunto il supporto per un massimo di 256 LUN e fino a 1.024 percorsi totali alle LUN. ESXi non vede LUN o percorsi oltre questi limiti. Supponendo il numero massimo di LUN, il limite di percorso consente quattro percorsi per LUN. In un cluster ONTAP più grande, è possibile raggiungere il limite di percorso prima del limite di LUN. Per risolvere questo limite, ONTAP supporta la mappa LUN selettiva (SLM) nella versione 8.3 e successive.</block>
  <block id="7eae63bf83e6298ab64a2dd5e2544df9" category="inline-link-macro">Strumento VMware Configuration Maximums</block>
  <block id="ee1c3928454779ec08bd2d50271b6621" category="admonition">Fare riferimento alla <block ref="ca32979bcc653e1966d3624ee8d76604" category="inline-link-macro-rx"></block> per i limiti supportati più aggiornati in ESXi.</block>
  <block id="387b349695476180bf90cc1891288318" category="list-text">Verificare <block ref="1f38ac07598dbb4b06912539aafa4211" category="inline-link-macro-rx"></block>le impostazioni consigliate da NetApp in collaborazione con VMware.</block>
  <block id="9c4a21e654649a6a5201381ce4ba6cbd" category="paragraph">Le tabelle seguenti presentano le funzionalità tradizionali del datastore supportate da vSphere con ONTAP. Queste informazioni non si applicano agli archivi dati vVol, ma in genere si applicano a vSphere 6.x e alle versioni successive che utilizzano le versioni supportate di ONTAP. È inoltre possibile consultare il <block ref="ca32979bcc653e1966d3624ee8d76604" category="inline-link-macro-rx"></block> per le release specifiche di vSphere per confermare i limiti specifici.</block>
  <block id="d325729822747316770c21019ec914ac" category="paragraph">^1^ *NetApp consiglia* l'utilizzo di iSCSI in-guest per i cluster Microsoft piuttosto che VMDK abilitati per il multi-writer in un datastore VMFS. Questo approccio è pienamente supportato da Microsoft e VMware, offre una grande flessibilità con ONTAP (da SnapMirror ai sistemi ONTAP on-premise o nel cloud), è semplice da configurare e automatizzare e può essere protetto con SnapCenter. VSphere 7 aggiunge una nuova opzione VMDK in cluster. Si tratta di un'operazione diversa dai VMDK abilitati per il multi-writer, che richiede un datastore presentato tramite il protocollo FC che ha attivato il supporto VMDK in cluster. Sono previste altre restrizioni. Per le linee guida sulla configurazione, consultare la documentazione di VMware<block ref="46658ede14d15d79e2a20c75a7b15bb2" category="inline-link-macro-rx"></block>.</block>
  <block id="27071f484b59aa9ce5f5cffcefefd481" category="paragraph">^2^ i datastore che utilizzano NVMe-of e NFS v4,1 richiedono la replica vSphere. La replica basata su array per NFS v4,1 non è attualmente supportata da SRM. La replica basata su array con NVMe-of non è attualmente supportata dai tool ONTAP per VMware vSphere Storage Replication Adapter (SRA).</block>
  <block id="f992800e6b8aa5ca675e5d1c9fd9950c" category="summary">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Essi continuano a consentire una selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di mettere in pausa l'i/o prima di scattare una snapshot VMware.</block>
  <block id="0a99e5aa10081a6cc2cd756764a791f5" category="inline-link-macro">Limitazioni delle snapshot</block>
  <block id="aa5047ea08cd6ab5089b7e97962beef9" category="paragraph">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Essi continuano a consentire una selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di mettere in pausa l'i/o prima di scattare una snapshot VMware. Tuttavia, a causa dell'effetto delle performance delle snapshot VMware, in genere non sono consigliate, a meno che non sia necessario interrompere il file system guest. Utilizza invece le snapshot per la protezione generale e utilizza strumenti applicativi come i plug-in SnapCenter per proteggere i dati transazionali come SQL Server o Oracle. Questi Snapshot sono diversi dalle Snapshot VMware (di coerenza) e sono adatti per una protezione a lungo termine. Le istantanee VMware sono consigliate solo per l'utilizzo a breve termine, a causa delle prestazioni e di altri effetti. Per <block ref="edb84c63886608dd2a747873a2732130" category="inline-link-macro-rx"></block>ulteriori dettagli, fare riferimento a.</block>
  <block id="029b7a5fa374f35f7d7eb7c6b5c66f41" category="paragraph">Questi plug-in offrono funzionalità estese per proteggere i database in ambienti fisici e virtuali. Con vSphere, è possibile utilizzarli per proteggere i database SQL Server o Oracle in cui i dati vengono memorizzati su LUN RDM, LUN iSCSI direttamente connessi al sistema operativo guest o file VMDK su datastore VMFS o NFS. I plug-in consentono di specificare diversi tipi di backup del database, supportando il backup online o offline e proteggendo i file di database insieme ai file di registro. Oltre al backup e alla recovery, i plug-in supportano anche la clonazione dei database a scopo di sviluppo o test.</block>
  <block id="aa4e326f7359bc14116e671e7002dd80" category="paragraph">ONTAP offre storage a blocchi di livello Enterprise per VMware vSphere utilizzando i tradizionali iSCSI e Fibre Channel Protocol (FCP) oltre al protocollo a blocchi di nuova generazione, NVMe over Fabrics (NVMe-of), ad alta efficienza e performance, con supporto per NVMe/FC e NVMe/TCP.</block>
  <block id="69ed4612751aa53c36bfb06723b9ac3c" category="inline-link-macro">Datastore e protocolli: SAN</block>
  <block id="6ed827bb740ef6ae13ba33875f09bd4d" category="paragraph">Per le Best practice dettagliate per l'implementazione dei protocolli a blocchi per lo storage delle macchine virtuali con vSphere e ONTAP, fare riferimento a. <block ref="851570383af5746336da824a0a2590e1" category="inline-link-macro-rx"></block></block>
  <block id="080533926d0a5f93ded730459d8fe38e" category="paragraph">VSphere consente ai clienti di utilizzare array NFS di livello Enterprise per fornire l'accesso simultaneo agli archivi dati a tutti i nodi di un cluster ESXi. Come menzionato nella <block ref="72b655a9973dbed02099f5e63762d591" category="inline-link-macro-rx"></block>sezione, quando si utilizza NFS con vSphere, esistono alcuni benefici di facilità d'uso ed efficienza dello storage.</block>
  <block id="d9243800afbb4af685507413cda85fb3" category="inline-link-macro">Datastore e protocolli: NFS</block>
  <block id="5b17d236da497a1c9e5d89b42dfc8264" category="paragraph">Per le Best practice consigliate fare riferimento a. <block ref="75fda850433b3639ed71701079d043be" category="inline-link-macro-rx"></block></block>
  <block id="d240aead1fe438e9f66d54e3cebb7e47" category="paragraph">Di seguito sono riportate le impostazioni dell'host consigliate per tutte le versioni di ONTAP attualmente supportate.</block>
  <block id="11d0e9e8442c67c812829427e008eb11" category="inline-link-macro">Recupero di spazio per VMFS5 macchine virtuali</block>
  <block id="fef769c2e7ba3ba16273c3c81c47ed9e" category="cell">Mantenere l'impostazione predefinita (0), ma può essere modificata se necessario. Per ulteriori informazioni, vedere <block ref="9b26e5c0136d6a9ffe3ef541d9621427" category="inline-link-macro-rx"></block></block>
  <block id="c99694bb5336dd37a10341183ec8a950" category="inline-link-macro">VMware KB 2069356</block>
  <block id="e6c0dd75e5461550c4a0e5988151488a" category="list-text">In ambienti dalle performance elevate o quando si testano le performance con un singolo datastore LUN, si consiglia di modificare l'impostazione del bilanciamento del carico del criterio di selezione del percorso (PSP) round-robin (VMW_PSP_RR) dall'impostazione IOPS predefinita di 1000 a un valore di 1. Per ulteriori informazioni, vedere<block ref="1687988694c35db61b845d7b15620672" category="inline-link-macro-rx"></block>.</block>
  <block id="2f5a0569065e71943058f8fb26e3e8da" category="inline-link">Modifica dei parametri predefiniti per la latenza Round Robin</block>
  <block id="18aa403816c42116dbae93c18dc9ce38" category="list-text">In vSphere 6.7 Update 1, VMware ha introdotto un nuovo meccanismo di bilanciamento del carico di latenza per la PSP Round Robin. La nuova opzione prende in considerazione la larghezza di banda i/o e la latenza del percorso quando si seleziona il percorso ottimale per i/O. Potresti trarre vantaggio dall'utilizzo in ambienti con una connettività di percorso non equivalente, ad esempio casi in cui sono presenti più nodi di rete su un percorso rispetto all'altro o quando si utilizza un sistema ASA (NetApp All SAN Array). Per ulteriori informazioni, vedere<block ref="d244127cef9364538ba1012ad8871adc" category="inline-link-rx"></block> .</block>
  <block id="da151950bd7f77d4d82f31a151e48d86" category="paragraph">Per FCP e iSCSI con vSphere 7, è possibile trovare ulteriori dettagli all'indirizzo <block ref="ad69e690a8561a2cf3328cde094252f4" category="inline-link-macro-rx"></block> per FCP e iSCSI con vSphere 8. Per ulteriori dettagli, visitare la pagina <block ref="0b6ab7c7c874850b69a7bdde572cc0ce" category="inline-link-macro-rx"></block> relativa a NVMe-of con vSphere 7. Per ulteriori dettagli, visitare il sito <block ref="72dcc917faa9346f108bcba624c6b54f" category="inline-link-macro-rx"></block> per NVMe-of con vSphere 8, ulteriori dettagli sono disponibili all'indirizzo <block ref="6388c35b35c0c848de96298937e342cf" category="inline-link-macro-rx"></block></block>
  <block id="b565c40b717c5d84ecaff52fbb94903d" category="paragraph">Annunciato per la prima volta nel 2012, NetApp è stato un primo partner di progettazione di VMware nello sviluppo di VMware vSphere APIs for Storage Awareness (VASA), le fondamenta della gestione basata su criteri storage (SPBM, Storage Policy Based Management) con array storage Enterprise. Questo approccio offriva una gestione granulare dello storage delle macchine virtuali limitata allo storage VMFS e NFS.</block>
  <block id="e01da3b454da14823394d0b9b3fac1d6" category="section-title">Volumi virtuali (vVol)</block>
  <block id="b077cca6e6fd5e690157294fd7f87e08" category="paragraph">I vVol sono una rivoluzionaria architettura di storage che consente la gestione granulare dello storage delle macchine virtuali, consentendo la gestione dello storage non solo in base alle macchine virtuali (compresi i metadati delle macchine virtuali) ma anche in base ai VMDK. I vVol sono un componente chiave della strategia SDDC (Software Defined Data Center) che costituisce la base di VMware Cloud Foundation (VCF), fornendo un'architettura di storage più efficiente e scalabile per gli ambienti virtualizzati.</block>
  <block id="7dba0dd24357e8a19109bbbf7f689fb2" category="paragraph">I vVol consentono alle macchine virtuali di utilizzare lo storage per ogni macchina virtuale, perché ogni oggetto storage delle macchine virtuali è un'entità univoca in NetApp ONTAP. Con i sistemi ASA R2, che non richiedono più la gestione dei volumi, questo significa che ogni oggetto storage delle macchine virtuali è un'unica unità di storage (su) sull'array e può essere controllato in modo indipendente. Ciò consente la creazione di policy di storage che possono essere applicate a singole macchine virtuali o VMDK (e quindi include un SUS duale), fornendo un controllo granulare sui servizi storage quali performance, disponibilità e protezione dei dati.</block>
  <block id="f467f22eb6ec5b3e0694963b3f16ebc2" category="section-title">Gestione basata su criteri storage (SPBM)</block>
  <block id="05ba8cf72b56cd6a89d699c0a922d186" category="paragraph">SPBM fornisce un framework che funge da layer di astrazione tra i servizi di storage disponibili per l'ambiente di virtualizzazione e gli elementi di storage sottoposti a provisioning tramite policy. Questo approccio consente agli storage architect di progettare pool di storage con funzionalità differenti. Questi pool possono essere facilmente utilizzati dagli amministratori VM. Gli amministratori possono quindi abbinare i requisiti dei carichi di lavoro delle macchine virtuali ai pool di storage di cui è stato eseguito il provisioning. Questo approccio semplifica la gestione dello storage e permette un utilizzo più efficiente delle risorse di storage.</block>
  <block id="4e1ae190f1f93f025754e7944927b697" category="paragraph">SPBM è un componente chiave di vVol, che fornisce un framework basato su criteri per la gestione dei servizi storage. Le policy vengono create dagli amministratori di vSphere utilizzando regole e funzionalità esposte dal provider VASA (VP) del vendor. È possibile creare policy per diversi servizi di storage, quali performance, disponibilità e protezione dei dati. È possibile assegnare le policy a singole macchine virtuali o VMDK per un controllo granulare sui servizi storage.</block>
  <block id="ac0bb89f2c9215fb6f1280fb1d88d213" category="section-title">NetApp ONTAP e vVol</block>
  <block id="1402ced4d3888a58c5af1059e38ea6b4" category="paragraph">NetApp ONTAP è leader nel settore dello storage nella scalabilità dei vVol, supportando centinaia di migliaia di vVol in un singolo cluster*. Al contrario, gli array Enterprise e i vendor di flash array più piccoli supportano fino a diverse migliaia di vVol per array. ONTAP offre una soluzione storage scalabile ed efficiente per ambienti VMware vSphere, supportando i vVol con un ricco set di servizi storage, tra cui deduplica dei dati, compressione, thin provisioning e protezione dei dati. SPBM consente un'integrazione perfetta con gli ambienti VMware vSphere.</block>
  <block id="6070863553bff7655694da4be22f793e" category="paragraph">In precedenza abbiamo indicato agli amministratori delle macchine virtuali la possibilità di consumare capacità come pool di storage. Ciò avviene mediante l'utilizzo di container di storage rappresentati in vSphere come datastore logici.</block>
  <block id="67fd8c9c20e6ac877f87b28741218bf1" category="paragraph">I container storage vengono creati dagli amministratori dello storage e utilizzati per raggruppare le risorse storage che possono essere consumate dagli amministratori delle macchine virtuali. I container storage possono essere creati in maniera differente a seconda del tipo di sistema ONTAP che stai utilizzando. Con i cluster tradizionali ONTAP 9, ai container viene assegnato uno o più FlexVol di supporto che formano insieme il pool di storage. Con i sistemi ASA R2, l'intero cluster è il pool di storage.</block>
  <block id="5db11f8fed5bd72f359ab9469069dffa" category="summary">Elenco di controllo per l'installazione di ONTAP tools 10</block>
  <block id="a5d727df2ce2d168bae39c78df4b9054" category="doc">Elenco di controllo</block>
  <block id="7aed7b3182cbdda9aceb9c8f8b3c2dbe" category="paragraph">Utilizzare questo elenco di controllo per garantire una distribuzione corretta (aggiornato per 10,3 e versioni successive).</block>
  <block id="06c2cea18679d64399783748fa367bdd" category="inline-image-macro">Uno</block>
  <block id="1e90f607d380c9ee51b487edec3975fa" category="list-title"><block ref="58f667aaf05f87159670e12bd9bc076b" category="inline-image-macro-rx" type="image"></block> Pianificazione iniziale</block>
  <block id="4f04d17639e7b735b12137c9c18a4ab8" category="list-text">Prima di iniziare l'installazione, è necessario controllare il<block ref="5f4d65abf1f4ea058efeaa8d75e7e1ba" category="inline-link-rx"></block> per assicurarsi che la distribuzione sia stata certificata.</block>
  <block id="5541521d8d465590f0919510f29154b2" category="inline-link">Limiti di configurazione per l'implementazione dei tool ONTAP per VMware vSphere</block>
  <block id="225d03736b7d93585b216af68e8caa12" category="list-text">Determina le dimensioni e il tipo di configurazione degli strumenti ONTAP richiesti dall'ambiente. Per ulteriori informazioni, fare riferimento alla<block ref="de0a48be1b1ae6c0ec73a4762c1d7abf" category="inline-link-rx"></block> .</block>
  <block id="e5cd295f99866f601e300eb40641d85c" category="list-text">Determinare se si utilizzeranno SVM multi-tenant o consentire l'accesso completo al cluster. Se utilizzi SVM multi-tenant, dovrai disporre di un LIF di gestione SVM su ciascuna SVM da utilizzare. Questa LIF deve essere raggiungibile tramite la porta 443 dagli strumenti ONTAP.</block>
  <block id="c56feb728c490e11ea8eba91afce9419" category="list-text">Determinare se si intende utilizzare l'adattatore di replica dello storage (SRA) degli strumenti ONTAP per VMware Site Recovery Manager (SRM) o Live Site Recovery (VLSR). In tal caso, sarà necessario accedere all'interfaccia di gestione del server SRM/VLSR per installare SRA.</block>
  <block id="15ee84770ceab89b9fe30ec618843c01" category="inline-link">Creare una relazione di peer cluster in ONTAP</block>
  <block id="bfbb5bcd0f88a18adcc2741da1b9063a" category="inline-link">Creare una relazione di peer intercluster SVM in ONTAP</block>
  <block id="d8a2601707345eab1d4df3e541d61f3c" category="list-text">Se si utilizza la replica di SnapMirror gestita dagli strumenti ONTAP (inclusa, ma non solo, la sincronizzazione attiva di SnapMirror), l'amministratore di ONTAP deve<block ref="f4be9e71a34420e69a7db6d0cf97d232" category="inline-link-rx"></block> e<block ref="42356490ef97c026f7c04a9cb9eeee7d" category="inline-link-rx"></block> prima di poter utilizzare gli strumenti ONTAP con SnapMirror.</block>
  <block id="801ab24683a4a8c433c6eb40c48bcd9d" category="inline-link">Scarica</block>
  <block id="18f5114f4a595ad26525bf20f301ce19" category="list-text"><block ref="20462cf0cb6f4e0f9c91cc66c831d98e" category="inline-link-rx"></block> ONTAP mette a disposizione OVA e, se necessario, il file SRA tar.gz.</block>
  <block id="aada29daee1d64ed0fe907043855cb7e" category="inline-image-macro">Due</block>
  <block id="770c8023395525bc05b5a8fc2e6efa8b" category="list-title"><block ref="54f425ce8d89f4ed6b8a546561af5d60" category="inline-image-macro-rx" type="image"></block> Fornire indirizzi IP e record DNS</block>
  <block id="08b0c7e27d2f1780fce59893f12e7642" category="list-text">ONTAP tools indirizzo applicazione \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="6bb090d29a0e3de8cc001d02c1e8a7b3" category="list-text">Indirizzo servizi interni \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="e32a9122e97bf17560b53c6993301629" category="list-text">Il nome host DNS del nodo uno \___________\_____\______\________________________________</block>
  <block id="1cb7943b8cf41289c8d5ae2c9f9ec310" category="list-text">L'indirizzo IP del nodo uno \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="2b5f3d5d41f4d2986a55a91aa934205c" category="list-text">Maschera di sottorete \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="ed7c49acbcb0724e63d695ba272bcd1d" category="list-text">Gateway predefinito \____\______ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="a637d19158a083f61d5e6d9df66998cb" category="list-text">Server DNS 1 \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="b7eed84956833fb9e8cbb126fb30803f" category="list-text">Server DNS 2 \_____\_____ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="7f7df9c7f87bea4d47136da35a80f4a9" category="list-text">Dominio di ricerca DNS \_____\______\______________________________________________</block>
  <block id="59cd965988b8905f3416029cd3a1facf" category="list-text">Nome host DNS del nodo due (opzionale) \______\_____________________________________________________</block>
  <block id="242e264b9e179f0ea25123089a967467" category="list-text">Indirizzo IP del nodo due (opzionale) \_____\______ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="4115e1d934066b360d5cdd8013198fff" category="list-text">Nome host DNS del nodo tre (opzionale) \______\_____________________________________________________</block>
  <block id="8043aaa26cf3f85d9ab4df441ceb6ef3" category="list-text">Indirizzo IP del nodo tre (opzionale) \_____\______ . \_____\______ . \_____\______ . \_____\_____</block>
  <block id="305c44d3641b44153a7487e28382fffb" category="list-text">Creare record DNS per tutti gli indirizzi IP indicati sopra.</block>
  <block id="ca8a2087e5557e317599344687a57391" category="inline-image-macro">Tre</block>
  <block id="543a0cfd4f6527c92c513911b3079c22" category="list-title"><block ref="05b2444faffd66d76e88602ea7dd353f" category="inline-image-macro-rx" type="image"></block> Configurazione del firewall di rete</block>
  <block id="76841410d8f9a6881e0b96f150e9cedf" category="inline-link">Requisiti delle porte</block>
  <block id="1cb44e38b7d534b49fb7ce15d6726cb0" category="list-text">Aprire le porte richieste per gli indirizzi IP sopra indicati nel firewall di rete. Per l'aggiornamento più recente, consultare la sezione<block ref="d75d54fbd8f18143d683ed6f5389e615" category="inline-link-rx"></block>.</block>
  <block id="981b8fcee42e1e726a67a2b9a98ea6e9" category="inline-image-macro">Quattro</block>
  <block id="640e990f06389e4b49f54086ba1aba46" category="inline-link">Modificare le impostazioni dell'appliance e attivare il servizio VASA</block>
  <block id="49b964c1f288e8e75650b3e86683914d" category="list-text">Per utilizzare vVol, è necessario prima<block ref="c9f7d482e0b51df808dc044e3e43f591" category="inline-link-rx"></block>. Allo stesso tempo, rivedere i due elementi seguenti.</block>
  <block id="8ba46a1826b102cd1b8b0fb75a241176" category="inline-link">abilita l'alta disponibilità</block>
  <block id="acc64c77b8528b3513e0bab18372f0d3" category="list-text">Se si prevede di utilizzare vVol in produzione,<block ref="b5eaf1d61c4c1246e4e215774dc53776" category="inline-link-rx"></block> con i due indirizzi IP opzionali sopra indicati.</block>
  <block id="fddd8f455515e6a6de8e8d876641e0c5" category="inline-link">Attivare i servizi SRA</block>
  <block id="777b715f4e7db3295048bd9409cb3a0f" category="list-text">Se si prevede di utilizzare l'adattatore di replica dello storage (SRA, Storage Replication Adapter) degli strumenti ONTAP per VMware Site Recovery Manager o Live Site Recovery,<block ref="9eb793199b56cb94f5df0c657a62ea9e" category="inline-link-rx"></block>.</block>
  <block id="e5d9de39f7ca1ba2637e5640af3ae8aa" category="inline-image-macro">Cinque</block>
  <block id="e03ec7d1e46f44c47e1547f8c19fdbb5" category="list-text">Per VMware, i certificati CA firmati sono necessari se si utilizzano vVol con più vCenter.</block>
  <block id="777f90dea67a6de19d7e4287d6d65525" category="list-text">Servizi VASA \_____\______\_____\______\__________________________________</block>
  <block id="50261e7dc97594e1ef47d1913fadd642" category="list-text">Servizi amministrativi \_____\______\_____\_____________\______________________</block>
  <block id="e6fbc0b9673f8c86726688d7607fc8f5" category="inline-image-macro">Sei</block>
  <block id="96c44f7328270a7b9e72a07f78739ecf" category="list-text">È necessario un datastore su un dispositivo storage condiviso. In alternativa, è possibile utilizzare una libreria di contenuti nello stesso datastore del nodo uno per semplificare la clonazione rapida del modello con VAAI.</block>
  <block id="656b82abf6edc190097506cd4d1d585b" category="list-text">Libreria di contenuti (richiesta solo per ha) \_____\______\______\_____\______\_______________________</block>
  <block id="99325facb7679dc357733bd909532cfc" category="list-text">Nodo 1 datastore \_____\______\________________________________________________</block>
  <block id="f669e2c7e65edea7adca0c4006b6cf36" category="list-text">Datastore nodo due (opzionale, ma consigliato per ha) \____________\_______\________\_______\______\________________</block>
  <block id="5ba1096fffa0ecfd4695651916c48133" category="list-text">Datastore nodo tre (opzionale, ma consigliato per ha) \____________\__________________________________________________</block>
  <block id="12e67aac3e7f9227cc35f8f047d7dc74" category="inline-image-macro">Sette</block>
  <block id="db5321854b38ff4107ff88c3d3fb2602" category="inline-link">Distribuire l'OVA</block>
  <block id="62386ee2b40ea01fd147eb04a3da8b17" category="list-text"><block ref="2b093a8e786abd40836246bfb87e05bd" category="inline-link-rx"></block> Utilizzando il client vSphere.</block>
  <block id="baca0ca6729684fd54206793ae4b5bd5" category="inline-image-macro">Otto</block>
  <block id="d40a477cc61e319a78ef1bb36d8ea566" category="list-text">Crea regole di affinità per le macchine virtuali in un'implementazione ha.</block>
  <block id="4695b076293ddedd5434ae5a73b57ae2" category="list-text">Se si utilizza l'ha, lo storage vMotion si nodi due e tre per separare i datastore (facoltativo, ma consigliato).</block>
  <block id="fde3f7a850bbaaac2a3706bf8c7df54c" category="inline-link">Configurare i ruoli e i privilegi degli utenti ONTAP</block>
  <block id="064719d8b0308f2a4bc89590c3becdab" category="inline-link">utilizzare gestisci certificati</block>
  <block id="d59a2f6a46dd460183ac2d0c23cf6f75" category="list-text"><block ref="53fb9f19112a80479a138e84ac0182c6" category="inline-link-rx"></block> In ONTAP Tools Manager per installare tutti i certificati CA firmati richiesti.</block>
  <block id="6245e46af5a3bdaf57696763c4214c70" category="inline-link">Aggiungere istanze di vCenter Server</block>
  <block id="427d083edfb4d6df118817492fea1fea" category="list-text"><block ref="9271e724c67dd3dffeb4e3ddaf43b80d" category="inline-link-rx"></block> In ONTAP Tools Manager.</block>
  <block id="75299228e38c6c56354b3fbc53bd01db" category="inline-link">cluster integrati</block>
  <block id="0583aea4353aeb5998071022ebbb79ae" category="inline-link">SVM integrate</block>
  <block id="4d5a9665c20fe0f045d612f3d7c14c3a" category="inline-link">Configurare SRA sull'appliance VMware Live Site Recovery</block>
  <block id="74d3c40ee5d2741e75390e90d13a881a" category="list-text">Se SRA è stato abilitato per SRM/VLSR per proteggere i datastore tradizionali,<block ref="ae14a63430307f4358dbb1aa0a6215ef" category="inline-link-rx"></block>.</block>
  <block id="56b3d744b9b4be462a3690ae4544597f" category="inline-link">RPO prossimo allo zero</block>
  <block id="f2866fe05fc7b275f3e2c504b39a3676" category="list-text">Configurare i backup nativi per<block ref="f915d15018e6084f8326718037772bc7" category="inline-link-rx"></block>.</block>
  <block id="c6a161ea3b473fa2cdc98e5283764902" category="list-text">Configurare backup regolari su altri supporti di archiviazione.</block>
  <block id="ed0748e15540f55b7e9e13424330165e" category="paragraph">Seguire queste Best practice per la creazione dello storage vVol per le macchine virtuali.</block>
  <block id="e747ebae9f47585b050b0fe47b1807b4" category="paragraph">Il provisioning dei datastore vVol implica diversi passaggi. I sistemi ASA R2 di NetApp sono progettati per carichi di lavoro VMware e offrono un'esperienza utente diversa dai sistemi ONTAP tradizionali. Quando si utilizzano i sistemi ASA R2, i tool ONTAP versione 10,3 o successive richiedono pochi passaggi per configurare e includere le estensioni dell'interfaccia utente e il supporto delle API REST ottimizzato per l'architettura storage aggiornata.</block>
  <block id="071d555e17e95fc548b89eaa2c3d9abf" category="section-title">Preparazione alla creazione di archivi dati vVol con gli strumenti ONTAP</block>
  <block id="96a0f754354a16524c8672aacf5ba9a6" category="paragraph">È possibile saltare le prime due fasi del processo di distribuzione se si utilizzano già strumenti ONTAP per gestire, automatizzare e creare report sui sistemi di storage VMFS o tradizionali basati su NFS.</block>
  <block id="6a78342dc1cffdf32c956e733c832cee" category="list-text">Creare la Storage Virtual Machine (SVM) e la relativa configurazione del protocollo. Questa operazione potrebbe non essere necessaria per i sistemi ASA R2, in quanto in genere disporranno già di una singola SVM per i servizi dati. È possibile selezionare NVMe/FC (solo tool ONTAP 9,13), NFSv3, NFSv4,1, iSCSI, FCP o un mix di queste opzioni. NVMe/TCP e NVMe/FC possono essere utilizzati anche per datastore VMFS tradizionali con tool ONTAP 10,3. È possibile utilizzare le procedure guidate di ONTAP System Manager o la riga di comando della shell del cluster.</block>
  <block id="ed0b328de155f4d64394b3fa01aa3eda" category="inline-link">Assegnazione dei Tier locali (aggregati) alle SVM</block>
  <block id="835f14a0eb02625831ec957a0e6d8a57" category="list-text"><block ref="62ee77b15c683e37c03a082cde78e3a1" category="inline-link-rx"></block> Per tutti i sistemi non ASA R2.</block>
  <block id="975336c37f4c9eec8db7574a1acdfc20" category="inline-link">Panoramica sulla configurazione delle LIF</block>
  <block id="a51cd3bd8dc9efabd4808d4faa54cb85" category="inline-link">Combina le porte fisiche per creare gruppi di interfacce</block>
  <block id="02da2876df386437299938fff21fad98" category="list-text">Almeno un LIF per nodo per ogni connessione switch/fabric. Come Best practice, creare due o più per nodo per i protocolli basati su FCP, iSCSI o NVMe. Un'unica LIF per nodo è sufficiente per i vVol basati su NFS, ma questa LIF deve essere protetta da un ifgroup LACP. Per ulteriori informazioni, fare riferimento alla<block ref="f0614b67c9ad440bb8aa968adbd6137a" category="inline-link-rx"></block> e<block ref="a5ffd5460ffa788a3fba4a7f91132efb" category="inline-link-rx"></block> alla.</block>
  <block id="1e410bafe9c5869016fc8d733372d354" category="list-text">Almeno una LIF di gestione per SVM se intendi utilizzare le credenziali scoped della SVM per i vCenter del tenant.</block>
  <block id="88ad52445ad4b758c30b8d41e4898479" category="inline-link">Peering di cluster ONTAP e SVM</block>
  <block id="9e972a46542b8d916a3d602fa7d61635" category="list-text">Se si prevede di utilizzare SnapMirror, assicurarsi che l'origine e la destinazione<block ref="03354afe01dc1f53e5b25fc0bc002ae0" category="inline-link-rx"></block>siano corrette.</block>
  <block id="dd441f913b3f6f72bcf4499b88815e03" category="list-text">È possibile creare volumi in questo momento, ma è consigliabile consentire alla procedura guidata _Provision DataStore_ negli strumenti ONTAP di crearli. L'unica eccezione a questa regola è se si prevede di utilizzare la replica vVol con VMware Site Recovery Manager e gli strumenti ONTAP 9. Questa operazione è più semplice da configurare con volumi FlexVol preesistenti con relazioni SnapMirror esistenti. Prestare attenzione a non abilitare la qualità del servizio su alcun volume da utilizzare per i vVol, in quanto questa operazione deve essere gestita dai tool SPBM e ONTAP.</block>
  <block id="2a03ee5b0887b8a6bf23fd52456544db" category="inline-link">Implementa i tool ONTAP per VMware vSphere</block>
  <block id="23f58455f809e6f8a8a2cac1db0e49cf" category="list-text"><block ref="17b63a5e90adbe276a8874700041ac19" category="inline-link-rx"></block> Utilizzando l'OVA scaricato dal sito di assistenza NetApp.</block>
  <block id="1bcb0e86c49aae8128bbabb5d9d3d585" category="list-text">Gli strumenti ONTAP 10,0 e versioni successive supportano più server vCenter per appliance. Non è più necessario implementare una singola appliance di strumenti ONTAP per vCenter.</block>
  <block id="951d3fc54a28f9f46798897467d96a5b" category="inline-link">Gestire i certificati</block>
  <block id="6d8aae47de809b9e77fb4f1ee0ed7730" category="list-text">Se si prevede di collegare più centri virtuali a una singola istanza di strumenti ONTAP, è necessario creare e installare certificati CA firmati. Fare riferimento alla<block ref="32dbc6ca4c4a8bcb0695dd873f46e9e4" category="inline-link-rx"></block> per i passi.</block>
  <block id="31be7f8c3c1f560d4cfdde9947673161" category="list-text">A partire dal 10,3, i tool ONTAP ora vengono implementati come appliance di piccole dimensioni a nodo singolo adatta alla maggior parte dei workload non vVol.</block>
  <block id="485a78e60d40cdf87a9864e840ed44a8" category="inline-link">Tool ONTAP a scalabilità orizzontale</block>
  <block id="a614ddc55c86c92e39a1e167189a59f3" category="list-text">La Best practice consigliata prevede una<block ref="ef398e4ee19e56a537bbd5564e5f4512" category="inline-link-rx"></block> configurazione ha (High Availability, alta disponibilità) a 3 nodi da 10,3 RU per tutti i carichi di lavoro di produzione. Ai fini dei laboratori o del test, è possibile utilizzare un'implementazione a nodo singolo.</block>
  <block id="0112f904af205a304a0144318d92a88f" category="inline-link">Utilizzo delle regole di affinità senza vSphere DRS</block>
  <block id="7ff088db1b9b2e6077b66b3e834c022c" category="inline-link">Creare una regola di affinità VM-VM</block>
  <block id="1d7299ee36dd01581c03d394e21875e9" category="inline-link">utilizzare l'utilità di backup della configurazione integrata</block>
  <block id="aaccfa1f911c7ed3afac8a1c9005cf08" category="list-text">La Best practice consigliata per l'uso dei vVol di produzione è eliminare ogni singolo punto di errore. Creare regole di anti-affinità per impedire l'esecuzione delle VM degli strumenti ONTAP sullo stesso host. Dopo l'implementazione iniziale, si consiglia anche di utilizzare storage vMotion per posizionare le macchine virtuali del tool ONTAP in datastore differenti. Ulteriori informazioni su<block ref="9d1413939148e981fa32923e1c0a740d" category="inline-link-rx"></block> o<block ref="33bad2ad715296cb3b9df2aa8e0bbe93" category="inline-link-rx"></block>. È inoltre necessario pianificare backup frequenti e/o<block ref="835137bc934138d6c89439748022267d" category="inline-link-rx"></block>.</block>
  <block id="97075bcba23b351ceb599f8167247f82" category="list-text">Configurare gli strumenti ONTAP 10,3 per il proprio ambiente.</block>
  <block id="46efd89ca4d682d645c74916f2c8e8f4" category="list-text"><block ref="9271e724c67dd3dffeb4e3ddaf43b80d" category="inline-link-rx"></block> Nell'interfaccia utente di ONTAP Tools Manager.</block>
  <block id="6eaf552fe4b827d87d969ecf00791fab" category="inline-link">Aggiungi i tuoi cluster ONTAP</block>
  <block id="e4c64ea440c0954a75e29bee53f58731" category="list-text">Gli strumenti ONTAP 10,3 supportano la multi-tenancy sicura. Se non hai bisogno della multi-tenancy sicura, puoi semplicemente<block ref="c70dc775815ebe034e3eb8a346ef862b" category="inline-link-rx"></block> accedere al menu degli strumenti di ONTAP in vCenter, fare clic su _backend di archiviazione_ e fare clic sul pulsante _add_.</block>
  <block id="b7e859c0d3a2db9fa17e5b88bf5ca641" category="list-text">In un ambiente multitenant sicuro dove desideri delegare alcune Storage Virtual Machine (SVM) a vCenter specifici, devi eseguire le seguenti operazioni.</block>
  <block id="2fdde12c870630cac6cf925e7762e8b7" category="list-text">Accedere all'interfaccia utente di ONTAP Tools Manager</block>
  <block id="bfae79cf17053457fef781bcd20e0f14" category="inline-link">Integrare il cluster di storage</block>
  <block id="b7d3b83b5327fbad54ed641ffe056c7b" category="list-text"><block ref="b7d3b83b5327fbad54ed641ffe056c7b" category="inline-link-rx"></block></block>
  <block id="a5ff3af9e80b6313b32053dd07f43a23" category="inline-link">Associazione di un backend dello storage a un'istanza di vCenter Server</block>
  <block id="b60bfa6652bfe8b1d4f8779e792ac95c" category="list-text"><block ref="b60bfa6652bfe8b1d4f8779e792ac95c" category="inline-link-rx"></block></block>
  <block id="e3efa7d6ee6a48514d6cd7ff7795498f" category="list-text">Fornisci le credenziali SVM specifiche all'amministratore vCenter, che aggiungerà la SVM come backend storage nel menu backend storage degli strumenti ONTAP in vCenter.</block>
  <block id="0abec471b6c51c227aee6d0b1708d228" category="list-text">È una Best practice creare ruoli RBAC per gli account storage.</block>
  <block id="e235f10d1a7bf30f3198a59ac049dc9c" category="list-text">Gli strumenti ONTAP includono un file JSON contenente le autorizzazioni di ruolo necessarie per gli account di storage degli strumenti ONTAP. Puoi caricare il file JSON in ONTAP System Manager per semplificare la creazione di ruoli e utenti RBAC.</block>
  <block id="8ca4b3b11e162a34da542a63661edf9a" category="list-text">Per ulteriori informazioni sui ruoli RBAC di ONTAP, visitare il sito Web all'indirizzo<block ref="34ad13b9bdc1ec3d2d017144f37b1766" category="inline-link-rx"></block>.</block>
  <block id="e4f0d44befb2f792ce908178a949f26d" category="admonition">Il motivo per cui l'intero cluster deve essere integrato nell'interfaccia utente del gestore degli strumenti di ONTAP è che molte delle API utilizzate per i vVol sono disponibili solo a livello di cluster.</block>
  <block id="90aa53fd267c0c35741d35381ad7a054" category="section-title">Creazione di archivi dati vVol con gli strumenti ONTAP</block>
  <block id="2899926e592e956d9ee50e9ac1a3fcc5" category="paragraph">Fare clic con il pulsante destro del mouse sull'host, sul cluster o sul data center su cui si desidera creare il datastore vVols, quindi selezionare _ONTAP Tools_ &gt; _Provision Datastore_.</block>
  <block id="893534fd72b00ed504664763cdcfc0a5" category="inline-image-macro">Role="thumb" "procedura guidata per il provisioning del datastore",300</block>
  <block id="4a68f477edf1ea24da48b805acb7318c" category="paragraph"><block ref="4a68f477edf1ea24da48b805acb7318c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20474b1a0c7edf7bd0809f2cb13dfe99" category="list-text">Scegliere vVol e fornire un nome significativo e selezionare il protocollo desiderato. È anche possibile fornire una descrizione del datastore.</block>
  <block id="f4f44261c4e217310cb4f0bb2cc389f5" category="list-text">Strumenti ONTAP 10,3 con ASA R2.</block>
  <block id="39a5735e417853a21c6d8ed53aa5cb1f" category="paragraph"><block ref="39a5735e417853a21c6d8ed53aa5cb1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e332ae811243a2074f58eb5d5efdcc21" category="list-text">Seleziona la SVM del sistema ASA R2 e fai clic su _next_.</block>
  <block id="dac9a06ae28c99c2bc00c2f1ca94c7ed" category="paragraph"><block ref="dac9a06ae28c99c2bc00c2f1ca94c7ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b3dd72cbd7ce4cf79b8fe46700d45d5" category="list-text">Fare clic su _fine_</block>
  <block id="278f04f3dff2f303eed4edfbc836f534" category="paragraph"><block ref="278f04f3dff2f303eed4edfbc836f534" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78195be4e07f2cf980cf70b78cfd4a62" category="list-text">È facile!</block>
  <block id="ca8e7cc39790460719db057ff38e167d" category="list-text">ONTAP Tools 10,3 con ONTAP FAS, AFF e ASA Prior ASA R2.</block>
  <block id="7f016940a12444f321c6a4251eb495cf" category="list-text">Selezionare il protocollo</block>
  <block id="c3646108adeb4be26557fcbb99f62dc2" category="paragraph"><block ref="c3646108adeb4be26557fcbb99f62dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0ec44dc6f9561dfdf58606f8e389753" category="list-text">Seleziona la SVM e fai clic su _next_.</block>
  <block id="444c0ec9fa985ffe1e7a13b90ec73f1b" category="paragraph"><block ref="444c0ec9fa985ffe1e7a13b90ec73f1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75403559d3b552e859c244a233ae00ac" category="list-text">Fare clic su _add new volumes_ o _use existing volume_ e specificare gli attributi. Nota: Negli strumenti di ONTAP 10,3 puoi richiedere la creazione contemporanea di più volumi. È possibile anche aggiungere manualmente più volumi per bilanciarli nel cluster ONTAP. Fare clic su _avanti_</block>
  <block id="9a7e72607a6faad27d7fbe6e5f295675" category="paragraph"><block ref="9a7e72607a6faad27d7fbe6e5f295675" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a38b50f0db11d407ccb112de6a782" category="paragraph"><block ref="4e1a38b50f0db11d407ccb112de6a782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2037e6ffbfee1dde5dddbbca50cda2de" category="paragraph"><block ref="2037e6ffbfee1dde5dddbbca50cda2de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="775c4cf447196b1d2af4bc4eb340eab0" category="list-text">I volumi assegnati possono essere visualizzati nel menu ONTAP tools della scheda Configure per l'archivio dati.</block>
  <block id="f16d549f88c459ef96e6cb1cfd5e5ad6" category="paragraph"><block ref="f16d549f88c459ef96e6cb1cfd5e5ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66ded2ce50d43c22f8e56efe6053a76d" category="list-text">Ora puoi creare policy storage delle macchine virtuali dal menu _Policies and Profiles_ nell'interfaccia utente di vCenter.</block>
  <block id="fc7ec2dfcc40e5c7c47dca5758e10523" category="paragraph">La migrazione delle macchine virtuali dai datastore tradizionali a un datastore vVol è semplice quanto lo spostamento delle macchine virtuali tra datastore tradizionali. È sufficiente selezionare le macchine virtuali, quindi Migrate (Migra) dall'elenco delle azioni e selezionare un tipo di migrazione di _change storage only_. Quando richiesto, seleziona una policy storage della macchina virtuale che corrisponda al datastore vVol. È possibile eseguire l'offload delle operazioni di copia della migrazione con vSphere 6,0 e versioni successive per le migrazioni da VMFS SAN a vVol, ma non da VMDK NAS a vVol.</block>
  <block id="26fcc57b7c0de02dc9e8360d6f4b3493" category="paragraph">Per automatizzare il provisioning dello storage con una gestione basata su criteri, è necessario creare policy di storage delle macchine virtuali associate alle funzionalità di storage desiderate.</block>
  <block id="8b8944ec0cef6dd0777b2144561987fe" category="admonition">Gli strumenti ONTAP 10,0 e versioni successive non utilizzano più i profili di funzionalità dello storage come le versioni precedenti. Le funzionalità di storage vengono invece definite direttamente nel criterio di storage delle macchine virtuali.</block>
  <block id="cdca3b3c5fbefb00afe4df9de69ab75b" category="paragraph">Le policy di storage delle macchine virtuali vengono utilizzate in vSphere per gestire funzionalità opzionali come Storage i/o Control o vSphere Encryption. Vengono inoltre utilizzati con vVol per applicare funzionalità di storage specifiche alla macchina virtuale. Utilizza il tipo di storage "NetApp.Clustered.Data.ONTAP.VP.vvol". Consulta link:vmware-vvol-ontap.html#Best practice[esempio di configurazione di rete con vVol su NFS v3] per un esempio con il provider VASA degli strumenti ONTAP. Le regole per lo storage "NetApp.Clustered.Data.ONTAP.VP.VASA10" devono essere utilizzate con datastore non basati su vVol.</block>
  <block id="0774b1717ce18129cd8e3ec0094e8640" category="paragraph">Una volta creato, il criterio storage può essere utilizzato per il provisioning di nuove macchine virtuali.</block>
  <block id="473e84e674f60e2fe619202a460efdfb" category="inline-image-macro">Role="thumb" "creazione di policy di storage delle macchine virtuali con strumenti ONTAP provider VASA 9,10",300</block>
  <block id="e2f8ccc321215682fc34ae142633f3ff" category="paragraph"><block ref="b8f36bdf242d29fb6768827d6130494d" category="inline-image-macro-rx" type="image"></block> <block ref="e2501bb4f16d0f74914f04323d8e5e58" category="inline-image-macro-rx" type="image"></block> <block ref="166606e94a626af27852e00771133222" category="inline-image-macro-rx" type="image"></block> <block ref="8a14d5d27355a6630c7d65d859977eb8" category="inline-image-macro-rx" type="image"></block> <block ref="50b6bc69b9e417ba7f80bbcc0baaf57d" category="inline-image-macro-rx" type="image"></block> <block ref="8ec6614ba8e8947129dafaaede18ec39" category="inline-image-macro-rx" type="image"></block> <block ref="7bf707d7de5e0a048094c66368c89e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71ea2d7b6b501372ec2ecc7846b5bd74" category="section-title">Gestione delle performance con tool ONTAP</block>
  <block id="4357d652f2cfe6e15b6e8c54aacec10b" category="paragraph">I tool ONTAP utilizzano il proprio algoritmo di posizionamento bilanciato per posizionare un nuovo vVol nel BEST FlexVol volume, con sistemi ASA unificati o classici, o Storage Availability zone (SAZ) con sistemi ASA R2, all'interno di un datastore vVol. Il posizionamento si basa sulla corrispondenza tra lo storage di backup e il criterio di archiviazione della VM. In questo modo si garantisce che il datastore e lo storage di backup soddisfino i requisiti di performance specificati.</block>
  <block id="97c380438d77f28866d8fca75c697d78" category="list-text">*IOPS minimi e massimi* possono essere specificati in un criterio VM.</block>
  <block id="f980d0e57da48ae0fc9f45625e32cf7d" category="list-text">La modifica degli IOPS della policy non modifica la QoS sui vVol fino a quando il criterio VM non viene riapplicato alle VM che lo utilizzano. In alternativa, è possibile creare una nuova policy con gli IOPS desiderati e applicarla alle macchine virtuali di destinazione. In genere, si consiglia di definire semplicemente policy di storage delle macchine virtuali separate per diversi Tier di servizio e di modificare semplicemente il criterio di storage delle macchine virtuali sulla macchina virtuale.</block>
  <block id="6c47cd98201c31f6165c0239e8fa84b8" category="list-text">Le personalità ASA, ASA R2, AFF e FAS hanno diverse impostazioni di IOPS. Sia min che Max sono disponibili sui sistemi all-flash; tuttavia, i sistemi non AFF possono utilizzare solo le impostazioni IOPS massime.</block>
  <block id="6c2d6091dcb0d9df928f0dc687f86383" category="inline-image-macro">Role="thumb" "riapplicazione dei criteri di archiviazione delle macchine virtuali",300</block>
  <block id="8551dcdff381e3430606b1ff98a1e369" category="paragraph"><block ref="8551dcdff381e3430606b1ff98a1e369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="def8fabb3f167c5ac05ad7f416c77a5c" category="paragraph">La chiave per l'utilizzo di vVol con NetApp sono i tool ONTAP per VMware vSphere, che funge da interfaccia provider VASA (vSphere API for Storage Awareness) per i sistemi ONTAP 9 di NetApp.</block>
  <block id="e1688cfcbc1a78418422879cc779caf5" category="paragraph">Gli strumenti ONTAP includono inoltre estensioni dell'interfaccia utente vCenter, servizi API REST, adattatori di replica storage per VMware Site Recovery Manager/Live Site Recovery, strumenti di monitoraggio e configurazione host e una serie di report che consentono di gestire al meglio l'ambiente VMware.</block>
  <block id="d943156d32e8da8030f35b3bdc46f06e" category="paragraph">La licenza ONTAP One include tutte le licenze necessarie per l'utilizzo di vVol con i sistemi ONTAP. L'unico requisito aggiuntivo è il ONTAP gratuito strumenti OVA, che agisce come il fornitore VASA. In un ambiente vVol, il software VASA Provider traduce le funzionalità di array in attributi basati su policy che possono essere sfruttati attraverso le API VASA senza che l'amministratore vSphere debba sapere come le funzionalità vengono gestite dietro le quinte. Ciò consente un consumo dinamico della capacità dello storage allocata in base alle policy, eliminando la necessità di creare manualmente datastore tradizionali e di gestire i rispettivi tassi di consumo dello storage individuale. In breve, i vVol eliminano tutta la complessità della gestione dello storage Enterprise e lo astraggono dall'amministratore vSphere, consentendo loro di concentrarsi sul layer di virtualizzazione.</block>
  <block id="3122b363be1cca4e9b79843907db549f" category="paragraph">Per i clienti che utilizzano VMware Cloud Foundation con vSAN, è possibile aggiungere vVol a qualsiasi dominio di gestione o carico di lavoro come storage supplementare. VVol si integra perfettamente con vSAN attraverso un framework di gestione comune basato su criteri di storage.</block>
  <block id="adcd94c2ec3aa54fc9fbaa77544ccc10" category="paragraph">La famiglia di strumenti ONTAP di nuova generazione release 10 modernizza le funzionalità precedenti con un'architettura scalabile, containerizzata e basata su microservizi, che può essere implementata tramite una semplice appliance in formato OVA su ESXi. Strumenti ONTAP 10 combina tutte le funzionalità di tre precedenti appliance e prodotti in un'unica implementazione. Per la gestione di vVol, userai le estensioni intuitive dell'interfaccia utente di vCenter o le API REST per il provider VASA degli strumenti ONTAP. Tenere presente che il componente SRA è destinato a datastore tradizionali; VMware Site Recovery Manager non utilizza SRA per vVol.</block>
  <block id="b87ac5af4acce876c9cb950c7c5a1891" category="section-title">ONTAP mette a disposizione l'architettura provider VASA quando si utilizza iSCSI o FCP con sistemi unificati</block>
  <block id="b566b0372bb84d18bc26fdc4c0fbd397" category="paragraph">Per le nuove installazioni, implementa l'appliance virtuale nel tuo ambiente vSphere. Una volta implementato, potrai accedere all'interfaccia utente del manager o utilizzare le API REST per scalare in verticale o in orizzontale l'implementazione, gli vCenter integrati (che registrano il plug-in con vCenter), i sistemi storage integrati e associare i sistemi storage ai vCenter. L'integrazione dei sistemi storage nell'interfaccia utente del gestore dei tool ONTAP e l'associazione dei cluster ai vCenter sono necessari solo se intendi utilizzare la multi-tenancy sicura con SVM dedicate, altrimenti potrai semplicemente integrare i cluster storage desiderati nelle estensioni dell'interfaccia utente di vCenter dei tool ONTAP o utilizzando le API REST.</block>
  <block id="26ffc687a7267f96a389530199971cd1" category="inline-link">Tool ONTAP per la documentazione di VMware vSphere</block>
  <block id="e8d49fe128837c5d33383898126449d6" category="paragraph">Fare riferimento a <block ref="d7e84668ac8db4130d4662ae6bde9c89" category="inline-link-macro-rx"></block> nel presente documento, o<block ref="b9c3640cd3dcc39d23d49bf169dd367b" category="inline-link-rx"></block>.</block>
  <block id="2e2b8d8692ea57a5a089be51e49a3104" category="paragraph">È consigliabile archiviare gli strumenti ONTAP e le appliance vCenter sui tradizionali datastore NFS o VMFS, in modo da evitare conflitti di interdipendenza. Poiché sia i tool vCenter che ONTAP devono comunicare tra loro durante le operazioni dei vVol, non installare o spostare le appliance dei tool ONTAP o le appliance vCenter Server (VCSA) nello storage vVol che stanno gestendo. In questo caso, il riavvio delle appliance per gli strumenti vCenter o ONTAP può causare un'interruzione dell'accesso al piano di controllo e l'impossibilità di avviare l'appliance.</block>
  <block id="d6776ddc59d905e2967855a8949b8ff0" category="inline-link">Tool ONTAP per VMware vSphere 10 - Download</block>
  <block id="e085c3225ffce6bb698ac8cf50cc0dc4" category="inline-link">Aggiornamento dai tool ONTAP per VMware vSphere 10.x alla 10,3</block>
  <block id="e43b5fd407b2bc9fda1a39851a48f9bb" category="inline-link">Migrazione dai tool ONTAP per VMware vSphere 9.x a 10,3</block>
  <block id="a3a288ec9e5f16d7de8c63fbc6934c97" category="paragraph">Gli aggiornamenti in-place degli strumenti ONTAP sono supportati utilizzando il file ISO di aggiornamento disponibile per il download all'indirizzo<block ref="b5b3717cb556fa4a89daf005a0a23ea8" category="inline-link-rx"></block> sul sito di supporto NetApp (NSS - è richiesto l'accesso). Seguire le<block ref="f4c1005a920344cdec43558687897506" category="inline-link-rx"></block> istruzioni della guida per aggiornare l'apparecchio. È inoltre possibile eseguire un aggiornamento affiancato dagli strumenti ONTAP 9,13 a 10,3. Fare riferimento a<block ref="f6676f6d529f1f81f9da02084f545f3c" category="inline-link-rx"></block> per un'analisi più approfondita dell'argomento.</block>
  <block id="8374c9fea191c7d2f4430555aa250de3" category="paragraph">Per il dimensionamento dell'appliance virtuale e la comprensione dei limiti di configurazione, fare riferimento alla sezione<block ref="d602e3cdd9623c66a90a3f53a55d967f" category="inline-link-rx"></block></block>
  <block id="eddf7820ea4e2a78603e1bff3aa3bbb6" category="paragraph"><block ref="eddf7820ea4e2a78603e1bff3aa3bbb6" category="inline-link-rx"></block></block>
  <block id="a4552c6e2a6c6188a04ffaf366c67ea5" category="list-text"><block ref="a4552c6e2a6c6188a04ffaf366c67ea5" category="inline-link-rx"></block></block>
  <block id="2bd2f3ded095498e9ee97f7cc9074dc0" category="inline-link">Panoramica sui tool ONTAP per VMware vSphere</block>
  <block id="0e8f3f9d7644f28839e4eb573b4c2589" category="list-text"><block ref="0e8f3f9d7644f28839e4eb573b4c2589" category="inline-link-rx"></block></block>
  <block id="b832e56b13b2026b9c4d50d0f3f07904" category="list-text"><block ref="b832e56b13b2026b9c4d50d0f3f07904" category="inline-link-rx"></block></block>
  <block id="f0bc076dbe95da208c42e642105b0125" category="list-text"><block ref="f0bc076dbe95da208c42e642105b0125" category="inline-link-rx"></block></block>
  <block id="5245dc6f2a790bb421c841d2dfa17c0d" category="inline-link">Eseguire il provisioning degli archivi dati</block>
  <block id="8faeb8c24af8fea505d7e93e49a7faa9" category="list-text"><block ref="8faeb8c24af8fea505d7e93e49a7faa9" category="inline-link-rx"></block></block>
  <block id="607bc4263c4e2c484eb0fbbfdc21b438" category="list-text"><block ref="607bc4263c4e2c484eb0fbbfdc21b438" category="inline-link-rx"></block></block>
  <block id="f5f3c80e03e60f2a58399685adcf6610" category="list-text"><block ref="f5f3c80e03e60f2a58399685adcf6610" category="inline-link-rx"></block></block>
  <block id="1608a10fc8319b14c6c50a77edab9e7c" category="inline-link">Modificare le impostazioni dell'host ESXi</block>
  <block id="1f4b95b02061cf146ca813dd68f240b5" category="list-text"><block ref="1f4b95b02061cf146ca813dd68f240b5" category="inline-link-rx"></block></block>
  <block id="952be4c4311cd0b3b105435f5c484336" category="inline-link">Configurare vSphere Metro Storage Cluster (vMSC) utilizzando gli strumenti ONTAP e la sincronizzazione attiva SnapMirror</block>
  <block id="4e22d6ab0229a29e7c9f041b1f4263a0" category="list-text"><block ref="4e22d6ab0229a29e7c9f041b1f4263a0" category="inline-link-rx"></block></block>
  <block id="c724784c65896d8b16350f4b0580dfd4" category="inline-link">Proteggere le macchine virtuali</block>
  <block id="19ffdbf6d480a0097bf46b6fe379b412" category="list-text"><block ref="7970b8a3df0aeb298f96944db6f19225" category="inline-link-rx"></block> Con SRM</block>
  <block id="cb2b70161843498e22e97eb5f155009c" category="inline-link">Monitorare cluster, datastore e macchine virtuali</block>
  <block id="1f901bed9e91faa77a039d895d167c4b" category="list-text"><block ref="1f901bed9e91faa77a039d895d167c4b" category="inline-link-rx"></block></block>
  <block id="90d45c9fcbbcfdfcff766c447a16f73a" category="paragraph">Il provider VASA include una dashboard con informazioni su performance e capacità per le singole VM vVol. Queste informazioni provengono direttamente da ONTAP per i file e le LUN di vVol, inclusi latenza, IOPS, throughput e altro ancora. È attivata per impostazione predefinita quando si utilizzano tutte le versioni attualmente supportate di ONTAP 9. Si noti che dopo la configurazione iniziale possono essere necessari fino a 30 minuti affinché i dati popolino la dashboard.</block>
  <block id="6861075c55e048882e2c055171a337b2" category="section-title">Altre Best practice</block>
  <block id="ce76fed6b9276669c61e2b0b85e8e767" category="paragraph">In generale, ONTAP supporta i limiti vVol definiti da VMware (vedere pubblicato<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). Verificare sempre la<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> presenza di limiti aggiornati su numero e dimensioni di LUN, namespace e file.</block>
  <block id="0441498a23e55973b6e2d5843b427613" category="paragraph">Anche se è possibile creare datastore vVol con l'interfaccia generale vSphere, utilizzando gli strumenti ONTAP sarà possibile creare automaticamente gli endpoint di protocollo in base alle necessità e creare volumi FlexVol (non richiesti con ASA R2) utilizzando le Best practice ONTAP. È sufficiente fare clic con il pulsante destro del mouse sull'host/cluster/data center, quindi selezionare _ONTAP tools_ e _provisioning datastore_. Da qui, è sufficiente scegliere le opzioni vVol desiderate nella procedura guidata.</block>
  <block id="3729a48b517da427fd2d9807ebc0fed5" category="paragraph">*Zona del fabric Fibre Channel prima di utilizzare FCP per vVol.*</block>
  <block id="f156d8db1f2ed380f0199266e583aa1b" category="paragraph">Per i sistemi diversi da ASA R2, può essere conveniente aggiungere diversi volumi di backup al datastore vVol per distribuire il carico di lavoro nel cluster ONTAP, supportare diverse opzioni di policy o aumentare il numero di LUN o file consentiti. Tuttavia, se è richiesta la massima efficienza dello storage, posizionare tutti i volumi di backup su un singolo aggregato. In alternativa, se sono richieste le massime prestazioni di cloning, prendere in considerazione l'utilizzo di un singolo volume FlexVol e la conservazione dei modelli o della libreria di contenuti nello stesso volume. Il provider VASA trasferisce molte operazioni di storage vVol a ONTAP, tra cui migrazione, cloning e snapshot. Quando questa operazione viene eseguita all'interno di un singolo volume FlexVol, vengono utilizzati cloni di file efficienti in termini di spazio e sono quasi immediatamente disponibili. Quando questo viene eseguito su volumi FlexVol, le copie sono rapidamente disponibili e utilizzano la deduplica e la compressione inline, ma la massima efficienza dello storage potrebbe non essere ripristinata fino a quando i processi in background non vengono eseguiti su volumi che utilizzano la deduplica e la compressione in background. A seconda dell'origine e della destinazione, un certo livello di efficienza potrebbe risultare degradato.</block>
  <block id="256a688cc49c759f4698b8d5d1dd7b6a" category="paragraph">Con i sistemi ASA R2, questa complessità viene rimossa dal momento che il concetto di un volume o aggregato viene astratto dall'utente. Il posizionamento dinamico viene gestito automaticamente e gli endpoint del protocollo vengono creati in base alle necessità. È possibile creare automaticamente al volo endpoint di protocollo aggiuntivi qualora sia necessaria una maggiore scalabilità.</block>
  <block id="66a77b29a2cc0bdf1aa1bf8f6d4dac96" category="paragraph">*Assicurarsi di disporre di LIF di dati sufficienti.* Fare riferimento alla <block ref="d7e84668ac8db4130d4662ae6bde9c89" category="inline-link-macro-rx"></block>.</block>
  <block id="3518579aa5aedcfb4f4b83a6ccbe9cb6" category="admonition">Questo documento è stato aggiornato per includere le nuove funzionalità di vVol disponibili in vSphere 8,0 update 3 e nella versione 10,3 degli strumenti ONTAP.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">Provider VASA</block>
  <block id="0a4ba68e118d83e29ea66516a02f1b48" category="section-title">Punto terminale del protocollo (PE)</block>
  <block id="974863a1395a284a680d09e18cf6c9cc" category="section-title">Virtual Protocol Endpoint (VPE)</block>
  <block id="8f13bfaaa8ba18765f4525a280f647cf" category="section-title">Datastore di volumi virtuali</block>
  <block id="80c64f568dcf805b418e425957b8c975" category="paragraph">| il datastore Virtual Volume è una rappresentazione logica del datastore di un contenitore vVol creato e gestito da un provider VASA. Il container rappresenta un pool di capacità di storage fornito dai sistemi storage gestiti dal provider VASA. Gli strumenti ONTAP supportano l'allocazione di più volumi FlexVol (noti come volumi di backup) a un singolo datastore vVols e questi datastore vVols possono estendersi su più nodi in un cluster ONTAP, combinando sistemi flash e ibridi con funzionalità diverse. L'amministratore può creare nuovi volumi FlexVol utilizzando la procedura guidata di provisioning o l'API REST oppure selezionare volumi FlexVol pre-creati per il backup dello storage, se disponibili.</block>
  <block id="3d947d83ddfd03d217cdfcc09be70c32" category="paragraph">Le API VMware vSphere per la consapevolezza dello storage (VASA) semplificano l'utilizzo da parte di un amministratore delle macchine virtuali delle funzionalità di storage necessarie per il provisioning delle macchine virtuali senza dover interagire con il proprio team di storage. Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con gli amministratori dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, gli amministratori di vCenter con le autorizzazioni appropriate possono definire una serie di funzionalità di storage che gli utenti di vCenter possono utilizzare per eseguire il provisioning delle macchine virtuali. Il mapping tra la policy dello storage delle macchine virtuali e le funzionalità del datastore consente a vCenter di visualizzare un elenco di datastore compatibili da selezionare, oltre a consentire ad altre tecnologie come aria (precedentemente nota come vRealize) Automation o Tanzu Kubernetes Grid di selezionare automaticamente lo storage da una policy assegnata. Questo approccio è noto come gestione basata su criteri di storage. Mentre le regole del provider VASA e le policy storage delle macchine virtuali possono anche essere utilizzate con i datastore tradizionali, la nostra attenzione si concentra sui datastore vVol.</block>
  <block id="9f1893d8db5ceaf62726d1a0aa228224" category="section-title">Policy di storage delle VM</block>
  <block id="0aa8052a92097a4f8ec3114e7249a0e1" category="paragraph">I criteri di storage delle macchine virtuali vengono creati in vCenter in Criteri e profili. Per i vVol, creare un set di regole utilizzando le regole del provider del tipo di storage NetApp vVols. Gli strumenti ONTAP 10.X ora offrono un approccio più semplice rispetto ai tool ONTAP 9.X, consentendo di specificare direttamente gli attributi di storage nel criterio di storage della VM.</block>
  <block id="2efad47a2579a212fb659be8b8101b3c" category="paragraph">Una volta eseguito il provisioning di una VM, il provider VASA continuerà a verificare la conformità e avviserà l'amministratore della VM tramite un allarme in vCenter quando il volume di backup non è più conforme alla policy.</block>
  <block id="ede8e2fa9dea87dd87a82bda2b2cf090" category="paragraph">Le istruzioni per l'installazione di NetApp MetroCluster (definite configurazione MCC) sono disponibili all'indirizzo<block ref="2c736bccede87dae47dcf61108f083c4" category="inline-link-rx"></block>. Le istruzioni per SnapMirror Active Sync (SMA) sono disponibili anche all'indirizzo<block ref="14203840309dd1b6e13f73373477bb9d" category="inline-link-rx"></block>.</block>
  <block id="ea27eb943310e6748735c2b98c65f5fd" category="paragraph">Se non utilizzi MetroCluster, puoi usare SnapMirror Active Sync che offre protezione granulare dei datastore e accesso Active-Active su diversi cluster ONTAP in diversi domini di errore. SMA utilizza gruppi di coerenza (CGS) per garantire la coerenza dell'ordine di scrittura tra uno o più datastore ed è possibile creare più CGS in base ai requisiti dell'applicazione e del datastore. I gruppi di coerenza sono particolarmente utili per le applicazioni che richiedono la sincronizzazione dei dati tra datastore multipli. SMA supporta inoltre RDM (Raw Device Mapping) e storage connesso al guest con iniziatori iSCSI in-guest. Per ulteriori informazioni sui gruppi di coerenza, visitare il sitoWeb all'indirizzo<block ref="8bba9b5b97dba092834d7a48a07f102d" category="inline-link-rx"></block>.</block>
  <block id="1bf63b567c68de7fcd78fcc89f42f93c" category="inline-link">Proteggere utilizzando la protezione del cluster host</block>
  <block id="1809bb507d1d8b8c1fbe71452026a52e" category="paragraph">Gli strumenti ONTAP forniscono ora un modo semplice per configurare la sincronizzazione attiva SnapMirror per vMSC. Puoi usare il plug-in vCenter di ONTAP Tools per creare e gestire relazioni di sincronizzazione attive di SnapMirror tra due cluster ONTAP. Il plug-in fornisce un'interfaccia semplice e intuitiva per creare e gestire relazioni di sincronizzazione attiva SnapMirror tra due cluster ONTAP. Per ulteriori informazioni sul plug-in vCenter degli strumenti ONTAP, visitare il sito Web all'indirizzo<block ref="238135431b1a2d25dda1f29146112b60" category="inline-link-rx"></block>, oppure accedere direttamente a<block ref="50b45f063e0080035a4876db2aa395bd" category="inline-link-rx"></block>.</block>
  <block id="0ed4664c1cb15021c67bd0d4753c18f0" category="paragraph">Esiste una certa differenza nella gestione di una configurazione vMSC con sincronizzazione attiva SnapMirror rispetto a una MetroCluster. In primo luogo, SMA è una configurazione solo SAN, nessun datastore NFS può essere protetto con la sincronizzazione attiva di SnapMirror. In secondo luogo, è necessario mappare entrambe le copie delle LUN agli host ESXi per accedere ai datastore replicati in entrambi i domini di errore.</block>
  <block id="b6930b017bd126db888766f9750b206b" category="section-title">Configurazione di VMware vSphere</block>
  <block id="2587ca69fa38fdcf84be76d7302e4e48" category="admonition">Nessuna disposizione del presente documento sostituisce<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block>. Questo contenuto viene fornito a scopo di riferimento e non sostituisce la documentazione ufficiale VMware.</block>
  <block id="7fb958c31516ee34a32cd425ce9f6084" category="list-text">È possibile creare un allarme basato su eventi che viene attivato quando una macchina virtuale viola una regola di affinità VM-host. Nel client vSphere, aggiungere un nuovo allarme per la macchina virtuale e selezionare "VM viola la regola di affinità VM-host" come trigger dell'evento. Per ulteriori informazioni sulla creazione e la modifica degli allarmi, consultare <block ref="68398319bb6b2bfb9f64390479799795" category="inline-link-macro-rx"></block>la documentazione.</block>
  <block id="0daafa8f38daf57ac774520f73c6131b" category="section-title">Crea cluster di datastore se necessario</block>
  <block id="5888812a5e670c1dc41279a5d93cc502" category="paragraph">*Quando si utilizza l'archiviazione ONTAP, si consiglia di disattivare l'archiviazione DRS.</block>
  <block id="f58d6a99824e61e497bca94714a3efef" category="list-text">I DRS di archiviazione non sono generalmente necessari o consigliati per l'uso con i sistemi di archiviazione ONTAP.</block>
  <block id="8525b77695e58a3254731f53ce2b2162" category="list-text">ONTAP offre proprie funzionalità di efficienza dello storage, come deduplica, compressione e compaction, che possono essere influenzate dallo Storage DRS.</block>
  <block id="c9a841ce409cdc722c7bdd080f0f88de" category="list-text">Se si utilizzano snapshot ONTAP, storage vMotion lascerebbe la copia della macchina virtuale nella snapshot, aumentando potenzialmente l'utilizzo dello storage e potrebbe avere un impatto sulle applicazioni di backup, come NetApp SnapCenter, che tengono traccia delle macchine virtuali e delle relative snapshot ONTAP.</block>
  <block id="e5239709587bb3ebb34629be6c41ac7b" category="paragraph">Le soluzioni vMSC sono supportate sia con NetApp® MetroCluster™ che con SnapMirror Active Sync (precedentemente noto come SnapMirror Business Continuity o SMBC) e forniscono una business continuity avanzata se uno o più domini di errore subiscono un'interruzione totale. La resilienza alle diverse modalità di errore dipende dalle opzioni di configurazione scelte.</block>
  <block id="5c6034b4452ec29d83cf38ddf5f9e2f6" category="paragraph">L'architettura ONTAP è una piattaforma di storage flessibile e scalabile che fornisce servizi SAN (FCP, iSCSI e NVMe-of) e NAS (NFS v3 e v4,1) per datastore. I sistemi storage NetApp AFF, ASA e FAS utilizzano il sistema operativo ONTAP per offrire protocolli aggiuntivi per l'accesso allo storage guest, come S3 e SMB/CIFS.</block>
  <block id="e495475024bf1186bfbf671683e828e6" category="paragraph">La sincronizzazione attiva di NetApp SnapMirror fornisce una protezione granulare dei datastore con protocolli SAN FCP e iSCSI, permettendoti di proteggere in modo selettivo solo i carichi di lavoro ad alta priorità. Offre l'accesso Active-Active ai siti locali e remoti, a differenza di NetApp MetroCluster, che è una soluzione Active-standby. A partire da ONTAP 9.15.1, SnapMirror Active Sync supporta una funzionalità Active/Active simmetrica, consentendo operazioni i/o in lettura e scrittura da entrambe le copie di un LUN protetto con replica sincrona bidirezionale, consentendo alle due copie LUN di servire le operazioni i/O. Prima di ONTAP 9.15.1, la sincronizzazione attiva di SnapMirror supporta solo configurazioni Active/Active asimmetriche, in cui i dati sul sito secondario sono sottoposti a un proxy in un LUN.</block>
  <block id="f1d3123c01306b368942c0739b049d98" category="paragraph">VSphere Metro Storage Cluster (vMSC) è una configurazione certificata che protegge le macchine virtuali (VM) e i container dai guasti. Ciò si ottiene utilizzando concetti di storage estesi insieme ai cluster di host ESXi, distribuiti in diversi domini di errore come rack, edifici, campus o persino città. Le tecnologie di storage Active Sync di NetApp MetroCluster e SnapMirror vengono utilizzate per fornire protezione rispettivamente con RPO=0 o RPO=0 ai cluster host. La configurazione vMSC è progettata per garantire che i dati siano sempre disponibili, anche in caso di errore di un "sito" fisico o logico completo. Un dispositivo di storage che fa parte della configurazione vMSC deve essere certificato dopo aver superato un processo di certificazione vMSC di successo. Tutti i dispositivi di archiviazione supportati sono disponibili nella<block ref="293ceee3268d7991d7fe245e02c1c5c9" category="inline-link-rx"></block> .</block>
  <block id="1e1566860cb6afbc338f9fba32c4e5e5" category="list-text">Active Sync simmetrico (ONTAP 9.15.1)</block>
  <block id="9354dd74ac44e8083ef676403653cf41" category="image-alt">Diagramma vMSC con MSAS e mediatore</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documenti NetApp</block>
  <block id="1c71125ba0668792e46d93c17dc6c428" category="paragraph">Per informazioni specifiche sulla progettazione e la distribuzione della sincronizzazione attiva di SnapMirror, consultare la sezione<block ref="9ace5d3ebe2fe57037322de54ac9a869" category="inline-link-rx"></block>.</block>
  <block id="c50c3de11b39aab15ac6b3b860691105" category="paragraph">La funzionalità VMware Storage DRS consente l'aggregazione di datastore in una singola unità e bilancia i dischi della macchina virtuale quando vengono superate le soglie di controllo i/o di storage (SIOC).</block>
  <block id="a6389705a0010980a83767268763aa53" category="sidebar">Volumi virtuali (vVol) con strumenti ONTAP 10</block>
  <block id="d858ab232a556e2be473d51d09bc0c3d" category="sidebar">Elenco di controllo per l'installazione degli strumenti ONTAP</block>
  <block id="2e0a1393be1d4f990f277513b8384831" category="cell">Mantenere l'impostazione predefinita (1) per ulteriori informazioni, vedere <block ref="3b98534d1167689d42f2d1a533484036" category="inline-link-macro-rx"></block></block>
  <block id="79a22fb066bcc86a371f557f30051d43" category="inline-link">configurare lo zoning</block>
  <block id="b5d661217ddfecce129a41707ffa9fa9" category="list-text">Determinare se si utilizzerà Fibre Channel (FC) per la connettività dello storage. In tal caso, occorre<block ref="1ce5ae0107fd362eacaa4ef5b56c5d82" category="inline-link-rx"></block> utilizzare gli switch FC per abilitare la connettività tra gli host ESXi e le LIF FC della SVM.</block>
  <block id="49e1b0dac188727de519431ac2068825" category="list-text">Richiedere le seguenti informazioni IP al proprio team di rete. Sono necessari i primi tre indirizzi IP; il nodo due e il nodo tre sono utilizzati per implementazioni di ha (high Availability) scale-out. I record host DNS sono obbligatori e tutti i nomi dei nodi e tutti gli indirizzi devono trovarsi sulla stessa VLAN e subnet.</block>
  <block id="7be8dd6dbcd142349f300df69f6a63d2" category="list-title"><block ref="beadfa85a2fdca06b91edc1131c603e6" category="inline-image-macro-rx" type="image"></block> Flash in modo Smart</block>
  <block id="829d9899725b36358387edfa5df0e486" category="list-title"><block ref="99e8b2f00e172bfcff96afdce69907bc" category="inline-image-macro-rx" type="image"></block> Distribuire l'OVA</block>
  <block id="2c63315a0e6899fa3f810f1b06553689" category="list-title"><block ref="ef78558f80439832e0f51cc22cee8b8c" category="inline-image-macro-rx" type="image"></block> Aggiungere vCenter agli strumenti ONTAP</block>
  <block id="0547f403694814dca82327ab77f95205" category="list-title"><block ref="36915574c413876eaa75cbd48f69fd00" category="inline-image-macro-rx" type="image"></block> Aggiungi i backend di storage ai tool ONTAP</block>
  <block id="3317c36267d6f484693b29dbd86b1e79" category="list-text">Se utilizzato se si utilizza la multi-tenancy dello storage con SVM</block>
  <block id="5abf46747a299bb4d24d81d3a3f343aa" category="list-text"><block ref="40ea307f91b1c1591600230b15a0b728" category="inline-link-rx"></block> In ONTAP Tools Manager e associarli a vCenter.</block>
  <block id="e69b3c58a2b1480f291387c690bf92b4" category="list-text"><block ref="9f5477aac946ec407262cd052d80864d" category="inline-link-rx"></block> Negli strumenti ONTAP, l'interfaccia utente vCenter.</block>
  <block id="1ca4d08fe4d0cced2e4ebb5629b6613c" category="list-text">In caso contrario * utilizzando SVM multi-tenant</block>
  <block id="9e80f1d38a7781fc49c6800d20337ec2" category="list-text"><block ref="40ea307f91b1c1591600230b15a0b728" category="inline-link-rx"></block> Direttamente nell'interfaccia utente vCenter degli strumenti ONTAP. In alternativa, in questo scenario è possibile aggiungere SVM direttamente quando non si utilizzano i vVol.</block>
  <block id="421bdf5be659af6d75aab31df92b7907" category="list-title"><block ref="430057c670c01688e904ed2ba129a0b5" category="inline-image-macro-rx" type="image"></block> Configurare i servizi delle appliance (opzionali)</block>
  <block id="24db11216549ee55172c33cf3def2f3f" category="inline-image-macro">Nove</block>
  <block id="8a339db13a88428ad39d370cfdd1129a" category="list-title"><block ref="b37b448eff4f65237cf47b29bdd2817c" category="inline-image-macro-rx" type="image"></block> Certificati (opzionali)</block>
  <block id="a185c3c138dca5ef46afc33288a67d1f" category="inline-image-macro">Dieci</block>
  <block id="71fc21799db94f8cae72c8732659492c" category="list-title"><block ref="6097494f0af631df68e3dcb7a6da8d2a" category="inline-image-macro-rx" type="image"></block> Altre attività successive all'implementazione</block>
  <block id="93da9d9a3842b9e17ab9de43211bf697" category="paragraph">Fare riferimento a<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block> per ulteriori informazioni__.__</block>
  <block id="275507174f3ab21b1a65c1d5e8446001" category="paragraph">Fare riferimento anche a<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block>.</block>
  <block id="c44625cf01f743c720301c28e8461709" category="list-text">Si noti che questo passaggio può richiedere fino a 45 minuti</block>
  <block id="7747c50f7bb3ac05c39d999f8d5ce43e" category="list-text">Nel passaggio 3 della distribuzione OVA, selezionare l'opzione "Customize this virtual machine's hardware" (Personalizza l'hardware di questa macchina virtuale) e impostare quanto segue nel passaggio 10:</block>
  <block id="a7510781f5c52d40e5706471809518f0" category="list-text">"Attiva aggiunta a caldo CPU"</block>
  <block id="5b1ae3ca31ee580e9664ebf0949a302c" category="list-text">"Hot plug memoria"</block>
  <block id="2cd9adcb9e8de7c58834011ca647797d" category="list-text"><block ref="4ccf4d83bac775854f5f0cfb549c6d86" category="inline-link-rx"></block> Utilizzo del file JSON incluso se non si utilizza admin.</block>
  <block id="067561a3b92d67321174249eb7de567d" category="paragraph">Nel 2012, NetApp ha iniziato a collaborare con VMware per supportare le API vSphere per la consapevolezza dello storage (VASA) per vSphere 5. Questo primo provider VASA consentiva la definizione delle funzionalità di storage in un profilo che poteva essere utilizzato per filtrare i datastore durante il provisioning e per verificare successivamente la conformità con la policy. Nel corso del tempo, questo si è evoluto per aggiungere nuove funzionalità per consentire una maggiore automazione nel provisioning, oltre all'aggiunta di volumi virtuali o vVol, in cui i singoli oggetti storage vengono utilizzati per i file delle macchine virtuali e i dischi virtuali. Questi oggetti potrebbero essere LUN, file e ora con vSphere 8 - namespace NVMe (utilizzati con gli strumenti ONTAP 9.13P2). NetApp ha lavorato a stretto contatto con VMware come partner di riferimento per vVol rilasciati con vSphere 6 nel 2015 e ancora come partner di progettazione per vVol che utilizzano NVMe over Fabrics in vSphere 8. NetApp continua a migliorare vVol per sfruttare le più recenti funzionalità di ONTAP.</block>
  <block id="e867f73e9a09d015c82be5c45264cda9" category="paragraph">I vVol sono i file e i dischi della macchina virtuale memorizzati nel datastore vVols. Il termine vVol (singolo) si riferisce a un singolo file, LUN o namespace specifico. ONTAP crea spazi dei nomi NVMe, LUN o file a seconda del protocollo utilizzato dal datastore. Esistono diversi tipi diversi di vVol; i più comuni sono Config (l'unico con VMFS su di esso, contiene file di metadati come il file VMX della VM), dati (disco virtuale o VMDK) e Swap (creato quando la VM è accesa). I vVol protetti dalla crittografia VMware VM saranno di tipo Altro. La crittografia di VMware VM non deve essere confusa con la crittografia aggregata o del volume ONTAP.</block>
  <block id="f615a85ee8b4ffd3bdd64ab72c2cf934" category="paragraph">Come menzionato in precedenza, l'utilizzo delle policy può contribuire a semplificare l'attività di provisioning di una macchina virtuale o di un VMDK. Basta selezionare una policy appropriata e il provider VASA mostrerà i datastore vVol che supportano tale policy e posizioneranno il vVol in un singolo FlexVol volume conforme.</block>
  <block id="d5938f26039c87ff0b18251b9b89e0ec" category="list-text">I cloni vengono creati rapidamente all'interno di un singolo volume o su più volumi in un cluster ONTAP, un vantaggio rispetto ai cloni abilitati VAAI tradizionali. Sono inoltre efficienti in termini di storage. I cloni all'interno di un volume utilizzano il clone del file ONTAP, simile ai volumi FlexClone, e memorizzano solo le modifiche dal file/LUN/namespace vVol di origine. In questo modo, le macchine virtuali a lungo termine per la produzione o altri scopi applicativi vengono create rapidamente, occupano poco spazio e possono beneficiare della protezione a livello di macchine virtuali (utilizzando il plug-in NetApp SnapCenter per VMware vSphere, le snapshot gestite da VMware o il backup VADP) e della gestione delle performance (con QoS ONTAP). I cloni cross volume sono molto più veloci con vVol che con VAAI becuase con VASA, possiamo creare il clone e permetterne l'accesso alla destinazione prima del completamento della copia. I blocchi di dati vengono copiati come processo in background per popolare il vVol di destinazione. In questo modo, lo spostamento delle LUN senza interruzioni di ONTAP funziona anche con le LUN tradizionali.</block>
</blocks>