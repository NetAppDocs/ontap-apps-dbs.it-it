<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Note legali</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Le note legali forniscono l'accesso a dichiarazioni di copyright, marchi, brevetti e altro ancora.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marchi</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, il logo NETAPP e i marchi elencati nella pagina dei marchi NetApp sono marchi di NetApp, Inc. Altri nomi di società e prodotti potrebbero essere marchi dei rispettivi proprietari.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevetti</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Un elenco aggiornato dei brevetti di proprietà di NetApp è disponibile all'indirizzo:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Direttiva sulla privacy</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Open source</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">I file di avviso forniscono informazioni sul copyright e sulle licenze di terze parti utilizzate nel software NetApp.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Avviso per ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Avviso per ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Avviso per ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Avviso per ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Avviso per ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Avviso per ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Avviso per ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Avviso per ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Avviso per ONTAP 9,7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Avviso per ONTAP 9,6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Avviso per ONTAP 9,5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Avviso per ONTAP 9,4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Avviso per ONTAP 9,3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Avviso per ONTAP 9,2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Avviso per ONTAP 9,1</block>
  <block id="5672f5979be77bb31dd559817c9e1e76" category="paragraph"><block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block>
<block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block>
<block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block>
<block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block>
<block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block>
<block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block>
<block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block>
<block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block>
<block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block>
<block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block>
<block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block>
<block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block>
<block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block>
<block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block>
<block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="07ee2fe6f236deffba69a7cf80a680fd" category="section-title">ONTAP Mediator per MCC IP</block>
  <block id="f089ab2b9f25f609795bdd46ae636f18" category="inline-link-macro">9.9.1 Avviso per ONTAP Mediator per MCC IP</block>
  <block id="239794a299abe62705440f2dab3114cb" category="inline-link-macro">9,8 Avviso per ONTAP Mediator per MCC IP</block>
  <block id="51fcca20d278d2d03192c01120f17442" category="inline-link-macro">9,7 Avviso per ONTAP Mediator per MCC IP</block>
  <block id="3ba2aeb22339424d5f5b15dafd2c3eca" category="paragraph"><block ref="c8696a7854fcd089ea112145e4968b10" category="inline-link-macro-rx"></block>
<block ref="4d19e06382f392d0f1a50df789d77c13" category="inline-link-macro-rx"></block>
<block ref="fe4ac88b6b3f1cb9f1dc6d5d4b5086ee" category="inline-link-macro-rx"></block></block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Policy</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Ciò è comune con i database. Anche i database che contengono blocchi inattivi sono candidati per il tiering FabricPool. Ad esempio, un database di gestione della catena logistica potrebbe contenere informazioni cronologiche che devono essere disponibili se necessario ma non accessibili durante le normali operazioni. La funzione FabricPool può essere utilizzata per spostare selettivamente i blocchi inattivi.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Ad esempio, i file di dati in esecuzione su un volume FabricPool con un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il periodo di 90 giorni conserva i blocchi a cui si accede nei 90 giorni precedenti nel tier di performance. Tuttavia, qualsiasi elemento a cui non si accede per 90 giorni viene ricollocato nel Tier di capacità. In altri casi, la normale attività applicativa preserva i blocchi corretti sul livello corretto. Ad esempio, se un database viene normalmente utilizzato per elaborare regolarmente i 60 giorni precedenti di dati, è molto più basso<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il periodo può essere impostato perché l'attività naturale dell'applicazione garantisce che i blocchi non vengano spostati prematuramente.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> i criteri devono essere utilizzati con attenzione per i database. Numerosi database prevedono attività periodiche come la fine del quarter o la reindicizzazione delle operazioni. Se il periodo di queste operazioni è superiore a.<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> possono verificarsi problemi di prestazioni. Ad esempio, se l'elaborazione a fine quarter richiede 1TB TB di dati che non vengono intatti, è possibile che tali dati siano presenti nel Tier di capacità. Le letture dal Tier di capacità sono spesso estremamente veloci e potrebbero non causare problemi di performance, ma i risultati esatti dipendono dalla configurazione dell'archivio di oggetti.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il criterio deve essere impostato su un livello sufficientemente alto da conservare i file che potrebbero essere necessari nel livello di prestazioni. Ad esempio, un database in cui potrebbero essere necessari gli ultimi 60 giorni di dati con prestazioni ottimali giustificherebbe l'impostazione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo a 60 giorni. Risultati simili possono essere ottenuti anche in base ai modelli di accesso dei file. Ad esempio, se sono necessari gli ultimi 90 giorni di dati e l'applicazione sta accedendo a quell'arco di dati di 90 giorni, i dati resteranno sul Tier di performance. Impostazione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> un periodo di 2 giorni eseguirebbe il tiering dei dati non appena i dati diventano meno attivi.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy è necessaria per gestire il tiering di questi blocchi perché solo l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio influisce sui blocchi che si trovano nel file system attivo.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Qualsiasi tipo di accesso ai dati ripristina i dati della mappa termica. Pertanto, le scansioni delle tabelle complete dei database e persino le attività di backup in grado di leggere i file di origine impediscono il tiering perché necessario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la soglia non viene mai raggiunta.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Sebbene il ridimensionamento delle LUN sia un'opzione per aumentare la capacità, in genere è preferibile utilizzare un LVM, incluso Oracle ASM. Uno dei motivi principali per cui esistono le LVM è evitare la necessità di ridimensionare le LUN. Con un LVM, più LUN sono unite in un pool virtuale di storage. I volumi logici scavati da questo pool sono gestiti da LVM e possono essere facilmente ridimensionati. Un ulteriore vantaggio è l'eliminazione degli hotspot su una determinata unità distribuendo un determinato volume logico su tutte le LUN disponibili. Di solito, la migrazione trasparente può essere eseguita utilizzando il volume manager per spostare le estensioni sottostanti di un volume logico su nuovi LUN.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL forzato manualmente</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">Questa sezione espande la spiegazione di ONTAP NVFAIL di base per affrontare argomenti specifici di MetroCluster.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Con MetroCluster, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight Se si verifica un guasto nella NVRAM locale o nella connettività ad altri nodi, i dati non verranno più mirrorati.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Se la NVRAM locale riporta un errore, il nodo si arresta. Questo arresto determina il failover su un partner controller quando vengono utilizzate coppie ha. Con MetroCluster, il comportamento dipende dalla configurazione complessiva scelta, ma può portare al failover automatico della nota remota. In ogni caso, nessun dato viene perso perché il controller che subisce l'errore non ha confermato l'operazione di scrittura.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Un guasto di connettività site-to-site che blocca la replica NVRAM ai nodi remoti è una situazione più complicata. Le scritture non vengono più replicate sui nodi remoti, con la possibilità di perdita di dati in caso di errore catastrofico su un controller. Cosa più importante, il tentativo di failover su un nodo diverso in queste condizioni comporta una perdita di dati.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">Il fattore di controllo è se la NVRAM è sincronizzata. Se la NVRAM è sincronizzata, il failover da nodo a nodo può procedere in tutta sicurezza senza il rischio di perdita di dati. In una configurazione MetroCluster, se la NVRAM e i plessi degli aggregati sottostanti sono sincronizzati, è possibile effettuare lo switchover senza correre il rischio di perdita di dati.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP non consente alcun failover o switchover quando i dati non sono sincronizzati, a meno che non sia forzato il failover o lo switchover. La forzatura di una modifica delle condizioni in questo modo riconosce che i dati potrebbero essere lasciati indietro nel controllore originale e che la perdita di dati è accettabile.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">I database sono particolarmente vulnerabili al danneggiamento se un failover o uno switchover è forzato, perché mantengono cache interne di dati su disco di dimensioni maggiori. In caso di failover o switchover forzato, le modifiche riconosciute in precedenza vengono eliminate del tutto. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Per proteggere le applicazioni da questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro gli errori della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano l'arresto di un'applicazione in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché eventuali scritture riconosciute sono ancora presenti nel sistema di storage e, nel caso dei database, tutti i dati delle transazioni con commit devono essere presenti nei registri.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Solitamente, gli amministratori dovranno arrestare completamente gli host prima di riportare manualmente LUN e volumi in linea. Sebbene queste fasi possano comportare un certo lavoro, questo approccio è il modo più sicuro per garantire l'integrità dei dati. Non tutti i dati richiedono questa protezione, motivo per cui il comportamento di NVFAIL può essere configurato in base al volume.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">L'opzione più sicura per forzare uno switchover con un cluster di applicazioni (inclusi VMware, Oracle RAC e altri) distribuito tra i siti dipende da come specificato<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> alla riga di comando. Questa opzione è disponibile come misura di emergenza per assicurarsi che tutti i dati memorizzati nella cache vengano eliminati. Se un host utilizza risorse di storage situate originariamente nel sito colpito da disastro, riceve errori di i/o o un handle di file obsoleto <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>). I database Oracle si arrestano in modo anomalo e i file system possono andare completamente offline o passare alla modalità di sola lettura.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Al termine dello switchover, il<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Il flag deve essere cancellato e i LUN devono essere messi online. Al termine di questa attività, è possibile riavviare il database. È possibile automatizzare queste attività per ridurre l'RTO.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">Come misura di sicurezza generale, impostare<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> contrassegnare tutti i volumi a cui è possibile accedere da un sito remoto durante le normali operazioni, ovvero si tratta di attività utilizzate prima del failover. Il risultato di questa impostazione è che i volumi remoti selezionati diventano non disponibili quando vengono immessi<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> durante uno switchover. Al termine dello switchover, il<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Il flag deve essere cancellato e i LUN devono essere messi online. Al termine di queste attività, è possibile riavviare le applicazioni. È possibile automatizzare queste attività per ridurre l'RTO.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">Il risultato è come usare l'<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> flag per commutatori manuali. Tuttavia, il numero di volumi interessati può essere limitato solo a quei volumi che devono essere protetti da applicazioni o sistemi operativi con cache obsolete.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Ci sono due requisiti critici per un ambiente che non utilizza<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> su volumi applicativi:</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Uno switchover forzato non deve avvenire più di 30 secondi dopo la perdita del sito primario.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Lo switchover non deve essere eseguito durante le attività di manutenzione o in altre condizioni in cui i plex SyncMirror o la replica della NVRAM non sono sincronizzati. Il primo requisito può essere soddisfatto con il software tiebreaker configurato per eseguire uno switchover entro 30 secondi da un guasto del sito. Questo requisito non significa che lo switchover debba essere eseguito entro 30 secondi dal rilevamento di un guasto del sito. Ciò significa che non è più sicuro forzare uno switchover se sono trascorsi 30 secondi da quando un sito è stato confermato operativo.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">Il secondo requisito può essere parzialmente soddisfatto disattivando tutte le funzionalità di switchover automatico quando la configurazione di MetroCluster non è sincronizzata. Un'opzione migliore è quella di disporre di una soluzione di tiebreaker in grado di monitorare lo stato di salute della replica NVRAM e dei plessi SyncMirror. Se il cluster non è completamente sincronizzato, il tiebreaker non deve attivare uno switchover.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">Il software NetApp MCTB non è in grado di monitorare lo stato di sincronizzazione, pertanto deve essere disattivato quando MetroCluster non è sincronizzato per alcun motivo. ClusterLion include funzionalità di monitoraggio NVRAM e plex e può essere configurato in modo da non attivare lo switchover a meno che il sistema MetroCluster non sia confermato completamente sincronizzato.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">Numero di LUN</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Un LUN è un oggetto virtualizzato in ONTAP presente in tutti i dischi dell'aggregato di hosting. Di conseguenza, le performance della LUN non sono influenzate dalle sue dimensioni, perché la LUN sfrutta al massimo il potenziale in termini di performance dell'aggregato, indipendentemente dalle dimensioni scelte.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">Per comodità, i clienti potrebbero desiderare di utilizzare un LUN di particolari dimensioni. Ad esempio, se un database è costruito su un gruppo di dischi LVM o Oracle ASM composto da due LUN da 1TB GB ciascuno, tale gruppo di dischi deve essere aumentato in incrementi di 1TB TB. Potrebbe essere preferibile costruire il gruppo di dischi da otto LUN da 500GB ciascuno in modo che il gruppo di dischi possa essere aumentato con incrementi più piccoli.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">La pratica di stabilire una dimensione LUN standard universale è scoraggiata perché ciò può complicare la gestibilità. Ad esempio, è possibile che una dimensione LUN standard di 100GB TB sia ottimale quando un database o un datastore è compreso nell'intervallo da 1TB a 2TB TB, ma un database o un datastore di 20TB GB richiederebbe 200 LUN. Ciò significa che i tempi di riavvio del server sono più lunghi, che vi sono più oggetti da gestire nelle varie interfacce utente e che prodotti come SnapCenter devono eseguire la ricerca su molti oggetti. Utilizzando un numero inferiore di LUN di dimensioni maggiori è possibile evitare questi problemi.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">Il numero di LUN è più importante delle dimensioni delle LUN.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">Le dimensioni dei LUN sono principalmente controllate dai requisiti di numero di LUN.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Evitare di creare più LUN del necessario.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">A differenza delle dimensioni delle LUN, il numero di LUN influisce sulle performance. Spesso le prestazioni delle applicazioni dipendono dalla capacità di eseguire i/o paralleli attraverso il livello SCSI. Di conseguenza, due LUN offrono performance migliori rispetto a una singola LUN. Utilizzare un LVM come Veritas VxVM, Linux LVM2 o Oracle ASM è il metodo più semplice per aumentare il parallelismo.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">I clienti di NetApp hanno in genere ottenuto il minimo beneficio dall'aumento del numero di LUN oltre i sedici, sebbene i test degli ambienti con dischi a stato solido al 100% con i/o casuali molto intensi abbiano dimostrato un ulteriore miglioramento fino a 64 LUN.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp consiglia* quanto segue:</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">In generale, da quattro a sedici LUN sono sufficienti per supportare le esigenze di i/o di qualsiasi carico di lavoro del database. Meno di quattro LUN potrebbero creare limiti di performance a causa delle limitazioni nelle implementazioni SCSI host.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Impostazioni del sistema operativo host</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">La maggior parte della documentazione del fornitore di applicazioni include impostazioni TCP ed ethernet specifiche per garantire il funzionamento ottimale dell'applicazione. Queste stesse impostazioni sono in genere sufficienti per fornire anche prestazioni ottimali dello storage basato su IP.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Controllo di flusso Ethernet</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Questa tecnologia consente a un client di richiedere che un mittente interrompa temporaneamente la trasmissione dei dati. Questa operazione viene solitamente eseguita perché il ricevitore non è in grado di elaborare i dati in ingresso abbastanza rapidamente. Una volta, la richiesta che un mittente cessi la trasmissione era meno disgregativa di avere pacchetti di scarto del destinatario perché i buffer erano pieni. Questo non è più il caso degli stack TCP utilizzati oggi nei sistemi operativi. Infatti, il controllo di flusso causa più problemi di quanti ne risolva.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Negli ultimi anni sono aumentati i problemi di prestazioni causati dal controllo di flusso Ethernet. Questo perché il controllo di flusso Ethernet opera al livello fisico. Se una configurazione di rete consente a qualsiasi sistema operativo host di inviare una richiesta di controllo di flusso Ethernet a un sistema di storage, il risultato è una pausa in i/o per tutti i client connessi. Poiché un numero crescente di client viene servito da un singolo storage controller, aumenta la probabilità che uno o più client inviino richieste di controllo di flusso. Il problema è stato riscontrato frequentemente presso le sedi dei clienti con un'ampia virtualizzazione del sistema operativo.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Una scheda NIC su un sistema NetApp non dovrebbe ricevere richieste di controllo di flusso. Il metodo utilizzato per ottenere questo risultato varia in base al produttore dello switch di rete. Nella maggior parte dei casi, il controllo di flusso su uno switch Ethernet può essere impostato su<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> oppure<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, il che significa che una richiesta di controllo di flusso non viene inoltrata al controller di memorizzazione. In altri casi, la connessione di rete sul controller di storage potrebbe non consentire la disattivazione del controllo di flusso. In questi casi, i client devono essere configurati in modo da non inviare mai richieste di controllo di flusso, modificando la configurazione NIC sul server host stesso o le porte switch a cui è connesso il server host.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp consiglia* assicurarsi che i controller di archiviazione NetApp non ricevano pacchetti di controllo di flusso Ethernet. In genere, è possibile eseguire questa operazione impostando le porte dello switch a cui è collegato il controller, ma alcuni hardware dello switch presentano dei limiti che potrebbero richiedere modifiche sul lato client.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">Dimensioni MTU</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">È stato dimostrato che l'utilizzo dei frame jumbo offre un certo miglioramento delle performance nelle reti 1Gb, riducendo l'overhead della CPU e della rete, ma i benefici non sono solitamente significativi.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp consiglia* l'implementazione di frame jumbo quando possibile, sia per ottenere potenziali vantaggi in termini di prestazioni sia per rendere la soluzione a prova di futuro.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">L'utilizzo di frame jumbo in una rete 10Gb è quasi obbligatorio. Questo perché la maggior parte delle implementazioni 10Gb raggiungono un limite di pacchetti al secondo senza frame jumbo prima che raggiungano il contrassegno 10Gb. L'utilizzo di frame jumbo migliora l'efficienza dell'elaborazione TCP/IP, poiché consente a sistema operativo, server, schede di rete e sistema di storage di elaborare un numero inferiore di pacchetti, anche se di dimensioni maggiori. Il miglioramento delle prestazioni varia da scheda di rete a scheda di rete, ma è significativo.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">Per le implementazioni jumbo-frame, esiste la convinzione comune, ma non corretta, che tutti i dispositivi connessi debbano supportare frame jumbo e che le dimensioni MTU debbano corrispondere end-to-end Al contrario, i due endpoint di rete negoziano la dimensione del frame più elevata reciprocamente accettabile quando si stabilisce una connessione. In un ambiente tipico, uno switch di rete è impostato su una dimensione MTU di 9216, il controller NetApp è impostato su 9000 e i client sono impostati su una combinazione di 9000 e 1514. I client in grado di supportare un valore MTU di 9000 possono utilizzare frame jumbo, mentre i client in grado di supportare solo 1514 possono negoziare un valore inferiore.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">I problemi con questa disposizione sono rari in un ambiente completamente commutato. Tuttavia, in un ambiente con routing occorre assicurarsi che nessun router intermedio sia costretto a frammentare frame jumbo.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp consiglia* di configurare quanto segue:</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">I frame jumbo sono desiderabili ma non necessari con 1Gb Ethernet (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">I frame jumbo sono necessari per ottenere le massime prestazioni con 10GbE e velocità.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">Parametri TCP</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">Tre impostazioni spesso non sono configurate correttamente: Timestamp TCP, riconoscimento selettivo (SACK) e ridimensionamento finestra TCP. Molti documenti obsoleti su Internet consigliano di disabilitare uno o più di questi parametri per migliorare le prestazioni. Molti anni fa, questa raccomandazione ha avuto un certo merito quando le capacità della CPU erano molto inferiori e, quando possibile, vi era un vantaggio nel ridurre il sovraccarico sull'elaborazione TCP.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Tuttavia, con i sistemi operativi moderni, la disattivazione di una qualsiasi di queste funzioni TCP in genere non comporta alcun vantaggio rilevabile e, allo stesso tempo, può danneggiare le prestazioni. In ambienti di rete virtualizzati, i danni alle prestazioni sono particolarmente probabili, poiché queste funzioni sono necessarie per gestire in modo efficiente la perdita di pacchetti e le modifiche della qualità della rete.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp consiglia* di abilitare timestamp TCP, SACCO e ridimensionamento finestra TCP sull'host, e tutti e tre questi parametri dovrebbero essere attivi per impostazione predefinita in qualsiasi sistema operativo corrente.</block>
  <block id="72a921ac9177188a9be32ec711fc15d8" category="doc">Accesso al percorso</block>
  <block id="544c599da087dba677a820c3df344503" category="paragraph">SnapMirror Business Continuity (SM-BC) è essenzialmente una funzionalità SnapMirror migliorata per LA SAN che consente agli host di accedere a una LUN dal sistema che ospita la LUN, nonché dal sistema che ospita la sua replica.</block>
  <block id="6139cdabb39d5ceac18a60642497c6a7" category="paragraph">SM-BC e SnapMirror Sync (SM-S) condividono un motore di replica, tuttavia SM-BC include funzionalità aggiuntive come il failover trasparente delle applicazioni e il failback per le applicazioni Enterprise.</block>
  <block id="a73743f15de974052b0640c60f489d90" category="paragraph">In pratica, funziona in modo simile a una versione granulare di MetroCluster, consentendo una replica sincrona RPO=0:1 selettiva e granulare per i singoli carichi di lavoro. Il comportamento del percorso di basso livello è molto diverso da MetroCluster, ma il risultato finale da un punto di vista dell'host è simile.</block>
  <block id="b3bf85c7b0a17286752c110f404a7035" category="paragraph">SM-BC rende i dispositivi di storage visibili per l'hosting dei sistemi operativi dagli array di storage primari e remoti. I percorsi vengono gestiti tramite l'ALUA (Asymmetric Logical Unit Access), un protocollo standard di settore per l'identificazione dei percorsi ottimizzati tra un sistema storage e un host.</block>
  <block id="cbf0bd4f4096570f567049c984f8c9d3" category="paragraph">Il percorso del dispositivo più breve per accedere all'i/o è considerato percorsi attivi/ottimizzati e il resto dei percorsi è considerato percorsi attivi/non ottimizzati.</block>
  <block id="350b9208772a185e0d0943b105765d89" category="paragraph">La relazione SM-BC è tra una coppia di SVM situate su cluster diversi. Entrambe le SVM sono in grado di fornire i dati, ma ALUA utilizza preferibilmente la SVM che attualmente è proprietaria dei dischi su cui risiedono le LUN. L'io alla SVM remota verrà fornito con un proxy attraverso l'interconnessione SM-BC.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Errore: Immagine grafica mancante</block>
  <block id="532db5273379dd6149d97b7ab6e420b6" category="paragraph"><block ref="532db5273379dd6149d97b7ab6e420b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Replica sincrona</block>
  <block id="8159c40a86db91b72e00c2eb5cf751fe" category="paragraph">Durante le normali operazioni, la copia remota è una replica sincrona RPO=0/7, con un'unica eccezione. Se i dati non possono essere replicati, SM-BC libera il requisito di replicare i dati e riprendere a servire io. Questa opzione è preferita dai clienti che considerano la perdita del collegamento di replica quasi un evento disastroso o che non desiderano arrestare le operazioni di business quando i dati non possono essere replicati.</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Hardware per lo storage</block>
  <block id="f0fd4c8ee2422af8e335cc85c485ccbf" category="paragraph">A differenza di altre soluzioni di disaster recovery per lo storage, SM-BC offre una flessibilità della piattaforma asimmetrica. Non è necessario che l'hardware di ciascun sito sia identico. Questa funzionalità consente di dimensionare correttamente l'hardware utilizzato per supportare SM-BC. Il sistema di storage remoto può essere identico al sito primario se deve supportare un carico di lavoro di produzione completo, ma se un disastro determina una riduzione dell'i/o, rispetto a un sistema più piccolo nel sito remoto potrebbe risultare più conveniente.</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">Mediatore ONTAP</block>
  <block id="b378eb5f2b386494f24a3f09afd8ae1f" category="paragraph">ONTAP Mediator è un'applicazione software scaricata dal supporto NetApp. Mediator automatizza le operazioni di failover sia per il cluster di storage primario che per quello remoto. Può essere implementato su una piccola macchina virtuale (VM) ospitata on-premise o nel cloud. Una volta configurato, funge da terzo sito per monitorare gli scenari di failover per entrambi i siti.</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Data Protection con SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">Al livello più semplice, la replica sincrona significa che qualsiasi modifica deve essere apportata a entrambi i lati dello storage con mirroring prima che venga riconosciuta. Ad esempio, se un database sta scrivendo un registro o un guest VMware viene aggiornato, non deve mai andare persa una scrittura. Come livello di protocollo, il sistema di storage non deve riconoscere la scrittura fino a quando non è stato assegnato a un supporto non volatile in entrambi i siti. Solo allora è sicuro procedere senza il rischio di perdita dei dati.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">L'utilizzo di una tecnologia di replica sincrona è il primo passo nella progettazione e nella gestione di una soluzione di replica sincrona. La considerazione più importante è capire cosa potrebbe accadere durante i vari scenari di guasto pianificati e non pianificati. Non tutte le soluzioni di replica sincrona offrono le stesse funzionalità. Se hai bisogno di una soluzione che offra un recovery point objective (RPO) pari a zero, ovvero zero data loss, devi prendere in considerazione tutti gli scenari di guasto. In particolare, qual è il risultato previsto quando la replica è impossibile a causa della perdita di connettività tra i siti?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">Disponibilità dei dati SyncMirror</block>
  <block id="bec293a9cf8e49ec40e6a4fdc02b9146" category="paragraph">La replica MetroCluster si basa sulla tecnologia NetApp SyncMirror, che è progettata per passare in modo efficiente dalla modalità sincrona alla modalità sincrona e viceversa. Questa funzionalità soddisfa i requisiti dei clienti che richiedono una replica sincrona, ma che hanno bisogno anche di un'alta disponibilità per i propri servizi dati. Ad esempio, se la connettività a un sito remoto viene interrotta, è generalmente preferibile che il sistema di storage continui a funzionare in uno stato non replicato.</block>
  <block id="9a9ce41f4b23474045b6c6e0ac7752af" category="paragraph">Molte soluzioni di replica sincrona sono in grado di funzionare solo in modalità sincrona. Questo tipo di replica "tutto o niente" viene talvolta chiamato modalità domino. Tali sistemi storage smettono di fornire i dati piuttosto che permettere alle copie locali e remote dei dati di diventare non sincronizzate. Se la replica viene forzata, la risincronizzazione può richiedere molto tempo e lasciare un cliente esposto a una perdita di dati completa durante il tempo in cui il mirroring viene ristabilita.</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">Non solo SyncMirror può passare alla modalità sincrona senza problemi se il sito remoto non è raggiungibile, ma può anche risincronizzare rapidamente uno stato RPO = 0 al ripristino della connettività. La copia obsoleta dei dati nel sito remoto può anche essere preservata in uno stato utilizzabile durante la risincronizzazione, garantendo l'esistenza in ogni momento di copie locali e remote dei dati.</block>
  <block id="995f5151d2d1c0a4e8371b2b3c9b6e5b" category="paragraph">Quando è richiesta la modalità domino, NetApp offre SnapMirror Synchronous (SM-S). Esistono anche opzioni a livello di applicazione, come Oracle DataGuard o timeout estesi per il mirroring del disco lato host. Per ulteriori informazioni e opzioni, consulta il tuo NetApp o il partner account team.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Solo snapshot</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">Il<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> si applica solo ai blocchi non condivisi con il file system attivo. Essenzialmente si traduce in tiering dei backup del database. I blocchi diventano candidati per il tiering dopo la creazione di uno snapshot e il blocco viene quindi sovrascritto, generando un blocco presente solo all'interno dello snapshot. Il ritardo prima di un<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> il blocco è considerato freddo e controllato da<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> impostazione del volume. L'intervallo a partire da ONTAP 9,8 è compreso tra 2 e 183 giorni.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">Molti set di dati hanno tassi di cambiamento bassi, con conseguenti risparmi minimi derivanti da questa policy. Ad esempio, un database tipico osservato con ONTAP ha un tasso di variazione inferiore al 5% alla settimana. I log di archivio dei database possono occupare spazio esteso, ma in genere continuano a esistere nel file system attivo e pertanto non possono essere candidati per il tiering in base a questa policy.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Automatico</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy di tiering estende il tiering sia a blocchi specifici di snapshot che a blocchi nel file system attivo. Il ritardo prima che un blocco venga considerato freddo è controllato dall'<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> impostazione del volume. L'intervallo a partire da ONTAP 9,8 è compreso tra 2 e 183 giorni.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Questo approccio abilita opzioni di tiering che non sono disponibili con<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> policy. Ad esempio, un criterio di protezione dei dati potrebbe richiedere la conservazione di 90 giorni di determinati file di registro. L'impostazione di un periodo di raffreddamento di 3 giorni comporta il tiering di tutti i file di registro precedenti a 3 giorni dal livello delle prestazioni. Questa azione libera spazio sostanziale sul Tier delle performance, consentendoti comunque di visualizzare e gestire tutti e 90 i giorni di dati.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Nessuno</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">Il<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la policy di tiering impedisce il tiering di blocchi aggiuntivi dal layer di storage, ma i dati ancora presenti nel tier di capacità rimangono nel tier di capacità fino a quando non vengono letti. Se quindi il blocco viene letto, viene tirato indietro e posizionato nel Tier di performance.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">Il motivo principale per cui si utilizza<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la policy di tiering impedisce il tiering dei blocchi, ma nel tempo potrebbe risultare utile modificarli. Ad esempio, supponiamo che un set di dati specifico venga suddiviso in Tier per il livello di capacità, ma sorge un'esigenza inaspettata di funzionalità di performance complete. La policy può essere modificata per impedire qualsiasi tiering aggiuntivo e per confermare che i blocchi letti nuovamente quando l'io aumenta rimangono nel Tier di performance.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Tutto</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">Il<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la policy di tiering sostituisce<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Policy in data ONTAP 9,6. Il<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Policy applicata solo ai volumi di data Protection, che significa destinazione SnapMirror o NetApp SnapVault. Il<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> le funzioni dei criteri sono identiche, ma non si limitano ai volumi di protezione dei dati.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Grazie a questa policy, i blocchi vengono immediatamente considerati COOL e possono essere immediatamente suddivisi in Tier nel livello di capacità.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Questo criterio è particolarmente appropriato per i backup a lungo termine. Può anche essere utilizzato come forma di gestione gerarchica dello storage (HSM, Hierarchical Storage Management). In passato, HSM veniva comunemente utilizzato per eseguire il tiering dei blocchi di dati di un file su nastro, mantenendo il file stesso visibile nel file system. Un volume FabricPool con<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> il criterio consente di archiviare i file in un archivio visibile e gestibile pur non occupando quasi nessuno spazio nel livello di storage locale.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">Suddivisione in zone</block>
  <block id="79da1502ddfac887bfdf0d92f2428fe6" category="paragraph">Ciò include misure di pianificazione tipiche, ad esempio garantire che esista una larghezza di banda sufficiente sulla SAN tra il sistema host e il sistema di storage, verificando che tutti i percorsi SAN esistano tra tutti i dispositivi richiesti, utilizzando le impostazioni della porta FC richieste dal fornitore dello switch FC, evitando conflitti ISL, e utilizzando un adeguato monitoraggio del fabric SAN.</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Una zona FC non deve mai contenere più di un iniziatore. Una tale disposizione potrebbe sembrare funzionare inizialmente, ma la diafonia tra gli iniziatori interferisce eventualmente con le prestazioni e la stabilità.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Le zone MultiTarget sono generalmente considerate sicure, anche se in rare circostanze il comportamento delle porte target FC di fornitori diversi ha causato problemi. Ad esempio, evita di includere nella stessa zona le porte di destinazione di uno storage array NetApp e non NetApp. Inoltre, l'inserimento di un sistema di storage NetApp e di un dispositivo a nastro nella stessa zona è ancora più probabile che causino problemi.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Una SVM, nota come vserver nell'interfaccia a riga di comando di ONTAP, è un'unità funzionale di base dello storage ed è utile confrontare una SVM con un guest su un server VMware ESX.</block>
  <block id="9efbaa34de852e33319ca8ceb1861832" category="paragraph">Quando viene installato per la prima volta, ESX non dispone di funzionalità preconfigurate, come l'hosting di un sistema operativo guest o il supporto di un'applicazione per l'utente finale. Si tratta di un container vuoto fino a quando non viene definita una macchina virtuale (VM). ONTAP è simile. Quando viene installata per la prima volta, ONTAP non dispone di funzionalità di servizio dati fino a quando non viene creata una SVM. È il linguaggio della SVM che definisce i servizi dati.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">Come per altri aspetti dell'architettura dello storage, le migliori opzioni per il design di SVM e interfaccia logica (LIF) dipendono in gran parte dai requisiti di scalabilità e dalle esigenze di business.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">Non esistono Best practice ufficiali per il provisioning di SVM per ONTAP. Il giusto approccio dipende dai requisiti di gestione e sicurezza.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">La maggior parte dei clienti utilizza una SVM primaria per la maggior parte delle loro esigenze quotidiane, quindi crea un piccolo numero di SVM per esigenze speciali. Ad esempio, è possibile creare:</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">Una SVM per un database aziendale critico gestita da un team di specialisti</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">Una SVM per un gruppo di sviluppo al quale è stato assegnato un controllo amministrativo completo in modo da poter gestire il proprio storage in maniera indipendente</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">Una SVM per i dati di business sensibili, come le risorse umane o i dati di reporting finanziario, per cui il team di amministrazione deve essere limitato</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe</block>
  <block id="bd32656670155eb09690047819fc0971" category="paragraph">In un ambiente multi-tenant, è possibile assegnare a ciascun tenant una SVM dedicata. Il limite per il numero di SVM e LIF per cluster, coppia ha e nodo dipende dal protocollo in uso, dal modello di nodo e dalla versione di ONTAP.  Consultare <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> per questi limiti.</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">Aggregati SSD, inclusi i sistemi AFF</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">Lo spazio libero viene definito come lo spazio non utilizzato per i dati effettivi e include lo spazio non allocato dell'aggregato e lo spazio non utilizzato all'interno dei volumi costituenti. È importante prendere in considerazione anche il thin provisioning. Ad esempio, un volume potrebbe contenere un LUN da 1TB GB, di cui solo il 50% viene utilizzato dai dati reali. In un ambiente con thin provisioning, questo sembra consumare correttamente 500GB GB di spazio. Tuttavia, in un ambiente con provisioning completo, la capacità completa di 1TB TB sembra essere in uso. I 500GB GB di spazio non allocato sono nascosti. Questo spazio non è utilizzato dai dati effettivi e deve quindi essere incluso nel calcolo dello spazio libero totale.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">Di seguito sono riportate le raccomandazioni NetApp per i sistemi storage utilizzati per le applicazioni aziendali:</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp consiglia* almeno il 10% di spazio libero. Ciò comprende tutto lo spazio inutilizzato, compreso lo spazio libero all'interno dell'aggregato o di un volume ed eventuale spazio libero allocato a causa dell'utilizzo del provisioning completo, ma non utilizzato dai dati effettivi. Lo spazio logico non è importante, la domanda è quanto spazio fisico libero effettivo è disponibile per lo storage dei dati.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">Il consiglio di liberare il 10% dello spazio è molto conservativo. Gli aggregati SSD possono supportare i carichi di lavoro a livelli di utilizzo ancora più elevati senza influire sulle performance. Tuttavia, con l'aumento dell'utilizzo dell'aggregato, aumenta anche il rischio di esaurimento dello spazio se l'utilizzo non viene monitorato con attenzione. Inoltre, mentre si utilizza un sistema al 99% della capacità potrebbe non verificarsi un peggioramento delle performance, tuttavia si verificherebbe un sforzo di gestione che impedirebbe il riempimento completo del sistema mentre si ordina hardware aggiuntivo e potrebbe essere necessario del tempo per l'acquisto e l'installazione di dischi aggiuntivi.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Aggregati HDD, compresi gli aggregati Flash Pool</block>
  <block id="7302e9f16fb8c5bc30f6035fe4098b52" category="admonition">*NetApp consiglia* almeno il 15% di spazio libero quando si utilizzano unità rotanti. Ciò comprende tutto lo spazio inutilizzato, compreso lo spazio libero all'interno dell'aggregato o di un volume ed eventuale spazio libero allocato a causa dell'utilizzo del provisioning completo, ma non utilizzato dai dati effettivi. Le prestazioni saranno influenzate dagli approcci di conversazione libera al 10%.</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio è il criterio più appropriato per i dati di backup. In questo modo si garantisce un tiering rapido quando la soglia di raffreddamento è stata raggiunta, indipendentemente dal fatto che i file siano stati eliminati o continuino a esistere nel file system primario. Inoltre, l'archiviazione di tutti i file potenzialmente necessari in un'unica posizione nel file system attivo semplifica la gestione. Non c'è motivo di cercare tra gli snapshot per individuare un file che deve essere ripristinato.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">Il<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> i criteri potrebbero funzionare, ma si applicano solo ai blocchi che non si trovano più nel file system attivo. Pertanto, i file presenti in una condivisione NFS o SMB devono essere eliminati prima del tiering dei dati.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Questa policy risulterebbe ancora meno efficiente con la configurazione LUN, poiché l'eliminazione di un file da una LUN rimuove solo i riferimenti dei file dai metadati del file system. I blocchi effettivi sui LUN restano in posizione fino a quando non vengono sovrascritti. Questa situazione può creare un lungo ritardo tra il tempo di eliminazione di un file e il tempo in cui i blocchi vengono sovrascritti e candidati per il tiering. Lo spostamento dell' comporta alcuni vantaggi<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Dei blocchi nel Tier di capacità, ma, nel complesso, la gestione FabricPool dei dati di backup funziona meglio con l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> policy.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Questo approccio aiuta gli utenti a gestire lo spazio richiesto per i backup in modo più efficiente, ma FabricPool non è una tecnologia di backup. Il tiering dei file di backup nell'archivio di oggetti semplifica la gestione perché i file sono ancora visibili nel sistema di storage originale, ma i blocchi di dati nella destinazione dell'archivio di oggetti dipendono dal sistema di storage originale. Se il volume di origine viene perso, i dati dell'archivio di oggetti non sono più utilizzabili.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">Su un sistema ONTAP, lo storage è organizzato in 4KB unità. Un blocco 8KB di un database o di un file system deve corrispondere esattamente a due blocchi 4KB. Se un errore nella configurazione LUN sposta l'allineamento di 1KB:1 in entrambe le direzioni, ogni blocco 8KB esisterebbe su tre blocchi di storage 4KB diversi invece che due. Questa disposizione causerebbe un aumento della latenza e causerebbe l'esecuzione di ulteriori i/o all'interno del sistema di storage.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">L'allineamento influisce anche sulle architetture LVM. Se un volume fisico all'interno di un gruppo di volumi logici viene definito sull'intero dispositivo del disco (non vengono create partizioni), il primo blocco 4KB sul LUN si allinea con il primo blocco 4KB sul sistema di storage. Questo è un allineamento corretto. I problemi si verificano con le partizioni perché spostano la posizione iniziale in cui il sistema operativo utilizza il LUN. Finché l'offset viene spostato in intere unità di 4KB, il LUN viene allineato.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">Negli ambienti Linux, creare gruppi di volumi logici sull'intero dispositivo di unità. Quando è necessaria una partizione, controllare l'allineamento eseguendo<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> e verificare che l'inizio di ogni partizione sia un multiplo di otto. Ciò significa che la partizione inizia da un multiplo di otto settori a 512 byte, ovvero 4KB.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Protezione da errori del sito: NVRAM e MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster estende la protezione dei dati NVRAM nei seguenti modi:</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">In una configurazione a due nodi, i dati NVRAM vengono replicati attraverso i collegamenti Inter-Switch (ISL) al partner remoto.</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">In una configurazione ha-Pair, i dati NVRAM vengono replicati sia nel partner locale che in un partner remoto.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">Una scrittura non viene riconosciuta fino a quando non viene replicata a tutti i partner. Questa architettura protegge gli i/o in fase di trasferimento dai guasti del sito replicando i dati NVRAM a un partner remoto. Il processo non è coinvolto nella replica dei dati a livello di unità. Il controller proprietario degli aggregati si occupa della replica dei dati per iscritto a entrambi i plessi dell'aggregato, ma in caso di perdita del sito occorre comunque proteggere dalle perdite di i/o in fase di trasferimento. I dati NVRAM replicati sono utilizzati solo se un partner controller deve subentrare a un controller guasto.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Protezione dai guasti di shelf e siti: SyncMirror e plessi</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror è una tecnologia di mirroring che migliora, ma non sostituisce, RAID DP o RAID-TEC. Esegue il mirroring del contenuto di due gruppi RAID indipendenti. La configurazione logica è la seguente:</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">I dischi sono configurati in due pool in base alla posizione. Un pool è composto da tutti i dischi sul sito A, mentre il secondo è composto da tutti i dischi sul sito B.</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">Viene quindi creato un pool di storage comune, detto aggregato, in base a set di gruppi RAID con mirroring. Viene ottenuto lo stesso numero di unità per ciascun sito. Ad esempio, un aggregato SyncMirror da 20 dischi sarebbe composto da 10 dischi del sito A e 10 dischi del sito B.</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Ogni set di unità su un dato sito viene configurato automaticamente come uno o più gruppi RAID DP o RAID-TEC completamente ridondanti, indipendentemente dall'utilizzo del mirroring. Questo utilizzo di RAID sottostante il mirroring garantisce la protezione dei dati anche dopo la perdita di un sito.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">La figura precedente illustra una configurazione SyncMirror di esempio. È stato creato un aggregato di 24 dischi sul controller con 12 dischi da uno shelf allocato sul sito A e 12 dischi da uno shelf allocato sul sito B. I dischi sono stati raggruppati in due gruppi RAID con mirroring. Il gruppo RAID 0 include un plesso A 6 dischi sul sito A con mirroring su un plesso A 6 dischi sul sito B. Analogamente, il gruppo RAID 1 include un plesso A 6 dischi sul sito A con mirroring su un plesso A 6 dischi sul sito B.</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">Di norma, SyncMirror viene utilizzato per fornire il mirroring remoto con i sistemi MetroCluster, con una copia dei dati in ciascun sito. A volte, è stato utilizzato per fornire un livello di ridondanza extra in un unico sistema. In particolare, fornisce ridondanza a livello di shelf. Uno shelf di dischi contiene già doppi controller e alimentatori e nel complesso è poco più di una lamiera, ma in alcuni casi è consigliabile garantire una protezione extra. Ad esempio, un cliente NetApp ha implementato SyncMirror per una piattaforma mobile di analytics in tempo reale utilizzata durante i test nel settore automobilistico. Il sistema è stato separato in due rack fisici forniti con alimentatori indipendenti e sistemi UPS indipendenti.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Errore di ridondanza: NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Come discusso in precedenza, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight Se si verifica un guasto nella NVRAM locale o nella connettività ad altri nodi, i dati non verranno più mirrorati.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">Il fattore di controllo è se la NVRAM è sincronizzata. Se la NVRAM è sincronizzata, il failover da nodo a nodo può procedere in tutta sicurezza senza rischio di perdita di dati. In una configurazione MetroCluster, se la NVRAM e i plessi degli aggregati sottostanti sono sincronizzati, è possibile procedere con lo switchover senza rischio di perdita di dati.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">I database e altre applicazioni sono particolarmente vulnerabili al danneggiamento se un failover o uno switchover è forzato perché mantengono cache interne di dati su disco di dimensioni maggiori. In caso di failover o switchover forzato, le modifiche riconosciute in precedenza vengono eliminate del tutto. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache non riflette più lo stato dei dati su disco.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Per evitare questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro i guasti della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano un crash dell'applicazione. Questo blocco causa l'arresto delle applicazioni in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché i dati delle transazioni devono essere presenti nei registri. Solitamente, gli amministratori dovranno arrestare completamente gli host prima di riportare manualmente LUN e volumi in linea. Sebbene queste fasi possano comportare un certo lavoro, questo approccio è il modo più sicuro per garantire l'integrità dei dati. Non tutti i dati richiedono questa protezione, motivo per cui il comportamento di NVFAIL può essere configurato in base al volume.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">Coppie HA e MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster è disponibile in due configurazioni: Due nodi e coppia ha. La configurazione a due nodi si comporta come una coppia ha in relazione alla NVRAM. In caso di guasto improvviso, il nodo partner può riprodurre i dati della NVRAM per rendere i dischi coerenti e garantire che non vengano perse scritture riconosciute.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">La configurazione ha-Pair replica la NVRAM anche sul nodo partner locale. Un semplice guasto al controller porta a un replay della NVRAM sul nodo partner, come nel caso di una coppia ha standalone, senza MetroCluster. In caso di improvvisa perdita completa del sito, il sito remoto dispone anche della NVRAM necessaria per rendere i dischi coerenti e iniziare a fornire i dati.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Un aspetto importante di MetroCluster è che i nodi remoti non hanno accesso ai dati partner in normali condizioni operative. Ogni sito funziona essenzialmente come un sistema indipendente che può assumere la personalità del sito opposto. Questo processo, noto come switchover, include uno switchover pianificato, in cui le operazioni del sito vengono migrate senza interruzioni nel sito opposto. Include anche le situazioni non pianificate in cui si perde un sito ed è necessario uno switchover manuale o automatico come parte del disaster recovery.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Switchover e switchback</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">I termini switchover e switchback si riferiscono al processo di transizione dei volumi tra controller remoti in una configurazione MetroCluster. Questo processo si applica solo ai nodi remoti. Se viene utilizzato MetroCluster in una configurazione a quattro volumi, il failover di nodo locale utilizza il medesimo processo di takeover e giveback descritto in precedenza.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Switchover e switchback pianificati</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Uno switchover o uno switchback pianificato è simile a un takeover o un giveback tra i nodi. Il processo prevede diverse fasi e potrebbe richiedere alcuni minuti, ma in realtà si tratta di una transizione graduale delle risorse di storage e di rete. Il momento in cui il trasferimento del controllo avviene molto più rapidamente del tempo richiesto per l'esecuzione del comando completo.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">La differenza principale tra takeover/giveback e switchover/switchback influisce sulla connettività FC SAN. Grazie al takeover/giveback locale, un host subisce la perdita di tutti i percorsi FC nel nodo locale e si affida al proprio MPIO nativo per passare ai percorsi alternativi disponibili. Le porte non vengono ricollocate. Grazie a switchover e switchback, le porte di destinazione FC virtuali sui controller passano all'altro sito. Di fatto, smettono di esistere sulla SAN per un momento e ricompaiono su un controller alternativo.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">Timeout SyncMirror</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror è una tecnologia di mirroring ONTAP che fornisce protezione dai guasti agli shelf. Quando gli shelf sono separati su una distanza, il risultato è una data Protection remota.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror non fornisce mirroring sincrono universale. Il risultato è una maggiore disponibilità. Alcuni sistemi di archiviazione utilizzano un mirroring costante tutto o niente, talvolta chiamato modalità domino. Questa forma di mirroring è limitata nell'applicazione poiché tutte le attività di scrittura devono cessare se la connessione al sito remoto viene persa. Altrimenti, una scrittura esisterebbe in un sito ma non nell'altro. Generalmente, tali ambienti sono configurati per portare le LUN offline in caso di perdita della connettività sito-sito per più di un breve periodo (ad esempio 30 secondi).</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Questo comportamento è desiderabile per un piccolo sottoinsieme di ambienti. Tuttavia, la maggior parte delle applicazioni richiede una soluzione che offra una replica sincrona garantita in normali condizioni operative, ma con la possibilità di sospendere la replica. Una perdita completa della connettività da sito a sito viene spesso considerata una situazione quasi disastrosa. Generalmente, tali ambienti vengono mantenuti online e forniscono dati fino al ripristino della connettività o alla decisione formale di arrestare l'ambiente per proteggere i dati. Un requisito per l'arresto automatico dell'applicazione solo a causa di un errore di replica remota è insolito.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror supporta i requisiti di mirroring sincrono con la flessibilità di un timeout. Se la connettività al telecomando e/o al plex viene persa, inizia il conto alla rovescia un timer di 30 secondi. Quando il contatore raggiunge 0, l'elaborazione i/o in scrittura riprende a utilizzare i dati locali. La copia remota dei dati è utilizzabile, ma viene bloccata in tempo fino a quando non viene ripristinata la connettività. La risincronizzazione sfrutta le snapshot a livello di aggregato per riportare il sistema in modalità sincrona il più rapidamente possibile.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">In particolare, in molti casi, questo tipo di replica universale in modalità domino a tutto o niente è meglio implementato a livello di applicazione. Ad esempio, Oracle DataGuard include la modalità di protezione massima, che garantisce la replica a lunga istanza in tutte le circostanze. Se il collegamento di replica non riesce per un periodo superiore a un timeout configurabile, i database vengono arrestati.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Switchover automatico senza intervento dell'utente con MetroCluster fabric-attached</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">Lo switchover automatico non assistito (ASOLO) è una funzione MetroCluster collegata al fabric che offre un tipo di ha cross-site. Come indicato in precedenza, MetroCluster è disponibile in due tipi: Un singolo controller su ciascun sito o una coppia ha su ciascun sito. Il vantaggio principale dell'opzione ha è che l'arresto pianificato o non pianificato del controller consente comunque a tutti gli i/o di essere locali. Il vantaggio dell'opzione a nodo singolo consiste nella riduzione di costi, complessità e infrastruttura.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">Il valore primario di AUSO è migliorare le capacità ha dei sistemi MetroCluster fabric-attached. Ciascun sito esegue il monitoraggio dello stato di salute del sito opposto e, se non sono ancora presenti nodi che forniscono dati, AUDO esegue un rapido switchover. Questo approccio è particolarmente utile nelle configurazioni MetroCluster con un solo nodo per sito, perché consente di avvicinare la configurazione a una coppia ha in termini di disponibilità.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO non è in grado di offrire un monitoraggio completo a livello di coppia ha. Una coppia ha può offrire una disponibilità estremamente elevata, perché include due cavi fisici ridondanti per la comunicazione diretta da nodo a nodo. Inoltre, entrambi i nodi di una coppia ha hanno accesso allo stesso set di dischi in loop ridondanti, offrendo un altro percorso a un nodo per monitorare la salute di un altro.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">I cluster MetroCluster esistono tra i siti per i quali le comunicazioni nodo-nodo e l'accesso al disco si basano sulla connettività di rete site-to-site. La capacità di monitorare il battito cardiaco del resto del cluster è limitata. AUSO deve discriminare tra una situazione in cui l'altro sito è effettivamente inattivo piuttosto che non disponibile a causa di un problema di rete.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">Di conseguenza, un controller in una coppia ha può richiedere un takeover se rileva un guasto del controller verificatosi per un motivo specifico, ad esempio un panico del sistema. Può anche richiedere un takeover in caso di perdita totale della connettività, talvolta nota come battito cardiaco perso.</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Un sistema MetroCluster può eseguire uno switchover automatico in modo sicuro solo quando viene rilevato un guasto specifico nel sito originale. Inoltre, il controller che prende la proprietà del sistema di storage deve essere in grado di garantire che i dati su disco e NVRAM siano sincronizzati. Il controller non è in grado di garantire la sicurezza di uno switchover solo perché ha perso il contatto con il sito di origine, cosa che potrebbe essere ancora operativa. Per ulteriori opzioni per automatizzare uno switchover, vedere le informazioni sulla soluzione MetroCluster Tiebreaker (MCTB) nella sezione successiva.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">Tiebreaker MetroCluster con MetroCluster fabric-attached</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">Tiebreaker NetApp MetroCluster</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">Sito di supporto NetApp</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">Il<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> È possibile eseguire il software su un terzo sito per monitorare lo stato dell'ambiente MetroCluster, inviare notifiche e, facoltativamente, imporre uno switchover in una situazione di emergenza. Una descrizione completa del rompighiaccio è disponibile sul<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>, Ma lo scopo principale di MetroCluster Tiebreaker è quello di rilevare la perdita del sito. Inoltre, deve discriminare tra la perdita del sito e la perdita della connettività. Ad esempio, lo switchover non deve essere eseguito perché il tiebreaker non è riuscito a raggiungere il sito primario; questo spiega perché il tiebreaker monitora anche la capacità del sito remoto di contattare il sito primario.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">Lo switchover automatico con AUSO è compatibile anche con l'MCTB. AUSO reagisce in modo molto rapido perché è progettato per rilevare eventi di errore specifici e quindi richiamare lo switchover solo quando i plex NVRAM e SyncMirror sono sincronizzati.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">Al contrario, il Tiebreaker è localizzato a distanza e quindi deve attendere che un temporizzatore trascorra prima di dichiarare un sito morto. Il tiebreaker alla fine rileva il tipo di guasto del controller coperto da AUSO, ma in generale AUSO ha già avviato lo switchover e, eventualmente, ha completato lo switchover prima che il tiebreaker agisca. Il secondo comando switchover risultante proveniente dal tiebreaker verrebbe rifiutato.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">*Attenzione: *Il software MCTB non verifica che la NVRAM sia e/o i plessi siano sincronizzati quando si forza uno switchover. Lo switchover automatico, se configurato, deve essere disattivato durante le attività di manutenzione che causano una perdita di sincronizzazione dei plessi NVRAM o SyncMirror.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">Inoltre, l'MCTB potrebbe non risolvere un disastro continuo che porta alla seguente sequenza di eventi:</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">La connettività tra i siti viene interrotta per più di 30 secondi.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">Timeout della replica SyncMirror e proseguimento delle operazioni sul sito primario, lasciando inattiva la replica remota.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Il sito primario viene perso. Il risultato è la presenza di modifiche non replicate sul sito primario. Uno switchover potrebbe quindi essere indesiderato per una serie di motivi, tra cui:</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">I dati critici potrebbero essere presenti sul sito primario e quindi ripristinabili. Uno switchover che ha permesso all'applicazione di continuare a funzionare eliminava efficacemente i dati critici.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Un'applicazione sul sito rimasto che stava utilizzando le risorse di storage sul sito primario al momento della perdita del sito potrebbe avere memorizzato nella cache i dati. Uno switchover introdurrebbe una versione obsoleta dei dati che non corrisponde alla cache.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Un sistema operativo del sito rimasto che utilizzava le risorse di storage del sito primario al momento della perdita del sito potrebbe avere memorizzato i dati nella cache. Uno switchover introdurrebbe una versione obsoleta dei dati che non corrisponde alla cache. L'opzione più sicura è configurare tiebreaker in modo da inviare un avviso se rileva un guasto del sito e chiedere a una persona di decidere se forzare uno switchover. Potrebbe essere necessario arrestare le applicazioni e/o i sistemi operativi per cancellare i dati memorizzati nella cache. Inoltre, è possibile utilizzare le impostazioni NVFAIL per aggiungere ulteriore protezione e semplificare il processo di failover.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">ONTAP Mediator con MetroCluster IP</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">ONTAP Mediator viene utilizzato con MetroCluster IP e con alcune altre soluzioni ONTAP. Funziona come un servizio di tiebreaker tradizionale, proprio come il software MetroCluster Tiebreaker descritto in precedenza, ma include anche una funzione critica che consente di eseguire uno switchover automatizzato e non assistito.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Un MetroCluster fabric-attached ha accesso diretto ai dispositivi di storage del sito opposto. Ciò consente a un controller MetroCluster di monitorare lo stato degli altri controller leggendo i dati heartbeat dalle unità. In questo modo, un controller riconosce il guasto di un altro controller ed esegue uno switchover.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">Al contrario, l'architettura IP di MetroCluster instrada tutti i/o esclusivamente attraverso la connessione controller-controller; non vi è accesso diretto ai dispositivi di storage sul sito remoto. Questo limita la possibilità per un controller di rilevare gli errori ed eseguire uno switchover. Pertanto, come dispositivo di tiebreaker occorre il ONTAP Mediator per rilevare la perdita di un sito ed eseguire automaticamente uno switchover.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Terzo sito virtuale con ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion è un'appliance di monitoraggio MetroCluster avanzata che funziona come un terzo sito virtuale. Questo approccio consente di implementare MetroCluster in maniera sicura in una configurazione a due siti con una funzionalità di switchover completamente automatizzata. Inoltre, ClusterLion può eseguire ulteriori operazioni di monitoraggio a livello di rete ed eseguire operazioni post-switchover. La documentazione completa è disponibile presso ProLion.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Gli appliance ClusterLion monitorano lo stato dei controller con cavi Ethernet e seriali collegati direttamente.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">I due dispositivi sono collegati tra loro mediante connessioni wireless 3G ridondanti.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">L'alimentazione alla centralina ONTAP viene instradata attraverso i relè interni. In caso di guasto a un sito, ClusterLion, che contiene un sistema UPS interno, interrompe i collegamenti di alimentazione prima di richiamare uno switchover. Questo processo assicura che non si verifichi alcuna condizione split-brain.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion esegue uno switchover entro il timeout SyncMirror di 30 secondi o non lo esegue affatto.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion non esegue uno switchover a meno che gli stati della NVRAM e dei plex SyncMirror non siano sincronizzati.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Poiché ClusterLion esegue uno switchover solo se MetroCluster è completamente sincronizzato, NVFAIL non è necessario. Questa configurazione consente ad ambienti che si estendono tra diversi siti, come un Oracle RAC esteso, di rimanere online anche durante uno switchover non pianificato.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">Il supporto include MetroCluster fabric-attached e MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Funzionamento normale</block>
  <block id="16dd4928055f2caf6f6fb8119ef69bcc" category="paragraph">SM-BC supporta due tipi di operazioni di failover dello storage: Pianificate e non pianificate, che funzionano in modi leggermente diversi. Un failover pianificato viene avviato manualmente dall'amministratore per uno switchover rapido verso un sito remoto, mentre il failover non pianificato viene avviato automaticamente dal mediatore del terzo sito. Lo scopo principale di un failover pianificato è quello di eseguire patch e aggiornamenti incrementali, eseguire test di disaster recovery o adottare una politica formale di passaggio da un sito all'altro durante tutto l'anno per dimostrare la piena capacità di business continuity.</block>
  <block id="63d4f976530f4faffa1ecd40fe8843f4" category="paragraph">I diagrammi mostrano cosa accade durante le normali operazioni di failover e failback. Per maggiore facilità di illustrazione, sono raffigurati un LUN replicato. In una configurazione SM-BC effettiva, la replica si basa sui volumi, dove ogni volume contiene una o più LUN, ma per semplificarne la visione, il livello del volume è stato rimosso.</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">Durante il normale funzionamento, è possibile accedere a un LUN dalla replica locale o remota. La linea rossa indica il percorso ottimizzato come pubblicizzato da ALUA, e il risultato dovrebbe essere che io è preferenzialmente inviato lungo questo percorso.</block>
  <block id="ef1d805ecb3b65664c42a1d32d8120d5" category="paragraph">La linea verde è un percorso attivo, ma richiede una maggiore latenza, perché io su quel percorso dovrebbe essere passato attraverso il percorso SM-BC. La latenza aggiuntiva dipende dalla velocità di interconnessione tra i siti utilizzati per SM-BC.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Guasto</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Se la copia del mirror attivo non è più disponibile, a causa di un failover pianificato o non pianificato, ovviamente non sarà più utilizzabile. Tuttavia, il sistema remoto possiede una replica sincrona e i percorsi SAN verso il sito remoto esistono già. Il sistema remoto è in grado di gestire i/o per quel LUN.</block>
  <block id="89a4933a199f7b0e286c8bcb1606905a" category="paragraph">L'utilizzo immediato della copia remota dipende dal fatto che SM-BC venga utilizzato in modalità Sync o StrictSync.</block>
  <block id="af43c542f512c4f7dc1b137d5de49d40" category="paragraph"><block ref="af43c542f512c4f7dc1b137d5de49d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Failover</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">Il failover fa sì che la copia remota diventi la copia attiva. I percorsi vengono modificati da Active a Active/Optimized e l'io continua a essere gestito senza perdita di dati.</block>
  <block id="52da4ea35ba60090f331eefab5d6c612" category="paragraph"><block ref="52da4ea35ba60090f331eefab5d6c612" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Riparare</block>
  <block id="4f125c91283d9dc1751ad99a7a171420" category="paragraph">Una volta che il sistema di origine è tornato in servizio, SM-BC può risincronizzare la replica, ma eseguendo l'altra direzione. Attualmente la configurazione è essenzialmente la stessa del punto di partenza, con la sola eccezione che i siti mirror attivi sono stati invertiti.</block>
  <block id="5c647f57a104a05d7d8b55d089efefbe" category="paragraph"><block ref="5c647f57a104a05d7d8b55d089efefbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Failback</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Se lo si desidera, un amministratore può eseguire un failback e riportare la copia attiva delle LUN nei controller originali.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">La registrazione di ripristino del database/transazioni genera di solito un i/o non allineato che può causare avvisi fuorvianti riguardo ai LUN disallineati su ONTAP.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">La registrazione esegue una scrittura sequenziale del file di registro con scritture di dimensioni variabili. Un'operazione di scrittura del registro che non si allinea ai limiti 4KB non causa normalmente problemi di prestazioni poiché l'operazione di scrittura del registro successiva completa il blocco. Il risultato è che ONTAP è in grado di elaborare quasi tutte le scritture come blocchi da 4KB KB completi, anche se i dati in alcuni blocchi da 4KB KB sono stati scritti in due operazioni separate.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Verifica dell'allineamento di WAFL</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Verificare l'allineamento utilizzando utilità come<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> oppure<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Che possono generare i/o a dimensioni dei blocchi definite. È possibile visualizzare le statistiche di allineamento di i/o del sistema di storage con<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> comando. Vedere <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">Molti set di dati delle applicazioni sono organizzati per data e tali dati hanno generalmente sempre meno probabilità di accedere man mano che invecchiano. Ad esempio, una banca potrebbe avere un archivio di file PDF che contengono cinque anni di dichiarazioni dei clienti, ma solo gli ultimi mesi sono attivi. FabricPool può essere utilizzato per spostare i file di dati meno recenti nel Tier di capacità. Un periodo di raffreddamento di 14 giorni garantirebbe che i 14 giorni più recenti di file PDF rimangano sul livello di prestazioni. Inoltre, i file letti almeno ogni 14 giorni resterebbero hot e quindi nel Tier di performance.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Per implementare un approccio di tiering basato su file, è necessario disporre di file scritti e non modificati successivamente. Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> i criteri devono essere impostati su un livello sufficientemente alto da mantenere i file di cui potresti aver bisogno nel tier di performance. Ad esempio, un set di dati per il quale sono necessari gli ultimi 60 giorni di dati con performance ottimali garantisce la definizione di<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo a 60. Risultati simili possono essere ottenuti anche in base ai modelli di accesso ai file. Ad esempio, se sono necessari gli ultimi 90 giorni di dati e l'applicazione sta accedendo a quell'arco di dati di 90 giorni, i dati resteranno sul Tier di performance. Impostando<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> a 2, si ottiene un tiering prompt dopo che i dati sono meno attivi.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Qualsiasi tipo di accesso ai dati ripristina i dati della mappa termica. La scansione virus, l'indicizzazione e persino le attività di backup in grado di leggere i file di origine impediscono il tiering perché è necessario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la soglia non viene mai raggiunta.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Predefinito</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Tutti i volumi FabricPool sono inizialmente impostati su<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, il che significa che il comportamento è controllato da `cloud-retrieval-policy. `il comportamento esatto dipende dal criterio di tiering utilizzato.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– consente di recuperare solo dati letti in modo casuale</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– consente di recuperare tutti i dati letti in modo sequenziale o casuale</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– consente di recuperare tutti i dati letti in modo sequenziale o casuale</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>– non recuperare i dati dal tier di capacità</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">A lettura</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Impostazione<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> in lettura sovrascrive il comportamento predefinito, in modo che una lettura di dati a livelli determini il ritorno dei dati al livello di prestazioni.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Ad esempio, un volume potrebbe essere stato leggermente utilizzato per un lungo periodo sotto il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la policy di tiering e la maggior parte dei blocchi ora vengono suddivisi in livelli.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Se una modifica imprevista delle esigenze aziendali richiedeva la scansione ripetuta di alcuni dati per preparare un determinato rapporto, potrebbe essere opportuno modificare<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> a.<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> per garantire che tutti i dati letti vengano restituiti al livello delle prestazioni, inclusi i dati letti in modo sequenziale e casuale. In questo modo si migliorano le prestazioni dell'i/o sequenziale rispetto al volume.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Promuovi</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">Il comportamento della policy di promozione dipende dalla policy di tiering. Se la policy di tiering è<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, quindi impostare<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> riporta tutti i blocchi dal tier di capacità nella successiva scansione del tiering.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Se la policy di tiering è<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, gli unici blocchi restituiti sono i blocchi associati al file system attivo. Normalmente questo non avrebbe alcun effetto perché gli unici blocchi suddivisi in livelli sotto<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la policy dovrebbe essere costituita da blocchi associati esclusivamente agli snapshot. Nel file system attivo non sono presenti blocchi a livelli.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Se, tuttavia, i dati di un volume sono stati ripristinati da un'operazione SnapRestore di volume o di file-clone da una snapshot, alcuni dei blocchi suddivisi in Tier perché associati solo a snapshot potrebbero ora essere richiesti dal file system attivo. Potrebbe essere opportuno modificare temporaneamente<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> policy to<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> per recuperare rapidamente tutti i blocchi richiesti localmente.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Mai</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">Non recuperare i blocchi dal Tier di capacità.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architettura</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool è una tecnologia di tiering che classifica i blocchi come "hot" o "cool" e li colloca nel Tier di storage più appropriato. Il Tier di performance è nella maggior parte dei casi collocato nello storage SSD e ospita i blocchi di dati "hot". Il Tier di capacità si trova in un archivio di oggetti e ospita i blocchi di dati "cool". Il supporto per lo storage a oggetti include NetApp StorageGRID, ONTAP S3, archiviazione BLOB di Microsoft Azure, il servizio di storage a oggetti Alibaba Cloud, archiviazione a oggetti IBM Cloud, archiviazione Google Cloud e Amazon AWS S3.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Sono disponibili più policy di tiering che controllano le modalità di classificazione dei blocchi come "hot" o "cool", che possono essere impostate in base al volume e modificate secondo necessità. Solo i blocchi di dati vengono spostati tra i Tier di performance e capacità. I metadati che definiscono la struttura LUN e del file system rimangono sempre sul Tier di performance. Di conseguenza, la gestione è centralizzata su ONTAP. I file e le LUN non appaiono diversi dai dati memorizzati in qualsiasi altra configurazione ONTAP. Il controller NetApp AFF o FAS applica le policy definite per spostare i dati nel Tier appropriato.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Provider di archivi di oggetti</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">I protocolli di storage a oggetti utilizzano semplici richieste HTTP o HTTPS per la memorizzazione di un grande numero di oggetti dati. L'accesso allo storage a oggetti deve essere affidabile, poiché l'accesso ai dati da parte di ONTAP dipende dalla puntuale manutenzione delle richieste. Le opzioni includono le opzioni Amazon S3 Standard e accesso poco frequente, Microsoft Azure Hot e Cool Blob Storage, IBM Cloud e Google Cloud. Le opzioni di archiviazione come Amazon Glacier e Amazon Archive non sono supportate, perché il tempo necessario per recuperare i dati può superare le tolleranze dei sistemi operativi e delle applicazioni host.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">NetApp StorageGRID è anche supportato e rappresenta una soluzione di livello Enterprise ottimale. Si tratta di un sistema storage a oggetti dalle performance elevate, scalabile e altamente sicuro, in grado di fornire ridondanza geografica per i dati FabricPool nonché per altre applicazioni di archivi di oggetti che hanno sempre più probabilità di far parte di ambienti applicativi Enterprise.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID può anche ridurre i costi evitando le spese di uscita imposte da molti provider di cloud pubblici per la lettura dei dati di nuovo dai propri servizi.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Dati e metadati</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Si noti che il termine "dati" si applica in questo caso ai blocchi di dati effettivi, non ai metadati. Viene eseguito il tiering solo dei blocchi di dati, mentre i metadati rimangono nel Tier di performance. Inoltre, lo stato di un blocco come caldo o freddo è influenzato solo dalla lettura del blocco di dati effettivo. La semplice lettura del nome, dell'indicatore data e ora o dei metadati di proprietà di un file non influisce sulla posizione dei blocchi di dati sottostanti.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Backup</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Anche se FabricPool può ridurre significativamente l'impatto dello storage, non rappresenta di per sé una soluzione di backup. I metadati NetApp WAFL rimangono sempre nel Tier di performance. Se un disastro catastrofico distrugge il Tier di performance, non è possibile creare un nuovo ambiente utilizzando i dati sul Tier di capacità perché non contiene metadati WAFL.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">FabricPool, tuttavia, può entrare a far parte di una strategia di backup. Ad esempio, FabricPool può essere configurato con la tecnologia di replica NetApp SnapMirror. Ciascuna metà del mirror può avere la propria connessione a una destinazione dello storage a oggetti. Il risultato sono due copie indipendenti dei dati. La copia primaria è costituita dai blocchi sul Tier di performance e dai blocchi associati nel Tier di capacità, mentre la replica è un secondo set di blocchi di performance e capacità.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Compressione</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Le funzionalità di efficienza in termini di spazio, come compressione, compaction e deduplica, sono progettate per aumentare la quantità di dati logici applicabili a una determinata quantità di storage fisico. Il risultato è una riduzione dei costi e dell'overhead di gestione.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">Ad un livello elevato, la compressione è un processo matematico in cui gli schemi nei dati vengono rilevati e codificati in modo da ridurre i requisiti di spazio. La deduplica, invece, rileva i blocchi di dati effettivi e ripetuti e rimuove le copie estranee. La tecnologia di compaction consente a più blocchi logici di dati di condividere lo stesso blocco fisico sui supporti.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Prima della disponibilità dei sistemi storage all-flash, la compressione basata su array aveva un valore limitato, perché la maggior parte dei carichi di lavoro con i/o-intensive richiedeva un numero molto elevato di spindle per fornire performance accettabili. I sistemi storage contenevano invariabilmente una capacità superiore rispetto a quella richiesta come effetto collaterale dell'elevato numero di dischi. La situazione è cambiata con l'ascesa dello storage a stato solido. Non è più necessario effettuare un provisioning in eccesso significativo dei dischi solo per ottenere buone prestazioni. Lo spazio su disco di un sistema di storage può essere adattato alle effettive esigenze di capacità.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">L'aumento della capacità degli IOPS dei dischi a stato solido (SSD) offre quasi sempre risparmi sui costi rispetto ai dischi rotanti, ma la compressione può ottenere ulteriori risparmi aumentando la capacità effettiva dei supporti a stato solido.</block>
  <block id="bd6c983943da8bf0ead08c643f0e75f3" category="paragraph">Esistono diversi modi per comprimere i dati. Molti database includono proprie funzionalità di compressione, sebbene raramente queste vengano osservate negli ambienti dei clienti. Il motivo è in genere la penalizzazione delle prestazioni per una *modifica* dei dati compressi, oltre ai costi di licenza spesso elevati. Infine, ci sono le conseguenze globali delle performance sulle operazioni di database. Ha poco senso pagare un costo elevato di licenza per CPU per una CPU che esegue la compressione e la decompressione dei dati piuttosto che un vero lavoro di database. Un'opzione migliore è trasferire il lavoro di compressione sul sistema storage.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Compressione adattiva</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">La compressione adattiva è stata testata accuratamente con carichi di lavoro Enterprise senza effetti osservati sulle performance, anche in un ambiente all-flash in cui la latenza viene misurata in microsecondi. Alcuni clienti hanno anche segnalato un aumento delle performance con l'utilizzo della compressione, perché i dati rimangono compressi nella cache, aumentando di fatto la quantità di cache disponibile in un controller.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP gestisce i blocchi fisici in 4KB unità. La compressione adattiva utilizza dimensioni predefinite dei blocchi di compressione di 8KB KB, il che significa che i dati sono compressi in unità da 8KB KB. Corrisponde alle dimensioni dei blocchi di 8KB KB utilizzate più spesso dai database relazionali. Gli algoritmi di compressione diventano più efficienti con la compressione di un numero maggiore di dati come una singola unità. Una dimensione dei blocchi di compressione da 32KB KB sarebbe più efficiente in termini di spazio rispetto a un'unità dei blocchi di compressione da 8KB KB. Ciò significa che la compressione adattiva che utilizza le dimensioni predefinite dei blocchi di 8KB KB produce tassi di efficienza leggermente inferiori, ma esiste anche un vantaggio significativo nell'utilizzo di dimensioni inferiori dei blocchi di compressione. I carichi di lavoro dei database includono un'elevata attività di sovrascrittura. La sovrascrittura di un 8KB di un blocco di dati 32KB compresso richiede la lettura dell'intero 32KB di dati logici, la decompressione, l'aggiornamento della regione 8KB richiesta, la ricompressione e quindi la riscrittura dell'intero 32KB sui dischi. Si tratta di un'operazione molto costosa per un sistema storage ed è il motivo per cui alcuni storage array concorrenti basati su dimensioni dei blocchi di compressione più grandi implicano anche una significativa penalizzazione delle performance con i carichi di lavoro dei database.</block>
  <block id="096cc7f8e7e1861c3ee0269a90fc27e3" category="admonition">Le dimensioni dei blocchi utilizzate dalla compressione adattiva possono essere aumentate fino a 32KB KB. Questo può migliorare l'efficienza di archiviazione e dovrebbe essere considerato per i file inattivi come i log di archiviazione e i file di backup quando una quantità sostanziale di tali dati è memorizzata nell'array. In alcune situazioni, i database attivi che utilizzano dimensioni blocco 16KB KB o 32KB KB possono anche trarre vantaggio dall'aumento delle dimensioni blocco della compressione adattiva per adeguarsi. Consulta un NetApp o un rappresentante del partner per ottenere indicazioni relative all'adeguatezza del tuo carico di lavoro.</block>
  <block id="f291779c724993ded5e79421d88f3e55" category="admonition">Le dimensioni dei blocchi di compressione superiori a 8KB KB non devono essere utilizzate insieme alla deduplica nelle destinazioni di backup in streaming. Il motivo è che piccole modifiche ai dati di backup influiscono sulla finestra di compressione 32KB. Se la finestra si sposta, i dati compressi risultanti differiscono per l'intero file. La deduplica si verifica dopo la compressione, il che significa che il motore di deduplica vede ogni backup compresso in modo diverso. Se è necessaria la deduplica dei backup in streaming (come Oracle RMAN), è consigliabile utilizzare solo la compressione adattiva per blocchi da 8KB KB. La compressione adattiva è preferibile, perché funziona a blocchi di dimensioni inferiori e non interrompe l'efficienza di deduplica. Per motivi simili, la compressione lato host interferisce anche con l'efficienza della deduplica.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Efficienza di conservazione sensibile alla temperatura</block>
  <block id="78aa8c12abb3bf9f61a08df0f9b403de" category="paragraph">L'efficienza dello storage sensibile alla temperatura (TSSE) è disponibile in ONTAP 9,8 e versioni successive e si basa sulle mappe termiche di accesso ai blocchi per identificare i blocchi a cui si accede raramente e comprimerli con una maggiore efficienza.</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Allineamento delle compressioni</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">La compressione adattiva in un ambiente di database richiede alcune considerazioni sull'allineamento dei blocchi di compressione. Ciò rappresenta solo una preoccupazione per i dati che sono soggetti a sovrascritture casuali di blocchi molto specifici. Questo approccio è simile in teoria all'allineamento complessivo del file system, dove l'inizio di un file system deve essere allineato al limite di un dispositivo 4K e la dimensione di blocco di un file system deve essere un multiplo di 4K.</block>
  <block id="327a36f7ca539411197c2f867b501719" category="paragraph">Ad esempio, una scrittura 8KB in un file viene compressa solo se si allinea con un limite 8KB all'interno del file system stesso. Questo punto significa che deve rientrare nel primo 8KB del file, nel secondo 8KB del file e così via. Dati come i backup RMAN o i log di archivio sono operazioni scritte in sequenza che coprono più blocchi, tutti compressi. Pertanto, non è necessario considerare l'allineamento. L'unico modello di i/o che desta preoccupazione sono le sovrascritture casuali dei file.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="8dae8f7054353dae17cd9da8deb0e091" category="paragraph">Utilizzando NFS, l'i/o del file è allineato, Ogni blocco di un file è allineato rispetto all'inizio del file.</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">SAN</block>
  <block id="b0762e9957c8485f911e57bfd027eddb" category="paragraph">Gli ambienti SAN richiedono l'allineamento dei dati a un confine di 8KB:1 per una compressione ottimale. Esistono due aspetti dell'allineamento per SAN: Il LUN e il file system. Il LUN deve essere configurato come dispositivo a disco intero (senza partizione) o con una partizione allineata a un limite di 8KB GB.</block>
  <block id="ad16b6d5634739ef4ceb795c5beea659" category="admonition">Vedere le sezioni sul thin provisioning per una spiegazione dell'interazione tra la compressione e la prenotazione frazionata.</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Compaction dei dati</block>
  <block id="546168bb7b68da66be7b6c0e60a23460" category="paragraph">La data compaction è una tecnologia introdotta in ONTAP che migliora l'efficienza di compressione. Come indicato in precedenza, la sola compressione adattiva può garantire risparmi 2:1:1 al meglio, perché è limitata alla memorizzazione di un i/o da 8KB KB in un blocco WAFL da 4KB KB. I metodi di compressione con dimensioni dei blocchi maggiori garantiscono una maggiore efficienza. Tuttavia, non sono adatte per i dati che sono soggetti a piccole sovrascritture dei blocchi. La decompressione di 32KB unità di dati, l'aggiornamento di una porzione 8KB, la ricompressione e la riscrittura sui dischi crea overhead.</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">La data compaction opera consentendo di memorizzare più blocchi logici all'interno dei blocchi fisici. Ad esempio, un database con dati altamente comprimibili come testo o blocchi parzialmente completi può comprimere da 8KB a 1KB. Senza la compaction, quei 1KB PB di dati continuerebbero ad occupare un intero blocco da 4KB KB. Inline data compaction per memorizzare 1KB TB di dati compressi in sole 1KB:1 di spazio fisico insieme ad altri dati compressi. Non si tratta di una tecnologia di compressione, ma semplicemente di un metodo più efficiente per allocare spazio sulle unità e quindi non dovrebbe creare alcun effetto rilevabile sulle prestazioni.</block>
  <block id="07b153ed9b6a6f9f334f2ad1fe94651e" category="paragraph">Il grado di risparmio ottenuto varia. I dati già compressi o crittografati non possono in genere essere ulteriormente compressi, e pertanto tali set di dati non traggono vantaggio dalla compattazione. I file di dati Oracle appena inizializzati contengono poco più dei metadati dei blocchi e compressi di zero fino a 80:1. Ciò crea una gamma estremamente ampia di possibilità.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Deduplica</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">La deduplica consiste nella rimozione di dimensioni dei blocchi duplicate da un set di dati. Ad esempio, se lo stesso blocco 4KB esistesse in 10 file diversi, la deduplica reindirizzerebbe quel blocco 4KB in tutti i file 10 allo stesso blocco fisico da 4KB KB. Il risultato sarebbe un miglioramento di 10:1 volte in efficienza per quei dati.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Dati come i LUN di avvio guest di VMware si deduplicano in genere in modo estremamente efficace poiché sono costituiti da più copie degli stessi file del sistema operativo. Sono state osservate un'efficienza pari o superiore a 100:1.</block>
  <block id="c3ed34b88ac0b8efff210a99f19a4b9b" category="paragraph">Alcuni dati non contengono dati duplicati. Ad esempio, un blocco Oracle contiene un'intestazione univoca a livello globale per il database e un trailer quasi univoco. Di conseguenza, la deduplica di un database Oracle raramente offre un risparmio superiore al 1%.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">In pochi casi, sono stati osservati risparmi di spazio fino al 15% nei database con blocchi di dimensioni grandi e 16KB. Il 4KB iniziale di ciascun blocco contiene la testata unica a livello globale, mentre il 4KB finale contiene il rimorchio quasi unico. I blocchi interni sono candidati per la deduplica, sebbene in pratica ciò sia quasi interamente attribuito alla deduplica di dati azzerati.</block>
  <block id="89d6ec0df0a54d3cdcc8f0573a6b37c5" category="paragraph">Molti array della concorrenza rivendicano la capacità di deduplicare i database Oracle sulla base del presupposto che un database venga copiato più volte. Anche in questo caso è possibile utilizzare la deduplica NetApp, ma ONTAP offre un'opzione migliore: La tecnologia FlexClone di NetApp. Il risultato finale è lo stesso; vengono create più copie di un database Oracle che condividono la maggior parte dei blocchi fisici sottostanti. L'utilizzo di FlexClone è molto più efficiente che impiegare il tempo per copiare i file di dati e quindi deduplicarli. In effetti, non viene effettuata alcuna duplicazione piuttosto che deduplica, poiché al primo posto non viene mai creato un duplicato.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Efficienza e thin provisioning</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Le funzionalità di efficienza sono forme di thin provisioning. Ad esempio, una LUN da 100GB GB che occupa un volume da 100GB GB potrebbe comprimere fino a 50GB GB. Non ci sono risparmi effettivi ancora realizzati perché il volume è ancora 100GB. Le dimensioni del volume devono essere innanzitutto ridotte in modo che lo spazio salvato possa essere utilizzato in un'altra posizione del sistema. Se successivamente le modifiche apportate al LUN da 100GB GB rendono i dati meno comprimibili, il LUN aumenta le dimensioni e il volume potrebbe riempirsi.</block>
  <block id="20132d08f816a6401f40a29feb68df8d" category="paragraph">Il thin provisioning è vivamente consigliato in quanto consente di semplificare la gestione, offrendo al contempo un sostanziale miglioramento della capacità utilizzabile con conseguenti risparmi sui costi. Il motivo è semplice: Gli ambienti Oracle spesso includono molto spazio vuoto, un elevato numero di volumi e LUN e dati comprimibili. Il thick provisioning crea la riserva di spazio sullo storage per volumi e LUN, nel caso in cui un giorno raggiungano il 100% di riempimento e contengano dati non comprimibili al 100%. È improbabile che ciò accada mai. Il thin provisioning consente di recuperare lo spazio e di utilizzarlo altrove e consente la gestione della capacità basata sul sistema storage stesso piuttosto che su molti volumi e LUN più piccoli.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Alcuni clienti preferiscono utilizzare il thick provisioning, per carichi di lavoro specifici o generalmente basato su pratiche operative e di approvvigionamento consolidate.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">*Attenzione:* se un volume viene sottoposto a thick provisioning, è necessario fare attenzione a disattivare completamente tutte le funzioni di efficienza per quel volume, inclusa la decompressione e la rimozione della deduplica tramite<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> comando. Il volume non dovrebbe essere visualizzato in<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> output. In tal caso, il volume è ancora parzialmente configurato per le funzioni di efficienza. Di conseguenza, la sovrascrittura garantisce un funzionamento diverso, aumentando le possibilità che le sovrascritture causino l'esaurimento inaspettato dello spazio del volume, con conseguenti errori di i/o del database.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Best practice di efficienza</block>
  <block id="d67dd6ae62908b7781805cf297fa8d87" category="paragraph">NetApp fornisce i seguenti consigli per ONTAP 9 e versioni successive. Per le versioni ONTAP precedenti a ONTAP 9, contattare il rappresentante NetApp di zona.</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">Valori predefiniti AFF</block>
  <block id="38b7d52fb2d518d07c1c857b20ebbbd2" category="paragraph">I volumi creati su ONTAP in esecuzione su un sistema AFF all-flash vengono sottoposti a thin provisioning con tutte le funzionalità di efficienza inline abilitate. Sebbene in genere i database Oracle non beneficino della deduplica e possano includere dati non comprimibili, le impostazioni predefinite sono comunque appropriate per quasi tutti i carichi di lavoro. ONTAP è progettato per elaborare in modo efficiente tutti i tipi di dati e gli schemi i/o, indipendentemente dal fatto che comportino risparmi. Le impostazioni predefinite devono essere modificate solo se le ragioni sono pienamente comprese e se vi è un vantaggio a deviare.</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Raccomandazioni generali</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Se i volumi e/o le LUN non sono dotati di thin provisioning, è necessario disabilitare tutte le impostazioni di efficienza perché queste funzioni non offrono risparmi e la combinazione del thick provisioning con l'efficienza dello spazio può causare comportamenti imprevisti, inclusi errori di spazio esaurito.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Se i dati non sono soggetti a sovrascritture, ad esempio con i backup o i log delle transazioni dei database, puoi ottenere una maggiore efficienza abilitando TSSE con un periodo di raffreddamento ridotto.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Alcuni file potrebbero contenere una quantità significativa di dati non comprimibili, ad esempio quando la compressione è già abilitata a livello di applicazione dei file sono crittografati. Se uno di questi scenari è vero, considerare la possibilità di disattivare la compressione per consentire un funzionamento più efficiente su altri volumi che contengono dati comprimibili.</block>
  <block id="11845fef1d21077d7b23ce880868b556" category="list-text">Non utilizzare sia la compressione 32KB che la deduplica con i backup del database. Vedere la sezione ""<block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block>"" per i dettagli.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Criteri - istantanee locali</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">La release iniziale di FabricPool era rivolta a un caso di utilizzo di backup. L'unico tipo di blocchi che è possibile eseguire il tiering era costituito da blocchi che non erano più associati a dati nel file system attivo. Pertanto, solo i blocchi di dati Snapshot possono essere spostati nel Tier di capacità. Questa rimane una delle opzioni di tiering più sicure quando occorre, in modo da garantire che le performance non subiscano alcun impatto.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Esistono due opzioni per il tiering di blocchi di snapshot inattivi nel Tier di capacità. Innanzitutto, la<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la politica riguarda solo i blocchi di snapshot. Anche se il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio include<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> ed esegue il tiering dei blocchi dal file system attivo. Ciò potrebbe non essere desiderabile.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">Il<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valore deve essere impostato su un periodo di tempo in cui i dati che potrebbero essere necessari durante un ripristino sono disponibili sul livello di prestazioni. Ad esempio, la maggior parte degli scenari di ripristino di un database di produzione critico include un punto di ripristino in un determinato momento dei giorni precedenti. Impostazione a.<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> il valore 3 garantisce che qualsiasi ripristino del file porti a un file che offre immediatamente le massime prestazioni. Tutti i blocchi dei file attivi sono ancora presenti sullo storage veloce senza dover ripristinarli dal livello di capacità.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Criteri - istantanee replicate</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Di norma, uno snapshot replicato con SnapMirror o SnapVault utilizzato solo per il ripristino deve utilizzare FabricPool<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> policy. Con questa policy, i metadati vengono replicati, ma tutti i blocchi di dati vengono inviati immediatamente al Tier di capacità, ottenendo il massimo delle performance. La maggior parte dei processi di recovery implica un i/o sequenziale, che è intrinsecamente efficiente. È necessario valutare il tempo di ripristino dalla destinazione dell'archivio oggetti, ma in un'architettura ben progettata questo processo di ripristino non deve essere significativamente più lento del ripristino da dati locali.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Se per il cloning è prevista anche l'utilizzo dei dati replicati, l'<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politica è più appropriata, con un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valore che comprende i dati che si prevede vengano utilizzati regolarmente in un ambiente di clonazione. Ad esempio, il working set attivo di un database potrebbe includere dati letti o scritti nei tre giorni precedenti, ma potrebbe includere anche altri 6 mesi di dati storici. In tal caso, il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> La policy nella destinazione di SnapMirror rende disponibile il working set nel Tier di performance.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">QoS (IOPS)</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">Nello specifico, la maggiore adozione dello storage all-flash ha permesso il consolidamento dei carichi di lavoro. Gli storage array che si affidano a supporti rotanti tendevano a supportare solo un numero limitato di workload i/o-intensive a causa delle limitate funzionalità IOPS della tecnologia delle unità rotazionali meno recente. Uno o due database altamente attivi saturerebbero i dischi sottostanti molto prima che gli storage controller raggiungano i loro limiti. Questo è cambiato. La capacità di performance di un numero relativamente contenuto di dischi SSD è in grado di saturare anche gli storage controller più potenti. Ciò significa che è possibile sfruttare tutte le funzionalità dei controller senza la paura di un improvviso crollo delle performance con picchi di latenza dei supporti rotanti.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">Come esempio di riferimento, un semplice sistema ha AFF A800 a due nodi è in grado di fornire fino a un milione di IOPS casuali prima che la latenza superi un millisecondo. Ci si aspetta che pochissimi carichi di lavoro singoli raggiungano tali livelli. L'utilizzo completo di questo array di sistema AFF A800 implicherà l'hosting di più carichi di lavoro, per questo motivo in modo sicuro, garantendo al contempo la prevedibilità dei requisiti di qualità del servizio.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">Esistono due tipi di qualità del servizio (QoS) in ONTAP: IOPS e larghezza di banda. È possibile applicare controlli di qualità del servizio a SVM, volumi, LUN e file.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Un controllo della qualità del servizio IOPS si basa ovviamente sugli IOPS totali di una data risorsa, ma esistono alcuni aspetti della qualità del servizio IOPS che potrebbero non essere intuitivi. Alcuni clienti sono rimasti colpiti dall'apparente aumento della latenza al raggiungimento di una soglia IOPS. L'aumento della latenza è il risultato naturale della limitazione degli IOPS. Logicamente, funziona in modo simile a un sistema token. Ad esempio, se un dato volume contenente file di dati ha un limite di 10K IOPS, ogni i/o che arriva deve prima ricevere un token per continuare l'elaborazione. Fino a quando non sono stati consumati più di 10K gettoni in un dato secondo, non sono presenti ritardi. Se le operazioni io devono attendere per ricevere il token, questa attesa viene visualizzata come latenza aggiuntiva. Più un carico di lavoro supera il limite di qualità del servizio, più a lungo ogni i/o deve attendere in coda per l'elaborazione del proprio turno, che appare all'utente come una latenza più elevata.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Prestare attenzione nell'applicazione dei controlli QoS ai dati dei log di transazione/ripristino del database. Mentre le richieste di performance del logging di redo sono in genere molto, molto più basse dei data afiles, l'attività del log di redo è molto bursty. L'io avviene in brevi impulsi e un limite QoS che appare appropriato per i livelli di io di redo medi potrebbe essere troppo basso per i requisiti effettivi. Il risultato può essere una serie di limitazioni delle performance, mentre la qualità del servizio viene associata a ogni burst dei log di ripristino. In generale, il redo e la registrazione dell'archivio non devono essere limitati dalla QoS.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">QoS della larghezza di banda</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">Non tutte le dimensioni i/o sono uguali. Ad esempio, un database potrebbe eseguire un elevato numero di piccoli blocchi di lettura con il raggiungimento della soglia IOPS, tuttavia, è possibile che i database eseguano anche un'operazione di scansione completa della tabella, che consisterebbe in un numero molto ridotto di letture di blocchi di grandi dimensioni, consumando una grande quantità di larghezza di banda ma con un numero relativamente basso di IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">Allo stesso modo, un ambiente VMware potrebbe gestire un numero molto elevato di IOPS casuali durante l'avvio, ma eseguirebbe un numero minore di io, ma più grande, durante un backup esterno.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">Una gestione efficace delle performance a volte richiede limiti di qualità del servizio (QoS) IOPS o larghezza di banda, o anche entrambi.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">Qualità del servizio minima/garantita</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">Molti clienti cercano una soluzione che includa QoS garantita, che sia più difficile da raggiungere di quanto possa sembrare e che sia potenzialmente abbastanza dispendiosa. Ad esempio, collocare 10 database con una garanzia di 10K IOPS richiede il dimensionamento di un sistema per uno scenario in cui tutti i 10 database vengono eseguiti contemporaneamente a 10K IOPS, per un totale di 100K.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">L'utilizzo ottimale per i controlli minimi della qualità del servizio è la protezione dei carichi di lavoro critici. Ad esempio, prendi in considerazione un controller ONTAP con un numero massimo di IOPS possibile di 500K e un mix di workload di produzione e sviluppo. È consigliabile applicare policy QoS massime ai carichi di lavoro di sviluppo per impedire a qualsiasi database di monopolizzare il controller. Quindi, ai carichi di lavoro di produzione si applicano policy minime di qualità del servizio per assicurarsi che dispongano sempre degli IOPS richiesti, quando necessario.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">QoS adattiva</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">La qualità del servizio adattiva fa riferimento alla funzionalità ONTAP, in cui il limite della qualità del servizio si basa sulla capacità dell'oggetto storage. Viene utilizzata raramente con i database perché di solito non esiste alcun collegamento tra le dimensioni di un database e i relativi requisiti prestazionali. I database di grandi dimensioni possono essere quasi inerti, mentre quelli di dimensioni inferiori possono utilizzare un numero elevato di IOPS.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">La qualità del servizio adattiva può rivelarsi molto utile con i datastore di virtualizzazione, perché i requisiti di IOPS di tali set di dati tendono a correlare le dimensioni totali del database. Un datastore più recente, che contiene 1TB TB di file VMDK, avrà probabilmente bisogno di circa la metà delle performance rispetto a un datastore da 2TB TB. La qualità del servizio adattiva ti consente di aumentare automaticamente i limiti della qualità del servizio, man mano che il datastore viene popolato con i dati.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">Il tiering di un set di dati con FabricPool determina una dipendenza tra lo storage array primario e il Tier dell'archivio di oggetti. Sono disponibili molte opzioni di storage a oggetti che offrono livelli di disponibilità variabili. È importante comprendere l'impatto di una possibile perdita di connettività tra lo storage array primario e il Tier dello storage a oggetti.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Se un i/o emesso a ONTAP richiede dati dal Tier di capacità e ONTAP non riesce a raggiungere il Tier di capacità per recuperare i blocchi, l'i/o finisce il time-out. L'effetto di questo timeout dipende dal protocollo utilizzato. In un ambiente NFS, ONTAP risponde con una risposta EJUKEBOX o EDELAY, a seconda del protocollo. Alcuni sistemi operativi meno recenti potrebbero interpretare questo come un errore, ma i sistemi operativi attuali e i livelli di patch correnti del client Oracle Direct NFS considerano questo come un errore recuperabile e continuano ad attendere il completamento dell'i/O.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Un timeout più breve si applica agli ambienti SAN. Se un blocco nell'ambiente dell'archivio oggetti è necessario e rimane irraggiungibile per due minuti, viene restituito un errore di lettura all'host. Il volume e i LUN di ONTAP rimangono online, ma il sistema operativo host potrebbe segnalare il file system come in uno stato di errore.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Problemi di connettività dello storage a oggetti<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> i criteri sono meno preoccupanti, perché vengono suddivisi in livelli solo i dati di backup. I problemi di comunicazione rallenterebbero il recupero dei dati, ma non influenzerebbero altrimenti l'utilizzo attivo dei dati. Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> e.<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Le policy consentono il tiering dei dati cold dal LUN attivo, il che significa che un errore durante il recupero dei dati dell'archivio oggetti può influire sulla disponibilità del database. Un'implementazione SAN con queste policy deve essere utilizzata solo con storage a oggetti di classe Enterprise e connessioni di rete progettate per l'alta disponibilità. NetApp StorageGRID è l'opzione superiore.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">La maggior parte dei database relazionali opera in modalità di archiviazione dei log delle transazioni per fornire un ripristino point-in-time. Le modifiche apportate ai database vengono salvate registrando le modifiche nei registri delle transazioni e il registro delle transazioni viene conservato senza essere sovrascritto. Il risultato può essere la necessità di conservare un enorme volume di registri delle transazioni archiviati. Esempi simili esistono con molti altri flussi di lavoro delle applicazioni che generano dati che devono essere conservati, ma con molte probabilità di accesso.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">FabricPool risolve questi problemi offrendo una singola soluzione con tiering integrato. I file vengono memorizzati e rimangono accessibili nella loro posizione abituale, ma non occupano praticamente spazio nell'array primario.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Utilizzare un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la policy di pochi giorni comporta la conservazione dei blocchi nei file creati di recente (che sono i file più probabilmente necessari a breve termine) nel tier di performance. I blocchi di dati dei file meno recenti vengono quindi spostati nel Tier di capacità.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">Il<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> applica il tiering prompt quando viene raggiunta la soglia di raffreddamento, indipendentemente dal fatto che i log siano stati eliminati o continuino a esistere nel file system primario. Inoltre, l'archiviazione di tutti i log potenzialmente necessari in un'unica posizione nel file system attivo semplifica la gestione. Non c'è motivo di cercare tra gli snapshot per individuare un file che deve essere ripristinato.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Alcune applicazioni, come Microsoft SQL Server, troncano i file di log delle transazioni durante le operazioni di backup in modo che i log non si trovino più nel file system attivo. È possibile risparmiare capacità utilizzando<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> tiering delle policy, ma<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> il criterio non è utile per i dati di log perché raramente dovrebbero essere raffreddati i dati di log nel file system attivo.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster è disponibile in 3 diverse configurazioni</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">Coppie HA con connettività IP</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">Coppie HA con connettività FC</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Controller singolo con connettività FC</block>
  <block id="6fa7041982bed9488213a7bd2ecccfdf" category="paragraph">[NOTA]il termine 'connettività' si riferisce alla connessione cluster utilizzata per la replica tra siti. Non si riferisce ai protocolli host. Tutti i protocolli lato host sono supportati come di consueto in una configurazione MetroCluster indipendentemente dal tipo di connessione utilizzata per la comunicazione tra cluster.</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">IP MetroCluster</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">La configurazione MetroCluster IP ha-Pair utilizza due o quattro nodi per sito. Questa opzione di configurazione aumenta la complessità e i costi rispetto all'opzione a due nodi, ma offre un vantaggio importante: La ridondanza intrasite. Un semplice errore del controller non richiede l'accesso ai dati nella WAN. L'accesso ai dati rimane locale attraverso il controller locale alternativo.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">La maggior parte dei clienti sceglie la connettività IP perché i requisiti dell'infrastruttura sono più semplici. In passato, la connettività cross-site ad alta velocità era generalmente più semplice da fornire utilizzando gli switch FC e in fibra scura, ma oggi i circuiti IP ad alta velocità e a bassa latenza sono più prontamente disponibili.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">L'architettura è anche più semplice perché le uniche connessioni cross-site sono per i controller. Nei MetroClusters collegati a FC SAN, un controller scrive direttamente sulle unità del sito opposto e quindi richiede connessioni SAN, switch e bridge aggiuntivi. Al contrario, un controller in una configurazione IP scrive sulle unità opposte tramite il controller.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Architettura e progettazione della soluzione IP di MetroCluster</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Per ulteriori informazioni, consultare la documentazione ufficiale di ONTAP e.<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">MetroCluster HA-Pair FC SAN-Attached</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">La configurazione ha-Pair MetroCluster FC utilizza due o quattro nodi per sito. Questa opzione di configurazione aumenta la complessità e i costi rispetto all'opzione a due nodi, ma offre un vantaggio importante: La ridondanza intrasite. Un semplice errore del controller non richiede l'accesso ai dati nella WAN. L'accesso ai dati rimane locale attraverso il controller locale alternativo.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Alcune infrastrutture multisito non sono progettate per le operazioni Active-Active, ma vengono utilizzate maggiormente come sito primario e sito di disaster recovery. In questa situazione, è generalmente preferibile un'opzione ha-Pair MetroCluster per i seguenti motivi:</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Anche se un cluster MetroCluster a due nodi è un sistema ha, un guasto imprevisto di un controller o una manutenzione pianificata richiedono che i servizi dati vengano online sul sito opposto. Se la connettività di rete tra i siti non supporta la larghezza di banda richiesta, le prestazioni ne risentono. L'unica opzione sarebbe anche eseguire il failover dei vari sistemi operativi host e dei servizi associati al sito alternativo. Il cluster MetroCluster ha-Pair elimina questo problema grazie alla perdita di un controller che consente di eseguire un semplice failover all'interno dello stesso sito.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Alcune topologie di rete non sono progettate per l'accesso tra siti, ma utilizzano sottoreti o SAN FC isolate. In questi casi, il cluster MetroCluster a due nodi non funziona più come sistema ha, perché il controller alternativo non può fornire dati ai server del sito opposto. L'opzione ha-Pair MetroCluster è necessaria per garantire ridondanza completa.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Se un'infrastruttura a due siti viene vista come una singola infrastruttura ad alta disponibilità, la configurazione MetroCluster a due nodi è adatta. Tuttavia, se il sistema deve funzionare per un periodo di tempo prolungato dopo il guasto del sito, è preferibile una coppia ha perché continua a fornire ha all'interno di un singolo sito.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">MetroCluster FC SAN-attached a due nodi</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">La configurazione MetroCluster a due nodi utilizza un solo nodo per sito. Questo design è più semplice rispetto all'opzione ha-Pair perché richiede meno componenti da configurare e gestire. Inoltre, ha ridotto le richieste di infrastruttura in termini di cablaggio e switch FC. Infine, riduce i costi.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">L'evidente impatto di questa progettazione è che un guasto del controller su un singolo sito implica che i dati sono disponibili dal sito opposto. Questa restrizione non è necessariamente un problema. Molte aziende hanno operazioni di data center multisito con reti estese, ad alta velocità e a bassa latenza che funzionano essenzialmente come una singola infrastruttura. In questi casi, la configurazione preferita è la versione a due nodi di MetroCluster. Diversi service provider utilizzano attualmente sistemi a due nodi con scalabilità di petabyte.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Funzionalità di resilienza di MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">Non esistono single point of failure in una soluzione MetroCluster:</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Ogni controller dispone di due percorsi indipendenti verso gli shelf di dischi sul sito locale.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Ogni controller dispone di due percorsi indipendenti verso gli shelf di dischi sul sito remoto.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Ciascun controller dispone di due percorsi indipendenti verso i controller sul sito opposto.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">Nella configurazione ha-Pair, ogni controller ha due percorsi verso il partner locale.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">Riassumendo, qualsiasi componente della configurazione può essere rimosso senza compromettere la capacità di MetroCluster di fornire dati. L'unica differenza in termini di resilienza tra le due opzioni è che la versione ha-Pair è ancora un sistema storage ha generale dopo un guasto del sito.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Gestione dello spazio</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">Il thin provisioning è disponibile in molte forme e rappresenta parte integrante di molte funzionalità offerte da ONTAP a un ambiente applicativo aziendale. Il thin provisioning è inoltre strettamente correlato alle tecnologie di efficienza per lo stesso motivo: Le funzionalità di efficienza consentono di memorizzare dati più logici rispetto a quanto tecnicamente esistente nel sistema storage.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">Quasi tutti gli utilizzi delle snapshot implicano il thin provisioning. Ad esempio, un tipico database da 10TB TB su storage NetApp include circa 30 giorni di snapshot. Questa disposizione risulta in circa 10TB di dati visibili nel file system attivo e 300TB dedicati agli snapshot. In genere, il 310TB GB di storage totale risiede su un totale di circa 12TB - 15TB GB di spazio. Il database attivo consuma 10TB e i restanti 300TB di dati richiedono solo da 2TB a 5TB di spazio, in quanto vengono memorizzate solo le modifiche apportate ai dati originali.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">Anche il cloning è un esempio di thin provisioning. Un importante cliente NetApp ha creato 40 cloni di un database da 80TB TB per l'utilizzo da parte dello sviluppo. Se tutti i 40 sviluppatori che utilizzano questi cloni sovrascrivono ogni blocco in ogni file dati, sarebbero necessari oltre 3,2PB TB di storage. In pratica, il turnover è basso e il requisito di spazio collettivo è più vicino a 40TB, perché solo le modifiche sono memorizzate sui drive.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">È necessario prestare particolare attenzione al thin provisioning di un ambiente applicativo, perché la velocità di modifica dei dati può aumentare inaspettatamente. Ad esempio, il consumo di spazio dovuto agli snapshot può crescere rapidamente se le tabelle di database vengono riindicizzate o se viene applicata una patch su larga scala ai guest VMware. Un backup posizionato in modo errato può scrivere una grande quantità di dati in un tempo molto breve. Infine, può essere difficile recuperare alcune applicazioni se un file system esaurisce inaspettatamente lo spazio libero.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Fortunatamente, questi rischi possono essere risolti con un'attenta configurazione di<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> criteri: Come indicato dai nomi, queste opzioni consentono a un utente di creare policy in grado di liberare automaticamente lo spazio occupato dalle snapshot o di far crescere un volume per ospitare dati aggiuntivi. Sono disponibili molte opzioni e le esigenze variano in base al cliente.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">documentazione per la gestione logica dello storage</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Vedere <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> per una discussione completa di queste funzioni.</block>
  <block id="8cf44a7a390ab582c5010ba430143d4b" category="section-title">Thin provisioning LUN</block>
  <block id="ba0bdf51bc57bacdd6f3f0bd26b7674c" category="paragraph">L'efficienza del thin provisioning delle LUN attive in un ambiente di file system può andare persa nel tempo quando i dati vengono eliminati. A meno che i dati eliminati non vengano sovrascritti con zero o lo spazio venga liberato con il recupero di spazio TRIM/UNMAP, i dati "cancellati" occupano sempre più spazi vuoti non allocati nel file system. Inoltre, in molti ambienti di database il thin provisioning delle LUN attive è limitato, in quanto i file di dati vengono inizializzati alle dimensioni massime al momento della creazione.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Un'attenta pianificazione della configurazione LVM può migliorare l'efficienza e ridurre al minimo la necessità di provisioning dello storage e di ridimensionamento delle LUN. Quando si utilizza un LVM come Veritas VxVM o Oracle ASM, le LUN sottostanti vengono suddivise in estensioni che vengono utilizzate solo quando necessario. Ad esempio, se un set di dati inizia a 2TB TB ma potrebbe crescere fino a 10TB TB con il passare del tempo, è possibile inserire il set di dati in 10TB LUN con thin provisioning organizzati in un gruppo di dischi LVM. Occupa solo 2TB GB di spazio al momento della creazione e richiederebbe spazio aggiuntivo solo se le estensioni sono allocate per ospitare la crescita dei dati. Questo processo è sicuro finché lo spazio è monitorato.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Prenotazioni frazionarie</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">Riserva frazionaria si riferisce al comportamento di un LUN in un volume rispetto all'efficienza dello spazio. Quando l'opzione<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> è impostato al 100%, tutti i dati nel volume possono subire un turnover del 100% con qualsiasi modello di dati senza esaurire lo spazio sul volume.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Ad esempio, si consideri un database su una singola LUN da 250GB GB in un volume da 1TB GB. La creazione di uno snapshot comporterebbe immediatamente la riserva di ulteriori 250GB GB di spazio nel volume per garantire che il volume non esaurisca lo spazio per alcun motivo. L'utilizzo di riserve frazionarie comporta in genere uno spreco di risorse poiché è estremamente improbabile che ogni byte nel volume del database debba essere sovrascritto. Non c'è motivo di riservare spazio per un evento che non si verifica mai. Tuttavia, se un cliente non è in grado di monitorare il consumo di spazio in un sistema di storage e deve essere certo che lo spazio non si esaurisce mai, sarebbero necessarie prenotazioni frazionarie del 100% per utilizzare gli snapshot.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Compressione e deduplica</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">Compressione e deduplica sono entrambe forme di thin provisioning. Ad esempio, un impatto dei dati di 50TB:1 potrebbe comprimere fino a 30TB:1, ottenendo un risparmio di 20TB:1. Affinché la compressione possa produrre vantaggi, alcuni di questi 20TB TB devono essere utilizzati per altri dati, altrimenti il sistema storage deve essere acquistato con meno di 50TB TB. In questo modo è possibile memorizzare una quantità di dati superiore rispetto a quella tecnicamente disponibile sul sistema storage. Dal punto di vista dei dati, i dati sono 50TB, anche se occupano solo 30TB sulle unità.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Esiste sempre la possibilità che la compressibilità di un set di dati cambi, con conseguente aumento del consumo di spazio reale. Questo aumento dei consumi implica che la compressione deve essere gestita come con altre forme di thin provisioning in termini di monitoraggio e utilizzo<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">Compressione e deduplica sono descritte in dettaglio nella sezione link:efficiency.html</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Compressioni e prenotazioni frazionarie</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">La compressione è una forma di thin provisioning. Le prenotazioni frazionarie influiscono sull'utilizzo della compressione, con una nota importante; lo spazio viene riservato prima della creazione dell'istantanea. Normalmente, la riserva frazionaria è importante solo se esiste uno snapshot. Se non è presente uno snapshot, la riserva frazionaria non è importante. Questo non è il caso della compressione. Se viene creata una LUN su un volume con compressione, ONTAP preserva lo spazio per ospitare uno snapshot. Questo comportamento può creare confusione durante la configurazione, ma è previsto.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Ad esempio, consideriamo un volume da 10GB GB con una LUN da 5GB GB compressa a 2,5GB GB senza snapshot. Considerare questi due scenari:</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">Riserva frazionaria = 100 risultati in 7,5GB utilizzo</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">Riserva frazionaria = 0 risultati in 2,5GB utilizzo</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">Il primo scenario include 2,5GB di consumo di spazio per i dati attuali e 5GB di spazio per rappresentare il 100% di fatturato della fonte in previsione dell'utilizzo di snapshot. Il secondo scenario non riserva spazio aggiuntivo.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Sebbene questa situazione possa sembrare confusa, è improbabile che si verifichi nella pratica. La compressione implica thin provisioning e il thin provisioning in un ambiente LUN richiede prenotazioni frazionarie. È sempre possibile sovrascrivere i dati compressi con qualcosa di non comprimibile, il che significa che un volume deve essere sottoposto a thin provisioning per la compressione per consentire qualsiasi risparmio.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp consiglia* le seguenti configurazioni riservate:</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Impostare<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 0 quando è in atto il monitoraggio della capacità di base con<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> e.<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Impostare<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 100 se non vi è alcuna capacità di monitoraggio o se è impossibile scaricare lo spazio in qualsiasi circostanza.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">Tipi di LIF</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Documentazione di gestione della rete ONTAP</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">Questa sezione offre una panoramica dei principali principi di progettazione della LIF. Per una documentazione più completa, vedere <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Come per altri aspetti dell'architettura dei database, le migliori opzioni per la progettazione di una Storage Virtual Machine (SVM, nota come vserver all'interfaccia della CLI) e di un'interfaccia logica (LIF) dipendono in gran parte dai requisiti di scalabilità e dalle esigenze di business.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Durante la creazione di una strategia LIF, prendi in considerazione i seguenti argomenti principali:</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Performance.* la larghezza di banda della rete è sufficiente?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Resilienza.* ci sono singoli punti di guasto nel progetto?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Gestibilità.* la rete può essere scalata senza interruzioni?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Gli argomenti trattati sono relativi alla soluzione end-to-end, dall'host fino agli switch fino al sistema storage.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">Documentazione ONTAP sui tipi di LIF</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Esistono diversi tipi di LIF. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Fornisci informazioni più complete su questo argomento, ma da un punto di vista funzionale le LIF possono essere divise in gruppi:</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*LIF di gestione cluster e nodi.* LIF utilizzati per gestire il cluster storage.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*LIF di gestione SVM.* interfacce che consentono l'accesso a una SVM tramite l'API REST o ONTAPI (nota anche come ZAPI) per funzioni come la creazione di snapshot o il ridimensionamento del volume. Prodotti come SnapManager for Oracle (SMO) devono avere accesso a una LIF di gestione SVM.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*Interfacce LIF dati* per FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, o dati SMB/CIFS.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">Una LIF dati utilizzata per il traffico NFS può anche essere utilizzata per la gestione cambiando la policy del firewall da<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> a.<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> O un'altra policy che consente HTTP, HTTPS o SSH. Questa modifica può semplificare la configurazione di rete evitando la configurazione di ciascun host per l'accesso sia alla LIF dati NFS che a una LIF di gestione separata. Non è possibile configurare un'interfaccia sia per iSCSI che per il traffico di gestione, nonostante entrambi utilizzino un protocollo IP. Negli ambienti iSCSI è necessaria una LIF di gestione separata.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Progettazione della SAN LIF</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">Il design di LIF in un ambiente SAN è relativamente semplice per un motivo: Il multipathing. Tutte le moderne implementazioni SAN consentono a un client di accedere ai dati su più percorsi di rete indipendenti e di selezionare i percorsi migliori per l'accesso. Di conseguenza, le performance rispetto alla progettazione LIF sono più semplici da gestire, perché i client SAN bilanciano automaticamente il carico dell'i/o nei migliori percorsi disponibili.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Se un percorso non è disponibile, il client seleziona automaticamente un percorso diverso. Grazie alla sua semplicità di progettazione, le LIF SAN sono generalmente più gestibili. Ciò non significa che un ambiente SAN sia sempre più facile da gestire, poiché vi sono molti altri aspetti dello storage SAN che sono molto più complicati di NFS. Significa semplicemente che la progettazione della SAN LIF è più semplice.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">La considerazione più importante riguardo le performance di una LIF in un ambiente SAN è la larghezza di banda. Ad esempio, un cluster ONTAP AFF a due nodi con due porte FC da 16GB GB per nodo offre fino a 32GB Gbps di larghezza di banda da/per ciascun nodo.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Resilienza</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">Le LIF SAN non eseguono il failover su un sistema storage AFF. In caso di guasto di una LIF SAN a causa del failover del controller, il software multipath del client rileva la perdita di un percorso e reindirizza l'i/o a una diversa LIF. Con i sistemi storage ASA, il failover delle LIF dopo un breve ritardo, ma ciò non interrompe l'io perché ci sono percorsi già attivi sull'altro controller. Il processo di failover viene eseguito per ripristinare l'accesso dell'host su tutte le porte definite.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Gestibilità</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">La migrazione LIF è un task molto più comune in un ambiente NFS, perché la migrazione LIF è spesso associata alla riallocazione dei volumi nel cluster. Non è necessario migrare una LIF in un ambiente SAN quando i volumi vengono ricollocati nella coppia ha. Questo perché, una volta completato lo spostamento del volume, ONTAP invia una notifica alla SAN in merito a una modifica dei percorsi e i client SAN vengono automaticamente risottimizzati. La migrazione LIF con SAN è associata principalmente a importanti modifiche hardware fisiche. Ad esempio, per eseguire un upgrade senza interruzioni dei controller, viene eseguita la migrazione di una SAN LIF nel nuovo hardware. Se una porta FC è guasta, una LIF può essere migrata a una porta inutilizzata.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Raccomandazioni di progettazione</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp formula i seguenti consigli:</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">Non creare più percorsi di quelli richiesti. Un numero eccessivo di percorsi complica la gestione complessiva e può causare problemi con il failover del percorso su alcuni host. Inoltre, alcuni host hanno limitazioni inattese del percorso per configurazioni come l'avvio SAN.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Un numero molto ridotto di configurazioni deve richiedere più di quattro percorsi a un LUN. Il valore di avere più di due nodi che pubblicizzano i percorsi delle LUN è limitato perché l'aggregato che ospita un LUN è inaccessibile in caso di guasto del nodo proprietario del LUN e del partner ha. In una situazione del genere, la creazione di percorsi su nodi diversi dalla coppia ha primaria non è d'aiuto.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Sebbene il numero di percorsi LUN visibili possa essere gestito selezionando le porte incluse nelle zone FC, in genere è più semplice includere tutti i potenziali punti di destinazione nella zona FC e controllare la visibilità delle LUN a livello ONTAP.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">In ONTAP 8,3 e versioni successive, la funzione SLM (Selective LUN mapping) è quella predefinita. Con SLM, ogni nuova LUN viene automaticamente pubblicizzata dal nodo proprietario dell'aggregato sottostante e del partner ha del nodo. Questa disposizione evita la necessità di creare set di porte o configurare la suddivisione in zone per limitare l'accessibilità delle porte. Ogni LUN è disponibile sul numero minimo di nodi necessari per performance e resilienza ottimali.
*Nel caso in cui sia necessario migrare un LUN all'esterno dei due controller, è possibile aggiungere i nodi aggiuntivi con<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> In modo che le LUN vengano pubblicizzate sui nuovi nodi. In questo modo si creano ulteriori percorsi SAN alle LUN per la migrazione delle LUN. Tuttavia, l'host deve eseguire un'operazione di rilevamento per utilizzare i nuovi percorsi.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">Non preoccupatevi eccessivamente del traffico indiretto. Si consiglia di evitare il traffico indiretto in un ambiente i/o-intensive per il quale è critico ogni microsecondo di latenza, ma l'effetto visibile delle performance è trascurabile per i workload tipici.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">Progettazione della LIF NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">A differenza dei protocolli SAN, NFS ha una capacità limitata di definire percorsi multipli ai dati. Le estensioni Parallel NFS (pNFS) a NFSv4 risolvono questo limite, ma poiché le velocità ethernet hanno raggiunto 100GB Mbps e oltre, raramente è utile aggiungere altri percorsi.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Performance e resilienza</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Sebbene la misurazione delle performance SAN LIF si debba principalmente calcolare la larghezza di banda totale da tutti i percorsi primari, la determinazione delle performance NFS LIF richiede un'analisi più approfondita dell'esatta configurazione di rete. Ad esempio, è possibile configurare due porte 10Gb come porte fisiche grezze oppure come gruppo di interfacce LACP (link Aggregation Control Protocol). Se sono configurati come gruppo di interfacce, sono disponibili più criteri di bilanciamento del carico che funzionano in modo diverso a seconda che il traffico sia commutato o instradato. Infine, Oracle Direct NFS (DNFS) offre configurazioni di bilanciamento del carico attualmente inesistenti in nessun client NFS del sistema operativo.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">A differenza dei protocolli SAN, i file system NFS richiedono resilienza al livello del protocollo. Ad esempio, un LUN è sempre configurato con il multipathing attivato, ovvero sono disponibili più canali ridondanti per il sistema storage, ciascuno dei quali utilizza il protocollo FC. Un file system NFS, invece, dipende dalla disponibilità di un unico canale TCP/IP che può essere protetto solo a livello fisico. Questa disposizione è il motivo per cui esistono opzioni quali il failover della porta e l'aggregazione della porta LACP.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">In un ambiente NFS, performance e resilienza sono fornite a livello del protocollo di rete. Di conseguenza, entrambi gli argomenti sono intrecciati e devono essere discussi insieme.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Associare le LIF ai gruppi di porte</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Per associare una LIF a un gruppo di porte, associare l'indirizzo IP della LIF a un gruppo di porte fisiche. Il metodo principale per aggregare insieme le porte fisiche è LACP. La capacità di fault tolerance di LACP è abbastanza semplice; ogni porta di un gruppo LACP viene monitorata e rimossa dal gruppo di porte in caso di malfunzionamento. Esistono, tuttavia, molte idee sbagliate sul funzionamento di LACP in relazione alle prestazioni:</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP non richiede che la configurazione sullo switch corrisponda all'endpoint. Ad esempio, ONTAP può essere configurato con il bilanciamento del carico basato su IP, mentre uno switch può utilizzare il bilanciamento del carico basato su MAC.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Ogni endpoint che utilizza una connessione LACP può scegliere indipendentemente la porta di trasmissione del pacchetto, ma non può scegliere la porta utilizzata per la ricezione. Ciò significa che il traffico da ONTAP a una destinazione specifica è legato a una porta specifica e il traffico di ritorno potrebbe arrivare su un'interfaccia diversa. Ciò non causa tuttavia problemi.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP non distribuisce uniformemente il traffico in ogni momento. In un ambiente di grandi dimensioni con molti client NFS, il risultato è generalmente l'utilizzo di tutte le porte in un'aggregazione LACP. Tuttavia, qualsiasi file system NFS nell'ambiente è limitato alla larghezza di banda di una sola porta, non all'intera aggregazione.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Sebbene i criteri LACP di robin-robin siano disponibili su ONTAP, questi criteri non indirizzano la connessione da uno switch a un host. Ad esempio, una configurazione con un trunk LACP a quattro porte su un host e un trunk LACP a quattro porte su ONTAP è ancora in grado di leggere un file system utilizzando una sola porta. Sebbene ONTAP sia in grado di trasmettere dati attraverso tutte e quattro le porte, non sono attualmente disponibili tecnologie di switch che inviano dallo switch all'host attraverso tutte e quattro le porte. Ne viene utilizzato uno solo.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">L'approccio più comune in ambienti di grandi dimensioni costituiti da molti host di database è quello di creare un aggregato LACP di un numero appropriato di interfacce 10Gb (o più veloce) utilizzando il bilanciamento del carico IP. Questo approccio consente a ONTAP di garantire l'uso uniforme di tutte le porte, purché esistano un numero sufficiente di client. Il bilanciamento del carico si interrompe quando nella configurazione sono presenti meno client, poiché il trunking LACP non ridistribuisce dinamicamente il carico.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Quando viene stabilita una connessione, il traffico in una determinata direzione viene posizionato su una sola porta. Ad esempio, un database che esegue una scansione completa della tabella su un file system NFS collegato tramite un trunk LACP a quattro porte legge i dati tramite una sola scheda di interfaccia di rete (NIC). Se in un tale ambiente sono presenti solo tre server di database, è possibile che tutti e tre stiano leggendo dalla stessa porta, mentre le altre tre porte sono inattive.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Lega le LIF alle porte fisiche</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">L'associazione di una LIF a una porta fisica dà come risultato un controllo più granulare della configurazione di rete, in quanto un dato indirizzo IP su un sistema ONTAP è associato a una sola porta di rete alla volta. La resilienza viene quindi ottenuta tramite la configurazione di gruppi di failover e policy di failover.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Criteri di failover e gruppi di failover</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">Documentazione sulla gestione della rete di ONTAP per gruppi e policy di failover</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">Il comportamento delle LIF durante un'interruzione di rete è controllato da policy di failover e gruppi di failover. Le opzioni di configurazione sono state modificate con le diverse versioni di ONTAP. Consultare <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Per informazioni specifiche sulla versione di ONTAP distribuita.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">ONTAP 8,3 (e versioni successive) consente la gestione del failover LIF in base ai domini di broadcast. Pertanto, un amministratore può definire tutte le porte che hanno accesso a una data subnet e consentire a ONTAP di selezionare una LIF di failover appropriata. Questo approccio può essere utilizzato da alcuni clienti, ma presenta limitazioni in un ambiente di rete di storage ad alta velocità a causa della mancanza di prevedibilità. Ad esempio, un ambiente può includere sia porte 1Gb GbE per l'accesso di routine al file system sia porte 10Gb GbE per l'i/o del file dati Se nello stesso dominio di broadcast sono presenti entrambi i tipi di porte, il failover LIF può spostare l'i/o del file dati da una porta 10Gb a una porta 1Gb.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">In sintesi, prendere in considerazione le seguenti pratiche:</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Configurare un gruppo di failover come definito dall'utente.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Popola il gruppo di failover con le porte sul partner controller di failover dello storage (SFO), in modo che le LIF seguano gli aggregati durante un failover dello storage. In questo modo si evita di creare traffico indiretto.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Utilizza porte di failover con caratteristiche di performance corrispondenti alla LIF originale. Ad esempio, una LIF su una singola porta fisica di 10Gb deve includere un gruppo di failover con una singola porta 10Gb. Un LIF LACP a quattro porte deve eseguire il failover in un altro LIF LACP a quattro porte. Queste porte sono un sottoinsieme delle porte definite nel dominio di broadcast.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Impostare la policy di failover solo su partner SFO. Questo assicura che la LIF segua l'aggregato durante il failover.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Ripristino automatico</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Impostare<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> parametro come desiderato. La maggior parte dei clienti preferisce impostare questo parametro su<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Di ripristinare la porta home della LIF. Tuttavia, in alcuni casi, i clienti hanno impostato questo valore su `false' per poter esaminare un failover imprevisto prima di restituire una LIF alla porta home.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">Rapporto LIF-volume</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">Un equivoco comune consiste nella necessità di una relazione 1:1:1 tra volumi e LIF NFS. Sebbene questa configurazione sia necessaria per spostare un volume ovunque in un cluster senza creare mai traffico di interconnessione aggiuntivo, non si tratta di un requisito categoricamente importante. Occorre considerare il traffico intercluster, ma la semplice presenza di traffico intercluster non crea problemi. Molti dei benchmark pubblicati per ONTAP includono principalmente l'i/o indiretto</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Ad esempio, un progetto di database contenente un numero relativamente contenuto di database critici per le performance, che richiedevano solo un totale di 40 volumi, potrebbe giustificare un volume da 1:1 GB per la strategia LIF, una disposizione che richiederebbe 40 indirizzi IP. Quindi, è possibile spostare un qualsiasi volume nel cluster insieme alla LIF associata e il traffico sarebbe sempre diretto, minimizzando ogni origine di latenza anche a livelli di microsecondi.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Ad esempio, è possibile gestire più facilmente un ambiente di grandi dimensioni in hosting con una relazione di 1:1:1 tra clienti e LIF. Con il passare del tempo, potrebbe essere necessario migrare un volume su un nodo diverso, causando traffico indiretto. Tuttavia, l'effetto sulle prestazioni non dovrebbe essere rilevabile a meno che le porte di rete sullo switch di interconnessione non siano saturanti. In caso di problemi, è possibile stabilire una nuova LIF sui nodi aggiuntivi e l'host può essere aggiornato nella successiva finestra di manutenzione per rimuovere il traffico indiretto dalla configurazione.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster e aggregati multipli</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">In condizioni normali, le scritture in arrivo su un dato controller vengono mirrorate in modo sincrono per il partner. In un ambiente NetApp MetroCluster, le scritture vengono anche mirrorate su un controller remoto. Fino a quando non viene memorizzata in un supporto non volatile in tutte le posizioni, la scrittura non viene riconosciuta all'applicazione host.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">Il supporto che memorizza i dati di scrittura è chiamato memoria non volatile o NVMEM. Viene anche talvolta indicata come memoria non volatile ad accesso casuale (NVRAM, nonvolatile Random Access Memory), e può essere considerata come una cache di scrittura anche se funziona come un journal. In condizioni normali, i dati provenienti da NVMEM non vengono letti; vengono utilizzati solo per proteggere i dati in caso di guasti software o hardware. Quando i dati vengono scritti sulle unità disco rigido, i dati vengono trasferiti dalla RAM nel sistema, non da NVMEM.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Durante un'operazione di takeover, un nodo di una coppia ha (high Availability) assume il controllo delle operazioni dal partner. Lo switchover è praticamente identico, ma si applica alle configurazioni MetroCluster in cui un nodo remoto assume le funzioni di un nodo locale.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Durante le normali operazioni di manutenzione, un'operazione di takeover o switchover dello storage deve essere trasparente, ad eccezione di una potenziale breve pausa nelle operazioni in base al cambiamento dei percorsi di rete. Il networking può rivelarsi complesso, tuttavia, ed è facile commettere errori, pertanto NetApp consiglia vivamente di eseguire accuratamente le operazioni di takeover e switchover prima di mettere in produzione un sistema storage. In questo modo, è possibile verificare che tutti i percorsi di rete siano configurati correttamente. In un ambiente SAN, controllare attentamente l'output del comando<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> per assicurarsi che tutti i percorsi primario e secondario previsti siano disponibili.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Occorre prestare attenzione quando si rilascia un'acquisizione forzata o uno switchover. Imporre una modifica alla configurazione dello storage con queste opzioni significa che lo stato del controller proprietario delle unità non viene preso in considerazione e il nodo alternativo assume forzatamente il controllo delle unità. Una forzatura non corretta di un takeover può causare la perdita o il danneggiamento dei dati. Questo perché un takeover o uno switchover forzato può scartare il contenuto di NVMEM. Una volta completato il takeover o lo switchover, la perdita dei dati potrebbe riportare i dati memorizzati nelle unità a uno stato leggermente più vecchio dal punto di vista del database.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">Raramente dovrebbe essere necessario un takeover forzato con una normale coppia ha. In quasi tutti gli scenari di errore, un nodo si arresta e informa il partner in modo che si verifichi un failover automatico. In alcuni casi, ad esempio in caso di guasto permanente che causa la perdita dell'interconnessione tra i nodi e la perdita di un controller, è necessario eseguire un takeover forzato. In una situazione del genere, il mirroring tra i nodi viene perso prima del guasto del controller, il che significa che il controller rimasto non avrebbe più una copia delle scritture in corso. Il takeover deve quindi essere forzato, il che significa che potenzialmente i dati vengono persi.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">La stessa logica si applica a uno switchover MetroCluster. In condizioni normali, lo switchover è quasi trasparente. Tuttavia, un disastro può causare una perdita di connettività tra il sito rimasto e il sito disastroso. Dal punto di vista del sito sopravvissuto, il problema potrebbe essere nient'altro che un'interruzione della connettività tra i siti, e il sito originale potrebbe ancora elaborare i dati. Se un nodo non è in grado di verificare lo stato del controller primario, è possibile solo uno switchover forzato.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp raccomanda* adottare le seguenti precauzioni:</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Prestare molta attenzione a non forzare accidentalmente un'acquisizione o uno switchover. In genere, non è necessario forzare e forzare la modifica può causare la perdita di dati.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Se è necessario un takeover o uno switchover forzato, assicurarsi che le applicazioni vengano arrestate, che tutti i file system vengano dismontati e che i gruppi di volumi LVM (Logical Volume Manager) siano diversi. I gruppi di dischi ASM devono essere smontati.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">In caso di switchover MetroCluster forzato, scollegare il nodo guasto da tutte le risorse di storage rimaste. Per ulteriori informazioni, consultare la Guida alla gestione e al ripristino di emergenza di MetroCluster per la versione pertinente di ONTAP.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster è una tecnologia di replica sincrona che passa alla modalità asincrona in caso di interruzione della connettività. Questa è la richiesta più comune da parte dei clienti, perché la replica sincrona garantita significa che l'interruzione della connettività del sito porta a uno stallo completo dell'i/o del database, mettendo il database fuori servizio.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Con MetroCluster, gli aggregati vengono sincronizzati rapidamente dopo il ripristino della connettività. A differenza di altre tecnologie di storage, MetroCluster non dovrebbe mai richiedere un reindirizzamento completo in seguito a un guasto del sito. È necessario spedire solo le modifiche delta.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">Nei set di dati estesi agli aggregati c'è solo un piccolo rischio che occorrano passaggi aggiuntivi di recovery dei dati in uno scenario di emergenza regolare. In particolare, se (a) la connettività tra siti viene interrotta, (b) la connettività viene ripristinata, (c) gli aggregati raggiungono uno stato in cui alcuni sono sincronizzati e alcuni non lo sono, quindi (d) il sito primario viene perso, il risultato è un sito sopravvissuto in cui gli aggregati non sono sincronizzati tra loro. In tal caso, parti del set di dati vengono sincronizzate tra loro e non è possibile ripristinare applicazioni, database o datastore senza un recovery. Se un set di dati si estende agli aggregati, NetApp consiglia vivamente di sfruttare i backup basati su snapshot con uno dei molti strumenti disponibili, per verificare la possibilità di recupero rapido in questo scenario insolito.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP e RAID-TEC utilizzano tutti la parità per garantire che il guasto al disco non determini una perdita di dati. Queste opzioni RAID offrono un utilizzo dello storage migliore rispetto al mirroring, ma la maggior parte delle implementazioni RAID presenta uno svantaggio che influisce sulle operazioni di scrittura. Il completamento di un'operazione di scrittura su altre implementazioni RAID potrebbe richiedere letture di più unità per rigenerare i dati di parità, un processo comunemente chiamato penalizzazione RAID.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">ONTAP, tuttavia, non subisce questa penalizzazione del RAID. Ciò è dovuto all'integrazione di NetApp WAFL (Write Anywhere file Layout) con il livello RAID. Le operazioni di scrittura vengono unite nella RAM e preparate come uno stripe RAID completo, inclusa la generazione della parità. ONTAP non ha bisogno di eseguire una lettura per completare una scrittura, il che significa che ONTAP e WAFL evitare la penalizzazione RAID. Le performance per le operazioni critiche in termini di latenza, come il logging di redo, vengono mantenute e le scritture random dei file di dati non comportano penalizzazioni RAID dovute alla necessità di rigenerare la parità.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">Per quanto riguarda l'affidabilità statistica, anche RAID DP offre una protezione migliore rispetto al mirroring RAID. Il problema principale è la richiesta fatta sui dischi durante una ricostruzione del RAID. Con un set RAID con mirroring, il rischio di perdita di dati causata da un guasto al disco e durante la ricostruzione nel partner nel set RAID è molto maggiore del rischio di un guasto a tre dischi in un set RAID DP.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Prima dell'era dei dischi flash, era stato utilizzato lo striping per superare i limiti di performance dei dischi rotanti. Ad esempio, se un sistema operativo deve eseguire un'operazione di lettura a 1MB bit, la lettura di 1MB GB di dati da un'unica unità richiederebbe un'ampia ricerca e lettura della testina dell'unità poiché il sistema 1MB viene trasferito lentamente. Se quei 1MB TB di dati sono stati suddivisi in 8 LUN, il sistema operativo potrebbe emettere otto operazioni di lettura 128K in parallelo, riducendo il tempo necessario per completare il trasferimento da 1MB GB.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">Lo striping con dischi rotanti era più difficile perché lo schema di i/o doveva essere noto in anticipo. Se lo striping non è stato regolato correttamente per i modelli i/o reali, le configurazioni con striping potrebbero danneggiare le prestazioni. Con i database Oracle, e in particolare con le configurazioni all-flash, lo striping è molto più semplice da configurare ed è stato dimostrato che le performance risultano notevolmente migliorate.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Per impostazione predefinita, i gestori di volume logici, come lo stripe di Oracle ASM, ma il sistema operativo LVM nativo non lo fanno. Alcune di esse collegano più LUN insieme come un dispositivo concatenato, il che comporta file di dati che esistono su un solo dispositivo LUN. Ciò causa punti caldi. Le altre implementazioni LVM sono impostate per impostazione predefinita su estensioni distribuite. Questo è simile allo striping, ma è più grossolano. I LUN nel gruppo di volumi vengono suddivisi in porzioni di grandi dimensioni, chiamate estensioni e generalmente misurati in molti megabyte, e i volumi logici vengono quindi distribuiti tra tali estensioni. Il risultato è un i/o casuale per un file dovrebbe essere ben distribuito tra i LUN, ma le operazioni i/o sequenziali non sono così efficienti come potrebbero essere.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">L'i/o delle applicazioni che richiedono elevate performance è quasi sempre (a) in unità delle dimensioni dei blocchi di base o (b) un megabyte.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">L'obiettivo principale di una configurazione con striping è quello di garantire che l'i/o a file singolo possa essere eseguito come una singola unità, mentre l'i/o a blocchi multipli, di dimensioni pari a 1MB GB, può essere parallelizzato in modo uniforme tra tutti i LUN del volume con striping. Ciò significa che la dimensione dello stripe non deve essere inferiore alla dimensione del blocco del database e che la dimensione dello stripe moltiplicata per il numero di LUN deve essere 1MB.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">La figura seguente mostra tre possibili opzioni per la regolazione delle dimensioni dello stripe e della larghezza. Il numero di LUN viene selezionato per soddisfare i requisiti di prestazioni come descritto sopra, ma in tutti i casi i dati totali all'interno di uno stripe singolo sono 1MB.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">Configurazione di ONTAP</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">qui.</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Tiering</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">Database PostgreSQL su ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Data Protection nativa</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">Uno degli aspetti principali della progettazione dello storage è la protezione dei volumi PostgreSQL. I clienti possono proteggere i database PostgreSQL utilizzando l'approccio dump o i backup del file system. In questa sezione vengono illustrati i diversi approcci per il backup di singoli database o dell'intero cluster.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Sono disponibili tre approcci per il backup dei dati PostgreSQL:</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">Dump di SQL Server</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Backup a livello di file system</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Archiviazione continua</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">L'idea alla base del metodo dump di SQL Server è generare un file con comandi di SQL Server che, quando viene restituito al server, può ricreare il database così come era al momento del dump. PostgreSQL fornisce i programmi di utilità<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> e.<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> per la creazione di backup singolo e a livello di cluster. Questi dump sono logici e non contengono informazioni sufficienti per essere utilizzati da WAL Replay.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Una strategia di backup alternativa consiste nell'utilizzare il backup a livello di file system, in cui gli amministratori copiano direttamente i file utilizzati da PostgreSQL per memorizzare i dati nel database. Questo metodo viene eseguito in modalità non in linea: Il database o il cluster devono essere chiusi. Un'altra alternativa è quella di utilizzare<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Per eseguire il backup hot streaming del database PostgreSQL.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">Database PostgreSQL su ONTAP</block>
  <block id="b5f477e959f26421a80e1eebdadbdd71" category="paragraph">PostgreSQL viene fornito con varianti che includono PostgreSQL, PostgreSQL Plus ed EDB Postgres Advanced Server (ECAS). PostgreSQL viene in genere distribuito come database back-end per applicazioni multi-Tier. È supportato da pacchetti middleware comuni (come PHP, Java, Python, Tcl/TK, ODBC, E JDBC) ed è stata storicamente una scelta popolare per i sistemi di gestione di database open-source. NetApp ONTAP è una scelta eccellente per l'esecuzione di database PostgreSQL per la sua affidabilità, prestazioni elevate ed efficienza di gestione dei dati.</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Questa documentazione su ONTAP e il database PostgreSQL sostituisce il database _TR-4770: PostgreSQL precedentemente pubblicato sulle Best practice di ONTAP._</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshot</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">I backup basati su snapshot con PostgreSQL richiedono la configurazione di snapshot per file di dati, file WAL e file WAL archiviati per garantire un ripristino completo o point-in-time.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Per i database PostgreSQL, il tempo medio di backup con gli snapshot è compreso tra pochi secondi e pochi minuti. Questa velocità di backup è da 60 a 100 volte più veloce di<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> e altri approcci di backup basati sul file system.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Le snapshot sullo storage NetApp possono essere coerenti con il crash e con l'applicazione. Viene creato uno snapshot coerente con i crash sullo storage senza chiudere il database, mentre uno snapshot coerente con l'applicazione viene creato mentre il database è in modalità backup. NetApp garantisce inoltre che le snapshot successive siano backup incrementali perenni, per promuovere il risparmio dello storage e l'efficienza della rete.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Poiché le snapshot sono rapide e non influiscono sulle prestazioni del sistema, è possibile pianificare snapshot multiple ogni giorno invece di creare un unico backup giornaliero come avviene con l'altra tecnologia di backup in streaming. Quando è necessaria un'operazione di ripristino e ripristino, il downtime del sistema viene ridotto da due caratteristiche principali:</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">La tecnologia di recovery di dati NetApp SnapRestore consente di eseguire l'operazione di ripristino in pochi secondi.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Obiettivi di recovery point (RPO) aggressivi richiedono l'applicazione di un numero inferiore di log dei database e un'accelerazione del recovery in avanti.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Per eseguire il backup di PostgreSQL, è necessario assicurarsi che i volumi di dati siano protetti contemporaneamente con WAL (gruppo di coerenza) e i registri archiviati. Mentre si utilizza la tecnologia Snapshot per copiare i file WAL, assicurarsi di eseguire<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Per svuotare tutte le voci WAL che devono essere archiviate. Se si svuotano le voci WAL durante il ripristino, sarà sufficiente arrestare il database, smontare o eliminare la directory dei dati esistente ed eseguire un'operazione SnapRestore sull'archiviazione. Al termine del ripristino, è possibile montare il sistema e riportarlo allo stato corrente. Per il ripristino point-in-time, è anche possibile ripristinare i registri WAL e di archivio; quindi PostgreSQL decide il punto più coerente e lo recupera automaticamente.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">I gruppi di coerenza sono una funzionalità di ONTAP e sono consigliati quando ci sono più volumi montati su una singola istanza o su un database con tablespace multiple. Uno snapshot del gruppo di coerenza garantisce che tutti i volumi siano raggruppati e protetti. È possibile gestire in modo efficiente un gruppo di coerenza da ONTAP System Manager, clonandolo per creare una copia dell'istanza di un database a scopo di test o sviluppo.</block>
  <block id="55ca4b30c6f7c3ef975a6d1e1fb222a2" category="inline-link-macro">Panoramica dei gruppi di coerenza di NetApp</block>
  <block id="69dd5879aee425e37fdd5796a8e06a56" category="paragraph">Per ulteriori informazioni sui gruppi di coerenza, vedere <block ref="112c5744a39904facdbc5fab385d9fe1" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Protezione dei dati</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Tablespace</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Due tablespace vengono create automaticamente al momento dell'inizializzazione del cluster di database.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">Il<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> tablespace viene utilizzato per i cataloghi di sistema condivisi. Il<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> tablespace è la tablespace predefinita dei database template1 e template0. Se la partizione o il volume su cui il cluster è stato inizializzato esaurisce lo spazio e non può essere esteso, è possibile creare uno spazio di tabella in un'altra partizione ed utilizzarlo fino a quando il sistema non può essere riconfigurato.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Un indice molto utilizzato può essere collocato su un disco veloce e altamente disponibile, come un dispositivo a stato solido. Inoltre, una tabella che memorizza i dati archiviati utilizzati raramente o non critici per le prestazioni può essere archiviata su un sistema su disco meno costoso e più lento, come le unità SAS o SATA.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Gli spazi di tabella fanno parte del cluster di database e non possono essere trattati come una raccolta autonoma di file di dati. Dipendono dai metadati contenuti nella directory dei dati principale e pertanto non possono essere collegati a un cluster di database diverso o sottoposti a backup individuale. Analogamente, se si perde uno spazio di tabella (a causa dell'eliminazione dei file, del guasto del disco e così via), il cluster del database potrebbe diventare illeggibile o non avviarsi. Posizionando una tablespace su un file system temporaneo come un disco RAM si rischia l'affidabilità dell'intero cluster.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Una volta creato, è possibile utilizzare un tablespace da qualsiasi database se l'utente richiedente dispone di privilegi sufficienti. PostgreSQL utilizza collegamenti simbolici per semplificare l'implementazione di tablespace. PostgreSQL aggiunge una riga al<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tabella (una tavola a livello di cluster) e assegna un nuovo identificatore di oggetto (OID) a quella riga. Infine, il server utilizza l'OID per creare un collegamento simbolico tra il cluster e la directory specificata. La directory<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> contiene collegamenti simbolici che puntano a ciascuno degli spazi di tabella non incorporati definiti nel cluster.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Configurazione del database</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Esistono diverse configurazioni di ottimizzazione PostgreSQL che possono migliorare le prestazioni.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">I parametri più comunemente utilizzati sono i seguenti:</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: Il numero massimo di connessioni al database da avere contemporaneamente. Utilizzare questo parametro per limitare lo scambio sul disco e l'interruzione delle prestazioni. A seconda delle esigenze dell'applicazione, è anche possibile regolare questo parametro per le impostazioni del pool di connessione.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: Il metodo più semplice per migliorare le prestazioni del server di database. Il valore predefinito è basso per la maggior parte dei componenti hardware moderni. Durante l'implementazione viene impostato su circa il 25% della RAM disponibile sul sistema. Questa impostazione di parametro varia in base al funzionamento con determinate istanze di database; potrebbe essere necessario aumentare e diminuire i valori per prova ed errore. Tuttavia, l'impostazione di un livello elevato potrebbe degradare le prestazioni.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Questo valore indica all'ottimizzatore di PostgreSQL la quantità di memoria disponibile per la memorizzazione nella cache dei dati e aiuta a determinare se utilizzare un indice. Un valore maggiore aumenta la probabilità di utilizzare un indice. Questo parametro deve essere impostato sulla quantità di memoria allocata a.<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> più la quantità di cache del sistema operativo disponibile. Spesso questo valore corrisponde a più del 50% della memoria di sistema totale.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Questo parametro controlla la quantità di memoria da utilizzare nelle operazioni di ordinamento e nelle tabelle hash. Se si esegue un ordinamento pesante nell'applicazione, potrebbe essere necessario aumentare la quantità di memoria, ma prestare attenzione. Non si tratta di un parametro a livello di sistema, ma di un parametro per operazione. Se una query complessa contiene diverse operazioni di ordinamento, utilizza più unità di memoria work_mem e più backend potrebbero farlo contemporaneamente. Questa query può spesso indurre il server di database a effettuare lo swap se il valore è troppo grande. Questa opzione era precedentemente chiamata sort_mem nelle versioni precedenti di PostgreSQL.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Questo parametro determina se tutte le pagine WAL devono essere sincronizzate su disco utilizzando fsync() prima che venga eseguito il commit di una transazione. Disattivandolo a volte si possono migliorare le prestazioni di scrittura e attivandolo si aumenta la protezione dal rischio di danneggiamento quando il sistema si blocca.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: Il processo del punto di verifica elimina i dati sottoposti a commit sul disco. Ciò comporta numerose operazioni di lettura/scrittura su disco. Il valore è impostato in secondi e valori inferiori riducono il tempo di recupero da crash e valori crescenti possono ridurre il carico sulle risorse di sistema riducendo le chiamate al punto di verifica. In base alla criticità dell'applicazione, all'utilizzo, alla disponibilità del database, impostare il valore di checkpoint_timeout.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> e.<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Queste opzioni vengono utilizzate insieme per migliorare le prestazioni scrivendo più transazioni che vengono effettuate contemporaneamente. Se ci sono diversi oggetti commit_siblings attivi nel momento in cui la transazione è in fase di commit, il server attende Commit_delay microsecondi per tentare di eseguire più transazioni contemporaneamente.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Configurare il numero ottimale di lavoratori per i processi. Max_Parallel_Workers corrisponde al numero di CPU disponibili. A seconda della progettazione dell'applicazione, le query potrebbero richiedere un numero minore di lavoratori per le operazioni parallele. È meglio mantenere lo stesso valore per entrambi i parametri, ma regolare il valore dopo la verifica.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Questo valore controlla il modo in cui PostgreSQL visualizza le letture del disco non sequenziali. Un valore più elevato indica che PostgreSQL è più probabile che utilizzi una scansione sequenziale invece di una scansione di indice, indicando che il server dispone di dischi veloci modificare questa impostazione dopo aver valutato altre opzioni come l'ottimizzazione basata su piano, l'aspirazione, l'indicizzazione per modificare query o schemi.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Questo parametro imposta il numero di operazioni di i/o su disco simultanee che PostgreSQL tenta di eseguire contemporaneamente. L'aumento di questo valore aumenta il numero di operazioni di i/o che una singola sessione PostgreSQL tenta di avviare in parallelo. L'intervallo consentito è compreso tra 1 e 1.000 o zero per disattivare l'emissione di richieste i/o asincrone. Attualmente, questa impostazione influisce solo sulle scansioni bitmap heap. I dischi a stato solido (SSD) e altro storage basato su memoria (NVMe) possono spesso elaborare molte richieste simultanee, cosicché il valore migliore può essere centinaia.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Consultare la documentazione di PostgreSQL per un elenco completo dei parametri di configurazione di PostgreSQL.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">TOAST</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST è l'acronimo di OVERSIZED-Attribute Storage Technique. PostgreSQL utilizza una dimensione di pagina fissa (in genere 8KB) e non consente alle tuple di occupare più pagine. Pertanto, non è possibile memorizzare direttamente valori di campo grandi. Quando si tenta di memorizzare una riga che supera queste dimensioni, TOAST suddivide i dati delle colonne di grandi dimensioni in "pezzi" più piccoli e li memorizza in una tabella TOAST.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">I valori elevati degli attributi tostati vengono estratti (se selezionati) solo quando il set di risultati viene inviato al client. La tabella stessa è molto più piccola e può contenere più righe nella cache buffer condivisa di quanto non possa fare senza alcuna archiviazione out-of-line (TOAST).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VUOTO</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">Nelle normali operazioni PostgreSQL, le tuple eliminate o rese obsolete da un aggiornamento non vengono fisicamente rimosse dalla tabella; rimangono presenti fino all'esecuzione di VACUUM. Pertanto, è necessario eseguire il VUOTO periodicamente, soprattutto nelle tabelle aggiornate di frequente. Lo spazio occupato deve quindi essere recuperato per essere riutilizzato da nuove righe, per evitare di esaurire lo spazio su disco. Tuttavia, non restituisce lo spazio al sistema operativo.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">Lo spazio libero all'interno di una pagina non è frammentato. L'ASPIRAPOLVERE riscrive l'intero blocco, comprimendo in modo efficiente le righe rimanenti e lasciando un singolo blocco contiguo di spazio libero in una pagina.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">Al contrario, VACUUM FULL comprime attivamente le tabelle scrivendo una versione completamente nuova del file di tabella senza spazio morto. Questa azione riduce al minimo le dimensioni della tabella, ma può richiedere molto tempo. Richiede inoltre ulteriore spazio su disco per la nuova copia della tabella fino al completamento dell'operazione. L'obiettivo del VUOTO DI routine è di evitare l'attività di VUOTO PIENO. Questo processo non solo mantiene le tabelle alla loro dimensione minima, ma mantiene anche l'utilizzo costante dello spazio su disco.</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Inizializzazione</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">È possibile creare un nuovo cluster di database utilizzando<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> programma. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script crea i file di dati, le tabelle di sistema e i database dei modelli (template0 e template1) che definiscono il cluster.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">Il database dei modelli rappresenta un database di stock. Contiene le definizioni per le tabelle di sistema, le viste standard, le funzioni e i tipi di dati.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> funge da argomento per il<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script che specifica la posizione del cluster di database.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Tutti gli oggetti di database in PostgreSQL sono gestiti internamente dai rispettivi OID. Le tabelle e gli indici sono inoltre gestiti da singoli OID. Le relazioni tra gli oggetti del database e i rispettivi OID vengono memorizzate in tabelle di cataloghi di sistema appropriate, a seconda del tipo di oggetto. Ad esempio, gli OID dei database e delle tabelle heap vengono memorizzati in<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> e `pg_class, rispettivamente. È possibile determinare gli OID eseguendo query sul client PostgreSQL.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Ogni database ha le proprie tabelle e i file di indice che sono limitati a 1GB. Ogni tabella ha due file associati, rispettivamente con il suffisso<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> e.<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Sono indicate come mappa dello spazio libero e mappa di visibilità. Questi file memorizzano le informazioni sulla capacità di spazio libero e hanno visibilità su ogni pagina del file di tabella. Gli indici hanno solo mappe di spazio libero individuali e non hanno mappe di visibilità.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">Il<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> la directory contiene i registri write-ahead. I registri write-ahead sono utilizzati per migliorare l'affidabilità e le performance del database. Ogni volta che si aggiorna una riga in una tabella, PostgreSQL scrive prima la modifica nel registro write-ahead e successivamente scrive le modifiche alle pagine di dati effettive su un disco. Il<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> la directory di solito contiene diversi file, ma initdb crea solo il primo. I file aggiuntivi vengono aggiunti in base alle necessità. Ciascun file xlog è lungo 16MB MB.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp consiglia* di utilizzare NFSv4,1 se sono necessarie funzionalità NFSv4. Sono stati apportati alcuni miglioramenti funzionali al protocollo NFSv4 di NFSv4,1 che migliorano la resilienza in alcuni casi edge.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">Dimensioni trasferimento NFS</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">SAN FC</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">Architettura PostgreSQL</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL è un RDBMS basato su architettura client e server. Un'istanza di PostgreSQL è nota come cluster di database, ovvero una raccolta di database anziché una raccolta di server.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Errore: Immagine non trovata</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">Un database PostgreSQL contiene tre elementi principali: Il postmaster, il front-end (client) e il back-end Il client invia richieste al postmaster con informazioni quali il protocollo IP e il database a cui connettersi. Il postmaster autentica la connessione e la passa al processo back-end per ulteriori comunicazioni. Il processo back-end esegue la query e invia i risultati direttamente al front-end (client).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Un'istanza PostgreSQL si basa su un modello multiprocesso anziché su un modello multithread. Genera più processi per diversi processi e ogni processo ha una propria funzionalità. I processi principali includono il processo client, il processo di scrittura WAL, il processo di scrittura in background e il processo di checkpointer:</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Quando un processo client (in primo piano) invia richieste di lettura o scrittura all'istanza PostgreSQL, non legge o scrive dati direttamente sul disco. Innanzitutto, memorizza i dati nei buffer condivisi e nei buffer WAL (Write-ahead logging).</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Un processo di scrittura WAL manipola il contenuto dei buffer condivisi e dei buffer WAL da scrivere nei registri WAL. I registri WAL sono in genere registri di transazioni di PostgreSQL e vengono scritti in sequenza. Pertanto, per migliorare i tempi di risposta dal database, PostgreSQL scrive prima nei registri delle transazioni e riconosce il client.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Per impostare il database in uno stato coerente, il processo di scrittura in background verifica periodicamente la presenza di pagine sporche nel buffer condiviso. Quindi, scarica i dati sui file di dati che sono memorizzati su volumi NetApp o LUN.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">Anche il processo checkpointer viene eseguito periodicamente (meno frequentemente del processo in background) e impedisce qualsiasi modifica ai buffer. Segnala al processo di scrittura WAL di scrivere e svuotare il record del punto di verifica alla fine dei registri WAL memorizzati sul disco NetApp. Segnala inoltre al processo di scrittura in background di scrivere e scaricare tutte le pagine sporche sul disco.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Software per la data Protection</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Il plug-in NetApp SnapCenter per i database PostgreSQL, combinato con le tecnologie Snapshot e NetApp FlexClone, offre diversi vantaggi, tra cui:</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Backup e ripristino rapidi.</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Cloni efficienti in termini di spazio.</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">La capacità di creare un sistema di disaster recovery rapido ed efficace.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Potresti preferire scegliere i partner di backup premium di NetApp come Veeam Software e CommVault nelle seguenti circostanze:</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Gestire i carichi di lavoro in un ambiente eterogeneo</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Memorizzazione dei backup su cloud o nastro per una conservazione a lungo termine</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Supporto per un'ampia gamma di versioni e tipi di sistema operativo</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">Il plug-in SnapCenter per PostgreSQL è un plugin supportato dalla comunità e la configurazione e la documentazione sono disponibili nell'archivio automazione di NetApp. Tramite SnapCenter, l'utente può eseguire il backup di database, clonare e ripristinare i dati in remoto.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Soluzioni per SAP HANA e AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA e SAP con AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Le Best practice per la configurazione, la gestione e l'automazione delle soluzioni SAP sono disponibili nella pagina soluzioni SAP di NetApp.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">qui</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Fare clic <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> per saperne di più.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server su ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Disaster recovery per Microsoft SQL Server</block>
  <block id="810304d54e0a61663cfc457b0894037b" category="paragraph">NetApp fornisce vari approcci per aumentare la disponibilità dei dati in caso di guasti hardware, software o del sito.</block>
  <block id="9c1e9d82d3220658621f72dca978adb0" category="section-title">SnapMirror di NetApp</block>
  <block id="46983273062fdc8ce8561a9ce89cdc5b" category="paragraph">La tecnologia SnapMirror di NetApp offre una soluzione aziendale rapida e flessibile per il mirroring o la replica dei dati su LAN e WAN. La tecnologia SnapMirror trasferisce solo i blocchi di dati 4KB modificati alla destinazione dopo il trasferimento di base iniziale, riducendo in modo significativo i requisiti di larghezza di banda di rete. SnapMirror fornisce una replica asincrona a livello di volume basata su un intervallo di aggiornamento della replica configurato.
Di seguito sono riportati alcuni consigli su SnapMirror per SQL Server:</block>
  <block id="5f3bfe8f92842bdc2f9455d4102f2531" category="list-text">In caso di utilizzo di CIFS, la SVM di destinazione deve appartenere allo stesso dominio Active Directory del quale fa parte la SVM di origine, in modo da non interrompere le liste per il controllo degli accessi (ACL) archiviate nei file NAS durante il ripristino in caso di disastro.</block>
  <block id="e0fd410ebdc68e7ca628bbca66b63ff4" category="list-text">L'utilizzo di nomi di volumi di destinazione identici ai nomi di volumi di origine non è necessario, ma può semplificare la gestione del processo di montaggio dei volumi di destinazione nella destinazione. Se viene utilizzato CIFS, occorre rendere identico il namespace NAS di destinazione nei percorsi e nella struttura delle directory al namespace di origine.</block>
  <block id="14b01fb6bdbebef1f8a00c7f84926307" category="list-text">Per motivi di coerenza, non pianificare l'update SnapMirror dai controller. Tuttavia, è possibile attivare l'aggiornamento SnapMirror da SnapCenter per aggiornare SnapMirror al termine del backup completo o del log.</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Distribuire volumi che contengono dati SQL Server tra diversi nodi nel cluster per consentire a tutti i nodi del cluster di condividere l'attività di replica di SnapMirror. Questa distribuzione ottimizza l'utilizzo delle risorse dei nodi.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">TR-4015: Guida alle Best practice e alla configurazione di SnapMirror per ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Per ulteriori informazioni su SnapMirror, vedere <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="3d4b417d78ff0ef4c84f0c043de24b10" category="doc">Sicurezza del database</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">Configurazione CPU</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">Hyperthreading</block>
  <block id="fe520b79816bad6a21fbebcb205c7ca9" category="paragraph">Hyperthreading è l'implementazione proprietaria di Intel della tecnologia SMT (simultaneità multithreading), che migliora la parallelizzazione dei calcoli (multitasking) eseguiti su microprocessori x86.</block>
  <block id="005f484c2235e04f39d2e69256147281" category="paragraph">L'hardware che utilizza l'hyperthreading consente alle CPU iperthread logiche di apparire come CPU fisiche nel sistema operativo. SQL Server rileva quindi le CPU fisiche, che il sistema operativo presenta, e quindi può utilizzare i processori iperthreaded.</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">Si noti che ogni versione di SQL Server presenta dei limiti specifici sulla potenza di calcolo che può utilizzare. Per ulteriori informazioni, vedere limiti di capacità di calcolo per edizione di SQL Server.</block>
  <block id="932a9271c08db114962ce3791480f371" category="paragraph">Le licenze di SQL Server esistono due principali scuole di pensiero. Il primo è noto come modello server + licenza di accesso client (CAL); il secondo è il modello core per processore. Sebbene sia possibile accedere a tutte le funzioni del prodotto disponibili in SQL Server con la strategia server + CAL, esiste un limite hardware di 20 core CPU per socket. Anche se si dispone di SQL Server Enterprise Edition + CAL per un server con più di 20 core di CPU per socket, l'applicazione non può utilizzare tutti questi core alla volta in tale istanza. La figura mostra il messaggio di log di SQL Server dopo l'avvio che indica l'imposizione del limite core.</block>
  <block id="d06fce44fdcf20791141e7585205a477" category="section-title">Le voci del registro indicano il numero di core utilizzati dopo l'avvio di SQL Server.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022: La tua moderna piattaforma per i dati</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Pertanto, per utilizzare tutte le CPU, è necessario utilizzare la licenza core per processore. Per informazioni dettagliate sulle licenze di SQL Server, vedere <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">Affinità della CPU</block>
  <block id="884be48d06a17be095fb51de089dfc89" category="paragraph">È improbabile che sia necessario modificare le impostazioni predefinite di affinità del processore a meno che non si verifichino problemi di prestazioni, ma vale ancora la pena capire cosa sono e come funzionano.</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server supporta l'affinità del processore mediante due opzioni:</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">Maschera di affinità della CPU</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Maschera i/o di affinità</block>
  <block id="14ad08466dec6635067b988a82e91a8e" category="paragraph">SQL Server utilizza tutte le CPU disponibili dal sistema operativo (se si sceglie la licenza core per processore). Crea degli scheduler su tutte le CPU per utilizzare al meglio le risorse per qualsiasi carico di lavoro. Durante il multitasking, il sistema operativo o altre applicazioni sul server possono passare da un processore all'altro. SQL Server è un'applicazione che richiede molte risorse e, in tal caso, può incidere sulle prestazioni. Per ridurre al minimo l'effetto, è possibile configurare i processori in modo che tutto il carico di SQL Server venga indirizzato a un gruppo preselezionato di processori. Ciò si ottiene utilizzando la maschera di affinità della CPU.</block>
  <block id="28a51b601de21080b76fe2d8b2ec8101" category="paragraph">L'opzione maschera i/o affinità associa l'i/o del disco di SQL Server a un sottoinsieme di CPU. Negli ambienti OLTP di SQL Server, questa estensione può migliorare le prestazioni dei thread di SQL Server che emettono operazioni i/O.</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Massimo grado di parallelismo (MAXDOP)</block>
  <block id="f7e9f8e341a301aec4560db108b93020" category="paragraph">Per impostazione predefinita, SQL Server utilizza tutte le CPU disponibili durante l'esecuzione delle query (se si sceglie la licenza core per processore).</block>
  <block id="9bdcdbe52ea41cf96b314b7b7671bd2a" category="paragraph">Anche se è ottimo per le query di grandi dimensioni, può causare problemi di prestazioni e limitare la concorrenza. Un approccio migliore consiste nel limitare il parallelismo al numero di core fisici in un singolo socket CPU. Ad esempio, su un server con due socket CPU fisici con 12 core per socket, indipendentemente dall'hyperthreading, MAXDOP dovrebbe essere impostato su 12. MAXDOP non può limitare o dettare quale CPU utilizzare. Limita invece il numero di CPU che possono essere utilizzate da una singola query batch.</block>
  <block id="1a6b79859b80796a108bd348f98856f6" category="admonition">*NetApp consiglia* per DSS, ad esempio data warehouse, iniziare con questa impostazione a 50 o così e regolare in alto o in basso secondo necessità. Assicurarsi di misurare le query critiche nell'applicazione e apportare le modifiche necessarie.</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Numero massimo di thread di lavoro</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">L'opzione numero massimo di thread di lavoro consente di ottimizzare le prestazioni quando un numero elevato di client è connesso a SQL Server.</block>
  <block id="aefc7f2ee96effbbbe49e6ece6d2f72a" category="paragraph">In genere, per ogni richiesta di query viene creato un thread del sistema operativo separato. Se vengono effettuate centinaia di connessioni simultanee a SQL Server, un thread per richiesta di query consuma grandi quantità di risorse di sistema. L'opzione numero massimo di thread di lavoro consente di migliorare le prestazioni consentendo a SQL Server di creare un pool di thread di lavoro per gestire un numero maggiore di richieste di query.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">Il valore predefinito è 0, che consente a SQL Server di configurare automaticamente il numero di thread di lavoro all'avvio. Funziona per la maggior parte dei sistemi. Max worker Threads è un'opzione avanzata e non deve essere alterata senza l'assistenza di un amministratore di database esperto (DBA).</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">Configurare l'opzione di configurazione del server numero massimo di thread di lavoro</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">Quando è necessario configurare SQL Server per utilizzare più thread di lavoro? Se la lunghezza media della coda di lavoro per ogni pianificatore è superiore a 1, si potrebbe trarre vantaggio dall'aggiunta di più thread al sistema, ma solo se il carico non è legato alla CPU o se si verificano altre attese pesanti. Se si verifica uno di questi due eventi, l'aggiunta di altri thread non aiuta perché sono in attesa di altri colli di bottiglia del sistema. Per ulteriori informazioni sui thread di lavoro max, vedere <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Configurazione di max worker threads con SQL Server Management Studio.</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="doc">File tempdb di Microsoft SQL Server</block>
  <block id="625156cc6cef9a3c56b1b535579bd2c9" category="paragraph">NetApp consiglia di gonfiare in modo proattivo i file tempdb alle dimensioni massime per evitare la frammentazione del disco.</block>
  <block id="ca75041d415f4dafabb49b7f06b634ed" category="paragraph">Il conflitto di pagina può verificarsi su pagine GAM (Lobabotal Allocation Map), SGAM (Shared Global Allocation Map) o PFS (Page Free Space) quando SQL Server deve scrivere in pagine di sistema speciali per allocare nuovi oggetti. I fermi proteggono (bloccano) queste pagine nella memoria. In un'istanza SQL Server occupata, può essere necessario molto tempo per ottenere un blocco in una pagina di sistema in tempdb. Ciò si traduce in tempi di esecuzione delle query più lenti ed è noto come conflitto di latch. Per la creazione di file di dati tempdb, vedere le procedure consigliate riportate di seguito:</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Per &lt; o = a 8 core: File di dati tempdb = numero di core</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Per più di 8 core: 8 file di dati tempdb</block>
  <block id="b9f341e4fb0e6b384aa7ec0b5c33f964" category="paragraph">Lo script di esempio seguente modifica tempdb creando otto file tempdb e spostando tempdb nel punto di montaggio<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> Per SQL Server 2012 e versioni successive.</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">A partire da SQL Server 2016, il numero di core di CPU visibili al sistema operativo viene rilevato automaticamente durante l'installazione e, in base a tale numero, SQL Server calcola e configura il numero di file tempdb necessari per ottenere prestazioni ottimali.</block>
  <block id="1c5b37437282a3648dde78afd914e452" category="doc">Panoramica su Microsoft SQL Server</block>
  <block id="9aa5016539f88d8f1972a16ce9babd34" category="paragraph">SQL Server è la base della piattaforma dati di Microsoft, che offre prestazioni mission-critical con tecnologie in memoria e informazioni più rapide su qualsiasi dato, sia in sede che nel cloud.</block>
  <block id="8133a02d7327679696821fb31b105177" category="paragraph">Microsoft SQL Server si basa sulle funzionalità mission-critical fornite nelle versioni precedenti offrendo prestazioni, disponibilità e gestibilità rivoluzionarie per le applicazioni mission-critical. Il sistema storage è un fattore chiave per le performance complessive di un database SQL Server. NetApp fornisce diversi prodotti per consentire al database SQL Server di offrire prestazioni di livello Enterprise fornendo strumenti di livello mondiale per la gestione dell'ambiente.</block>
  <block id="0bdfc026961d516d3d473152b4b6a87e" category="section-title">Scopo e ambito di applicazione</block>
  <block id="d0554e23b25bb82082a0cd9eaf810d0f" category="paragraph">Questa sezione descrive le Best practice e offre approfondimenti sulle considerazioni di progettazione per la distribuzione di SQL Server su sistemi di storage NetApp che eseguono il software NetApp ONTAP, con l'obiettivo di ottenere una distribuzione di storage efficace ed efficiente e una pianificazione end-to-end della protezione e della conservazione dei dati. L'ambito di questa guida si limita alle linee guida tecniche di progettazione basate sui principi di progettazione e sugli standard preferiti che NetApp consiglia per l'infrastruttura di storage durante la distribuzione di SQL Server. L'attuazione end-to-end non rientra nell'ambito della presente relazione.</block>
  <block id="cf4cab9c6fd24025b34dfcae06e9b6fc" category="paragraph">Le Best practice e i consigli descritti in questa guida consentono agli architetti SQL Server e agli amministratori dello storage NetApp di pianificare un ambiente SQL Server altamente disponibile e facile da gestire e di rispettare SLA rigorosi. NetApp presuppone che il lettore disponga delle seguenti conoscenze operative:</block>
  <block id="9801f873fe2232da0de3cbab00483bfb" category="list-text">Software NetApp ONTAP</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter come software di backup, che include:</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Plug-in SnapCenter per Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">Plug-in di SnapCenter per SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Architettura e amministrazione di Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">Tool di matrice di interoperabilità NetApp (IMT)</block>
  <block id="c02eaaaf0eed9e51c3a9e1e9ae8b9147" category="paragraph">Per informazioni sulla compatibilità della configurazione nello stack NetApp, consultare la <block ref="ea0e6fe442c1f7a042a8853ffcc2b382" category="inline-link-macro-rx"></block>.</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Considerazioni sullo storage per Microsoft SQL Server</block>
  <block id="8c2a9e7195a263b5d79d397f5c6a9f68" category="paragraph">La combinazione delle soluzioni storage NetApp e Microsoft SQL Server consente di creare design di storage per database di livello Enterprise in grado di soddisfare le più esigenti esigenze applicative odierne.</block>
  <block id="8136e237a15b0f72e5d7a60392225d17" category="paragraph">Per ottimizzare entrambe le tecnologie, è fondamentale comprendere lo schema e le caratteristiche di i/o di SQL Server. Un layout di storage ben progettato per un database SQL Server supporta le performance di SQL Server e la gestione dell'infrastruttura SQL Server. Un buon layout dello storage permette inoltre di avere successo nell'implementazione iniziale e di far crescere l'ambiente senza problemi nel tempo, con il crescere dell'azienda.</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Progettazione dello storage dei dati</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Per i database SQL Server che non utilizzano SnapCenter per eseguire i backup, Microsoft consiglia di posizionare i file di dati e di log su dischi separati. Per le applicazioni che aggiornano e richiedono contemporaneamente i dati, il file di log è intensivo in scrittura e il file di dati (a seconda dell'applicazione) è intensivo in lettura/scrittura. Per il recupero dei dati, il file di log non è necessario. Pertanto, le richieste di dati possono essere soddisfatte dal file di dati posto sul proprio disco.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Posizionare i file di dati e di registro su unità separate</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Quando si crea un nuovo database, Microsoft consiglia di specificare unità separate per i dati e i registri. Per spostare i file dopo la creazione del database, il database deve essere portato offline. Per ulteriori consigli Microsoft, vedere <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">Aggregati</block>
  <block id="b8212b86fca1dcaeb0438529a03212c3" category="paragraph">Gli aggregati sono i container di storage primari per le configurazioni di storage NetApp e contengono uno o più gruppi RAID costituiti da dischi di dati e dischi di parità. NetApp ha eseguito diverse prove di caratterizzazione dei carichi di lavoro i/o utilizzando aggregati condivisi e dedicati con file di dati e file di log delle transazioni separati. I test dimostrano che un aggregato di grandi dimensioni con più gruppi RAID e spindle ottimizza e migliora le performance dello storage ed è più semplice da gestire per due motivi:</block>
  <block id="5f9196be7c85ebe3a38375ace1f3a345" category="list-text">Un unico aggregato di grandi dimensioni rende disponibili per tutti i file le funzionalità di i/o di tutti gli spindle.</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Un grande aggregato consente l'utilizzo più efficiente dello spazio su disco.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Per l'high Availability (ha), posiziona la replica sincrona secondaria di SQL Server Always on Availability Group su una Storage Virtual Machine (SVM) separata nell'aggregato. Per scopi di disaster recovery, posizionare la replica asincrona in un aggregato che fa parte di un cluster di storage separato nel sito di disaster recovery, con contenuto replicato utilizzando la tecnologia NetApp SnapMirror. NetApp consiglia di disporre di almeno il 10% di spazio libero in un aggregato per ottenere performance dello storage ottimali.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volumi</block>
  <block id="5ec65e803efce0f0779c59e4df9b2a71" category="paragraph">I volumi NetApp FlexVol vengono creati e risiedono all'interno degli aggregati. È possibile creare diversi volumi in un singolo aggregato ed è possibile espandere, ridurre o spostare ciascun volume fra gli aggregati senza downtime per gli utenti.</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Considerazioni sulla progettazione dei volumi</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Prima di creare una progettazione di volumi di database, è importante comprendere in che modo il modello i/o di SQL Server e le relative caratteristiche variano in base al carico di lavoro e ai requisiti di backup e ripristino. Consulta i seguenti consigli NetApp per i volumi flessibili:</block>
  <block id="570f1006846b0d45ff44b4332b9b4d14" category="list-text">Utilizzare volumi flessibili per archiviare i file di database di SQL Server ed evitare la condivisione di volumi tra host.</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Utilizzare i punti di montaggio NTFS invece delle lettere dell'unità per superare il limite di 26 lettere di unità in Windows. Quando si utilizzano punti di montaggio del volume, si consiglia di assegnare all'etichetta del volume lo stesso nome del punto di montaggio.</block>
  <block id="d5fe4f7f1c47df1ec78c926d21498f73" category="list-text">Se necessario, configurare un criterio di dimensionamento automatico dei volumi per evitare condizioni di spazio insufficiente. 17 Guida alle Best practice per Microsoft SQL Server con ONTAP © 2022 NetApp, Inc Tutti i diritti riservati.</block>
  <block id="fdb3a973962ea77cf56d76e12cff8c7d" category="list-text">Abilitare la riallocazione in lettura sul volume quando il profilo di i/o del database di SQL Server è costituito per lo più da letture sequenziali di grandi dimensioni, ad esempio con carichi di lavoro del sistema di supporto decisionale. La riallocazione in lettura ottimizza i blocchi per fornire performance migliori.</block>
  <block id="3a9320cf27fb328f77ec6153273784d5" category="list-text">Se si installa SQL Server su una condivisione SMB, assicurarsi che Unicode sia attivato sui volumi SMB/CIFS per la creazione delle cartelle.</block>
  <block id="08a6901e4e7b04d6170563bc57864093" category="list-text">Impostare il valore di riserva delle copie Snapshot di NetApp nel volume a zero per semplificare il monitoraggio dal punto di vista operativo.</block>
  <block id="156ce9adf6c474183396aa3cfb8f92f1" category="list-text">Disattivare le pianificazioni delle copie Snapshot™ di archiviazione e i criteri di conservazione. Utilizzare invece SnapCenter per coordinare le copie Snapshot dei volumi di dati di SQL Server.</block>
  <block id="f2e00c12259a4bb11608f2a12fc8014a" category="list-text">Posizionamento dei database di sistema di SQL Server su un volume dedicato o VMDK.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb è un database di sistema utilizzato da SQL Server come area di lavoro temporanea, in particolare per operazioni DBCC CHECKDB i/o intensive. Pertanto, collocare questo database su un volume dedicato con un set separato di spindle. In ambienti di grandi dimensioni in cui il numero di volumi rappresenta una sfida, è possibile consolidare il tempdb in un numero inferiore di volumi e memorizzarlo nello stesso volume degli altri database di sistema dopo un'attenta pianificazione. La protezione dei dati per tempdb non è una priorità elevata perché questo database viene ricreato ogni volta che SQL Server viene riavviato.</block>
  <block id="57eda1aa66778bf3c77caa0294652ba8" category="list-text">Posizionare i file di dati utente (.mdf) su volumi separati perché si tratta di carichi di lavoro di lettura/scrittura casuali. È comune creare backup del log delle transazioni con maggiore frequenza rispetto ai backup del database. Per questo motivo, collocare i file di log delle transazioni (.ldf) in un volume separato o VMDK dai file di dati in modo che sia possibile creare pianificazioni di backup indipendenti per ciascuno di essi. Questa separazione isola inoltre l'i/o di scrittura sequenziale dei file di log dall'i/o di lettura/scrittura casuale dei file di dati e migliora significativamente le prestazioni di SQL Server.</block>
  <block id="b26e74ed6e2892c7e2bb95e414d460c6" category="section-title">LUN</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Assicurarsi che i file del database utente e la directory di registro per l'archiviazione del backup del registro si trovino su volumi separati per evitare che il criterio di conservazione sovrascriva gli snapshot quando vengono utilizzati con la tecnologia SnapVault.</block>
  <block id="152bb9192ea87919eda3b4f97fd4e1bf" category="list-text">Accertarsi che i database di SQL Server risiedano in LUN separate da LUN che dispongono di file non di database, come i file relativi alla ricerca full-text.</block>
  <block id="e2faf723544ceb1ea01ba41cef2d633a" category="list-text">L'inserimento di file secondari del database (come parte di un filegroup) in volumi separati migliora le prestazioni del database di SQL Server. Questa separazione è valida solo se il file .mdf del database non condivide il proprio LUN con altri file .mdf.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Se si creano LUN con DiskManager o altri strumenti, assicurarsi che la dimensione dell'unità di allocazione sia impostata su 64K per le partizioni durante la formattazione dei LUN.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows e MPIO nativo nelle Best practice ONTAP per le SAN moderne</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Vedere <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Per applicare il supporto multipathing in Windows ai dispositivi iSCSI nelle proprietà MPIO.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Directory di log</block>
  <block id="973781a026becacffaae9fd5fd5c2b7b" category="paragraph">La directory di registro è specificata in SQL Server per archiviare i dati di backup del registro delle transazioni a livello di host. Se si utilizza SnapCenter per eseguire il backup dei file di registro, ciascun host SQL Server utilizzato da SnapCenter deve disporre di una directory di registro host configurata per eseguire i backup dei registri. SnapCenter dispone di un repository di database, pertanto i metadati relativi alle operazioni di backup, ripristino o clonazione vengono memorizzati in un repository di database centrale.</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">Le dimensioni della directory del registro host vengono calcolate come segue:
Dimensione della directory del log host = ( (dimensione massima LDF DB x velocità di modifica giornaliera del log %) x (conservazione snapshot) ÷ (1 - spazio di overhead LUN %)
La formula di dimensionamento della directory del registro host presuppone uno spazio di overhead LUN del 10%</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Posizionare la directory di registro su un volume o LUN dedicato. La quantità di dati nella directory del registro host dipende dalle dimensioni dei backup e dal numero di giorni in cui i backup vengono conservati. SnapCenter consente una sola directory di registro host per host SQL Server. È possibile configurare le directory del registro host in SnapCenter --&gt; host --&gt; Configura plug-in.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp consiglia* quanto segue per una directory del registro host:</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Assicurarsi che la directory del registro host non sia condivisa da altri tipi di dati che potrebbero danneggiare i dati dello snapshot di backup.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">Non posizionare database utente o database di sistema su un LUN che ospita punti di montaggio.</block>
  <block id="bdfdf6f1492d7a7beac0bce2c4109f95" category="list-text">Creare la directory di log dell'host sul volume FlexVol dedicato a cui SnapCenter copia i registri delle transazioni.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Utilizzare le procedure guidate SnapCenter per migrare i database nello storage NetApp in modo che i database vengano memorizzati in posizioni valide, consentendo operazioni di backup e ripristino SnapCenter corrette. Tenere presente che il processo di migrazione causa interruzioni e può causare la disconnessione dei database mentre è in corso la migrazione.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Per le istanze di cluster di failover (FCI) di SQL Server devono essere presenti le seguenti condizioni:</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Se si utilizza un'istanza del cluster di failover, il LUN della directory del log host deve essere una risorsa del disco del cluster nello stesso gruppo di cluster dell'istanza di SQL Server di cui viene eseguito il backup in SnapCenter.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Se si utilizza un'istanza cluster di failover, i database utente devono essere collocati su LUN condivisi che sono risorse cluster di dischi fisici assegnate al gruppo di cluster associato all'istanza di SQL Server.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Configurazione della memoria di Microsoft SQL Server</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Memoria massima del server</block>
  <block id="81dbc262a15fc545920141998ddd1c17" category="paragraph">L'opzione memoria massima del server imposta la quantità massima di memoria che l'istanza di SQL Server può utilizzare.</block>
  <block id="c9fa383209ffc05f20049101298fec96" category="paragraph">Viene generalmente utilizzata se più applicazioni vengono eseguite sullo stesso server in cui SQL Server è in esecuzione e si desidera garantire che queste applicazioni dispongano di memoria sufficiente per funzionare correttamente.</block>
  <block id="1ceeb5f5f18aefbc39e34d0d3c7b7e1c" category="paragraph">Alcune applicazioni utilizzano solo la memoria disponibile all'avvio e non richiedono altro, anche se necessario. È qui che entra in gioco l'impostazione della memoria massima del server.</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">In un cluster SQL Server con diverse istanze SQL Server, ciascuna istanza potrebbe competere per le risorse. L'impostazione di un limite di memoria per ciascuna istanza di SQL Server può contribuire a garantire le migliori prestazioni per ciascuna istanza.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp consiglia* di lasciare almeno 4GB o 6GB GB di RAM per il sistema operativo per evitare problemi di prestazioni.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Regolazione della memoria minima e massima del server mediante SQL Server Management Studio.</block>
  <block id="2e0d4de7d927936246f5537ba48015d2" category="paragraph">L'utilizzo di SQL Server Management Studio per regolare la memoria minima o massima del server richiede il riavvio del servizio SQL Server. È possibile regolare la memoria del server utilizzando Transact SQL (T-SQL) utilizzando il seguente codice:</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Accesso alla memoria non uniforme</block>
  <block id="d92030bf70ac1cf1da30ce4c9ab2bbf6" category="paragraph">L'accesso alla memoria non uniforme (NUMA, non Uniform Memory Access) è un metodo di ottimizzazione dell'accesso alla memoria che consente di aumentare la velocità del processore senza aumentare il carico sul bus del processore.</block>
  <block id="6ef102e61df24a50b0119558432f5623" category="paragraph">Se NUMA è configurato sul server su cui è installato SQL Server, non è necessaria alcuna configurazione aggiuntiva perché SQL Server è compatibile con NUMA e funziona bene sull'hardware NUMA.</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Indice creare memoria</block>
  <block id="8e7c0153e4b7aa851a5a62683c378d1c" category="paragraph">L'opzione di creazione della memoria di indice è un'altra opzione avanzata che solitamente non si dovrebbe modificare.</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Controlla la quantità massima di RAM inizialmente allocata per la creazione degli indici. Il valore predefinito per questa opzione è 0, il che significa che è gestita automaticamente da SQL Server. Tuttavia, se si riscontrano difficoltà nella creazione degli indici, è consigliabile aumentare il valore di questa opzione.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Memoria minima per query</block>
  <block id="027d5a3eabe88aa0ab705b9c4a2fe096" category="paragraph">Quando viene eseguita una query, SQL Server tenta di allocare la quantità di memoria ottimale per un'esecuzione efficiente.</block>
  <block id="4c7836a7e63c3ecb3f6860ec19643561" category="paragraph">Per impostazione predefinita, l'impostazione memoria minima per query assegna &gt; o = a 1024KB per ogni query da eseguire. È consigliabile lasciare questa impostazione al valore predefinito 0 per consentire a SQL Server di gestire dinamicamente la quantità di memoria allocata per le operazioni di creazione dell'indice. Tuttavia, se SQL Server dispone di una quantità di RAM superiore a quella necessaria per un'esecuzione efficiente, le prestazioni di alcune query possono essere migliorate se si aumenta questa impostazione. Pertanto, se sul server non viene utilizzata SQL Server, altre applicazioni o il sistema operativo è disponibile memoria, il miglioramento di questa impostazione può contribuire alle prestazioni complessive di SQL Server. Se non è disponibile memoria libera, l'aumento di questa impostazione potrebbe compromettere le prestazioni complessive.</block>
  <block id="d2a88da9a0fcc96168f8f051909d5599" category="section-title">Estensioni del pool di buffer</block>
  <block id="11a3fdcfeb0715eaf26e855034f6ab9a" category="paragraph">L'estensione del pool di buffer consente l'integrazione perfetta di un'estensione NVRAM con il pool di buffer del motore di database per migliorare significativamente la velocità i/O.</block>
  <block id="c722da593d2f37b2c1ffc91a10c03dad" category="paragraph">L'estensione del pool di buffer non è disponibile in ogni edizione di SQL Server. È disponibile solo con le edizioni SQL Server Standard, Business Intelligence ed Enterprise a 64 bit.</block>
  <block id="df07548a7c164cbe93b68c4cbebbdcf8" category="paragraph">La funzione di estensione del pool di buffer estende la cache del pool di buffer con lo storage non volatile (generalmente SSD). L'estensione consente al pool di buffer di ospitare un working set di database più grande, forzando il paging dell'i/o tra la RAM e gli SSD e trasferendo efficacemente i/o casuali di piccole dimensioni dai dischi meccanici agli SSD. Grazie alla minore latenza e alle migliori prestazioni i/o random degli SSD, l'estensione del pool di buffer migliora significativamente l'elaborazione i/O.</block>
  <block id="54af95ef673718e2f8bf1cc873d8b3ce" category="paragraph">La funzione di estensione del pool di buffer offre i seguenti vantaggi:</block>
  <block id="2c250b49dc6705e6d219cf2bf8d50bc5" category="list-text">Maggiore throughput i/o casuale</block>
  <block id="93dce890e8c62b3a651edb9098201e58" category="list-text">Latenza i/o ridotta</block>
  <block id="d7e49f79c1b78c9ead1e9541d2160307" category="list-text">Aumento del throughput delle transazioni</block>
  <block id="6643befb3c9dc2fbb68fe1107fe24842" category="list-text">Migliori performance di lettura con un pool di buffer ibridi più ampio</block>
  <block id="6609220b8670ffd627a3663b3beef46b" category="list-text">Architettura di caching che consente di sfruttare la memoria a basso costo esistente e futura</block>
  <block id="471bda18bb94c589b421edccb0e402fe" category="paragraph">*NetApp consiglia* di configurare le estensioni del pool di buffer in modo da:</block>
  <block id="12810c53d2afa05bd2a75aa3c0c55592" category="list-text">Verificare che un LUN con supporto SSD (ad esempio NetApp AFF) venga presentato all'host SQL Server in modo che possa essere utilizzato come disco di destinazione dell'estensione del pool di buffer.</block>
  <block id="824cfa1576a82f89ee0af13fb9f086dc" category="list-text">Il file di estensione deve avere la stessa dimensione del pool di buffer o essere più grande.</block>
  <block id="c7e0d87e723625072015431887edf349" category="paragraph">Nell'esempio seguente viene illustrato un comando T-SQL per impostare un'estensione del pool di buffer di 32GB.</block>
  <block id="7ef20d2374bc8b734222e4ec2f0f3643" category="doc">Efficienza dello storage ONTAP con Microsoft SQL Server</block>
  <block id="e5bc122522e9ae1409590d9944ec4421" category="paragraph">L'efficienza dello storage è la capacità di archiviare e gestire i dati di SQL Server in modo che consumano la minor quantità di spazio di storage con effetti minimi o nulli sulle performance complessive del sistema.</block>
  <block id="2d3c9d6f03cd640c224f5daf9c2352b0" category="paragraph">SQL Server dispone inoltre di funzionalità per comprimere e gestire in modo efficiente i dati. Attualmente SQL Server supporta due tipi di compressione dati: Compressione riga e compressione pagina.</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Implementazione della compressione pagina</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">La compressione riga modifica il formato di memorizzazione dei dati. Ad esempio, cambia interi e decimali nel formato a lunghezza variabile invece del formato a lunghezza fissa nativo. Inoltre, le stringhe di caratteri a lunghezza fissa vengono modificate nel formato a lunghezza variabile eliminando gli spazi vuoti. La compressione della pagina implementa la compressione della riga e altre due strategie di compressione (compressione del prefisso e compressione del dizionario). Per ulteriori dettagli sulla compressione delle pagine, consultare <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">La compressione dei dati è attualmente supportata nelle edizioni Enterprise, Developer e Evaluation di SQL Server 2008 e versioni successive. Sebbene la compressione possa essere eseguita dal database stesso, ciò si verifica raramente in un ambiente SQL Server.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Di seguito sono riportati i suggerimenti per la gestione dello spazio per i file di dati di SQL Server</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Utilizzo del thin provisioning negli ambienti SQL Server per migliorare l'utilizzo dello spazio e ridurre i requisiti generali di storage quando viene utilizzata la funzionalità di garanzia di spazio.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Utilizza l'espansione automatica per la maggior parte delle configurazioni di implementazione più comuni, perché l'amministratore dello storage deve solo monitorare l'utilizzo dello spazio nell'aggregato.</block>
  <block id="13a233d96ce19e7530391105360d749b" category="list-text">Si consiglia di non abilitare la deduplica su qualsiasi volume contenente file di dati di SQL Server a meno che non sia noto che il volume contiene più copie degli stessi dati, come ad esempio il ripristino del database dai backup su un singolo volume.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Bonifica dello spazio</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">Il recupero di spazio può essere avviato periodicamente per recuperare spazio inutilizzato in un LUN. Con SnapCenter, puoi usare il seguente comando PowerShell per iniziare il recupero dello spazio.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Se è necessario eseguire il recupero di spazio, questo processo deve essere eseguito durante i periodi di attività bassa, poiché inizialmente consuma cicli sull'host.</block>
  <block id="a356c94dff23a233551ff221e74a144d" category="summary">Data Protection di Microsoft SQL Server con ONTAP</block>
  <block id="731c00fe6475fb22aece82ffa9d74ef3" category="paragraph">Proteggere il database è fondamentale per qualsiasi organizzazione. Con l'aumento delle dimensioni e del numero dei dati dei database, il mantenimento degli obiettivi RTO (Recovery Time Objective) e RPO (Recovery Point Objective) è fondamentale.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="2ddb1872f6c378e74cb7269e9de4c4e5" category="paragraph">SnapCenter è il software di protezione dei dati NetApp per le applicazioni aziendali. I database di SQL Server possono essere protetti in modo rapido e semplice utilizzando il software NetApp SnapCenter con il plug-in per SQL Server e il plug-in per Microsoft Windows.</block>
  <block id="bdc6c0cf646d837838203c2980eba84a" category="paragraph">Questi prodotti consentono il backup coerente con le applicazioni, il cloning automatizzato e il ripristino di database, istanze o gruppi di disponibilità di SQL Server.</block>
  <block id="2450e19674db2a865555d3c04563e647" category="admonition">*NetApp recommended* Using SnapCenter to create Snapshot copy.</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">TR-4714: Guida alle Best practice per SQL Server con NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Per ulteriori informazioni sul plug-in di SQL Server per SnapCenter, vedere <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Protezione del database mediante snapshot T-SQL</block>
  <block id="e158e137ead13fd14e064b875e45df20" category="paragraph">In SQL Server 2022, Microsoft ha introdotto le istantanee T-SQL che offrono vantaggi integrati rispetto al metodo tradizionale che non è stato facilmente utilizzato dall'amministratore del database. Sfruttando le API REST di ONTAP, puoi chiamare comandi per creare snapshot sui volumi.</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">Di seguito è riportato un esempio di flusso di lavoro di backup:</block>
  <block id="17884d5a1cfc06145e718a49c8d6ac66" category="list-text">Blocco di un database con il comando ALTER - consente di eseguire uno snapshot coerente sullo storage sottostante. Dopo di che è possibile scongelare il database e registrare lo snapshot con il comando di BACKUP.</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Eseguire snapshot di più database sui volumi di storage contemporaneamente con il nuovo GRUPPO DI BACKUP e i comandi DEL SERVER DI BACKUP.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Eseguire backup COMPLETI o backup COMPLETI COPY_ONLY. Anche questi backup sono registrati in msdb.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Eseguire il recovery point-in-time utilizzando i backup di log eseguiti con il normale approccio di streaming dopo il backup COMPLETO delle snapshot. Se lo si desidera, sono supportati anche i backup differenziali in streaming.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Documentazione Microsoft per conoscere le istantanee T-SQL</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Per ulteriori informazioni, vedere <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Workload di Microsoft SQL Server</block>
  <block id="764e07fc8f1f5e2d1b9fc63f83b88cbd" category="paragraph">La piattaforma di database SQL Server supporta molte applicazioni.</block>
  <block id="25343e3363b414e89943f5a4e46f51ad" category="paragraph">Prima di distribuire SQL Server, è necessario comprendere i requisiti del carico di lavoro del database delle applicazioni supportate dalle istanze di SQL Server. Ogni applicazione ha requisiti differenti in termini di capacità, performance e disponibilità, per cui ogni database dovrebbe essere progettato per supportare al meglio tali requisiti. Molte organizzazioni classificano i database in più Tier di gestione, utilizzando i requisiti delle applicazioni per definire gli SLA. I carichi di lavoro di SQL Server possono essere descritti come segue:</block>
  <block id="c6a1c5843ff7b078079edf24beeea746" category="list-text">I database OLTP sono spesso anche i database più critici di un'organizzazione. In genere, questi database supportano le applicazioni rivolte ai clienti e sono considerati essenziali per le operazioni chiave dell'azienda. I database OLTP mission-critical e le applicazioni che questi supportano spesso hanno SLA che richiedono elevati livelli di performance e sono sensibili al peggioramento delle performance e alla disponibilità. Potrebbero anche essere candidati per cluster di failover sempre attivi o gruppi di disponibilità sempre attivi. La combinazione di i/o di questi tipi di database è in genere caratterizzata da un tasso di random Read compreso tra il 75% e il 90% e un tasso di scrittura compreso tra il 25% e il 10%.</block>
  <block id="96d864d235bcd68e1ef22c2c49aef352" category="list-text">I database DSS (Decision Support System) possono anche essere definiti data warehouse. Questi database sono mission-critical in molte organizzazioni che si affidano alle analytics per il loro business. Questi database sono sensibili all'utilizzo della CPU e alle operazioni di lettura dal disco quando vengono eseguite query. In molte organizzazioni, i database DSS sono i più critici durante la fine di mese, trimestre e anno Questo carico di lavoro solitamente presenta una combinazione di i/o di lettura al 100%.</block>
  <block id="da02a82356735ded82f6661108abe7ef" category="section-title">Analisi comparativa</block>
  <block id="b9a9b34816c2e5ebaecb45f376b52bc3" category="paragraph">Il Transaction Process Council (TPC) è una società no profit fondata per definire l'elaborazione delle transazioni e i benchmark dei database e per diffondere al settore dati sulle prestazioni TPC oggettivi e verificabili. I test TPC simulano ambienti di calcolo completi in cui una popolazione di utenti esegue transazioni su database.</block>
  <block id="427af860f9733f0c5427a1408195bb2b" category="cell">Tipo di carico di lavoro</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="cell">Scenario</block>
  <block id="b130fcf8f0704ab887b72883b1eda2fa" category="cell">Rapporto lettura/scrittura (percentuali)</block>
  <block id="3edb9cc3b98f151feb21dbde6323e82a" category="cell">OLTP</block>
  <block id="69e16af975a283d07a422bdbcc70aa33" category="cell">TPC-C</block>
  <block id="b1e04731135df8a16c5318612ec8654e" category="cell">Circa 75/25 MB</block>
  <block id="106ff1baff5c32dc414f262e0a710c54" category="cell">TPC-E</block>
  <block id="48e219d97cf4619f212471bafd4215ec" category="cell">Circa 90/10 MB</block>
  <block id="e71f0182ed04206cb78bd7ceb2d9f4f3" category="cell">DSS</block>
  <block id="5788057170990ecf5e4d921f2853c2ae" category="cell">TPC-H.</block>
  <block id="492d66c3da61bdb9c69261aa1aa6f5f9" category="cell">Circa 100/0 MB</block>
  <block id="0737ef89fbed16c79fadf3568aad6ba0" category="inline-link-macro">HammerDB.com</block>
  <block id="45e5ae4569fb8a91cd5513654f31b764" category="paragraph">Sebbene siano disponibili diverse opzioni di generazione di workload, in genere ci dedichiamo alla misurazione delle performance dei database SQL Server nella gestione dei carichi di lavoro transazionali e utilizziamo i tool TPC-e di Microsoft o TPC-H tramite HammerDB (<block ref="af66be8e0834614cdd62ca4f34bc61ec" category="inline-link-macro-rx"></block>^). Le istruzioni dettagliate su come utilizzare questi benchmark specifici esulano dall'ambito di questo documento.</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">File di database e filegroup di Microsoft SQL Server</block>
  <block id="381c0738613a6b6a27d1c14f223e99ba" category="paragraph">Un database SQL Server è un insieme di oggetti che consente di memorizzare e manipolare i dati.</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">In teoria, SQL Server (a 64 bit) supporta 32.767 database per istanza e 524.272TB di dimensioni del database, sebbene l'installazione tipica abbia in genere diversi database. Tuttavia, il numero di database che SQL Server è in grado di gestire dipende dal carico e dall'hardware. Non è insolito vedere le istanze di SQL Server che ospitano decine, centinaia o persino migliaia di database di piccole dimensioni.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Ogni database è costituito da uno o più file di dati e da uno o più file di registro delle transazioni. Il registro delle transazioni memorizza le informazioni sulle transazioni del database e tutte le modifiche apportate ai dati da ciascuna sessione. Ogni volta che i dati vengono modificati, SQL Server memorizza informazioni sufficienti nel log delle transazioni per annullare (eseguire il rollback) o ripristinare (riprodurre nuovamente) l'azione. Un log delle transazioni di SQL Server è parte integrante della reputazione di SQL Server in termini di integrità e robustezza dei dati. Il log delle transazioni è fondamentale per le funzionalità di atomicità, coerenza, isolamento e durata (ACID) di SQL Server. SQL Server scrive nel registro delle transazioni non appena si verifica una modifica alla pagina dei dati. Ogni istruzione DML (Data Manipulation Language) (ad esempio, SELECT, INSERT, Update o DELETE) è una transazione completa e il log delle transazioni garantisce che l'intera operazione basata su set abbia luogo, assicurando l'atomicità della transazione.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Ogni database dispone di un file di dati primario che, per impostazione predefinita, ha l'estensione .mdf. Inoltre, ogni database può disporre di file di database secondari. Questi file, per impostazione predefinita, hanno estensioni .ndf.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Tutti i file di database sono raggruppati in filegroup. Un filegroup è l'unità logica, che semplifica l'amministrazione del database. Consentono la separazione tra il posizionamento degli oggetti logici e i file di database fisici. Quando si creano le tabelle degli oggetti del database, si specifica in quale filegroup devono essere posizionati senza preoccuparsi della configurazione del file di dati sottostante.</block>
  <block id="3717596742d438a1c8e77b0aeb58fcec" category="paragraph">La possibilità di inserire più file di dati all'interno del filegroup consente di distribuire il carico su diversi dispositivi di archiviazione, migliorando le prestazioni di i/o del sistema. Al contrario, il log delle transazioni non trae vantaggio dai file multipli poiché SQL Server scrive nel log delle transazioni in modo sequenziale.</block>
  <block id="c136ffb510a6a465d338ab0affc16641" category="paragraph">La separazione tra il posizionamento degli oggetti logici nei filegroup e i file di database fisici consente di ottimizzare il layout dei file di database, ottenendo il massimo dal sottosistema di storage. Ad esempio, i fornitori di software indipendenti (ISV) che distribuiscono i propri prodotti a clienti diversi possono regolare il numero di file di database in base alla configurazione i/o sottostante e alla quantità prevista di dati durante la fase di implementazione. Tali modifiche sono trasparenti per gli sviluppatori di applicazioni, che posizionano gli oggetti database nei filegroup anziché nei file di database.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp recommended* evitare l'utilizzo del filegroup primario per oggetti diversi da quelli di sistema. La creazione di un filegroup separato o di un set di filegroup per gli oggetti utente semplifica l'amministrazione del database e il ripristino di emergenza, soprattutto nel caso di database di grandi dimensioni.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">È possibile specificare le dimensioni iniziali del file e i parametri di crescita automatica al momento della creazione del database o dell'aggiunta di nuovi file a un database esistente. SQL Server utilizza un algoritmo di riempimento proporzionale quando sceglie in quale file di dati scrivere i dati. Scrive una quantità di dati proporzionalmente allo spazio libero disponibile nei file. Maggiore è lo spazio libero nel file, maggiore è il numero di scritture gestite.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp consiglia* che tutti i file nel singolo filegroup abbiano le stesse dimensioni iniziali e parametri di crescita automatica, con la dimensione di crescita definita in megabyte piuttosto che in percentuali. Questo aiuta l'algoritmo di riempimento proporzionale a bilanciare uniformemente le attività di scrittura nei file di dati.</block>
  <block id="a39d73055b8dbbe112e749e7c3ededb8" category="paragraph">Ogni volta che SQL Server espande i file, riempie di zero lo spazio appena allocato nei file. Questo processo blocca tutte le sessioni che devono scrivere nel file corrispondente o, in caso di crescita del log delle transazioni, genera record di log delle transazioni.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server azzera sempre il log delle transazioni e questo comportamento non può essere modificato. Tuttavia, è possibile controllare se i file di dati vengono azzerati attivando o disattivando l'inizializzazione istantanea dei file. L'attivazione dell'inizializzazione immediata dei file consente di velocizzare la crescita dei file di dati e di ridurre il tempo necessario per creare o ripristinare il database.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Un piccolo rischio per la sicurezza è associato all'inizializzazione immediata dei file. Quando questa opzione è attivata, le parti non allocate del file di dati possono contenere informazioni provenienti da file del sistema operativo eliminati in precedenza. Gli amministratori di database possono esaminare tali dati.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">È possibile attivare l'inizializzazione immediata dei file aggiungendo l'autorizzazione SA_MANAGE_VOLUME_NAME, nota anche come "Esegui attività di manutenzione del volume" all'account di avvio di SQL Server. È possibile eseguire questa operazione nell'applicazione di gestione dei criteri di protezione locale (secpol.msc), come illustrato nella figura seguente. Aprire le proprietà per l'autorizzazione "Esegui attività di manutenzione del volume" e aggiungere l'account di avvio di SQL Server all'elenco degli utenti.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Per verificare se l'autorizzazione è attivata, è possibile utilizzare il codice riportato nell'esempio seguente. Questo codice imposta due flag di traccia che obbligano SQL Server a scrivere informazioni aggiuntive nel registro degli errori, a creare un database di piccole dimensioni e a leggere il contenuto del registro.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Quando l'inizializzazione immediata del file non è attivata, il registro degli errori di SQL Server mostra che SQL Server sta azzerando il file di dati mdf oltre a azzerare il file di registro ldf, come illustrato nell'esempio seguente. Quando l'inizializzazione immediata del file è attivata, viene visualizzato solo l'azzeramento del file di registro.</block>
  <block id="cf346325be0652c6b6e9a04b9352bda3" category="paragraph">L'attività di manutenzione del volume viene semplificata in SQL Server 2016 e viene fornita come opzione durante il processo di installazione. In questa figura viene visualizzata l'opzione per concedere al servizio del motore di database di SQL Server il privilegio di eseguire l'attività di manutenzione del volume.</block>
  <block id="638b283700120d26a838f9cb56fca59d" category="paragraph">Un'altra importante opzione del database che controlla le dimensioni dei file di database è l'autohrink. Quando questa opzione è attivata, SQL Server riduce regolarmente i file di database, ne riduce le dimensioni e rilascia spazio al sistema operativo. Questa operazione richiede molte risorse ed è raramente utile perché i file di database crescono di nuovo dopo un certo periodo di tempo quando nuovi dati entrano nel sistema. Il collegamento automatico non deve mai essere attivato nel database.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Istanza condivisa Microsoft SQL Server rispetto a istanza dedicata</block>
  <block id="8b58192b54b5dc25444ace0536a34893" category="paragraph">Se un'applicazione dispone di molti schemi e stored procedure, potrebbe influire potenzialmente su altre applicazioni che condividono un'istanza di SQL Server.</block>
  <block id="0f85d9701e2ca305652e98c4181097e4" category="paragraph">Le risorse di istanza potrebbero potenzialmente essere divise o bloccate, il che a sua volta causa problemi di prestazioni per altre app che hanno database ospitati nell'istanza condivisa di SQL Server.</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">La risoluzione dei problemi di prestazioni può essere complicata, perché è necessario capire quale istanza è la causa principale. Questa domanda è valutata rispetto ai costi delle licenze del sistema operativo e delle licenze di SQL Server. Se le performance applicative sono fondamentali, si consiglia vivamente un'istanza dedicata.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft concede in licenza SQL Server per core a livello di server e non per istanza. Per questo motivo, gli amministratori di database sono tentati di installare tutte le istanze di SQL Server che il server è in grado di gestire per risparmiare sui costi di licenza, il che può portare a gravi problemi di performance in un secondo momento.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp consiglia* di scegliere istanze dedicate di SQL Server quando possibile per ottenere prestazioni ottimali.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP e applicazioni aziendali</block>
  <block id="6e1c62c6c9ec560b6b6cf47a8a8c83f8" category="summary">Oracle su ONTAP con Solaris</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Argomenti di configurazione specifici di Solaris.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Opzioni di montaggio NFS Solaris</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio di Solaris NFS per una singola istanza.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Tipo di file</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Opzioni di montaggio</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">Pagina iniziale ADR</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">L'utilizzo di<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> è stato dimostrato di migliorare drasticamente le performance negli ambienti dei clienti rimuovendo la latenza associata all'acquisizione e al rilascio di blocchi sul sistema storage. Utilizzare questa opzione con attenzione negli ambienti in cui sono configurati numerosi server per montare gli stessi file system e Oracle è configurato per montare questi database. Sebbene si tratti di una configurazione molto insolita, viene utilizzata da un numero limitato di clienti. Se un'istanza viene avviata accidentalmente una seconda volta, i dati potrebbero danneggiarsi perché Oracle non è in grado di rilevare i file di blocco sul server esterno. I blocchi NFS non offrono altrimenti protezione; come nella versione 3 di NFS, sono solo di natura consultiva.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Perché il<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> i parametri si escludono a vicenda, è importante che<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> è presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file in modo che<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> viene utilizzato. Senza questo parametro, viene utilizzato il caching del buffer del sistema operativo host e le prestazioni possono essere compromesse.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio Solaris NFS RAC.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/votazione</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Dedicato<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">Il motivo<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password Oracle e file spfile. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è richiesto.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Opzioni di montaggio UFS di Solaris</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp consiglia vivamente di utilizzare l'opzione di montaggio della registrazione in modo che l'integrità dei dati venga preservata in caso di arresto anomalo dell'host Solaris o di interruzione della connettività FC. L'opzione di montaggio della registrazione preserva anche l'usabilità dei backup Snapshot.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">Solaris ZFS</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS deve essere installato e configurato con attenzione per garantire prestazioni ottimali.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector</block>
  <block id="c54b9977f43cf2f9a1aa7cb0de8fec22" category="paragraph">Solaris 11 ha introdotto una modifica nel modo in cui elabora operazioni i/o di grandi dimensioni, che può causare gravi problemi di prestazioni sugli array di storage SAN. Il problema è documentato in dettaglio nel bug report di NetApp 630173, "riduzione delle prestazioni di Solaris 11 ZFS. " La soluzione è modificare un parametro OS chiamato<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block>.</block>
  <block id="17e692fa261653b11634297d15070637" category="paragraph">Eseguire il seguente comando come root:</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">Se da questa modifica emergono problemi imprevisti, è possibile annullarli facilmente eseguendo il seguente comando come root:</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Kernel</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">Prestazioni ZFS affidabili richiedono un kernel Solaris con patch contro i problemi di allineamento LUN. La correzione è stata introdotta con la patch 147440-19 in Solaris 10 e con SRU 10,5 per Solaris 11. Utilizzare solo Solaris 10 e versioni successive con ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">Configurazione del LUN</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Per configurare un LUN, attenersi alla seguente procedura:</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Creare un LUN di tipo<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Installare l'host Utility Kit (HUK) appropriato specificato da <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">documentazione più recente</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Seguire esattamente le istruzioni nell'HUK come descritto. I passaggi di base sono descritti di seguito, ma fare riferimento a. <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> per la procedura corretta.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Eseguire<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> utilità per aggiornare<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> file. Questo consente alle unità SCSI di rilevare correttamente i LUN ONTAP.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Seguire le istruzioni fornite da<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Utility per abilitare l'input/output multipath (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Reboot (Riavvia). Questa fase è necessaria per consentire il riconoscimento di eventuali modifiche nel sistema.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Partizionare i LUN e verificare che siano allineati correttamente. Vedere "Appendice B: Verifica dell'allineamento WAFL" per istruzioni su come eseguire direttamente il test e confermare l'allineamento.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpool</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">Configurazione LUN</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">Il valore di<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> il valore predefinito è 9, ovvero 2^9 o 512 byte. Per prestazioni ottimali, la<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Il valore deve essere 12 (2^12=4K). Questo valore viene impostato al momento della creazione di zpool e non può essere modificato, il che significa che i dati in zpool con<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> oltre a 12 deve essere eseguita la migrazione copiando i dati in uno zpool appena creato.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Dopo aver creato uno zpool, verificare il valore di<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> prima di procedere. Se il valore non è 12, i LUN non sono stati rilevati correttamente. Distruggere lo zpool, verificare che tutti i passaggi indicati nella relativa documentazione delle utilità host siano stati eseguiti correttamente e ricreare lo zpool.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpool e LDOM Solaris</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Gli LDOM di Solaris creano un requisito aggiuntivo per assicurarsi che l'allineamento i/o sia corretto. Sebbene un LUN possa essere rilevato correttamente come un dispositivo 4K, un dispositivo vdsk virtuale su un LDOM non eredita la configurazione dal dominio i/O. Vdsk basato su tale LUN torna per impostazione predefinita a un blocco da 512 byte.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">È necessario un file di configurazione aggiuntivo. In primo luogo, i singoli LDOM devono essere aggiornati per Oracle bug 15824910 per abilitare le opzioni di configurazione aggiuntive. Questa patch è stata trasferita in tutte le versioni attualmente utilizzate di Solaris. Una volta installato il software LDOM, è pronto per la configurazione dei nuovi LUN correttamente allineati come segue:</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identificare il LUN o i LUN da utilizzare nel nuovo zpool. In questo esempio, si tratta del dispositivo c2d1.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Recuperare l'istanza vdc dei dispositivi da utilizzare per un pool ZFS:</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Modifica<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Ciò significa che all'istanza di dispositivo 1 viene assegnata una dimensione di blocco di 4096.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Come ulteriore esempio, si supponga che le istanze vdsk da 1 a 6 debbano essere configurate per una dimensione di blocco di 4K e.<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> recita:</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">La finale<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> il file deve contenere quanto segue:</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Attenzione</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">L'LDOM deve essere riavviato dopo la configurazione di vdc.conf e la creazione di vdsk. Questa fase non può essere evitata. La modifica delle dimensioni del blocco ha effetto solo dopo un riavvio. Procedere con la configurazione di zpool e accertarsi che l'ashift sia impostato correttamente su 12 come descritto in precedenza.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">ZFS Intent Log (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">In genere, non esiste alcun motivo per individuare ZFS Intent Log (ZIL) su un dispositivo diverso. Il registro può condividere lo spazio con il pool principale. L'uso principale di una ZIL separata è quando si utilizzano unità fisiche che non dispongono delle funzionalità di cache di scrittura nei moderni array di storage.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">logbias</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Impostare<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Parametro sui file system ZFS che ospitano dati Oracle.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">L'utilizzo di questo parametro riduce i livelli di scrittura complessivi. Per impostazione predefinita, i dati scritti vengono salvati prima nella ZIL e quindi nel pool di storage principale. Questo approccio è appropriato per una configurazione che utilizza una configurazione a disco normale, che include un dispositivo ZIL basato su SSD e supporti rotanti per il pool di storage principale. Questo perché consente l'esecuzione di un commit in una singola transazione i/o sul supporto con latenza più bassa disponibile.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Quando si utilizza un moderno storage array che include funzionalità di caching autonome, questo approccio generalmente non è necessario. In rare circostanze, potrebbe essere opportuno assegnare una scrittura con una singola transazione al registro, ad esempio un carico di lavoro costituito da scritture casuali altamente concentrate e sensibili alla latenza. Vi sono conseguenze sotto forma di amplificazione in scrittura poiché i dati registrati vengono infine scritti nel pool di archiviazione principale, con il risultato di raddoppiare l'attività di scrittura.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">I/o diretto</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">Molte applicazioni, inclusi i prodotti Oracle, possono bypassare la cache del buffer host attivando l'i/o diretto Questa strategia non funziona come previsto con i file system ZFS. Anche se la cache del buffer host viene ignorata, ZFS continua a memorizzare i dati nella cache. Questa azione può produrre risultati fuorvianti quando si utilizzano strumenti come fio o sio per eseguire test delle prestazioni perché è difficile prevedere se l'i/o raggiunge il sistema di storage o se viene memorizzato nella cache locale del sistema operativo. Questa azione rende inoltre molto difficile l'utilizzo di tali test sintetici per confrontare le prestazioni di ZFS con altri file system. In pratica, le performance del file system differiscono da poco a nulla per i carichi di lavoro degli utenti reali.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Diversi zpool</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Backup basati su snapshot, ripristini, cloni e archiviazione dei dati basati su ZFS devono essere eseguiti al livello di zpool e in genere richiedono più zpool. Uno zpool è analogo a un gruppo di dischi LVM e deve essere configurato utilizzando le stesse regole. Ad esempio, è probabilmente meglio disporre un database con i file di dati residenti su<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> e i log di archivio, i file di controllo e i log di ripristino che risiedono su<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Questo approccio consente un backup a caldo standard in cui il database viene posto in modalità hot backup, seguito da uno snapshot di<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. Il database viene quindi rimosso dalla modalità di backup a caldo, l'archivio di log viene forzato e viene creata una snapshot di<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> viene creato. Un'operazione di ripristino richiede lo smontaggio dei file system zfs e l'offlining completo di zpool, in seguito a un'operazione di ripristino di SnapRestore. Lo zpool può quindi essere portato nuovamente online e il database recuperato.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesystemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Parametro Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Funziona in modo diverso con ZFS. Se<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> oppure<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Viene utilizzato, le operazioni di scrittura sono sincrone e ignorano la cache del buffer del sistema operativo, ma le letture sono bufferizzate da ZFS. Questa azione causa difficoltà nell'analisi delle performance perché talvolta l'i/o viene intercettato e gestito dalla cache ZFS, rendendo la latenza dello storage e l'i/o totale inferiori a quanto pare.</block>
  <block id="22a7d37643562540ddbda52f511fb1fe" category="summary">Oracle su ONTAP con HP-UX</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX</block>
  <block id="5be7e182308e16aee80978c6a5ebe02b" category="paragraph">Argomenti di configurazione specifici del sistema operativo HP-UX.</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">Opzioni di montaggio NFS HP-UX</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS HP-UX per una singola istanza.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">File di controllo
File di dati
Registri di ripristino</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS HP-UX per RAC.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">Il motivo<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password Oracle e file spfile. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è richiesto.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">Opzioni di montaggio VxFS HP-UX</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i file system che ospitano file binari Oracle:</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i file system contenenti file di dati, log di ripristino, log di archivio e file di controllo in cui la versione di HP-UX non supporta i/o simultanei:</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Quando l'i/o simultaneo è supportato (VxFS 5.0.1 e versioni successive o con ServiceGuard Storage Management Suite), utilizzare queste opzioni di montaggio per i file system contenenti file di dati, log di ripristino, log di archivio e file di controllo:</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">Il parametro<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> È particolarmente critico negli ambienti VxFS. Oracle consiglia di non impostare questo parametro in Oracle 10g R1 e versioni successive, a meno che non sia diversamente specificato. L'impostazione predefinita con dimensioni blocco Oracle 8KB è 128 KB. Se il valore di questo parametro è forzato a 16 o inferiore, rimuovere l'<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Montare l'opzione perché può danneggiare le prestazioni i/o sequenziali. Questa operazione danneggia altri aspetti delle prestazioni e deve essere eseguita solo se il valore di<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> deve essere modificato dal valore predefinito.</block>
  <block id="ca3fa25943498edb0ee62d0ea286bb7a" category="summary">Oracle su ONTAP utilizzando Linux e driver filtro ASMlib/ASM</block>
  <block id="d7e9c72be485a5a848f1f7cd15a9a5ba" category="doc">Driver filtro ASMlib e ASM</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Argomenti di configurazione specifici per il sistema operativo Linux utilizzando AFD e ASMlib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">Dimensioni dei blocchi ASMlib</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib è una libreria di gestione ASM opzionale e le utilità associate. Il suo valore principale è la capacità di contrassegnare un LUN o un file basato su NFS come una risorsa ASM con un'etichetta leggibile da un utente.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Le versioni recenti di ASMlib rilevano un parametro LUN chiamato Logical Blocks per Physical Block Exponent (LBPPBE). Questo valore non è stato segnalato dal target SCSI ONTAP fino a poco tempo fa. Ora restituisce un valore che indica che è preferibile una dimensione blocco 4KB. Questa non è una definizione della dimensione del blocco, ma è un suggerimento per qualsiasi applicazione che utilizza LBPPBE che i/o di una certa dimensione potrebbero essere gestiti in modo più efficiente. ASMlib, tuttavia, interpreta LBPPBE come dimensione del blocco e contrassegna in modo permanente l'intestazione ASM quando viene creato il dispositivo ASM.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Questo processo può causare problemi di aggiornamento e migrazione in vari modi, tutti basati sull'impossibilità di combinare dispositivi ASMlib con dimensioni dei blocchi diverse nello stesso gruppo di dischi ASM.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Ad esempio, gli array meno recenti generalmente riportavano un valore LBPPBE pari a 0 o non riportavano affatto questo valore. ASMlib lo interpreta come una dimensione di blocco di 512 byte. Gli array più recenti dovrebbero essere interpretati come aventi una dimensione del blocco di 4KB KB. Non è possibile combinare dispositivi a 512 byte e 4KB nello stesso gruppo di dischi ASM. In questo modo, si impedirebbe a un utente di aumentare le dimensioni del gruppo di dischi ASM utilizzando LUN di due array o sfruttando ASM come strumento di migrazione. In altri casi, RMAN potrebbe non consentire la copia dei file tra un gruppo di dischi ASM con dimensioni del blocco di 512 byte e un gruppo di dischi ASM con dimensioni del blocco di 4KB KB.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">La soluzione preferita è quella di tamponare ASMlib. L'ID del bug di Oracle è 13999609 e la patch è presente in oracleasm-support-2,1.8-1 e versioni successive. Questo patch consente all'utente di impostare il parametro<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> a.<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> in<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> file di configurazione. In questo modo, ASMlib non utilizza il parametro LBPPBE, il che significa che i LUN del nuovo array sono ora riconosciuti come dispositivi a blocchi da 512 byte.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">L'opzione non modifica le dimensioni del blocco sui LUN precedentemente contrassegnati da ASMlib. Ad esempio, se un gruppo di dischi ASM con blocchi da 512 byte deve essere migrato in un nuovo sistema di storage che riporta un blocco da 4KB KB, è possibile scegliere questa opzione<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Deve essere impostato prima che i nuovi LUN siano contrassegnati con ASMlib.  Se i dispositivi sono già stati contrassegnati da oracleasm, è necessario riformattarli prima di essere contrassegnati con una nuova dimensione del blocco. Innanzitutto, deconfigurare il dispositivo con<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, E quindi cancellare i primi 1GB del dispositivo con<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Infine, se il dispositivo era stato precedentemente partizionato, utilizzare<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Per rimuovere le partizioni obsolete o semplicemente riavviare il sistema operativo.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Se ASMlib non può essere aggiornato, ASMlib può essere rimosso dalla configurazione. Questa modifica comporta un'interruzione e richiede la rimozione dello stampaggio dei dischi ASM e la verifica che<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> parametro impostato correttamente. Questa modifica, tuttavia, non richiede la migrazione dei dati.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Dimensioni blocco comando filtro ASM (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD è una libreria di gestione ASM opzionale che sta diventando il sostituto di ASMlib. Dal punto di vista dello storage, è molto simile ad ASMlib, ma include funzionalità aggiuntive come la capacità di bloccare i/o non Oracle per ridurre le possibilità di errori di utenti o applicazioni che potrebbero danneggiare i dati.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Dimensioni dei blocchi dei dispositivi</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Come ASMlib, anche AFD legge il parametro LUN Logical Blocks per Physical Block Exponent (LBPPBE) e per impostazione predefinita utilizza la dimensione fisica del blocco, non la dimensione logica del blocco.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Ciò potrebbe creare un problema se l'AFD viene aggiunto a una configurazione esistente in cui i dispositivi ASM sono già formattati come dispositivi a blocchi da 512 byte. Il driver AFD riconosce il LUN come un dispositivo 4K e la mancata corrispondenza tra l'etichetta ASM e il dispositivo fisico impedirebbe l'accesso. Allo stesso modo, le migrazioni sarebbero influenzate dal fatto che non è possibile combinare dispositivi a 512 byte e 4KB nello stesso gruppo di dischi ASM. In questo modo, si impedirebbe a un utente di aumentare le dimensioni del gruppo di dischi ASM utilizzando LUN di due array o sfruttando ASM come strumento di migrazione. In altri casi, RMAN potrebbe non consentire la copia dei file tra un gruppo di dischi ASM con dimensioni del blocco di 512 byte e un gruppo di dischi ASM con dimensioni del blocco di 4KB KB.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">La soluzione è semplice: AFD include un parametro per controllare se utilizza le dimensioni del blocco logico o fisico. Si tratta di un parametro globale che interessa tutti i dispositivi del sistema. Per forzare AFD a utilizzare le dimensioni del blocco logico, impostare<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> in<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> file.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Dimensioni di trasferimento multipath</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Le recenti modifiche al kernel linux impongono restrizioni delle dimensioni di i/o inviate ai dispositivi multipath e AFD non rispetta queste restrizioni. Gli i/o vengono quindi rifiutati, il che causa la disconnessione del percorso LUN. Il risultato è un'impossibilità di installare Oracle Grid, configurare ASM o creare un database.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">La soluzione consiste nel specificare manualmente la lunghezza massima di trasferimento nel file multipath.conf per i LUN ONTAP:</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Anche se attualmente non esistono problemi, questo parametro deve essere impostato se si utilizza AFD per garantire che un futuro aggiornamento linux non causi inaspettatamente problemi.</block>
  <block id="72247c591c444399f3d42dffa31b644e" category="summary">Oracle su ONTAP utilizzando AIX</block>
  <block id="23802d94b756cf69028557bea156ab1a" category="doc">IBM AIX</block>
  <block id="5b8d4d99cdcb494ca636eb065004b165" category="paragraph">Argomenti di configurazione specifici del sistema operativo IBM AIX.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">I/o simultanei</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Per ottenere prestazioni ottimali su IBM AIX è necessario utilizzare l'i/o simultaneo Senza i/o simultaneo, è probabile che le limitazioni delle prestazioni siano dovute al fatto che AIX esegue i/o atomico serializzato, che comporta un overhead significativo.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">In origine, NetApp ha consigliato di utilizzare<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Opzione di montaggio per forzare l'uso di i/o simultanei sul file system, ma questo processo ha avuto degli inconvenienti e non è più necessario. Dall'introduzione di AIX 5,2 e Oracle 10gR1, Oracle su AIX può aprire singoli file per i/o simultanei, anziché forzare i/o simultanei sull'intero file system.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">Il metodo migliore per abilitare l'i/o simultaneo è impostare<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> a.<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. In questo modo, Oracle può aprire file specifici da utilizzare con i/o simultanei</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">Utilizzo di<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Come opzione di montaggio, l'utilizzo di i/o simultanei può avere conseguenze negative. Ad esempio, forzando i/o simultanei si disabilita la lettura dei file system, che può danneggiare le prestazioni dell'i/o al di fuori del software del database Oracle, come la copia dei file e l'esecuzione di backup su nastro. Inoltre, prodotti come Oracle GoldenGate e SAP BR*Tools non sono compatibili con l'uso di<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Montare l'opzione con alcune versioni di Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">Non utilizzare<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> opzione di montaggio a livello di file system. Abilitare invece l'i/o simultaneo tramite l'utilizzo di<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Utilizzare solo l'<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> l'opzione di montaggio dovrebbe essere impostata se non è possibile<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Opzioni di montaggio NFS AIX</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS AIX per i database Oracle a istanza singola.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS AIX per RAC.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare la cache del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">Anche se si utilizza il<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> montare l'opzione e.<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Implementazioni per facilitare la coerenza di file quali file di password Oracle e.<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> file di parametri. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è necessario.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Opzioni di montaggio di AIX jfs/JFS2</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio di AIX jfs/JFS2.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Valori predefiniti</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Prima di utilizzare AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> i dispositivi in qualsiasi ambiente, inclusi i database, controllano il parametro<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Questo parametro non è la profondità della coda HBA, bensì la profondità della coda SCSI dell'individuo<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> potrebbe essere troppo basso per garantire buone prestazioni. I test hanno dimostrato che il valore ottimale è 64.</block>
  <block id="6e1dee25b21d0005970053df9e9384ba" category="summary">Oracle su ONTAP con Microsoft Windows</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="44959b8c12de9e1107621ee8c0337463" category="paragraph">Argomenti di configurazione specifici del sistema operativo Microsoft Windows.</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle supporta l'utilizzo di Microsoft Windows con il client NFS diretto. Questa funzionalità offre un percorso per i vantaggi di gestione di NFS, tra cui la possibilità di visualizzare i file tra più ambienti, ridimensionare dinamicamente i volumi e sfruttare un protocollo IP meno costoso. Consultare la documentazione ufficiale di Oracle per informazioni sull'installazione e la configurazione di un database in Microsoft Windows utilizzando DNFS. Non esistono Best practice speciali.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Per un'efficienza di compressione ottimale, assicurarsi che il file system NTFS utilizzi un'unità di allocazione di 8K GB o superiore. L'utilizzo di un'unità di allocazione 4K, generalmente predefinita, influisce negativamente sull'efficienza della compressione.</block>
  <block id="140def8362bd2cf6a999328e25572cfd" category="summary">Oracle su ONTAP con Linux</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Argomenti di configurazione specifici del sistema operativo Linux.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Tavoli con fessure</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Opzioni di montaggio NFS Linux</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS Linux per una singola istanza.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">Nella tabella seguente sono elencate le opzioni di montaggio NFS Linux per RAC.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/votazione</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">L'aggiunta fa la differenza principale tra le opzioni di montaggio RAC e a istanza singola<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> alle opzioni di montaggio. Questa aggiunta ha l'effetto di disabilitare il caching del sistema operativo host, consentendo a tutte le istanze nel cluster RAC di avere una visione coerente dello stato dei dati. Anche se si utilizza il<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parametro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> ha lo stesso effetto di disabilitare la cache dell'host, è comunque necessario utilizzare<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">Il motivo<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> è obbligatorio per condiviso<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Le distribuzioni consentono di semplificare la coerenza di file quali file di password e file spfile di Oracle. Se ogni istanza di un cluster RAC dispone di un'istanza dedicata<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, questo parametro non è necessario.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">In genere, i file non di database devono essere montati con le stesse opzioni utilizzate per i file di dati a singola istanza, sebbene applicazioni specifiche possano avere requisiti diversi. Evitare le opzioni di montaggio<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> se possibile perché queste opzioni disabilitano la lettura e il buffering a livello di file system. Ciò può causare gravi problemi di prestazioni per processi quali l'estrazione, la traduzione e il caricamento.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESSO e GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Alcuni clienti hanno notato che un livello estremamente elevato di altri IOPS, come ACCESSO e GETATTR, può dominare i propri workload. In casi estremi, operazioni come letture e scritture possono arrivare fino al 10% del totale. Si tratta di un comportamento normale con qualsiasi database che include l'uso di<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> e/o.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Su Linux perché queste opzioni fanno sì che il sistema operativo Linux ricarichi costantemente i metadati dei file dal sistema di archiviazione. Operazioni quali ACCESS e GETATTR sono operazioni a basso impatto gestite dalla cache ONTAP in un ambiente di database. Non dovrebbero essere considerati IOPS autentici, come le letture e le scritture, che creano una vera domanda sui sistemi storage. Tuttavia, questi altri IOPS creano un certo carico, specialmente negli ambienti RAC. Per risolvere questo problema, abilitare DNFS, che ignora la cache buffer del sistema operativo ed evita queste operazioni non necessarie relative ai metadati.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">Linux Direct NFS</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Un'opzione di montaggio aggiuntiva, denominata<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, È necessario quando (a) DNFS è abilitato e (b) un volume sorgente è montato più di una volta su un singolo server (c) con un mount NFS nidificato. Questa configurazione si osserva principalmente in ambienti che supportano applicazioni SAP. Ad esempio, un singolo volume di un sistema NetApp può avere una directory situata in<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> e un secondo a.<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Se<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> è montato su<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> e.<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> è montato su<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, Il risultato sono montaggi NFS nidificati che hanno origine sulla stessa fonte.</block>
  <block id="b06ff38483faff2d17d8de1fc966848e" category="paragraph">Il sistema operativo è in grado di rilevare il fatto che<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> e.<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> risiedono sullo stesso volume, che è lo stesso file system di origine. Il sistema operativo utilizza quindi lo stesso handle di dispositivo per l'accesso ai dati. In questo modo si migliora l'uso della cache del sistema operativo e di alcune altre operazioni, ma interferisce con DNFS. Se DNFS deve accedere a un file, ad esempio<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block>, attivato<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, potrebbe erroneamente tentare di utilizzare il percorso errato per i dati. Il risultato è un'operazione i/o non riuscita. In queste configurazioni, aggiungere<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> Opzione di montaggio su qualsiasi file system NFS che condivide un volume FlexVol di origine con un altro file system NFS su quell'host. In questo modo, il sistema operativo Linux assegna un handle di dispositivo indipendente al file system.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS e Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">L'uso di DNFS offre speciali vantaggi in termini di prestazioni per Oracle RAC sul sistema operativo Linux, poiché Linux non dispone di un metodo per forzare l'i/o diretto, necessario con RAC per la coerenza tra i nodi. Come soluzione, Linux richiede l'uso di<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Opzione di montaggio, che fa sì che i dati dei file scadano immediatamente dalla cache del sistema operativo. Questa opzione a sua volta obbliga il client NFS Linux a rileggere costantemente i dati degli attributi, danneggiando la latenza e aumentando il carico sullo storage controller.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">Abilitando DNFS si ignora il client NFS dell'host ed evita questo danno. Diversi clienti hanno segnalato significativi miglioramenti delle performance sui cluster RAC e una significativa riduzione del carico ONTAP (soprattutto in relazione ad altri IOPS) quando si attiva DNFS.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS e file oranfstab</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Quando si utilizza DNFS su Linux con l'opzione multipathing, è necessario utilizzare più sottoreti. Su altri sistemi operativi, è possibile stabilire più canali DNFS utilizzando<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> e.<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Opzioni per configurare più canali DNFS su una singola subnet. Tuttavia, questo non funziona correttamente su Linux e possono verificarsi problemi di prestazioni imprevisti. Con Linux, ogni NIC utilizzata per il traffico DNFS deve trovarsi su una subnet diversa.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">Utilità di pianificazione i/O.</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Il kernel Linux permette un controllo di basso livello sul modo in cui l'i/o blocca i dispositivi è programmato. Le impostazioni predefinite su varie distribuzioni di Linux variano notevolmente. I test dimostrano che la scadenza di solito offre i migliori risultati, ma a volte NOOP è stato leggermente migliore. La differenza di prestazioni è minima, ma è necessario verificare entrambe le opzioni se è necessario estrarre le massime prestazioni possibili da una configurazione di database. CFQ è l'impostazione predefinita in molte configurazioni e ha dimostrato di avere problemi significativi di prestazioni con i carichi di lavoro del database.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Per istruzioni sulla configurazione dello scheduler i/o, consultare la documentazione del fornitore di Linux pertinente.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Multipathing</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Alcuni clienti hanno riscontrato arresti anomali durante l'interruzione della rete perché il daemon multipath non era in esecuzione sul proprio sistema. Nelle versioni recenti di Linux, il processo di installazione del sistema operativo e del demone multipathing potrebbero lasciare questi sistemi operativi vulnerabili a questo problema. I pacchetti sono installati correttamente, ma non sono configurati per l'avvio automatico dopo un riavvio.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Ad esempio, il valore predefinito per il daemon multipath su RHEL5,5 potrebbe essere il seguente:</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Questo può essere corretto con i seguenti comandi:</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">Mirroring ASM</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">Il mirroring ASM potrebbe richiedere modifiche alle impostazioni di multipath Linux per consentire ad ASM di riconoscere un problema e passare a un gruppo di errori alternativo. La maggior parte delle configurazioni ASM su ONTAP utilizza la ridondanza esterna, il che significa che la protezione dei dati è fornita dall'array esterno e ASM non esegue il mirroring dei dati. Alcuni siti utilizzano ASM con ridondanza normale per fornire il mirroring bidirezionale, in genere su siti diversi.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">Documentazione delle utilità host NetApp</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">Le impostazioni di Linux visualizzate nella <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Includi parametri multipath che determinano indefinite code di i/O. Ciò significa che un i/o su un dispositivo LUN senza percorsi attivi attende finché l'i/o non viene completato. Questo è solitamente consigliabile perché gli host Linux attendono il tempo necessario per il completamento delle modifiche al percorso SAN, per il riavvio degli switch FC o per il completamento di un failover da parte di un sistema di storage.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Questo comportamento di accodamento illimitato causa un problema con il mirroring ASM perché ASM deve ricevere un errore di i/o per consentire al reparto IT di riprovare l'i/o su un LUN alternativo.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Impostare i seguenti parametri in Linux<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> File per i LUN ASM utilizzati con il mirroring ASM:</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Queste impostazioni creano un timeout di 120 secondi per i dispositivi ASM. Il timeout viene calcolato come<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> in pochi secondi. In alcuni casi potrebbe essere necessario regolare il valore esatto, ma per la maggior parte degli utilizzi dovrebbe essere sufficiente un timeout di 120 secondi. In particolare, 120 secondi devono consentire il takeover o il giveback del controller senza produrre un errore di i/o che porterebbe il gruppo guasto a diventare offline.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">Un più basso<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> Il valore può ridurre il tempo richiesto per ASM per passare a un gruppo di errori alternativo, ma aumenta anche il rischio di un failover indesiderato durante attività di manutenzione come il takeover di un controller. Il rischio può essere mitigato tramite un attento monitoraggio dello stato di mirroring ASM. Se si verifica un failover indesiderato, è possibile risincronizzare rapidamente i mirror se la risincronizzazione viene eseguita in modo relativamente rapido. Per ulteriori informazioni, consultare la documentazione Oracle su ASM Fast Mirror Resync per la versione del software Oracle in uso.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Linux xfs, ext3, e ext4 opzioni di mount</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp recommended* usando le opzioni di mount predefinite.</block>
  <block id="17361a1d111a3ff3a45b20c3a1efa11b" category="summary">Configurazione Oracle e TCP/IP ed ethernet.</block>
  <block id="fe586387f0871fa578f77ac2e26e624a" category="doc">Configurazione TCP/IP ed Ethernet per Oracle Database</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">Molti clienti di Oracle su ONTAP utilizzano ethernet, il protocollo di rete di NFS, iSCSI, NVMe/TCP e specialmente il cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Progettazione dell'interfaccia logica per i database Oracle</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">I database Oracle devono accedere allo storage. Le interfacce logiche (LIF) sono le tubazioni di rete che collegano una Storage Virtual Machine (SVM) alla rete e a loro volta al database. La corretta progettazione della LIF è necessaria per garantire una larghezza di banda sufficiente per ogni carico di lavoro del database e il failover non comporta una perdita dei servizi storage.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Configurazione di rete FC per database Oracle</block>
  <block id="ee955933387c00b282dcfda69005517f" category="doc">Configurazione FC per Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">La configurazione di FC SAN per database Oracle riguarda principalmente le seguenti Best practice quotidiane SAN.</block>
  <block id="953369199e3a71ad1ad58bc7d5ad2d9f" category="summary">NetApp ONTAP è una potente piattaforma di gestione dei dati con funzionalità native che includono funzionalità di backup, ripristino e cloning istantanei, funzionalità di efficienza come compressione inline, upgrade hardware senza interruzioni e la possibilità di importare una LUN da uno storage array esterno.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Database Oracle su ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP è progettato per i database Oracle. Per decenni, ONTAP è stato ottimizzato per le esigenze uniche di i/o dei database relazionali e sono state create più funzionalità di ONTAP appositamente per soddisfare le esigenze dei database Oracle e persino su richiesta della stessa Oracle Inc.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-3633: Database Oracle su ONTAP; TR-4591: Protezione dei dati Oracle: Backup, recovery, replica; TR-4592: Oracle su MetroCluster; e TR-4534: Migrazione dei database Oracle su sistemi di storage NetApp_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Oltre ai numerosi modi possibili in cui ONTAP apporta valore all'ambiente di database, esiste anche una vasta gamma di requisiti utente, incluse le dimensioni del database, i requisiti di performance e le esigenze di protezione dei dati. Le distribuzioni note di storage NetApp includono tutto, da un ambiente virtualizzato di circa 6.000 database in esecuzione su VMware ESX a un data warehouse a singola istanza, di dimensioni attuali pari a 996TB TB e in crescita. Di conseguenza, sono disponibili alcune Best practice chiare per la configurazione di un database Oracle su storage NetApp.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">I requisiti per l'utilizzo di un database Oracle su storage NetApp vengono risolti in due modi. In primo luogo, quando esiste una buona pratica chiara, essa verrà richiamata in modo specifico. A un livello generale, verranno spiegate molte considerazioni di progettazione che i progettisti delle soluzioni di storage Oracle devono affrontare in base ai loro specifici requisiti di business.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Introduzione alla migrazione dello storage Oracle</block>
  <block id="6ca08c212e9ec987ce485fd9c7705eff" category="doc">Migrazione dei database Oracle sui sistemi di storage NetApp</block>
  <block id="9e099143017b5d9ff9c117de4ac659d7" category="paragraph">L'utilizzo delle funzionalità di una nuova piattaforma di storage impone un requisito inevitabile e prevede il posizionamento dei dati nel nuovo sistema di storage.</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4534: Migrazione dei database Oracle in sistemi di storage NetApp_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">Nel caso di un nuovo progetto di database, questo non rappresenta un problema, poiché gli ambienti di database e applicazioni sono stati costruiti in sede. La migrazione, tuttavia, pone sfide speciali in relazione all'interruzione del business, al tempo necessario per il completamento della migrazione, alle competenze necessarie e alla minimizzazione del rischio.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Script</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">La presente documentazione contiene script di esempio. Questi script forniscono metodi di esempio per automatizzare vari aspetti della migrazione per ridurre la possibilità di errori da parte degli utenti. Gli script possono ridurre le richieste generali del personale IT responsabile della migrazione e accelerare il processo complessivo. Questi script sono ricavati da progetti di migrazione effettivi eseguiti dai servizi di assistenza professionale NetApp e dai partner NetApp. Nella presente documentazione sono riportati alcuni esempi del loro utilizzo.</block>
  <block id="b3978e376e381abd116a2ae7938d8a9c" category="summary">Cutover FLI - Oracle</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">Una parte delle interruzioni durante l'importazione di LUN esterne è inevitabile a causa della necessità di modificare la configurazione di rete FC. Tuttavia, l'interruzione non deve durare più a lungo del tempo necessario per riavviare l'ambiente di database e aggiornare lo zoning FC per passare dalla connettività FC dell'host al ONTAP.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Questo processo può essere riassunto come segue:</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Quiete di tutta l'attività LUN sui LUN esterni.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Reindirizzare le connessioni FC dell'host al nuovo sistema ONTAP.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Attivare il processo di importazione.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Rilevare nuovamente i LUN.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Riavviare il database.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">Non è necessario attendere il completamento del processo di migrazione. Non appena inizia la migrazione di un determinato LUN, questo è disponibile su ONTAP e può fornire dati durante il processo di copia dei dati. Tutte le letture vengono passate alla LUN esterna e tutte le scritture vengono scritte in modo sincrono su entrambi gli array. L'operazione di copia è molto veloce e l'overhead del reindirizzamento del traffico FC è minimo, per cui qualsiasi impatto sulle performance deve essere transitorio e minimo. In caso di problemi, è possibile ritardare il riavvio dell'ambiente fino al completamento del processo di migrazione e all'eliminazione delle relazioni di importazione.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Chiudere il database</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">Il primo passo per chiudere l'ambiente in questo esempio è arrestare il database.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Chiudere i servizi di rete</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">Uno dei file system basati su SAN oggetto della migrazione include anche i servizi Oracle ASM. La disattivazione dei LUN sottostanti richiede lo smontaggio dei file system, il che a sua volta significa l'arresto di tutti i processi con file aperti su questo file system.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Smontare i file system</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Se tutti i processi vengono arrestati, l'operazione umount ha esito positivo. Se l'autorizzazione viene negata, è necessario che sul file system sia presente un processo con blocco. Il<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> command può aiutare a identificare questi processi.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Disattivare i gruppi di volumi</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Una volta smontati tutti i file system di un dato gruppo di volumi, è possibile disattivare il gruppo di volumi.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Modifiche alla rete FC</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">È ora possibile aggiornare le zone FC per rimuovere tutti gli accessi dall'host all'array esterno e stabilire l'accesso a ONTAP.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Avviare il processo di importazione</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Per avviare i processi di importazione LUN, eseguire<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> comando.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Monitorare l'avanzamento dell'importazione</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">L'operazione di importazione può essere monitorata con<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> comando. Come illustrato di seguito, è in corso l'importazione di tutte le LUN da 20 GB, il che significa che i dati sono ora accessibili tramite ONTAP, anche se l'operazione di copia dei dati continua a proseguire.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Importazione di LUN esterne - completamento</block>
  <block id="24a74765303a8fc0e4b1e7afbb8e2205" category="paragraph">Se è necessario un processo non in linea, ritardare il riscoperta o il riavvio dei servizi fino al<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> il comando indica che tutta la migrazione è stata eseguita correttamente e completata. È quindi possibile completare il processo di migrazione come descritto in <block ref="5b0017122426f8734e0358273adc6802" category="inline-link-macro-rx"></block>.</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Se hai bisogno di una migrazione online, procedi con il rilevamento dei LUN nella nuova sede e attiva i servizi.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Eseguire la scansione delle modifiche al dispositivo SCSI</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">Nella maggior parte dei casi, l'opzione più semplice per ritrovare nuove LUN è riavviare l'host. In questo modo, si rimuovono automaticamente i vecchi dispositivi obsoleti, si rilevano correttamente tutti i nuovi LUN e si creano dispositivi associati come i dispositivi multipathing. L'esempio qui mostra una procedura completamente online a scopo dimostrativo.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Attenzione: Prima di riavviare un host, assicurarsi che tutte le voci in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Il riferimento alle risorse SAN migrate verrà commentato. Se questa operazione non viene eseguita e si verificano problemi con l'accesso LUN, il sistema operativo potrebbe non avviarsi. Questa situazione non danneggia i dati. Tuttavia, può essere molto scomodo avviare in modalità rescue o in una modalità simile e correggere<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> In modo che il sistema operativo possa essere avviato per consentire la risoluzione dei problemi.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">I LUN della versione di Linux utilizzata in questo esempio possono essere rianalizzati con<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> comando. Se il comando viene eseguito correttamente, nell'output viene visualizzato ogni percorso LUN. L'output può essere difficile da interpretare, ma, se la configurazione di zoning e igroup era corretta, molti LUN dovrebbero apparire che includono un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> stringa fornitore.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Verificare la presenza di dispositivi multipercorso</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">Il processo di rilevamento LUN attiva anche la ricreazione dei dispositivi multipath, ma è noto che il driver multipathing Linux presenta problemi occasionali. L'output di<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> dovrebbe essere controllato per verificare che l'output sia come previsto. Per esempio, l'uscita seguente mostra dispositivi multipercorso associati a A.<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> stringa fornitore. Ciascun dispositivo dispone di quattro percorsi, di cui due con priorità 50 e due con priorità 10. Anche se l'output esatto può variare con diverse versioni di Linux, questo risultato sembra come previsto.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Fare riferimento alla documentazione delle utilità host per la versione di Linux utilizzata per verificare che<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> le impostazioni sono corrette.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Riattivare il gruppo di volumi LVM</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Se i LUN LVM sono stati rilevati correttamente, l'<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> il comando dovrebbe riuscire. Questo è un buon esempio del valore di un volume manager logico. Una modifica del WWN di una LUN o anche di un numero di serie non è importante perché i metadati del gruppo di volumi vengono scritti sul LUN stesso.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">Il sistema operativo ha eseguito la scansione dei LUN e ha rilevato una piccola quantità di dati scritti sul LUN che lo identifica come volume fisico appartenente a.<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Successivamente, ha costruito tutti i dispositivi necessari. È sufficiente riattivare il gruppo di volumi.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Rimontare i file system</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Dopo la riattivazione del gruppo di volumi, i file system possono essere montati con tutti i dati originali intatti. Come indicato in precedenza, i file system sono completamente operativi anche se la replica dei dati è ancora attiva nel gruppo back.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Ripetere la scansione per i dispositivi ASM</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">I dispositivi ASMlib dovrebbero essere stati riselezionati al momento della nuova scansione dei dispositivi SCSI. La riscoperta può essere verificata online riavviando ASMlib e quindi eseguendo la scansione dei dischi.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Questa fase è pertinente solo alle configurazioni ASM in cui viene utilizzato ASMlib.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Attenzione: Se non viene utilizzato ASMlib, il<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> i dispositivi dovrebbero essere stati ricreati automaticamente. Tuttavia, le autorizzazioni potrebbero non essere corrette. È necessario impostare autorizzazioni speciali sui dispositivi sottostanti per ASM in assenza di ASMlib. Questa operazione viene solitamente eseguita tramite voci speciali in entrambi<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> oppure<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> o eventualmente in entrambi i set di regole. È possibile che questi file debbano essere aggiornati per riflettere le modifiche apportate all'ambiente in termini di numeri WWN o di serie per assicurarsi che i dispositivi ASM dispongano ancora delle autorizzazioni corrette.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">In questo esempio, il riavvio di ASMlib e la scansione dei dischi mostrano gli stessi 10 LUN ASM dell'ambiente originale.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Riavviare i servizi di rete</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Ora che i dispositivi LVM e ASM sono online e disponibili, è possibile riavviare i servizi grid.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Riavviare il database</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Dopo aver riavviato i servizi di griglia, è possibile avviare il database. Potrebbe essere necessario attendere alcuni minuti affinché i servizi ASM diventino completamente disponibili prima di provare ad avviare il database.</block>
  <block id="0b986cf2a434b03b097578ad444e72f0" category="summary">Completamento di un cutover FLI - Oracle</block>
  <block id="24bd7d2a01571aa270c81d8d9f8370e9" category="doc">Completamento FLI - Oracle</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Dal punto di vista dell'host, la migrazione è completa, ma l'i/o viene ancora servito dall'array esterno fino a quando le relazioni di importazione non vengono eliminate.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Prima di eliminare le relazioni, è necessario confermare che il processo di migrazione è completo per tutte le LUN.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Elimina relazioni di importazione</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Al termine del processo di migrazione, eliminare la relazione di migrazione. Dopo aver fatto ciò, l'i/o viene servito esclusivamente dalle unità su ONTAP.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Annullare la registrazione di LUN esterne</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Infine, modificare il disco per rimuovere<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> designazione.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Migrazione di Oracle tramite la distribuzione dei log</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Log shipping di Oracle</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">L'obiettivo di una migrazione utilizzando la distribuzione dei log è creare una copia dei file di dati originali in una nuova posizione e quindi stabilire un metodo per la distribuzione delle modifiche nel nuovo ambiente.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Una volta stabiliti, è possibile automatizzare la spedizione e la riproduzione dei log per mantenere il database di replica ampiamente sincronizzato con l'origine. Ad esempio, un job cron può essere programmato per (a) copiare i log più recenti nella nuova posizione e (b) riprodurli ogni 15 minuti. In questo modo si riduce al minimo l'interruzione al momento del cutover, in quanto è necessario riprodurre non più di 15 minuti dei registri di archivio.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">La procedura illustrata di seguito è essenzialmente un'operazione di clonazione del database. La logica illustrata è simile al motore all'interno di NetApp SnapManager per Oracle (SMO) e al plug-in NetApp SnapCenter per Oracle. Alcuni clienti utilizzano la procedura indicata negli script o nei workflow Wfa per le operazioni di cloning personalizzate. Sebbene questa procedura sia più manuale che non utilizzi SMO o SnapCenter, viene comunque rapidamente script e le API di gestione dei dati all'interno di ONTAP semplificano ulteriormente il processo.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Log shipping - dal file system al file system</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">In questo esempio viene illustrata la migrazione di un database denominato WAFFLE da un normale file system a un altro normale file system situato su un server diverso. Illustra anche l'utilizzo di SnapMirror per eseguire una copia rapida dei file di dati, ma questa non è parte integrante della procedura generale.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Creare il backup del database</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">Il primo passo consiste nel creare un backup del database. In particolare, questa procedura richiede una serie di file di dati che possono essere utilizzati per la riproduzione del log di archivio.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">Ambiente</block>
  <block id="82f9b672d88793b2ca5716b2a5427056" category="paragraph">In questo esempio, il database di origine si trova su un sistema ONTAP. Il metodo più semplice per creare un backup di un database consiste nell'utilizzare una copia Snapshot. Il database viene messo in modalità di backup a caldo per alcuni secondi mentre un<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> l'operazione viene eseguita sul volume che ospita i file di dati.</block>
  <block id="1fd3a22cf15d1e18a6507f539346c40d" category="paragraph">Il risultato è una copia Snapshot su disco chiamata<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> che contiene un'immagine dei file di dati in modalità di backup a caldo. Se combinati con i log di archivio appropriati per rendere i file di dati coerenti, i dati in questa copia Snapshot possono essere utilizzati come base per un ripristino o un clone. In questo caso, viene replicato sul nuovo server.</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Ripristino in un nuovo ambiente</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">Ora il backup deve essere ripristinato nel nuovo ambiente. Questa operazione può essere eseguita in vari modi, tra cui Oracle RMAN, ripristino da un'applicazione di backup come NetBackup o semplice operazione di copia dei file di dati inseriti in modalità hot backup.</block>
  <block id="ca7da361ad92f677545e12dd462c6e39" category="paragraph">In questo esempio, SnapMirror viene utilizzato per replicare in una nuova posizione la copia Snapshot chiamata hot backup.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Creare un nuovo volume per ricevere i dati dello snapshot. Inizializzare il mirroring da<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> a.<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Una volta impostato lo stato da SnapMirror, a indicare che la sincronizzazione è completa, aggiornare il mirror in base allo snapshot desiderato,</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">La sincronizzazione può essere verificata visualizzando<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> sul volume speculare.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">Lo specchio può quindi essere rotto.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Montare il nuovo file system.con i file system basati su blocchi, le procedure precise variano in base al LVM in uso. È necessario configurare lo zoning FC o le connessioni iSCSI. Dopo aver stabilito la connettività ai LUN, comandi come Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Potrebbe essere necessario per rilevare quali gruppi di volumi o LUN devono essere configurati correttamente per essere rilevati da ASM.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">In questo esempio viene utilizzato un semplice file system NFS. Questo file system può essere montato direttamente.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Creare un modello di creazione controlfile</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">Successivamente, è necessario creare un modello controlfile. Il<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> comando crea comandi di testo per ricreare un controlfile. In alcuni casi, questa funzione può risultare utile per ripristinare un database da un backup e viene spesso utilizzata con script che eseguono attività come la clonazione dei database.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">L'output del comando seguente viene utilizzato per ricreare i file di controllo per il database migrato.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Una volta creati i file di controllo, copiarli nel nuovo server.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">File dei parametri di backup</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">Nel nuovo ambiente è necessario anche un file di parametri. Il metodo più semplice consiste nel creare un pfile dal file spfile o pfile corrente. In questo esempio, il database di origine utilizza un spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Crea voce oratab</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">La creazione di una voce oratab è necessaria per il corretto funzionamento di utility come oraenv. Per creare una voce oratab, completare il passaggio seguente.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Preparare la struttura delle directory</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Se le directory richieste non sono già presenti, è necessario crearle oppure la procedura di avvio del database non riesce. Per preparare la struttura di directory, completare i seguenti requisiti minimi.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Aggiornamenti del file dei parametri</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Per copiare il file dei parametri nel nuovo server, eseguire i seguenti comandi. La posizione predefinita è<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directory. In questo caso, il pfile può essere posizionato ovunque. Viene utilizzata solo come fase intermedia del processo di migrazione.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Modificare il file come richiesto. Ad esempio, se la posizione del log di archivio è stata modificata, il file pfile deve essere modificato per riflettere la nuova posizione. In questo esempio, vengono ricollocati solo i file di controllo, in parte per distribuirli tra i file system di log e di dati.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Al termine delle modifiche, creare un file spfile basato su questo file pfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Ricreare i file di controllo</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">In una fase precedente, l'output di<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> è stato copiato nel nuovo server. La parte specifica dell'uscita richiesta è la<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> comando. Queste informazioni si trovano nel file sotto la sezione contrassegnata<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Inizia con la linea<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> e dovrebbe includere la parola<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Termina con il punto e virgola (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">In questa procedura di esempio, il file viene letto come segue.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Modificare lo script come desiderato per riflettere la nuova posizione dei vari file. Ad esempio, alcuni file di dati noti per supportare un i/o elevato potrebbero essere reindirizzati a un file system su un Tier di storage dalle performance elevate. In altri casi, le modifiche possono essere apportate solo per motivi di amministrazione, ad esempio isolando i file di dati di un PDB in volumi dedicati.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">In questo esempio, il<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> stanza viene lasciata invariata, ma i log di redo vengono spostati in una nuova posizione in<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> piuttosto che condividere lo spazio con i log di archivio<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Se i file sono posizionati in modo errato o i parametri non sono configurati correttamente, vengono generati errori che indicano ciò che deve essere corretto. Il database è montato, ma non è ancora aperto e non può essere aperto perché i file di dati in uso sono ancora contrassegnati come in modalità di backup a caldo. Per rendere il database coerente, è necessario applicare prima i registri di archiviazione.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Replica iniziale del registro</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Per rendere coerenti i file di dati è necessaria almeno un'operazione di risposta del registro. Sono disponibili molte opzioni per la riproduzione dei registri. In alcuni casi, la posizione originale del log di archivio sul server originale può essere condivisa tramite NFS e la risposta del log può essere effettuata direttamente. In altri casi, è necessario copiare i registri di archivio.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Ad esempio, un semplice<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> l'operazione può copiare tutti i log correnti dal server di origine al server di migrazione:</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Riproduzione del registro iniziale</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Una volta che i file si trovano nella posizione del log di archivio, è possibile riprodurli inviando il comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguito dalla risposta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> per riprodurre automaticamente tutti i registri disponibili.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">La risposta finale del log di archivio riporta un errore, ma questo è normale. Il registro indica che<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> stava cercando un particolare file di registro e non lo ha trovato. Il motivo è, molto probabilmente, che il file di registro non esiste ancora.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Se il database di origine può essere arrestato prima di copiare i registri di archivio, questa operazione deve essere eseguita una sola volta. I log di archivio vengono copiati e riprodotti, quindi il processo può continuare direttamente con il processo di cutover che replica i log di ripristino critici.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Replica e riproduzione incrementale dei log</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">Nella maggior parte dei casi, la migrazione non viene eseguita immediatamente. Il completamento del processo di migrazione potrebbe richiedere alcuni giorni o addirittura settimane, pertanto i log devono essere inviati continuamente al database di replica e riprodotti. Pertanto, quando arriva il cutover, occorre trasferire e riprodurre minimi dati.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">In questo modo è possibile eseguire script in molti modi diversi, ma uno dei metodi più diffusi è l'utilizzo di rsync, un'utilità comune di replica dei file. Il modo più sicuro per usare questa utility è configurarla come demone. Ad esempio, il<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> file che segue mostra come creare una risorsa chiamata<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> A cui si accede con le credenziali utente Oracle e a cui è mappato<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Soprattutto, la risorsa è impostata su sola lettura, consentendo la lettura dei dati di produzione, ma non l'alterazione.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">Il seguente comando sincronizza la destinazione del log di archivio del nuovo server con la risorsa rsync<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> sul server originale. Il<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> argomento in<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> fa sì che l'elenco di file venga confrontato in base alla data e all'ora e che vengano copiati solo i nuovi file. Questo processo fornisce un aggiornamento incrementale del nuovo server. Questo comando può anche essere programmato in cron per essere eseguito regolarmente.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Riproduci i registri sul database</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Una volta ricevuti i registri, è necessario riprodurli. Gli esempi precedenti mostrano l'uso di sqlplus per l'esecuzione manuale<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, un processo che può essere facilmente automatizzato. Nell'esempio illustrato viene utilizzato lo script descritto nella <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Gli script accettano un argomento che specifica il database che richiede un'operazione di riproduzione. Ciò consente di utilizzare lo stesso script in una migrazione di più database.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Cutover</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Quando si è pronti per il passaggio al nuovo ambiente, è necessario eseguire una sincronizzazione finale che includa sia i registri di archivio che i registri di ripristino. Se la posizione originale del log di ripristino non è già nota, è possibile identificarla come segue:</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Arrestare il database di origine.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Eseguire una sincronizzazione finale dei registri di archivio sul nuovo server con il metodo desiderato.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">I log di ripristino di origine devono essere copiati nel nuovo server. In questo esempio, i log di ripristino sono stati spostati in una nuova directory all'indirizzo<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">In questa fase, il nuovo ambiente di database contiene tutti i file necessari per portarlo nello stesso stato dell'origine. I registri di archivio devono essere riprodotti una volta finale.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Al termine, i log di ripristino devono essere riprodotti. Se il messaggio<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> viene restituito, il processo è riuscito e i database sono sincronizzati e possono essere aperti.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Log shipping - da ASM a file system</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">In questo esempio viene illustrato l'utilizzo di Oracle RMAN per la migrazione di un database. È molto simile all'esempio precedente di distribuzione del log del file system, ma i file su ASM non sono visibili all'host. Le uniche opzioni per la migrazione dei dati presenti sui dispositivi ASM sono il riposizionamento del LUN ASM o l'utilizzo di Oracle RMAN per eseguire le operazioni di copia.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Sebbene RMAN sia un requisito per la copia dei file da Oracle ASM, l'utilizzo di RMAN non è limitato a ASM. RMAN può essere utilizzato per migrare da qualsiasi tipo di storage a qualsiasi altro tipo.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Questo esempio mostra il trasferimento di un database chiamato PANCAKE dallo storage ASM a un file system normale situato su un server diverso nei percorsi<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> e.<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">Il primo passo consiste nel creare un backup del database da migrare su un server alternativo. Poiché l'origine utilizza Oracle ASM, è necessario utilizzare RMAN. Un semplice backup RMAN può essere eseguito come segue. Questo metodo crea un backup con tag che può essere facilmente identificato da RMAN più avanti nella procedura.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">Il primo comando definisce il tipo di destinazione per il backup e la posizione da utilizzare. Il secondo avvia il backup dei soli file di dati.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Backup controlfile</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Un controlfile di backup è necessario più avanti nella procedura per<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> operazione.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">Nel nuovo ambiente è necessario anche un file di parametri. Il metodo più semplice consiste nel creare un pfile dal file spfile o pfile corrente. In questo esempio, il database di origine utilizza un spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Script di ridenominazione file ASM</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Diverse posizioni dei file attualmente definite nei file di controllo cambiano quando il database viene spostato. Lo script seguente crea uno script RMAN per semplificare il processo. Questo esempio mostra un database con un numero molto ridotto di file di dati, ma in genere i database contengono centinaia o addirittura migliaia di file di dati.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Conversione da ASM a nome file system</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Questo script si trova in <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> e fa due cose.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">In primo luogo, viene creato un parametro per ridefinire le posizioni del log di ripristino chiamate<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Si tratta essenzialmente di un elenco di campi alternati. Il primo campo rappresenta la posizione di un registro di ripristino corrente, mentre il secondo campo rappresenta la posizione sul nuovo server. Il modello viene quindi ripetuto.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">La seconda funzione consiste nel fornire un modello per la ridenominazione dei file di dati. Lo script esegue il ciclo dei file di dati, estrae le informazioni sul nome e sul numero del file e lo formatta come uno script RMAN. Quindi fa lo stesso con i file temporanei. Il risultato è un semplice script rman che può essere modificato come desiderato per assicurarsi che i file vengano ripristinati nella posizione desiderata.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Acquisire l'output di questa schermata. Il<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> il parametro viene inserito nel file pfile come descritto di seguito. Il file di dati RMAN rinominato e lo script duplicato devono essere modificati di conseguenza per posizionare i file di dati nelle posizioni desiderate. In questo esempio, sono tutti inseriti<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Gli script sono quasi pronti per l'esecuzione, ma prima la struttura di directory deve essere in posizione. Se le directory richieste non sono già presenti, è necessario crearle oppure la procedura di avvio del database non riesce. L'esempio riportato di seguito riflette i requisiti minimi.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">Il seguente comando è necessario per il corretto funzionamento di utility come oraenv.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Aggiornamenti dei parametri</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">Il file pfile salvato deve essere aggiornato per riflettere eventuali modifiche di percorso sul nuovo server. Le modifiche al percorso del file di dati vengono modificate dallo script di duplicazione RMAN e quasi tutti i database richiedono modifiche al<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> e.<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> parametri. Potrebbero inoltre essere presenti posizioni dei file di controllo che devono essere modificate e parametri quali<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Potrebbe non essere rilevante al di fuori di ASM. Prima di procedere, un DBA esperto deve esaminare attentamente le modifiche proposte.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">In questo esempio, le modifiche principali sono le posizioni controlfile, la destinazione di archivio del registro e l'aggiunta di<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Dopo la conferma dei nuovi parametri, i parametri devono essere applicati. Esistono diverse opzioni, ma la maggior parte dei clienti crea un file spfile basato sul file pfile di testo.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Nomount di avvio</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">Il passaggio finale prima della replica del database consiste nel visualizzare i processi del database ma non nel montare i file. In questa fase, potrebbero manifestarsi problemi con spfile. Se il<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> comando non riesce a causa di un errore di parametro, è semplice chiudere, correggere il modello pfile, ricaricarlo come spfile, e riprovare.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Duplicare il database</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">Il ripristino del backup RMAN precedente nella nuova posizione richiede più tempo rispetto ad altre fasi di questo processo. Il database deve essere duplicato senza modificare l'ID del database (DBID) o reimpostare i registri. Ciò impedisce l'applicazione dei registri, operazione necessaria per la sincronizzazione completa delle copie.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Connettersi al database con RMAN come aux ed eseguire il comando duplicato del database utilizzando lo script creato in un passaggio precedente.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">A questo punto è necessario inviare le modifiche dal database di origine a una nuova posizione. In tal caso, potrebbe essere necessario eseguire una combinazione di operazioni. Il metodo più semplice sarebbe fare in modo che RMAN nel database di origine scriva i log di archivio in una connessione di rete condivisa. Se una posizione condivisa non è disponibile, un metodo alternativo consiste nell'utilizzare RMAN per scrivere su un file system locale e quindi utilizzare rcp o rsync per copiare i file.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">In questo esempio, il<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Directory è una condivisione NFS disponibile sia per il database originale che per quello migrato.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">Una questione importante in questo caso è la<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> clausola. Il formato del disco del backup è<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Che significa che è necessario utilizzare il formato del numero di thread, il numero di sequenza e l'ID di attivazione per il database. Anche se le lettere sono diverse, questa corrisponde alla<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> parametro nel pfile. Questo parametro specifica inoltre i log di archivio nel formato di numero di thread, numero di sequenza e ID di attivazione. Il risultato finale è che i backup del file di registro sull'origine utilizzano una convenzione di denominazione prevista dal database. In questo modo, vengono eseguite operazioni come<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> molto più semplice perché sqlplus anticipa correttamente i nomi dei log di archivio da riprodurre.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Una volta che i file si trovano nella posizione del log di archivio, è possibile riprodurli inviando il comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguito dalla risposta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> per riprodurre automaticamente tutti i registri disponibili. Il file dei parametri sta attualmente indirizzando i log di archivio a.<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Ma non corrisponde alla posizione in cui RMAN è stato utilizzato per salvare i registri. La posizione può essere reindirizzata temporaneamente come segue prima di ripristinare il database.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">La risposta finale del log di archivio riporta un errore, ma questo è normale. L'errore indica che sqlplus stava cercando un particolare file di registro e non lo ha trovato. Il motivo è molto probabile che il file di registro non esista ancora.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">Nella maggior parte dei casi, la migrazione non viene eseguita immediatamente. Il completamento del processo di migrazione potrebbe richiedere alcuni giorni o addirittura settimane, pertanto i log devono essere inviati continuamente al database di replica e riprodotti. In questo modo si assicura che i dati minimi debbano essere trasferiti e riprodotti all'arrivo del cutover.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Questo processo può essere facilmente gestito tramite script. Ad esempio, è possibile pianificare il seguente comando nel database originale per assicurarsi che la posizione utilizzata per la spedizione dei log venga aggiornata continuamente.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Replay Logs on Standby Database</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Una volta ricevuti i registri, è necessario riprodurli. Gli esempi precedenti hanno mostrato l'uso di sqlplus per l'esecuzione manuale<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, che può essere facilmente automatizzato. Nell'esempio illustrato viene utilizzato lo script descritto nella <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. Lo script accetta un argomento che specifica il database che richiede un'operazione di riproduzione. Questo processo consente di utilizzare lo stesso script in una migrazione di più database.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Quando si è pronti a passare al nuovo ambiente, è necessario eseguire una sincronizzazione finale. Quando si lavora con i normali file system, è facile assicurarsi che il database migrato sia sincronizzato al 100% rispetto all'originale, poiché i log di ripristino originali vengono copiati e riprodotti. Con ASM non esiste un buon modo per farlo. È possibile recuperare facilmente solo i registri di archivio. Per assicurarsi che i dati non vadano persi, è necessario eseguire con attenzione l'arresto finale del database originale.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">In primo luogo, la base di dati deve essere chiusa, garantendo che non vengano apportate modifiche. Questa chiusura potrebbe includere la disattivazione delle operazioni pianificate, la chiusura dei listener e/o la chiusura delle applicazioni.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Una volta eseguita questa operazione, la maggior parte dei DBA crea una tabella fittizia da utilizzare come indicatore dell'arresto.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Forzare l'archiviazione di un registro per assicurarsi che la creazione della tabella fittizia sia registrata nei registri di archivio. A tale scopo, eseguire i seguenti comandi:</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Per copiare l'ultimo dei registri di archivio, eseguire i seguenti comandi. Il database deve essere disponibile ma non aperto.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Per copiare i log di archivio, eseguire i seguenti comandi:</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Infine, riprodurre i log di archivio rimanenti sul nuovo server.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">In questa fase, replicare tutti i dati. Il database è pronto per essere convertito da un database di standby a un database operativo attivo e quindi aperto.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Verificare la presenza della tabella fittizia e poi rilasciarla.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Migrazione dei log di ripristino senza interruzioni</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">A volte, un database è organizzato correttamente in generale, ad eccezione dei registri di ripristino. Questo può accadere per molte ragioni, la più comune delle quali è correlata agli snapshot. Prodotti come SnapManager per Oracle, SnapCenter e il framework di gestione dello storage NetApp Snap Creator consentono il ripristino quasi istantaneo di un database, ma solo se vengono ripristinati i volumi dei file di dati. Se i log di redo condividono lo spazio con i file di dati, non è possibile eseguire la reversione in modo sicuro, poiché causerebbe la distruzione dei log di redo, probabilmente la perdita di dati. Pertanto, i log di ripristino devono essere spostati.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Questa procedura è semplice e può essere eseguita senza interruzioni.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Configurazione corrente del log di ripristino</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Identificare il numero di gruppi di log di ripristino e i rispettivi numeri di gruppo.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Immettere le dimensioni dei registri di ripristino.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Creare nuovi registri</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo con dimensioni e numero di membri corrispondenti.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Verificare la nuova configurazione.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Rilasciare i vecchi registri</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Rilasciare i vecchi registri (gruppi 1, 2 e 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Se si verifica un errore che impedisce di rilasciare un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un checkpoint globale. Fare riferimento al seguente esempio di questo processo. Il tentativo di rilasciare il gruppo di file di registro 2, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Un'archiviazione dei log seguita da un punto di verifica consente di rilasciare il file di log.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">Quindi, eliminare i log dal file system. Questo processo deve essere eseguito con estrema attenzione.</block>
  <block id="eb290dfcb2d35cffcb49a22fd05168b5" category="summary">Pianificazione della migrazione a Oracle</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">La migrazione dei dati Oracle può avvenire a uno di tre livelli: Database, host o storage array.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Le differenze risiedono in quale componente della soluzione globale è responsabile dello spostamento dei dati: Il database, il sistema operativo host o il sistema di archiviazione.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">La figura riportata di seguito mostra un esempio dei livelli di migrazione e del flusso di dati. In caso di migrazione a livello di database, i dati vengono spostati dal sistema di storage originale ai livelli di host e database nel nuovo ambiente. La migrazione a livello di host è simile, ma i dati non passano attraverso il livello di applicazione e vengono invece scritti nella nuova posizione utilizzando i processi degli host. Infine, con la migrazione a livello di storage, un array come un sistema NetApp FAS si occupa dello spostamento dei dati.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Una migrazione a livello di database si riferisce generalmente all'utilizzo di Oracle log shipping attraverso un database di standby per completare una migrazione a livello di Oracle. Le migrazioni a livello di host vengono eseguite utilizzando le funzionalità native della configurazione del sistema operativo host. Questa configurazione include le operazioni di copia dei file utilizzando comandi quali cp, tar e Oracle Recovery Manager (RMAN) o un gestore del volume logico (LVM) per spostare i byte sottostanti di un file system. Oracle Automatic Storage Management (ASM) è classificato come capacità a livello di host perché viene eseguito al di sotto del livello dell'applicazione di database. ASM sostituisce il normale volume manager logico su un host. Infine, i dati possono essere migrati a livello di storage array, il che significa sotto il livello del sistema operativo.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Considerazioni sulla pianificazione</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">La scelta migliore per la migrazione dipende da una combinazione di fattori, inclusa la dimensione dell'ambiente da migrare, la necessità di evitare il downtime e lo sforzo complessivo necessario per eseguire la migrazione. Ovviamente, i database di grandi dimensioni richiedono più tempo e lavoro per la migrazione, ma la complessità di una migrazione di questo tipo è minima. I database di piccole dimensioni possono essere migrati rapidamente, ma se ne devono migrare migliaia, la portata dello sforzo può creare complicazioni. Infine, più grande è il database, più probabile è che l'IT sia business-critical, generando la necessità di ridurre al minimo i downtime mantenendo un percorso di back-out.</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Alcune considerazioni per la pianificazione di una strategia di migrazione sono discusse qui.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Dimensioni dei dati</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">Le dimensioni dei database da migrare influiscono ovviamente sulla pianificazione della migrazione, sebbene le dimensioni non influiscano necessariamente sul tempo di cutover. Quando è necessario migrare una grande quantità di dati, l'aspetto più importante è la larghezza di banda. Le operazioni di copia vengono in genere eseguite con un efficiente i/o sequenziale Come stima conservativa, si presuppone un utilizzo del 50% della larghezza di banda della rete disponibile per le operazioni di copia. Ad esempio, una porta FC da 8GB GB può trasferire in teoria circa 800Mbps GB. Ipotizzando un utilizzo del 50%, è possibile copiare un database a una velocità di circa 400Mbps KB. Pertanto, un database 10TB può essere copiato in circa sette ore a questa velocità.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Spostamento file dati online</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Numero di database</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">In molti casi, il problema dello spostamento di una grande quantità di dati non è la dimensione dei dati, ma piuttosto la complessità della configurazione che supporta il database. Semplicemente sapere che 50TB database devono essere migrati non è sufficiente. Può essere un singolo database mission-critical 50TB, una raccolta di 4 database legacy 000 o un mix di dati di produzione e non. In alcuni casi, gran parte dei dati è costituita da cloni di un database di origine. Non è necessario migrare questi cloni perché possono essere facilmente ricreati, specialmente quando la nuova architettura è progettata per sfruttare i volumi FlexClone di NetApp.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Per la pianificazione della migrazione, è necessario comprendere il numero dei database interessati e la priorità da assegnare. Con l'aumento del numero di database, l'opzione di migrazione preferita tende a essere più bassa e più bassa nello stack. Ad esempio, la copia di un singolo database può essere eseguita facilmente con RMAN e con una breve interruzione del servizio. Si tratta di una replica a livello di host.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">Se ci sono 50 database, potrebbe essere più facile evitare di impostare una nuova struttura del file system per ricevere una copia RMAN e spostare invece i dati sul posto. Questo processo può essere eseguito sfruttando la migrazione LVM basata su host per spostare i dati dalle vecchie LUN ai nuovi LUN. In tal modo, la responsabilità viene trasferita dal team di amministratori del database (DBA) al team del sistema operativo e, di conseguenza, i dati vengono migrati in modo trasparente rispetto al database. La configurazione del file system rimane invariata.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Infine, se occorre migrare 500 database su 200 server, è possibile utilizzare opzioni basate sullo storage come la funzionalità FLI (ONTAP Foreign LUN Import) per eseguire una migrazione diretta delle LUN.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Requisiti di riarchitettura</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">In genere, per sfruttare le funzionalità del nuovo storage array è necessario modificare il layout dei file del database; tuttavia, non sempre questo avviene. Ad esempio, le funzionalità degli array all-flash EF-Series sono rivolte principalmente alle performance e all'affidabilità della SAN. Nella maggior parte dei casi, i database possono essere migrati su un array EF-Series senza particolari considerazioni sul layout dei dati. Gli unici requisiti sono IOPS elevati, bassa latenza e solida affidabilità. Sebbene esistano Best practice correlate a fattori quali la configurazione RAID o Dynamic Disk Pools, i progetti EF-Series raramente richiedono modifiche significative all'architettura dello storage generale per sfruttare tali funzionalità.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">Al contrario, la migrazione a ONTAP richiede in genere una maggiore considerazione del layout del database per garantire che la configurazione finale fornisca il massimo valore. In sé, ONTAP offre molte funzionalità per un ambiente di database, anche senza interventi specifici sull'architettura. Soprattutto, offre la possibilità di migrare senza interruzioni al nuovo hardware quando l'hardware attuale termina la sua vita utile. In generale, la migrazione a ONTAP è l'ultima migrazione che è necessario eseguire. L'hardware successivo viene aggiornato e i dati vengono migrati senza interruzioni sui nuovi supporti.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Con una certa pianificazione, ancora più benefici sono disponibili. Le considerazioni più importanti riguardano l'uso delle istantanee. Le snapshot sono la base per l'esecuzione di backup, ripristini e operazioni di cloning quasi istantanei. Come esempio della potenza delle istantanee, il più grande utilizzo noto è con un singolo database di 996TB in esecuzione su circa 250 LUN su 6 controller. È possibile eseguire il backup di questo database in 2 minuti, ripristinarlo in 2 minuti e clonarlo in 15 minuti. Tra gli altri benefici, è inclusa la capacità di spostare i dati nel cluster in risposta alle variazioni del carico di lavoro e all'applicazione di controlli di qualità del servizio (QoS) per offrire performance buone e coerenti in un ambiente multi-database.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Panoramica delle procedure di migrazione Oracle</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Tecnologie come controlli della QoS, trasferimento dei dati, snapshot e cloning funzionano praticamente in ogni configurazione. Tuttavia, un certo pensiero è generalmente richiesto per elevare i benefici. In alcuni casi, i layout dello storage del database possono richiedere modifiche di progettazione per massimizzare l'investimento nel nuovo storage array. Tali modifiche di progettazione possono influire sulla strategia di migrazione perché le migrazioni basate su host o su storage replicano il layout dei dati originale. Per completare la migrazione e offrire un layout dei dati ottimizzato per ONTAP potrebbero essere necessari ulteriori passaggi. Le procedure illustrate nella <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> in seguito, dimostrare alcuni metodi non solo per migrare un database, ma anche per eseguirne la migrazione nel layout finale ottimale con il minimo sforzo.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Tempo di cutover</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Occorre determinare il disservizio massimo consentito del servizio durante il cutover. È un errore comune presumere che l'intero processo di migrazione causi interruzioni. È possibile eseguire numerose attività prima dell'inizio di qualsiasi interruzione del servizio e completare la migrazione senza interruzioni o black-out attraverso diverse opzioni. Anche quando è inevitabile un'interruzione, è comunque necessario definire il fuori servizio massimo consentito poiché la durata del tempo di cutover varia da procedura a procedura.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Percorso di ritorno</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Nessuna migrazione è completamente priva di rischi. Anche se la tecnologia funziona perfettamente, c'è sempre la possibilità di errori da parte dell'utente. Il rischio associato a un percorso di migrazione scelto deve essere preso in considerazione insieme alle conseguenze di una migrazione non riuscita. Ad esempio, la capacità di migrazione trasparente dello storage online di Oracle ASM è una delle sue caratteristiche principali e questo metodo è uno dei più affidabili. Tuttavia, i dati vengono copiati irreversibilmente con questo metodo. Nel caso altamente improbabile in cui si verifichi un problema con ASM, non esiste un facile percorso di back-out. L'unica opzione è ripristinare l'ambiente originale o utilizzare ASM per riportare la migrazione ai LUN originali. Il rischio può essere minimizzato, ma non eliminato, eseguendo un backup di tipo snapshot sul sistema di storage originale, supponendo che il sistema sia in grado di eseguire tale operazione.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Prova</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Alcune procedure di migrazione devono essere verificate completamente prima dell'esecuzione. La necessità di migrazione e verifica del processo di cutover è una richiesta comune con i database mission-critical per i quali la migrazione deve avere successo e il downtime deve essere ridotto al minimo. Inoltre, i test di accettazione da parte dell'utente sono spesso inclusi come parte del lavoro di post-migrazione e il sistema complessivo può essere riportato in produzione solo dopo il completamento di questi test.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">In caso di necessità di prove, diverse funzionalità di ONTAP possono rendere il processo molto più semplice. In particolare, le istantanee possono ripristinare un ambiente di test e creare rapidamente più copie di un ambiente di database efficienti in termini di spazio.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migrazione di singoli file di dati Oracle</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Spostamento del file dati</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">È possibile spostare singoli file di dati Oracle con un singolo comando.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Ad esempio, il comando seguente sposta il file dati IOPST.dbf dal filesystem<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> al filesystem<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Lo spostamento di un file dati con questo metodo può essere lento, ma in genere non dovrebbe produrre i/o sufficienti da interferire con i carichi di lavoro del database quotidiani. Al contrario, la migrazione tramite il ribilanciamento di ASM può essere eseguita molto più rapidamente, ma con il rischio di rallentare il database globale durante lo spostamento dei dati.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">È possibile misurare facilmente il tempo necessario per spostare i file di dati creando un file di dati di test e spostandolo. Il tempo trascorso per l'operazione viene registrato nei dati di v$session:</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">In questo esempio, il file spostato era datafile 8, della dimensione di 21GB GB e della durata di 6 minuti per la migrazione. Il tempo necessario dipende ovviamente dalle funzionalità del sistema di storage, della rete di storage e dall'attività complessiva del database che si verifica al momento della migrazione.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Migrazione di Oracle mediante lo stack di storage lato host</block>
  <block id="174f3246d5f9cdf330404cb6158e67e2" category="doc">Copia dei dati host Oracle</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">Come per la migrazione a livello di database, la migrazione nel layer host fornisce un approccio indipendente dal vendor di soluzioni di storage.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">In altre parole, talvolta "basta copiare i file" è l'opzione migliore.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Sebbene questo approccio a bassa tecnologia possa sembrare troppo semplice, offre comunque vantaggi significativi in quanto non è richiesto alcun software speciale e i dati originali rimangono intatti in tutta sicurezza durante il processo. Il limite principale è rappresentato dal fatto che la migrazione dei dati di una copia file causa interruzioni, poiché il database deve essere arrestato prima dell'inizio dell'operazione di copia. Non esiste un buon modo per sincronizzare le modifiche all'interno di un file, quindi i file devono essere completamente disattivati prima che la copia abbia inizio.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Se l'arresto richiesto da un'operazione di copia non è desiderabile, l'opzione successiva migliore basata su host è sfruttare un Logical Volume Manager (LVM). Esistono molte opzioni LVM, tra cui Oracle ASM, tutte con funzionalità simili, ma anche con alcune limitazioni che è necessario tenere in considerazione. Nella maggior parte dei casi, la migrazione può essere eseguita senza downtime e interruzioni.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Copia da filesystem a filesystem</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">L'utilità di una semplice operazione di copia non deve essere sottovalutata. Si tratta di un processo altamente affidabile che non richiede particolari competenze su sistemi operativi, database o sistemi storage. Inoltre, è molto sicuro perché non influisce sui dati originali. In genere, un amministratore di sistema modifica i file system di origine in modo che vengano montati in sola lettura e quindi riavvia un server per garantire che nessun elemento possa danneggiare i dati correnti. Il processo di copia può essere eseguito tramite script per garantire che venga eseguito il più rapidamente possibile senza il rischio di errori dell'utente. Poiché il tipo di i/o è un semplice trasferimento sequenziale dei dati, risulta estremamente efficiente in termini di larghezza di banda.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">Nell'esempio seguente viene illustrata un'opzione per una migrazione sicura e rapida.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">L'ambiente da migrare è il seguente:</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">File system attuali</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Nuovi file system</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Panoramica</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">Un DBA può migrare il database chiudendo semplicemente il database e copiando i file. Tuttavia, se occorre migrare molti database o ridurre al minimo il downtime, il processo può essere facilmente gestito tramite script. L'utilizzo di script riduce inoltre la possibilità di errori da parte dell'utente.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Gli script di esempio illustrati automatizzano le seguenti operazioni:</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Chiusura del database in corso</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Conversione dei file system esistenti in uno stato di sola lettura</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Copiare tutti i dati dai file system di origine a quelli di destinazione, mantenendo tutte le autorizzazioni dei file</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Smontaggio dei file system vecchi e nuovi</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Rimontaggio dei nuovi file system negli stessi percorsi dei file system precedenti</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Procedura</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Arrestare il database.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Convertire il file system in sola lettura</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Convertire i file system in sola lettura. Questa operazione può essere eseguita più rapidamente utilizzando uno script, come illustrato nella <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Verificare che i file system siano ora di sola lettura.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Sincronizzare il contenuto del file system con<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> comando.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Sostituire il file system</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Smontare i vecchi file system e riposizionare i dati copiati. Questa operazione può essere eseguita più rapidamente utilizzando uno script, come illustrato nella <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Verificare che i nuovi file system siano in posizione.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Avviare il database.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Cutover completamente automatizzato</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Questo script di esempio accetta argomenti del SID del database seguiti da coppie di file system delimitate in comune. Per l'esempio sopra illustrato, il comando viene inviato come segue:</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Quando viene eseguito, lo script di esempio tenta di eseguire la seguente sequenza. Termina se incontra un errore in qualsiasi fase:</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Convertire i file system correnti in stato di sola lettura.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Utilizzare ciascuna coppia di argomenti del file system delimitati da virgole e sincronizzare il primo file system con il secondo.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Smontare i file system precedenti.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Aggiornare<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archiviare come segue:</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Creare un backup in<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Annotare le voci precedenti per i file system precedenti e nuovi.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Creare una nuova voce per il nuovo file system che utilizza il vecchio punto di montaggio.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Montare i file system.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">Il testo seguente fornisce un esempio di esecuzione per questo script:</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Migrazione Oracle ASM spfile e passwd</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Una difficoltà nel completare la migrazione che coinvolge ASM è rappresentata dallo spfile specifico per ASM e dal file delle password. Per impostazione predefinita, questi file di metadati critici vengono creati nel primo gruppo di dischi ASM definito. Se un particolare gruppo di dischi ASM deve essere evacuato e rimosso, il file spfile e la password che governano l'istanza ASM deve essere riposizionato.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Un altro caso d'utilizzo in cui potrebbe essere necessario trasferire questi file è durante una distribuzione di software di gestione del database, come SnapManager per Oracle o il plug-in SnapCenter Oracle. Una delle funzionalità di questi prodotti è il ripristino rapido di un database ripristinando lo stato dei LUN ASM che ospitano i file di dati. Per eseguire questa operazione, è necessario portare il gruppo di dischi ASM offline prima di eseguire un ripristino. Questo non è un problema, purché i file di dati di un determinato database siano isolati in un gruppo di dischi ASM dedicato.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Quando il gruppo di dischi contiene anche il file ASM spfile/passwd, l'unico modo per mettere il gruppo di dischi in modalità non in linea è arrestare l'intera istanza ASM. Si tratta di un processo di interruzione, il che significa che il file spfile/passwd dovrebbe essere riposizionato.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">SID database = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">File di dati correnti su<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">File di log e file di controllo correnti attivati<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Nuovi gruppi di dischi ASM stabiliti come<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> e.<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Posizioni dei file spfile/passwd ASM</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">Il trasferimento di questi file può essere eseguito senza interruzione delle attività. Tuttavia, per motivi di sicurezza, NetApp consiglia di arrestare l'ambiente del database in modo da poter essere certi che i file siano stati spostati e che la configurazione sia stata aggiornata correttamente. Questa procedura deve essere ripetuta se su un server sono presenti più istanze ASM.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Identificare le istanze ASM</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Identificare le istanze ASM in base ai dati registrati in<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> file. Le istanze di ASM sono indicate dal simbolo +.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Su questo server è presente un'istanza ASM denominata +ASM.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Assicurarsi che tutti i database siano chiusi</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">L'unico processo di smon visibile dovrebbe essere quello per l'istanza ASM in uso. La presenza di un altro processo di smon indica che un database è ancora in esecuzione.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">L'unico processo di smon è l'istanza ASM stessa. Ciò significa che nessun altro database è in esecuzione ed è sicuro procedere senza il rischio di interrompere le operazioni del database.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Individuare i file</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Identificare la posizione corrente del file spfile e della password di ASM utilizzando<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> e.<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> comandi.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">I file si trovano entrambi alla base di<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> gruppo di dischi.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Copiare i file</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Copiare i file nel nuovo gruppo di dischi ASM con<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> e.<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> comandi. Se il nuovo gruppo di dischi è stato creato di recente ed è attualmente vuoto, potrebbe essere necessario montarlo per primo.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">I file sono stati copiati da<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> a.<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">Aggiornare l'istanza ASM</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">L'istanza ASM deve ora essere aggiornata per riflettere la modifica della posizione. Il<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> e.<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> I comandi aggiornano i metadati ASM richiesti per l'avvio del gruppo di dischi ASM.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Attivare ASM utilizzando i file aggiornati</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">A questo punto, l'istanza ASM utilizza ancora le posizioni precedenti di questi file. L'istanza deve essere riavviata per forzare una rilettura dei file dalle nuove posizioni e per rilasciare i blocchi sui file precedenti.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Rimuovere i vecchi file spfile e password</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Se la procedura è stata eseguita correttamente, i file precedenti non sono più bloccati e possono essere rimossi.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Copia da Oracle ASM a ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM è essenzialmente un volume manager e un file system combinati e leggeri. Poiché il file system non è facilmente visibile, è necessario utilizzare RMAN per eseguire operazioni di copia. Sebbene il processo di migrazione basato sulle copie sia sicuro e semplice, si traduce in un'interruzione. È possibile ridurre al minimo le interruzioni, ma non eliminarle completamente.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Se si desidera eseguire la migrazione senza interruzioni di un database basato su ASM, l'opzione migliore è sfruttare la capacità di ASM di riequilibrare le estensioni ASM nei nuovi LUN, eliminando al contempo i vecchi LUN. In genere, questo tipo di operazioni è sicuro e senza interruzioni, ma non offre alcun percorso di back-out. Se si riscontrano problemi di funzionamento o di prestazioni, l'unica opzione è quella di trasferire nuovamente i dati all'origine.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Questo rischio può essere evitato copiando il database nella nuova posizione piuttosto che spostare i dati, in modo che i dati originali non vengano toccati. Il database può essere completamente testato nella sua nuova posizione prima di entrare in funzione e il database originale è disponibile come opzione di fallback se vengono rilevati problemi.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Questa procedura è una delle numerose opzioni che interessano RMAN. È progettato per consentire un processo in due fasi in cui viene creato il backup iniziale e quindi sincronizzato successivamente tramite la riproduzione del registro. Questo processo è auspicabile per ridurre al minimo i tempi di inattività, in quanto consente al database di rimanere operativo e di distribuire i dati durante la copia di base iniziale.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Copia database</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN crea una copia di livello 0 (completa) del database di origine attualmente presente nel gruppo di dischi ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> alla nuova posizione su<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Forzare l'interruttore del registro di archiviazione</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">È necessario forzare un'opzione del log di archivio per assicurarsi che i log di archivio contengano tutti i dati necessari per rendere la copia completamente coerente. Senza questo comando, i dati chiave potrebbero essere ancora presenti nei log di ripristino.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Arrestare il database di origine</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">L'interruzione inizia in questa fase perché il database viene arrestato e inserito in una modalità di sola lettura ad accesso limitato. Per arrestare il database di origine, eseguire i seguenti comandi:</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Backup ControlFile</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">È necessario eseguire il backup di controlfile nel caso in cui sia necessario interrompere la migrazione e ripristinare la posizione di archiviazione originale. Una copia del controlfile di backup non è richiesta al 100%, ma rende più semplice il processo di ripristino delle posizioni dei file di database nella posizione originale.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">Il file spfile corrente contiene riferimenti ai file di controllo nelle posizioni correnti all'interno del vecchio gruppo di dischi ASM. Deve essere modificato, il che è fatto facilmente modificando una versione pfile intermedia.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Aggiornare pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Aggiornare tutti i parametri che fanno riferimento ai vecchi gruppi di dischi ASM per riflettere i nuovi nomi dei gruppi di dischi ASM. Quindi salvare il file pfile aggiornato. Assicurarsi che il<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> parametri presenti.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">Nell'esempio seguente, i riferimenti a.<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> che sono stati modificati in<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> sono evidenziati in giallo. Due parametri chiave sono<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> parametri che creano nuovi file nella posizione corretta.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Aggiorna il file init.ora</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">La maggior parte dei database basati su ASM utilizza un<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file che si trova in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Directory, che è un punto di spfile sul gruppo di dischi ASM. Questo file deve essere reindirizzato a una posizione sul nuovo gruppo di dischi ASM.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Modificare questo file come segue:</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Ricreazione del file dei parametri</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">spfile è ora pronto per essere popolato dai dati nel pfile modificato.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Avviare il database per iniziare a utilizzare il nuovo spfile</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Avviare il database per assicurarsi che utilizzi ora il nuovo spfile creato e che eventuali ulteriori modifiche ai parametri di sistema siano registrate correttamente.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Ripristina controlfile</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">Il controlfile di backup creato da RMAN può anche essere ripristinato da RMAN direttamente nella posizione specificata nel nuovo spfile.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Montare il database e verificare l'uso del nuovo controlfile.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Riproduzione del registro</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">Il database utilizza attualmente i file di dati nella vecchia posizione. Prima di poter utilizzare la copia, è necessario sincronizzarla. È trascorso del tempo durante il processo di copia iniziale e le modifiche sono state registrate principalmente nei registri di archivio. Queste modifiche vengono replicate come segue:</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Eseguire un backup incrementale RMAN, che contiene i registri di archivio.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Riprodurre nuovamente il registro.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Attivazione</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">Il controlfile ripristinato fa ancora riferimento ai file di dati nella posizione originale e contiene anche le informazioni di percorso per i file di dati copiati.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Per modificare i file di dati attivi, eseguire<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">I file di dati attivi sono ora i file di dati copiati, ma potrebbero comunque essere presenti modifiche nei log di ripristino finali.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Per riprodurre tutti i registri rimanenti, eseguire il<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando. Se il messaggio<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> il processo è stato eseguito correttamente.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Questo processo ha modificato solo la posizione dei file di dati normali. I file di dati temporanei devono essere rinominati, ma non devono essere copiati perché sono solo temporanei. Il database è attualmente inattivo, pertanto non sono presenti dati attivi nei file di dati temporanei.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Per spostare i file di dati temporanei, identificarne prima la posizione.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Spostare i file di dati temporanei utilizzando un comando RMAN che imposta il nuovo nome per ciascun file di dati. Con Oracle Managed Files (OMF), il nome completo non è necessario; il gruppo di dischi ASM è sufficiente. Quando il database viene aperto, OMF si collega alla posizione appropriata nel gruppo di dischi ASM. Per spostare i file, eseguire i seguenti comandi:</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migrazione dei log di ripristino</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">Il processo di migrazione è quasi completo, ma i log di ripristino si trovano ancora nel gruppo di dischi ASM originale. I log di ripristino non possono essere spostati direttamente. Viene invece creata una nuova serie di log di ripristino che viene aggiunta alla configurazione, seguita da una rimozione dei log precedenti.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo con una configurazione corrispondente. Se non si utilizza OMF, è necessario specificare il percorso completo. Questo è anche un esempio che utilizza<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> parametri. Come mostrato in precedenza, questo parametro era impostato su +NEWLOGS. Questa configurazione consente di utilizzare i seguenti comandi per creare nuovi registri online senza dover specificare un percorso di file o un gruppo di dischi ASM specifico.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Aprire il database.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Rilasciare i vecchi registri.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Se si verifica un errore che impedisce di rilasciare un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un checkpoint globale. Di seguito è riportato un esempio. Il tentativo di rilasciare il gruppo di file di registro 3, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi. L'archiviazione di un registro dopo un punto di verifica consente di eliminare il file di registro.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Esaminare l'ambiente per assicurarsi che tutti i parametri basati sulla posizione siano aggiornati.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">Nello script seguente viene illustrato come semplificare questo processo:</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Se i gruppi di dischi ASM sono stati completamente evacuati, è possibile smontarli con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Tuttavia, in molti casi i file appartenenti ad altri database o al file ASM spfile/passwd potrebbero essere ancora presenti.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Copia da Oracle ASM al file system</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">La procedura di copia da Oracle ASM a file system è molto simile alla procedura di copia da ASM a ASM, con vantaggi e restrizioni simili. La differenza principale è la sintassi dei vari comandi e parametri di configurazione quando si utilizza un file system visibile anziché un gruppo di dischi ASM.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN viene utilizzato per creare una copia di livello 0 (completa) del database di origine attualmente presente nel gruppo di dischi ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> alla nuova posizione su<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">È necessario forzare lo switch del log di archivio per assicurarsi che i log di archivio contengano tutti i dati necessari per rendere la copia completamente coerente. Senza questo comando, i dati chiave potrebbero essere ancora presenti nei log di ripristino. Per forzare un'opzione del log di archivio, eseguire il comando seguente:</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">L'interruzione inizia in questa fase perché il database viene arrestato e inserito in una modalità di sola lettura ad accesso limitato. Per arrestare il database di origine, eseguire i seguenti comandi:</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Eseguire il backup dei file di controllo nel caso in cui sia necessario interrompere la migrazione e ripristinare la posizione di archiviazione originale. Una copia del controlfile di backup non è richiesta al 100%, ma rende più semplice il processo di ripristino delle posizioni dei file di database nella posizione originale.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Tutti i parametri che fanno riferimento ai vecchi gruppi di dischi ASM devono essere aggiornati e, in alcuni casi, eliminati quando non sono più rilevanti. Aggiornarli per riflettere i nuovi percorsi del file system e salvare il file pfile aggiornato. Assicurarsi che sia elencato il percorso di destinazione completo. Per aggiornare questi parametri, eseguire i seguenti comandi:</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Disattivare il file init.ora originale</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Questo file si trova in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Ed è in genere in un pfile che funge da puntatore a spfile sul gruppo di dischi ASM. Per assicurarsi che spfile originale non sia più utilizzato, rinominarlo. Non eliminarlo, tuttavia, perché questo file è necessario se la migrazione deve essere interrotta.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Questa è la fase finale del trasferimento di spfile. Il file spfile originale non viene più utilizzato e il database viene avviato (ma non montato) utilizzando il file intermedio. Il contenuto di questo file può essere scritto nella nuova posizione spfile come segue:</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">È necessario avviare il database per rilasciare i blocchi sul file intermedio e avviare il database utilizzando solo il nuovo file spfile. L'avvio del database dimostra inoltre che la nuova posizione di spfile è corretta e che i suoi dati sono validi.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">È stato creato un controlfile di backup nel percorso<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> nelle fasi precedenti della procedura. Il nuovo spfile definisce le posizioni controlfile come <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> e.<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Tuttavia, tali file non esistono ancora.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Questo comando ripristina i dati controlfile nei percorsi definiti in spfile.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Eseguire il comando mount in modo che i file di controllo vengano rilevati correttamente e contengano dati validi.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Per convalidare<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> eseguire il seguente comando:</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">Il database sta attualmente utilizzando i file di dati nella vecchia posizione. Prima di poter utilizzare la copia, è necessario sincronizzare i file di dati. È trascorso del tempo durante il processo di copia iniziale e le modifiche sono state registrate principalmente nei registri di archivio. Queste modifiche vengono replicate nei due passaggi seguenti.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Riprodurre i registri.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Per modificare i file di dati attivi, eseguire<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando:</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Sebbene i file di dati debbano essere completamente coerenti, è necessario eseguire un passaggio finale per riprodurre le modifiche rimanenti registrate nei registri di ripristino online. Utilizzare<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando per riprodurre queste modifiche e rendere la copia identica al 100% all'originale. Tuttavia, la copia non è ancora aperta.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Spostare i file di dati temporanei</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Identificare la posizione dei file di dati temporanei ancora in uso sul gruppo di dischi originale.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Per spostare i file di dati, eseguire i seguenti comandi. Se ci sono molti tempfile, utilizzare un editor di testo per creare il comando RMAN e quindi tagliarlo e incollarlo.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">Il processo di migrazione è quasi completo, ma i log di ripristino si trovano ancora nel gruppo di dischi ASM originale. I log di ripristino non possono essere spostati direttamente. Al contrario, viene creata e aggiunta alla configurazione una nuova serie di log di ripristino, in seguito a una perdita dei vecchi log.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Per ogni log di ripristino, creare un nuovo gruppo utilizzando le stesse dimensioni del gruppo di log di ripristino corrente utilizzando la nuova posizione del file system.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Rimuovere i vecchi gruppi di file di registro che si trovano ancora nell'archivio precedente.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Se si verifica un errore che blocca l'eliminazione di un registro attivo, forzare un passaggio al registro successivo per rilasciare il blocco e forzare un punto di verifica globale. Di seguito è riportato un esempio. Il tentativo di rilasciare il gruppo di file di registro 3, che si trovava nella vecchia posizione, è stato negato perché in questo file di registro erano ancora presenti dati attivi. L'archiviazione dei log seguita da un punto di verifica consente l'eliminazione dei file di log.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">Nel seguente script viene illustrato come semplificare questo processo.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Se i gruppi di dischi ASM sono stati completamente evacuati, è possibile smontarli con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. In molti casi, i file appartenenti ad altri database o al file ASM spfile/passwd possono essere ancora presenti.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Procedura di pulizia del file di dati</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Pulitura della migrazione ASM</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">Il processo di migrazione potrebbe generare file di dati con sintassi lunga o criptica, a seconda del modo in cui è stato utilizzato Oracle RMAN. Nell'esempio illustrato, il backup è stato eseguito con il formato file di<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Indica che RMAN deve creare un nome univoco predefinito per ciascun file di dati. Il risultato è simile a quanto illustrato nel testo seguente. I nomi tradizionali dei file di dati sono incorporati nei nomi. Questo può essere ripulito utilizzando l'approccio basato su script illustrato nella <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Ribilanciamento di Oracle ASM</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Come indicato in precedenza, è possibile eseguire la migrazione trasparente di un gruppo di dischi Oracle ASM in un nuovo sistema di storage utilizzando il processo di ribilanciamento. Riassumendo, il processo di ribilanciamento richiede l'aggiunta di LUN di dimensioni uguali al gruppo esistente di LUN, seguita da un'operazione di disgregazione del LUN precedente. Oracle ASM riposiziona automaticamente i dati sottostanti nel nuovo storage in un layout ottimale e, al termine, rilascia i vecchi LUN.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">Il processo di migrazione utilizza un i/o sequenziale efficiente e non causa generalmente un'interruzione delle performance, ma la velocità di migrazione può essere rallentata quando necessario.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identificazione dei dati da migrare</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Creazione di nuovi LUN</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Creare nuovi LUN delle stesse dimensioni e impostare l'appartenenza a utenti e gruppi come richiesto. I LUN devono essere visualizzati come<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> dischi.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Aggiungere nuovi LUN</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Anche se è possibile eseguire tutte le operazioni di aggiunta e rilascio, in genere è più semplice aggiungere nuovi LUN in due passaggi. Innanzitutto, aggiungere i nuovi LUN al gruppo di dischi. Questo passaggio comporta la migrazione di metà delle estensioni dai LUN ASM correnti ai nuovi LUN.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">La potenza di riequilibrio indica la velocità di trasferimento dei dati. Più alto è il numero, più alto è il parallelismo del trasferimento dei dati. La migrazione viene eseguita con efficienti operazioni di i/o sequenziali che hanno scarse probabilità di causare problemi di performance. Tuttavia, se lo si desidera, il potere di riequilibrio di una migrazione in corso può essere regolato con<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> comando. Le migrazioni tipiche utilizzano un valore di 5.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Funzionamento del monitor</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">È possibile monitorare e gestire un'operazione di ribilanciamento in più modi. Per questo esempio è stato utilizzato il comando seguente.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Una volta completata la migrazione, non vengono segnalate operazioni di ribilanciamento.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">LUN meno recenti</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">La migrazione è ormai a metà strada. Potrebbe essere opportuno eseguire alcuni test delle prestazioni di base per assicurarsi che l'ambiente sia sano. Dopo la conferma, è possibile spostare i dati rimanenti eliminando i vecchi LUN. Tenere presente che ciò non determina il rilascio immediato dei LUN. L'operazione di rilascio indica ad Oracle ASM di riposizionare prima le estensioni e quindi rilasciare il LUN.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">L'operazione di ribilanciamento può essere monitorata e gestita in più modi. Per questo esempio è stato utilizzato il seguente comando:</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Rimuovere i vecchi LUN</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Prima di rimuovere i vecchi LUN dal gruppo di dischi, è necessario eseguire un controllo finale dello stato dell'intestazione. Dopo il rilascio di un LUN da ASM, non viene più elencato un nome e lo stato dell'intestazione viene elencato come<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Questo indica che questi LUN possono essere rimossi in modo sicuro dal sistema.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">Migrazione LVM</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">La procedura qui presentata mostra i principi di una migrazione basata su LVM di un gruppo di volumi chiamato<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Gli esempi sono tratti da Linux LVM, ma i principi si applicano ugualmente a AIX, HP-UX e VxVM. I comandi precisi possono variare.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identificare i LUN attualmente presenti in<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> gruppo di volumi.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Creazione di nuovi LUN di dimensioni fisiche identiche o leggermente superiori e definizione di volumi fisici.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Aggiungere i nuovi volumi al gruppo di volumi.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Eseguire il<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Comando per spostare le estensioni di ogni LUN corrente nel nuovo LUN. Il<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> l'argomento controlla l'avanzamento dell'operazione.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Una volta completato questo processo, rimuovere i LUN precedenti dal gruppo di volumi utilizzando<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> comando. Se l'operazione ha esito positivo, è ora possibile rimuovere il LUN dal sistema in modo sicuro.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Procedure di migrazione Oracle</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">Sono disponibili molte procedure per il database di migrazione Oracle. La giusta dipende dalle vostre esigenze aziendali.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">In molti casi, gli amministratori di sistema e i DBA dispongono dei propri metodi preferiti per trasferire i dati dei volumi fisici, eseguire il mirroring e il demirroring o utilizzare Oracle RMAN per copiare i dati.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Queste procedure vengono fornite principalmente come guida per il personale IT meno esperto di alcune delle opzioni disponibili. Inoltre, vengono illustrate le attività, i requisiti di tempo e le richieste di competenze per ogni approccio alla migrazione. Ciò consente ad altre parti, come NetApp e i servizi professionali dei partner o i responsabili dell'IT, di apprezzare più pienamente i requisiti di ogni procedura.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">Non esiste un'unica Best practice per la creazione di una strategia di migrazione. La creazione di un piano richiede prima di tutto la comprensione delle opzioni di disponibilità e quindi la selezione del metodo più adatto alle esigenze dell'azienda. La figura seguente illustra le considerazioni di base e le conclusioni tipiche dei clienti, ma non è applicabile a tutte le situazioni.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Ad esempio, un passaggio solleva il problema della dimensione totale del database. Il passaggio successivo dipende dal fatto che il database sia maggiore o minore di 1TB. I passaggi consigliati sono solo questi: Consigli basati su pratiche tipiche del cliente. La maggior parte dei clienti non utilizzerebbe DataGuard per copiare un database di piccole dimensioni, ma alcuni potrebbero farlo. La maggior parte dei clienti non tenterebbe di copiare un database 50TB per il tempo necessario, ma alcuni potrebbero avere una finestra di manutenzione sufficientemente grande da consentire tale operazione.</block>
  <block id="82f59f5f005a6ea06f0466a4ffc18b6c" category="paragraph">È possibile trovare un diagramma di flusso dei tipi di considerazioni sul percorso di migrazione più adatto <block ref="d197151b12289ca0258c12e9b0e8fb1c" category="inline-link-macro-rx"></block>.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 e versioni successive includono la possibilità di spostare un file dati mentre il database rimane online. Inoltre funziona tra diversi tipi di filesystem. Ad esempio, è possibile spostare un file dati da un filesystem xfs ad ASM. Questo metodo non viene generalmente utilizzato su larga scala a causa del numero di operazioni singole di spostamento del file di dati che sarebbero necessarie, ma è un'opzione che vale la pena considerare con database più piccoli con meno file di dati.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">Inoltre, il semplice spostamento di un file dati è un'ottima opzione per la migrazione di parti di database esistenti. Ad esempio, è possibile ricollocare i file di dati meno attivi in uno storage più conveniente, ad esempio un volume FabricPool che consente di memorizzare blocchi inattivi in Object Store.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migrazione a livello di database</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">La migrazione a livello di database significa consentire il trasferimento dei dati. In particolare, ciò significa spedizione dei log. Tecnologie come RMAN e ASM sono prodotti Oracle, ma, ai fini della migrazione, operano a livello di host in cui copiano i file e gestiscono i volumi.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Spedizione dei log</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">La base per la migrazione a livello di database è il log di archivio di Oracle, che contiene un registro delle modifiche apportate al database. Nella maggior parte dei casi, un registro di archiviazione fa parte di una strategia di backup e ripristino. Il processo di ripristino inizia con il ripristino di un database e quindi la riproduzione di uno o più log di archivio per portare il database allo stato desiderato. Questa stessa tecnologia di base può essere utilizzata per eseguire una migrazione con interruzioni delle operazioni minime o nulle. Cosa ancora più importante, questa tecnologia consente la migrazione senza intaccare il database originale, preservando un percorso di back-out.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">Il processo di migrazione inizia con il ripristino di un backup del database su un server secondario. È possibile farlo in vari modi, ma la maggior parte dei clienti utilizza la normale applicazione di backup per ripristinare i file di dati. Una volta ripristinati i file di dati, gli utenti stabiliscono un metodo per la distribuzione dei log. L'obiettivo è creare un feed costante di log di archivio generati dal database primario e riprodurli sul database ripristinato per mantenerli entrambi vicini allo stesso stato. Quando arriva il tempo di cutover, il database di origine viene completamente arrestato e i log di archivio finali e, in alcuni casi, i log di redo vengono copiati e riprodotti. È fondamentale che i log di ripristino vengano presi in considerazione anche perché potrebbero contenere alcune delle transazioni finali impegnate.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Una volta trasferiti e riprodotti questi log, entrambi i database sono coerenti l'uno con l'altro. A questo punto, la maggior parte dei clienti esegue alcuni test di base. In caso di errori durante il processo di migrazione, la riproduzione del registro dovrebbe segnalare errori e errori. È comunque consigliabile eseguire alcuni test rapidi basati su query note o su attività guidate dalle applicazioni per verificare che la configurazione sia ottimale. È inoltre pratica comune creare una tabella di test finale prima di chiudere il database originale per verificare se è presente nel database migrato. Questa operazione garantisce che non siano stati commessi errori durante la sincronizzazione finale del registro.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Una semplice migrazione log-shipping può essere configurata fuori banda rispetto al database originale, il che lo rende particolarmente utile per i database mission-critical. Non sono richieste modifiche alla configurazione per il database di origine e il ripristino e la configurazione iniziale dell'ambiente di migrazione non hanno alcun effetto sulle operazioni di produzione. Una volta configurato, il log shipping pone alcune richieste di i/o sui server di produzione. Tuttavia, il log shipping è costituito da semplici letture sequenziali dei registri di archivio, che hanno scarse probabilità di influire sulle prestazioni del database di produzione.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">La distribuzione dei log si è dimostrata particolarmente utile per progetti di migrazione a lunga distanza e ad alta velocità di cambiamento. In un'istanza, è stata eseguita la migrazione di un singolo database 220TB in una nuova posizione a circa 500 km di distanza. La velocità di modifica era estremamente elevata e le restrizioni di sicurezza impedivano l'utilizzo di una connessione di rete. La spedizione dei log è stata eseguita utilizzando nastro e corriere. Una copia del database di origine è stata inizialmente ripristinata utilizzando le procedure descritte di seguito. Quindi, i registri sono stati spediti settimanalmente tramite corriere fino al momento del cutover, al momento della consegna del set finale di nastri e dell'applicazione dei registri al database di replica.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">In alcuni casi, è garantito un ambiente DataGuard completo. Non è corretto utilizzare il termine DataGuard per fare riferimento a qualsiasi configurazione del database di standby o di distribuzione dei log. Oracle DataGuard è un framework completo per la gestione della replica dei database, ma non è una tecnologia di replica. Il vantaggio principale di un ambiente DataGuard completo in uno sforzo di migrazione è lo switchover trasparente da un database all'altro. DataGuard consente inoltre uno switchover trasparente nel database originale in caso di problemi, ad esempio problemi di prestazioni o connettività di rete nel nuovo ambiente. Un ambiente DataGuard completamente configurato richiede la configurazione non solo del livello del database ma anche delle applicazioni in modo che le applicazioni siano in grado di rilevare una modifica nella posizione del database primario. In generale, non è necessario utilizzare DataGuard per completare una migrazione, ma alcuni clienti hanno una vasta esperienza DataGuard in-house e già si affidano a essa per le attività di migrazione.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Riarchitettura</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Come discusso in precedenza, per sfruttare le funzionalità avanzate degli storage array è talvolta necessario modificare il layout del database. Inoltre, una modifica nel protocollo di storage, come il passaggio da ASM a un file system NFS, altera necessariamente il layout del file system.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">Uno dei principali vantaggi dei metodi di distribuzione dei log, incluso DataGuard, è che la destinazione di replica non deve corrispondere all'origine. Non vi sono problemi con l'utilizzo di un approccio di log-shipping per migrare da ASM a un normale file system o viceversa. Il layout preciso dei file di dati può essere modificato a destinazione per ottimizzare l'uso della tecnologia Pluggable Database (PDB) o per impostare i controlli QoS in modo selettivo su determinati file. In altre parole, un processo di migrazione basato sul log shipping consente di ottimizzare il layout dello storage del database in modo semplice e sicuro.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Risorse dei server</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">Un limite alla migrazione a livello di database è la necessità di un secondo server. Questo secondo server può essere utilizzato in due modi:</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">È possibile utilizzare il secondo server come nuova casa permanente per il database.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">È possibile utilizzare il secondo server come server di staging temporaneo. Una volta completata e testata la migrazione dei dati nel nuovo storage array, i file system LUN o NFS vengono disconnessi dal server di staging e riconnessi al server originale.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">La prima opzione è la più semplice, ma l'utilizzo potrebbe non essere possibile in ambienti molto grandi che richiedono server molto potenti. La seconda opzione richiede ulteriore lavoro per riportare i file system nella posizione originale. Si tratta di una semplice operazione in cui NFS viene utilizzato come protocollo storage, poiché i file system possono essere smontati dal server di staging e rimontati sul server originale.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">I file system basati su blocchi richiedono lavoro extra per l'aggiornamento dello zoning FC o degli iSCSI initiator. Con la maggior parte dei gestori di volumi logici (incluso ASM), i LUN vengono automaticamente rilevati e portati online una volta resi disponibili sul server originale. Tuttavia, alcune implementazioni di file system e LVM potrebbero richiedere più lavoro per esportare e importare i dati. La procedura precisa può variare, ma in genere è facile stabilire una procedura semplice e ripetibile per completare la migrazione e ripristinare i dati sul server originale.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Sebbene sia possibile impostare la distribuzione dei log e replicare un database all'interno di un singolo ambiente server, la nuova istanza deve avere un SID di processo diverso per riprodurre i log. È possibile visualizzare temporaneamente il database con un diverso gruppo di ID di processo con un SID diverso e modificarlo in un secondo momento. Tuttavia, questo può portare a numerose e complicate attività di gestione ed espone l'ambiente di database al rischio di errori dell'utente.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migrazione a livello di host</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">Migrare i dati a livello di host significa utilizzare il sistema operativo host e le utility associate per completare la migrazione. Questo processo include qualsiasi utility che copia i dati, inclusi Oracle RMAN e Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Copia dei dati</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">Il valore di un'operazione di copia semplice non deve essere sottovalutato. Le moderne infrastrutture di rete sono in grado di spostare i dati a velocità misurate in gigabyte al secondo, mentre le operazioni di copia dei file si basano su un efficiente i/o di lettura e scrittura sequenziale L'interruzione è inevitabile con un'operazione di copia dell'host rispetto alla spedizione dei log, ma la migrazione non riguarda solo lo spostamento dei dati. In genere sono incluse le modifiche alla rete, il tempo di riavvio del database e i test post-migrazione.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">Il tempo effettivo richiesto per copiare i dati potrebbe non essere significativo. Inoltre, l'operazione di copia preserva un percorso di back-out garantito perché i dati originali non vengono intatti. In caso di problemi durante il processo di migrazione, è possibile riattivare i file system originali con i dati originali.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Riformulazione</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">Replatforming si riferisce a una modifica del tipo di CPU. Quando un database viene migrato da una piattaforma Solaris, AIX o HP-UX tradizionale a x86 Linux, i dati devono essere riformattati a causa delle modifiche apportate all'architettura della CPU. Le CPU SPARC, IA64 e POWER sono note come grandi processori endian, mentre le architetture x86 e x86_64 sono note come Little endian. Di conseguenza, alcuni dati all'interno dei file di dati Oracle vengono ordinati in modo diverso a seconda del processore in uso.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">Tradizionalmente, i clienti utilizzano DataPump per replicare i dati su più piattaforme. DataPump è un'utilità che crea un tipo speciale di esportazione dei dati logici che può essere importata più rapidamente nel database di destinazione. Poiché crea una copia logica dei dati, DataPump lascia alle spalle le dipendenze dell'endianness del processore. Anche se alcuni clienti usano DataPump per il replatform, con Oracle 11g è ora disponibile un'opzione più rapida: Tablespace trasportabili su più piattaforme. Questo avanzamento consente di convertire un tablespace in un diverso formato endian. Si tratta di una trasformazione fisica che offre prestazioni migliori rispetto a un'esportazione DataPump, che deve convertire i byte fisici in dati logici e quindi riconvertirli in byte fisici.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">Una discussione completa su DataPump e tablespace trasportabili va oltre la documentazione relativa al NetApp dell'ambito, ma NetApp offre alcuni consigli basati sulla nostra esperienza nell'assistenza ai clienti durante la migrazione a un nuovo log di storage array con una nuova architettura della CPU:</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Se si utilizza DataPump, il tempo necessario per completare la migrazione deve essere misurato in un ambiente di test. A volte i clienti vengono sorpresi del tempo necessario per completare la migrazione. Questo downtime aggiuntivo e inatteso può causare interruzioni delle attività.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">Molti clienti credono erroneamente che gli spazi di tabella trasportabili su più piattaforme non richiedano la conversione dei dati. Quando si utilizza una CPU con un endian diverso, viene utilizzato un RMAN<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> l'operazione deve essere eseguita sui file di dati in anticipo. Non si tratta di un'operazione istantanea. In alcuni casi, il processo di conversione può essere accelerato avendo più thread che operano su file di dati diversi, ma il processo di conversione non può essere evitato.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migrazione guidata dal volume logico</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">Le LVM funzionano prendendo un gruppo di uno o più LUN e suddividendoli in piccole unità generalmente denominate estensioni. Il pool di estensioni viene quindi utilizzato come origine per creare volumi logici essenzialmente virtualizzati. Questo livello di virtualizzazione offre valore in vari modi:</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">I volumi logici possono utilizzare estensioni tratte da più LUN. Quando un file system viene creato su un volume logico, può utilizzare le funzionalità con le performance complete di tutte le LUN. Inoltre, promuove il caricamento uniforme di tutte le LUN nel gruppo di volumi, offrendo performance più prevedibili.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">I volumi logici possono essere ridimensionati aggiungendo e, in alcuni casi, rimuovendo le estensioni. Il ridimensionamento di un file system su un volume logico avviene in genere senza interruzione delle attività.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">È possibile migrare i volumi logici senza interruzioni spostando le estensioni sottostanti.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">La migrazione tramite LVM funziona in due modi: Spostare un'estensione o specchiare/demirrorizzare un'estensione. La migrazione LVM utilizza l'efficiente i/o sequenziale a blocchi di grandi dimensioni e solo raramente crea problemi di performance. In tal caso, sono solitamente disponibili opzioni per la riduzione della velocità di i/O. In tal modo, si aumenta il tempo necessario per completare la migrazione, riducendo al contempo il carico di i/o sui sistemi host e di storage.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Specchiatura e demirrorazione</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Alcuni gestori di volumi, come AIX LVM, consentono all'utente di specificare il numero di copie per ogni estensione e di controllare quali periferiche ospitano ciascuna copia. La migrazione viene eseguita prelevando un volume logico esistente, eseguendo il mirroring delle estensioni sottostanti nei nuovi volumi, attendendo la sincronizzazione delle copie e rilasciando la copia precedente. Se si desidera un percorso di back-out, è possibile creare un'istantanea dei dati originali prima del punto in cui viene rilasciata la copia speculare. In alternativa, è possibile arrestare brevemente il server per mascherare i LUN originali prima di eliminare forzatamente le copie mirror contenute. In tal modo, si preserva una copia recuperabile dei dati nella loro posizione originale.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Estensione della migrazione</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">Quasi tutti i gestori di volumi consentono la migrazione delle estensioni e talvolta esistono diverse opzioni. Ad esempio, alcuni responsabili di volume consentono a un amministratore di spostare le singole estensioni per un volume logico specifico dal vecchio al nuovo storage. I gestori di volume come Linux LVM2 offrono<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Che riposiziona tutti gli extent sul dispositivo LUN specificato in un nuovo LUN. Una volta evacuata, la vecchia LUN può essere rimossa.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">Il rischio principale per le operazioni è la rimozione delle LUN vecchie e non utilizzate dalla configurazione. È necessario prestare la massima attenzione quando si modifica la suddivisione in zone FC e si rimuovono i dispositivi LUN obsoleti.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Gestione automatica dello storage Oracle</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM è un volume manager e un file system logici combinati. A un livello elevato, Oracle ASM prende una raccolta di LUN, le suddivide in piccole unità di allocazione e le presenta come un singolo volume noto come gruppo di dischi ASM. ASM include inoltre la possibilità di eseguire il mirroring del gruppo di dischi impostando il livello di ridondanza. Un volume può essere senza mirror (ridondanza esterna), con mirroring (ridondanza normale) o con mirroring a tre vie (ridondanza elevata). Prestare attenzione durante la configurazione del livello di ridondanza perché non può essere modificato dopo la creazione.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM fornisce anche funzionalità di file system. Sebbene il file system non sia visibile direttamente dall'host, il database Oracle può creare, spostare ed eliminare file e directory in un gruppo di dischi ASM. Inoltre, è possibile navigare nella struttura utilizzando l'utilità asmcmd.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Come per altre implementazioni LVM, Oracle ASM ottimizza le performance di i/o mediante lo striping e il bilanciamento del carico dell'i/o di ciascun file su tutti i LUN disponibili. In secondo luogo, è possibile riposizionare le estensioni sottostanti per consentire sia il ridimensionamento del gruppo di dischi ASM sia la migrazione. Oracle ASM automatizza il processo mediante l'operazione di ribilanciamento. Le nuove LUN vengono aggiunte a un gruppo di dischi ASM e le vecchie LUN vengono eliminate, innescando il trasferimento dell'estensione e la successiva caduta della LUN evacuata dal gruppo di dischi. Questo processo è uno dei metodi di migrazione più comprovati e l'affidabilità di ASM nel fornire una migrazione trasparente è probabilmente la sua caratteristica più importante.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Poiché il livello di mirroring di Oracle ASM è fisso, non può essere utilizzato con il metodo di migrazione mirror e demirroring.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migrazione a livello di storage</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">Migrazione a livello di storage: Migrazione al di sotto del livello dell'applicazione e del sistema operativo. In passato, questo a volte significava l'utilizzo di dispositivi specializzati che copiano i LUN a livello di rete, ma queste funzionalità ora si trovano in modo nativo in ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">La migrazione di database da un sistema NetApp all'altro viene eseguita quasi universalmente con il software di replica dei dati NetApp SnapMirror. Il processo prevede la configurazione di una relazione di mirroring per i volumi da migrare, in modo che possano essere sincronizzati e quindi in attesa della finestra di cutover. Quando arriva, il database di origine viene arrestato, viene eseguito un aggiornamento finale del mirror e il mirror viene interrotto. I volumi di replica sono quindi pronti per l'uso, montando una directory del file system NFS contenuta oppure rilevando i LUN contenuti e avviando il database.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">Il riposizionamento dei volumi in un singolo cluster ONTAP non viene preso in considerazione dalla migrazione, ma piuttosto da una routine<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> operazione. SnapMirror viene utilizzato come motore di replica dei dati all'interno del cluster. Questo processo è completamente automatizzato. Non esistono ulteriori passaggi da eseguire per la migrazione quando gli attributi del volume, come la mappatura delle LUN o le autorizzazioni di esportazione NFS, vengono spostati con il volume stesso. Il trasferimento non comporta interruzioni per le operazioni dell'host. In alcuni casi, l'accesso alla rete deve essere aggiornato per garantire che l'accesso ai dati appena ricollocati sia nel modo più efficiente possibile, ma anche queste attività non comportano interruzione delle attività.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Importazione di LUN esterne (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">FLI è una funzione che consente a un sistema Data ONTAP con versione 8,3 o superiore di migrare una LUN esistente da un altro storage array. La procedura è semplice: Il sistema ONTAP viene sottoposto a zoning sull'array di storage esistente come se fosse un qualsiasi altro host SAN. Data ONTAP può quindi controllare le LUN legacy desiderate ed eseguire la migrazione dei dati sottostanti. Inoltre, il processo di importazione utilizza le impostazioni di efficienza del nuovo volume durante la migrazione dei dati, vale a dire che i dati possono essere compressi e deduplicati inline durante il processo di migrazione.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">La prima implementazione di FLI in Data ONTAP 8,3 consentiva solo la migrazione offline. Si trattava di un trasferimento molto veloce, ma i dati LUN continuavano a non essere disponibili fino al completamento della migrazione. La migrazione online è stata introdotta in Data ONTAP 8,3.1. Questo tipo di migrazione consente di ridurre al minimo le interruzioni, consentendo a ONTAP di fornire dati LUN durante il processo di trasferimento. Si verifica una breve interruzione mentre l'host viene sottoposto a zoning per l'utilizzo dei LUN tramite ONTAP. Tuttavia, non appena tali modifiche vengono apportate, i dati sono ancora una volta accessibili e rimangono accessibili per l'intero processo di migrazione.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">L'i/o in lettura viene fornito con un proxy tramite ONTAP fino al completamento dell'operazione di copia, mentre l'i/o in scrittura viene scritta in modo sincrono su LUN esterna e ONTAP. Le due copie LUN vengono mantenute sincronizzate in questo modo fino a quando l'amministratore non esegue un cutover completo che rilascia la LUN esterna e non replica più le scritture.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI è progettato per funzionare con FC, ma se si desidera passare a iSCSI, la LUN migrata può essere facilmente rimappata come una LUN iSCSI al termine della migrazione.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Tra le caratteristiche di FLI vi è il rilevamento e la regolazione automatici dell'allineamento. In questo contesto, il termine allineamento si riferisce a una partizione su un dispositivo LUN. Per ottenere prestazioni ottimali è necessario allineare l'i/o ai blocchi da 4K KB. Se una partizione viene posizionata su un offset che non è multiplo di 4K, le prestazioni ne risentono.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Esiste un secondo aspetto dell'allineamento che non può essere corretto regolando un offset di partizione, ovvero la dimensione del blocco del file system. Ad esempio, un file system ZFS generalmente utilizza per impostazione predefinita una dimensione di blocco interna di 512 byte. Altri clienti che utilizzano AIX hanno occasionalmente creato file system JFS2 con dimensioni blocco di 512 o 1, 024 byte. Anche se il file system potrebbe essere allineato a un limite di 4K, i file creati all'interno di tale file system non lo sono e le prestazioni ne risentono.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI non deve essere usato in queste circostanze. Anche se i dati sono accessibili dopo la migrazione, il risultato sono file system con gravi limitazioni delle prestazioni. In linea di principio, qualsiasi file system che supporti un carico di lavoro di sovrascrittura casuale su ONTAP dovrebbe utilizzare una dimensione del blocco di 4K KB. Ciò è applicabile principalmente a workload come file di dati di database e implementazioni di VDI. La dimensione del blocco può essere identificata utilizzando i comandi del sistema operativo host pertinente.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Ad esempio, su AIX, la dimensione del blocco può essere visualizzata con<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Con Linux,<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> e.<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> può essere utilizzato per<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> e.<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>, rispettivamente. Con<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, il comando è<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">Il parametro che controlla la dimensione del blocco è<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> e generalmente il valore predefinito è 9, che significa 2^9, o 512 byte. Per prestazioni ottimali, la<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Il valore deve essere 12 (2^12=4K). Questo valore viene impostato al momento della creazione di zpool e non può essere modificato, il che significa che i data zpool con un<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> oltre a 12 deve essere eseguita la migrazione copiando i dati in uno zpool appena creato.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM non ha dimensioni dei blocchi fondamentali. L'unico requisito è che la partizione su cui è stato creato il disco ASM sia allineata correttamente.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">7-Mode Transition Tool</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">7-Mode Transition Tool (7MTT) è un'utility di automazione utilizzata per migrare configurazioni 7- Mode di grandi dimensioni a ONTAP. La maggior parte dei clienti che gestiscono i database trovano altri metodi più semplici, in parte perché eseguono di solito la migrazione dei database piuttosto che trasferire l'intero footprint dello storage. Inoltre, i database sono spesso solo una parte di un ambiente di storage più ampio. Pertanto, spesso i database vengono migrati singolarmente, quindi l'ambiente rimanente può essere spostato con 7MTT.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Alcuni clienti con sistemi di storage dedicati a ambienti di database complicati hanno un numero limitato ma significativo di essi. Questi ambienti potrebbero contenere molti volumi, snapshot e numerosi dettagli di configurazione, come autorizzazioni di esportazione, gruppi iniziatori LUN, autorizzazioni utente e configurazione del protocollo Lightweight Directory Access Protocol. In questi casi, le capacità di automazione di 7MTT possono semplificare una migrazione.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT può funzionare in una delle due modalità seguenti:</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Copy- Based Transition (CBT).* 7MTT con CBT imposta i volumi SnapMirror da un sistema 7- Mode esistente nel nuovo ambiente. Una volta sincronizzati i dati, 7MTT orchestra il processo di cutover.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Copy- Free Transition (CFT).* 7MTT con CFT si basa sulla conversione in-place degli shelf di dischi 7- Mode esistenti. I dati non vengono copiati e gli shelf di dischi esistenti possono essere riutilizzati. La configurazione esistente di data Protection ed efficienza dello storage viene preservata.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">La differenza principale tra queste due opzioni consiste nel fatto che la transizione senza copie è un approccio a big-bang, in cui tutti gli shelf di dischi collegati alla coppia ha 7- Mode originale devono essere ricollocati nel nuovo ambiente. Non esiste alcuna opzione per spostare un sottoinsieme di shelf. L'approccio basato sulla copia consente lo spostamento dei volumi selezionati. Esiste anche potenzialmente una finestra di cutover più lunga con transizione priva di copie a causa del legame necessario per la riselezione degli shelf di dischi e la conversione dei metadati. In base all'esperienza sul campo, NetApp consiglia di lasciare trascorrere 1 ora per il riposizionamento e il ripristino degli shelf di dischi e tra 15 minuti e 2 ore per la conversione dei metadati.</block>
  <block id="c8365c28332d425fd91f2de2e2c22dfb" category="summary">Preparazione di ONTAP per una migrazione FLI</block>
  <block id="25c18537e56595b3e7f3ce78905917ba" category="doc">Pianificazione FLI - Oracle</block>
  <block id="f1033948d9d2d14612d27f1808720f12" category="inline-link">TR-4380: Migrazione SAN con importazione di LUN esterne</block>
  <block id="58fc59a248fefa86003ac1867e5bd279" category="paragraph">Le procedure per la migrazione delle risorse SAN utilizzando FLI sono documentate in NetApp<block ref="5abd855dd5d8332b78fa966ac34c0f22" category="inline-link-rx"></block>.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Dal punto di vista del database e dell'host, non sono necessarie operazioni speciali. Dopo l'aggiornamento delle zone FC e la disponibilità dei LUN su ONTAP, LVM dovrebbe essere in grado di leggere i metadati LVM dai LUN. Inoltre, i gruppi di volumi sono pronti per l'uso senza ulteriori passaggi di configurazione. Rari casi, gli ambienti potrebbero includere file di configurazione con hard-code e riferimenti allo storage array precedente. Ad esempio, un sistema Linux che includeva<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Le regole che fanno riferimento a un WWN di un dato dispositivo devono essere aggiornate per riflettere le modifiche introdotte da FLI.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Fare riferimento alla matrice di compatibilità NetApp per informazioni sulle configurazioni supportate. Se il proprio ambiente non è incluso, contattare il rappresentante NetApp per assistenza.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Questo esempio mostra la migrazione di LUN ASM e LVM ospitati su un server Linux. FLI è supportato su altri sistemi operativi e, sebbene i comandi sul lato host possano differire, i principi sono gli stessi e le procedure ONTAP sono identiche.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">Identificare i LUN LVM</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">La prima fase della preparazione consiste nell'identificare i LUN da migrare. Nell'esempio mostrato qui, due file system basati su SAN sono montati su<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> e.<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">Il nome del gruppo di volumi può essere estratto dal nome del dispositivo, che utilizza il formato (nome del gruppo di volumi)-(nome del volume logico). In questo caso, viene chiamato il gruppo di volumi<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">Il<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> Il comando può essere utilizzato come segue per identificare i LUN che supportano questo gruppo di volumi. In questo caso, sono presenti 10 LUN che compongono il<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> gruppo di volumi.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">Identificare i LUN ASM</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">Anche i LUN ASM devono essere migrati. Per ottenere il numero di LUN e percorsi LUN da sqlplus come utente sysasm, eseguire il comando seguente:</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">L'ambiente corrente contiene 20 LUN da migrare. Aggiornare la SAN corrente in modo che ONTAP possa accedere ai LUN correnti. I dati non sono ancora stati migrati, ma ONTAP deve leggere le informazioni di configurazione dalle LUN correnti per creare la nuova home page per quei dati.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Almeno una porta HBA sul sistema AFF/FAS deve essere configurata come porta Initiator. Inoltre, le zone FC devono essere aggiornate in modo che ONTAP possa accedere alle LUN sullo storage array esterno. Alcuni storage array hanno configurato il masking dei LUN, che limita i WWN che possono accedere a una determinata LUN. In tal caso, è necessario aggiornare anche il masking dei LUN per garantire l'accesso ai WWN di ONTAP.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Al termine di questa operazione, ONTAP dovrebbe essere in grado di visualizzare l'array di archiviazione esterno con<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> comando. Il campo chiave restituito è il prefisso utilizzato per identificare il LUN esterno sul sistema. Nell'esempio seguente, i LUN dell'array esterno<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Appare in ONTAP usando il prefisso di<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identificare un array esterno</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identificare i LUN esterni</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">I LUN possono essere elencati passando l'<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> al<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> comando. I dati restituiti vengono referenziati più volte durante la procedura di migrazione.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Registrare LUN di array esterni come candidati di importazione</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Le LUN esterne vengono inizialmente classificate come qualsiasi tipo di LUN specifico. Prima di poter importare i dati, i LUN devono essere contrassegnati come esterni e quindi come candidati al processo di importazione. Questo passaggio viene completato passando il numero di serie a.<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> , come illustrato nell'esempio seguente. Si noti che questa procedura etichetta solo il LUN come estraneo all'interno di ONTAP. Nessun dato viene scritto nella LUN esterna stessa.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Creazione di volumi per l'hosting di LUN migrati</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Per ospitare le LUN migrate è necessario un volume. La configurazione esatta dei volumi dipende dal piano generale per sfruttare le funzionalità di ONTAP. In questo esempio, i LUN ASM vengono posizionati in un volume e i LUN LVM in un secondo volume. In questo modo, puoi gestire le LUN come gruppi indipendenti per scopi come il tiering, la creazione di snapshot o l'impostazione di controlli della qualità del servizio.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Impostare<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. Il processo di migrazione può comportare un notevole ricambio dei dati. Pertanto, potrebbe verificarsi un notevole aumento del consumo di spazio se le istantanee vengono create accidentalmente perché i dati indesiderati vengono acquisiti nelle istantanee.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Creare LUN ONTAP</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Una volta creati i volumi, è necessario creare i nuovi LUN. In genere, la creazione di un LUN richiede all'utente di specificare tali informazioni come la dimensione LUN, ma in questo caso l'argomento del disco esterno viene passato al comando. Di conseguenza, ONTAP replica i dati di configurazione LUN correnti dal numero di serie specificato. Utilizza inoltre la geometria del LUN e i dati della tabella delle partizioni per regolare l'allineamento delle LUN e stabilire prestazioni ottimali.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">In questo passaggio, i numeri di serie devono essere referenziati rispetto all'array esterno per assicurarsi che il LUN esterno corretto corrisponda al nuovo LUN corretto.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Creare relazioni di importazione</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">I LUN sono stati creati ma non sono configurati come destinazione di replica. Prima di eseguire questo passaggio, i LUN devono essere messi offline. Questo passaggio aggiuntivo è progettato per proteggere i dati dagli errori dell'utente. Se ONTAP consentisse di eseguire una migrazione su un LUN online, rischierebbe di provocare la sovrascrittura dei dati attivi con un errore tipografico. Questa fase aggiuntiva, che obbliga l'utente a portare un LUN offline, consente di verificare se viene utilizzato il LUN di destinazione corretto come destinazione della migrazione.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Una volta che i LUN sono offline, è possibile stabilire la relazione di importazione passando il numero di serie del LUN esterno a.<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> comando.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Una volta stabilite tutte le relazioni di importazione, è possibile riportare online i LUN.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Crea gruppo iniziatore</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Conversione protocollo</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">In questo esempio, viene creato un igroup che contiene due WWN corrispondenti alle due porte disponibili sull'HBA dell'host.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Mappare nuovi LUN all'host</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Dopo la creazione di igroup, i LUN vengono quindi mappati all'igroup definito. Questi LUN sono disponibili solo per i WWN inclusi in questo igroup. In questa fase del processo di migrazione, NetApp presume che l'host non sia stato sottoposto a zoning in ONTAP. Questo è importante perché se l'host è contemporaneamente collegato all'array esterno e al nuovo sistema ONTAP, vi è il rischio che su ogni array possano essere rilevati LUN con lo stesso numero di serie. Questa situazione potrebbe causare malfunzionamenti del multipath o danni ai dati.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Script di esempio per l'automazione delle operazioni di migrazione Oracle</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Script di esempio</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Gli script presentati sono forniti come esempi di come eseguire lo script di varie attività del sistema operativo e del database. Vengono forniti così come sono. Se è necessario supporto per una procedura particolare, contattare NetApp o un rivenditore NetApp.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Arresto del database</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">Lo script Perl seguente prende un singolo argomento del SID Oracle e chiude un database. Può essere eseguito come utente Oracle o come root.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Avvio del database</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Convertire il file system in sola lettura</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">Lo script seguente prende un argomento del file system e tenta di smontarlo e rimontarlo in modalità di sola lettura. Questa operazione è utile durante i processi di migrazione in cui un file system deve essere mantenuto disponibile per replicare i dati e deve essere protetto contro danni accidentali.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Sostituire il file system</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">L'esempio di script riportato di seguito viene utilizzato per sostituire un file system con un altro. Poiché modifica il file ``/etc/fstab, deve essere eseguito come root. Accetta un singolo argomento delimitato da virgole per i file system vecchi e nuovi.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Per sostituire il file system, eseguire lo script seguente:</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Come esempio di utilizzo di questo script, si supponga che i dati in<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> viene migrato in<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> e.<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> viene migrato in<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. Uno dei metodi più semplici per eseguire questa attività consiste nell'utilizzare una semplice operazione di copia dei file per riportare la nuova periferica al punto di montaggio originale.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Si supponga che i file system vecchi e nuovi siano presenti in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archiviare come segue:</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Quando viene eseguito, questo script smonta il file system corrente e lo sostituisce con il nuovo:</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">Lo script aggiorna anche<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> file di conseguenza. Nell'esempio illustrato, sono incluse le seguenti modifiche:</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Migrazione automatizzata del database</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">In questo esempio viene illustrato l'utilizzo di script di arresto, avvio e sostituzione del file system per automatizzare completamente la migrazione.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Visualizzare le posizioni dei file</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Questo script raccoglie una serie di parametri critici del database e li stampa in un formato di facile lettura. Questo script può essere utile quando si esaminano i layout dei dati. Inoltre, lo script può essere modificato per altri usi.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Pulitura della migrazione ASM</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Conversione del nome da ASM a file system</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Riprodurre i log sul database</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Questo script accetta un singolo argomento di un SID Oracle per un database in modalità mount e tenta di riprodurre tutti i log di archivio attualmente disponibili.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Riprodurre i registri sul database di standby</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Questo script è identico allo script precedente, tranne che è progettato per un database di standby.</block>
  <block id="109be8945d38cda6c034a22373bdbd3b" category="summary">Modifica del protocollo SAN dopo la migrazione FLI</block>
  <block id="b5e65fbdff41aa940dad918d9f7c0b9e" category="doc">Conversione del protocollo FLI - Oracle</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">La modifica del protocollo utilizzato per accedere a un LUN è un requisito comune.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">In alcuni casi, fa parte di una strategia globale di migrazione dei dati nel cloud. TCP/IP è il protocollo del cloud e il passaggio da FC a iSCSI facilita la migrazione in vari ambienti cloud. In altri casi, iSCSI potrebbe essere desiderabile per sfruttare i costi ridotti di un IP SAN. A volte, una migrazione potrebbe utilizzare un protocollo diverso come misura temporanea. Ad esempio, se un array esterno e LUN basati su ONTAP non possono coesistere sugli stessi HBA, è possibile utilizzare LUN iSCSI abbastanza a lungo da copiare i dati dal vecchio array. Dopo la rimozione dei vecchi LUN dal sistema, è possibile riconvertirli in FC.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">La seguente procedura illustra la conversione da FC a iSCSI, ma i principi generali si applicano a una conversione da iSCSI a FC inversa.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Installare iSCSI Initiator</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">La maggior parte dei sistemi operativi include un iniziatore iSCSI software per impostazione predefinita, ma se non è incluso, può essere facilmente installato.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identificare il nome dell'iniziatore iSCSI</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Durante il processo di installazione viene generato un nome iSCSI initiator univoco. Su Linux, si trova in<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> file. Questo nome viene utilizzato per identificare l'host sulla SAN IP.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Creare un nuovo gruppo iniziatore</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Un gruppo iniziatore (igroup) fa parte dell'architettura di mascheramento LUN di ONTAP. Un LUN appena creato non è accessibile a meno che non venga concesso per la prima volta l'accesso a un host. Questa operazione viene eseguita creando un igroup che elenca i nomi WWN FC o iniziatori iSCSI che richiedono l'accesso.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">In questo esempio, viene creato un igroup che contiene l'iniziatore iSCSI dell'host Linux.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Chiudere l'ambiente</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Prima di modificare il protocollo LUN, è necessario disattivare completamente i LUN. Tutti i database di uno dei LUN da convertire devono essere chiusi, i file system devono essere dismontati e i gruppi di volumi devono essere disattivati. Se si utilizza ASM, assicurarsi che il gruppo di dischi ASM sia smontato e chiudere tutti i servizi della griglia.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">Rimuovere la mappatura dei LUN dalla rete FC</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Una volta terminate completamente le LUN, rimuovere le mappature dall'igroup FC originale.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">Eseguire nuovamente il mapping dei LUN alla rete IP</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Concedere l'accesso a ogni LUN al nuovo gruppo di iniziatori basati su iSCSI.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">Rilevamento delle destinazioni iSCSI</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">Il rilevamento iSCSI richiede due fasi. La prima è scoprire le destinazioni, che non è la stessa cosa per scoprire un LUN. Il<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> il comando mostrato di seguito verifica il gruppo di portali specificato da<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Memorizza un elenco di tutti gli indirizzi IP e le porte che offrono servizi iSCSI. In questo caso, vi sono quattro indirizzi IP con servizi iSCSI sulla porta predefinita 3260.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Il completamento di questo comando può richiedere alcuni minuti se non è possibile raggiungere uno qualsiasi degli indirizzi IP di destinazione.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">Rilevamento delle LUN iSCSI</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Dopo aver rilevato le destinazioni iSCSI, riavviare il servizio iSCSI per rilevare i LUN iSCSI disponibili e creare i dispositivi associati, ad esempio i dispositivi multipath o ASMlib.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Riavviare l'ambiente</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Riavviare l'ambiente riattivando i gruppi di volumi, rimontando i file system, riavviando i servizi RAC e così via. Per precauzione, NetApp consiglia di riavviare il server al termine del processo di conversione, per assicurarsi che tutti i file di configurazione siano corretti e che tutti i dispositivi obsoleti vengano rimossi.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Attenzione: Prima di riavviare un host, assicurarsi che tutte le voci in<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Il riferimento alle risorse SAN migrate verrà commentato. Se questa operazione non viene eseguita e si verificano problemi con l'accesso LUN, il risultato può essere un sistema operativo che non si avvia. Questo problema non danneggia i dati. Tuttavia, può essere molto scomodo avviare in modalità rescue o una modalità simile e corretta<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> In modo che il sistema operativo possa essere avviato per consentire l'avvio delle operazioni di risoluzione dei problemi.</block>
  <block id="7e712b6bec5dd0821f1822121da9f0c6" category="summary">Gestione delle performance di Oracle con QoS</block>
  <block id="ff8b87ff7571fb54e71c9589f1b886a3" category="doc">Qualità del servizio con i database Oracle</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">La gestione sicura ed efficiente di più database Oracle richiede un'efficace strategia di QoS. Il motivo è rappresentato dalle funzionalità di performance in costante aumento offerte da un sistema storage moderno.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Efficienza dello storage e dei database Oracle</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Database Oracle e funzionalità di efficienza ONTAP</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Le funzionalità di efficienza dello spazio di ONTAP sono ottimizzate per i database Oracle. In quasi tutti i casi, l'approccio migliore è quello di lasciare le impostazioni predefinite con tutte le funzioni di efficienza attivate.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID e database Oracle</block>
  <block id="ead1ce56c368cc12c4f8932e01c92f65" category="doc">Requisiti RAID Oracle</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID si riferisce all'utilizzo della ridondanza per proteggere i dati dalla perdita di un'unità.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Occasionalmente sorgono domande riguardanti i livelli RAID nella configurazione dello storage NetApp utilizzato per i database Oracle e altre applicazioni aziendali. Molte Best practice Oracle precedenti relative alla configurazione degli array di storage contengono avvisi sull'utilizzo del mirroring RAID e/o sull'eliminazione di determinati tipi di RAID. Sebbene sollevino punti validi, questi sorgenti non si applicano a RAID 4 e alle tecnologie NetApp RAID DP e RAID-TEC utilizzate in ONTAP.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Thin provisioning di Oracle e ONTAP</block>
  <block id="e04c5c8668870edf8392b07169f96644" category="doc">Thin provisioning con Oracle</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Il thin provisioning per un database Oracle richiede un'attenta pianificazione, perché ne consegue che è possibile configurare più spazio su un sistema di storage rispetto a quello necessariamente fisicamente disponibile. Vale la pena di fare tutto questo perché, se eseguito correttamente, il risultato è un notevole risparmio sui costi e un miglioramento della gestibilità.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Provisioning delle SVM per database Oracle</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Database Oracle e Storage Virtual Machine</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">La gestione dello storage del database Oracle è centralizzata su una Storage Virtual Machine (SVM)</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Le operazioni di takeover e switchover dello storage devono garantire l'integrità delle operazioni dei database Oracle. Inoltre, gli argomenti utilizzati dalle operazioni di takeover e switchover possono influire sull'integrità dei dati se utilizzati in modo errato.</block>
  <block id="75f921b4326183319e82bc907e80cc42" category="doc">Failover/switchover del controller Oracle e ONTAP</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Capacità e spazio libero per database e storage ONTAP</block>
  <block id="3736e7d9912dca1541f3d86788010d1d" category="doc">Gestione della capacità di Oracle e dello storage</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">La gestione di un database o di un'altra applicazione aziendale con storage aziendale prevedibile, gestibile e ad alte prestazioni richiede spazio libero sulle unità per la gestione di dati e metadati. La quantità di spazio libero richiesta dipende dal tipo di unità utilizzata e dai processi aziendali.</block>
  <block id="655dc175973dc3d055e6e798ce1399a6" category="summary">Parametro di lettura multiblocco Oracle</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multiblock_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">Il<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Parametro controlla il numero massimo di blocchi di database Oracle che Oracle legge come singola operazione durante l'i/o sequenziale</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Questo parametro non influisce tuttavia sul numero di blocchi letti da Oracle durante qualsiasi e in tutte le operazioni di lettura, né sull'i/o casuale Ciò influisce solo sulle dimensioni del blocco degli i/o sequenziali.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle consiglia all'utente di lasciare il parametro non impostato. In questo modo, il software del database può impostare automaticamente il valore ottimale. Questo generalmente significa che questo parametro è impostato su un valore che fornisce una dimensione i/o di 1MB. Ad esempio, una lettura 1MB di 8KB blocchi richiederebbe la lettura di 128 blocchi e il valore predefinito per questo parametro sarebbe 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">La maggior parte dei problemi di prestazioni del database osservati da NetApp presso le sedi dei clienti implica un'impostazione errata per questo parametro. Ci sono motivi validi per modificare questo valore con le versioni 8 e 9 di Oracle. Di conseguenza, il parametro potrebbe essere inconsapevolmente presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Perché il database è stato aggiornato in posizione a Oracle 10 e versioni successive. Un'impostazione legacy di 8 o 16, rispetto a un valore predefinito di 128, danneggia significativamente le prestazioni i/o sequenziali.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp recommended* impostando<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> il parametro non deve essere presente in<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> file. NetApp non ha mai riscontrato una situazione in cui la modifica di questo parametro ha migliorato le prestazioni, ma in molti casi ha causato evidenti danni al throughput i/o sequenziale.</block>
  <block id="669ebbf33c0b19005e2ccaf02ba69e5f" category="summary">Impostazioni di Oracle RAC con storage in rete</block>
  <block id="5c87e825763ec1e41a459f6baa4b2a44" category="doc">Oracle Real Application Clusters (RAC)</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC è un prodotto clusterware con diversi tipi di processi heartbeat interni che monitorano lo stato del cluster.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">errore di montaggio</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">Le informazioni contenute in <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> La sezione contiene informazioni critiche per gli ambienti Oracle RAC che utilizzano lo storage di rete e, in molti casi, è necessario modificare le impostazioni predefinite di Oracle RAC per garantire che il cluster RAC sopravviva alle modifiche del percorso di rete e alle operazioni di failover/switchover dello storage.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">disktimeout</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">Il parametro RAC relativo allo storage primario è<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Questo parametro controlla la soglia entro la quale l'i/o del file di voting deve essere completato. Se il<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Il parametro viene superato, quindi il nodo RAC viene eliminato dal cluster. Il valore predefinito per questo parametro è 200. Questo valore dovrebbe essere sufficiente per le procedure standard di takeover e giveback dello storage.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp consiglia di eseguire il test approfondito delle configurazioni RAC prima di metterle in produzione, perché molti fattori influiscono su un takeover o un giveback. Oltre al tempo richiesto per il completamento del failover dello storage, è necessario ulteriore tempo affinché le modifiche LACP (link Aggregation Control Protocol) vengano propagate. Inoltre, il software multipathing SAN deve rilevare un timeout i/o e riprovare su un percorso alternativo. Se un database è estremamente attivo, è necessario accodare e rieseguire una grande quantità di i/o prima di elaborare l'i/o del disco di voting.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">Nel caso in cui non sia possibile eseguire un takeover o un giveback effettivo dello storage, l'effetto può essere simulato con test di pull dei cavi sul server di database.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">Lasciando il<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> parametro al valore predefinito di 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Verificare sempre accuratamente la configurazione di un RAC.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">Il<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> In genere, il parametro influisce solo sull'heartbeat di rete tra i nodi RAC. Il valore predefinito è 30 secondi. Se i binari della griglia si trovano su un array di storage o l'unità di avvio del sistema operativo non è locale, questo parametro potrebbe diventare importante. Ciò comprende host con unità di boot ubicate su una SAN FC, sistemi operativi basati su NFS e unità di boot ubicate in datastore di virtualizzazione, come un file VMDK.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Se l'accesso a un'unità di boot viene interrotto da un takeover o un giveback dello storage, è possibile che la posizione binaria della griglia o l'intero sistema operativo si blocchi temporaneamente. Il tempo necessario affinché ONTAP completi l'operazione di storage e affinché il sistema operativo modifichi i percorsi e riprenda l'i/o potrebbe superare l'<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> soglia. Di conseguenza, un nodo viene eliminato immediatamente dopo il ripristino della connettività al LUN di avvio o ai binari della griglia. Nella maggior parte dei casi, l'eviction e il successivo riavvio si verificano senza messaggi di registrazione per indicare il motivo del riavvio. Non tutte le configurazioni sono interessate dal problema, pertanto è possibile testare host basati su boot SAN, NFS o datastore in un ambiente RAC in modo che RAC rimanga stabile in caso di interruzione della comunicazione con il disco di avvio.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">Nel caso di unità di avvio non locali o di un hosting di file system non locale<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> binari, il<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> deve essere modificato per corrispondere<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Se questo parametro viene modificato, eseguire ulteriori test per identificare anche eventuali effetti sul comportamento RAC, come il tempo di failover dei nodi.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Lasciare la<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> parametro al valore predefinito di 30 a meno che non si verifichi una delle seguenti condizioni:</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> I file binari sono collocati in un disco collegato in rete, inclusi dischi NFS, iSCSI, FC e basati su datastore.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">Il sistema operativo viene avviato SAN.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">In questi casi, valutare l'effetto delle interruzioni di rete che influiscono sull'accesso al sistema operativo o.<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> file system. In alcuni casi, tali interruzioni causano lo stallo dei daemon Oracle RAC, che può portare a un<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>timeout e sfratto basati su -. Il valore predefinito del timeout è 27 secondi, ovvero il valore di<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> meno<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. In questi casi, aumentare<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> a 200 per la corrispondenza<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="6cde0106c3eb71034259ac34de5e6a2c" category="summary">Oracle filesystemio_options</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Parametro di inizializzazione Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Controlla l'utilizzo dell'i/o asincrono e diretto</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Contrariamente a quanto si crede, l'i/o asincrono e diretto non si escludono a vicenda. NetApp ha osservato che questo parametro è spesso configurato in modo non corretto negli ambienti dei clienti e che questa errata configurazione è direttamente responsabile di molti problemi di prestazioni.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">L'i/o asincrono significa che le operazioni i/o di Oracle possono essere parallelizzate. Prima della disponibilità di i/o asincrono su vari sistemi operativi, gli utenti hanno configurato numerosi processi dbwriter e modificato la configurazione del processo del server. Con l'i/o asincrono, il sistema operativo stesso esegue i/o per conto del software di database in modo altamente efficiente e parallelo. La procedura non pone i dati a rischio e le operazioni critiche, come il logging di redo di Oracle, vengono comunque eseguite in maniera sincrona.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">L'i/o diretto ignora la cache buffer del sistema operativo. L'i/o su un sistema UNIX scorre normalmente attraverso la cache del buffer del sistema operativo. Ciò è utile per le applicazioni che non mantengono una cache interna, ma Oracle dispone di una propria cache buffer all'interno di SGA. In quasi tutti i casi, è meglio abilitare l'i/o diretto e allocare la RAM del server all'SGA piuttosto che affidarsi alla cache del buffer del sistema operativo. Oracle SGA utilizza la memoria in modo più efficiente. Inoltre, quando l'i/o fluisce attraverso il buffer del sistema operativo, è soggetto a un'ulteriore elaborazione, che aumenta le latenze. L'aumento delle latenze è particolarmente percepibile con un elevato i/o in scrittura quando una bassa latenza è un requisito critico.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Le opzioni per<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> sono:</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle invia le richieste di i/o al sistema operativo per l'elaborazione. Questo processo consente a Oracle di eseguire altri lavori anziché attendere il completamento dell'i/o e quindi aumentare la parallelizzazione i/O.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle esegue l'i/o direttamente sui file fisici piuttosto che instradare l'i/o attraverso la cache del sistema operativo host.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle utilizza i/o sincroni e bufferizzati In questa configurazione, la scelta tra processi server condivisi e dedicati e il numero di dbwriter è più importante.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*Setall.* Oracle utilizza i/o sia asincrono che diretto In quasi tutti i casi, l'uso di<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> è ottimale.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">Il<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Parametro non ha effetto negli ambienti DNFS e ASM. L'utilizzo di DNFS o ASM comporta automaticamente l'utilizzo dell'i/o asincrono e diretto</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">In passato alcuni clienti hanno riscontrato problemi di i/o asincrono, in particolare con le precedenti versioni di Red Hat Enterprise Linux 4 (RHEL4). Alcuni consigli aggiornati su Internet suggeriscono comunque di evitare l'i/o asincrono a causa di informazioni non aggiornate. L'i/o asincrono è stabile su tutti i sistemi operativi correnti. Non c'è motivo di disabilitarlo, in assenza di un bug noto con il sistema operativo.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Se un database utilizza l'i/o con buffer, un passaggio all'i/o diretto potrebbe anche richiedere una modifica delle dimensioni SGA. La disattivazione dell'i/o con buffer elimina i vantaggi prestazionali che la cache del sistema operativo host fornisce al database. L'aggiunta di RAM alla SGA risolve questo problema. Il risultato netto dovrebbe essere un miglioramento delle performance di i/O.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Sebbene sia quasi sempre meglio utilizzare la RAM per Oracle SGA piuttosto che per il caching del buffer del sistema operativo, potrebbe essere impossibile determinare il valore migliore. Ad esempio, potrebbe essere preferibile utilizzare i/o con buffer di dimensioni SGA molto ridotte su un server di database con molte istanze Oracle attive in modo intermittente. Questa disposizione consente l'utilizzo flessibile della RAM disponibile rimanente sul sistema operativo da parte di tutte le istanze di database in esecuzione. Si tratta di una situazione molto insolita, ma è stata osservata presso alcune sedi dei clienti.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp recommended*<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> a.<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Ma essere consapevoli che in alcune circostanze la perdita della cache del buffer host potrebbe richiedere un aumento nella SGA di Oracle.</block>
  <block id="caa6d47f2f011d5d1b5fb830e85a37f0" category="summary">Dimensioni dei blocchi Oracle</block>
  <block id="6db776dab2989df63d245511a4dccf08" category="doc">Dimensioni dei blocchi Oracle</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP utilizza internamente dimensioni dei blocchi variabili, il che significa che è possibile configurare i database Oracle con le dimensioni desiderate per i blocchi. Tuttavia, le dimensioni dei blocchi del file system possono influire sulle prestazioni e in alcuni casi una maggiore dimensione dei blocchi di ripristino può migliorare le prestazioni.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Dimensioni dei blocchi di dati</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Alcuni sistemi operativi offrono una scelta di dimensioni dei blocchi del file system. Per i file system che supportano i file di dati Oracle, quando si utilizza la compressione le dimensioni del blocco devono essere pari a 8KB KB. Quando la compressione non è necessaria, è possibile utilizzare dimensioni del blocco pari a 8KB K o 4KB K.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Se un file dati viene inserito in un file system con un blocco di 512 byte, è possibile che i file non siano allineati correttamente. Il LUN e il file system potrebbero essere allineati correttamente in base ai consigli di NetApp, ma l'i/o del file non sarebbe allineato correttamente. Un tale disallineamento causerebbe gravi problemi di prestazioni.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">I file system che supportano i log di ripristino devono utilizzare una dimensione blocco pari a un multiplo della dimensione del blocco di ripristino. In genere, questo richiede che sia il file system del redo log sia il redo log stesso utilizzino una dimensione del blocco di 512 byte.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Ripristina le dimensioni dei blocchi</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">A velocità di ripristino molto elevate, è possibile che le dimensioni dei blocchi di 4KB KB funzionino meglio, perché alte velocità di ripristino consentono di eseguire l'i/o in un numero inferiore di operazioni più efficienti. Se le velocità di ripristino sono superiori a 50Mbps KB, valutare la possibilità di testare dimensioni blocco di 4KB KB.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Sono stati identificati alcuni problemi dei clienti con i database che utilizzano i log di redo con dimensioni dei blocchi di 512 byte in un file system con dimensioni dei blocchi di 4KB KB e molte transazioni di dimensioni molto ridotte. L'overhead coinvolto nell'applicazione di modifiche multiple a 512 byte a un singolo blocco di file system da 4KB ha portato a problemi di performance che sono stati risolti modificando il file system in modo da utilizzare dimensioni dei blocchi di 512 byte.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp consiglia* di non modificare le dimensioni del blocco di redo se non dietro indicazione di un'organizzazione di assistenza clienti o servizi professionali o se la modifica si basa sulla documentazione ufficiale del prodotto.</block>
  <block id="00783c075f877e6e69c64079296967ed" category="summary">Disaster recovery di Oracle con ONTAP</block>
  <block id="6a87f84ba62b57e5643d5bfa5967c7a8" category="doc">Disaster recovery con ONTAP</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">Il disaster recovery si riferisce al ripristino dei servizi dati dopo un evento catastrofico, come un incendio che distrugge un sistema storage o persino un'intera sede.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4591: Oracle Data Protection_ e _TR-4592: Oracle on MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">Il disaster recovery può essere eseguito mediante una semplice replica dei dati tramite SnapMirror, naturalmente, con molti clienti che aggiornano le repliche con mirroring ogni ora.</block>
  <block id="0f1b72a875a2bcb3d0e844ca2dcee233" category="paragraph">Per la maggior parte dei clienti, il disaster recovery non richiede solo una copia remota dei dati, ma anche la capacità di sfruttarli in maniera rapida. NetApp offre due tecnologie che soddisfano questa esigenza: MetroCluster e SnapMirror Business Continuity (SM-BC)</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster fa riferimento a ONTAP in una configurazione hardware che include storage con mirroring sincrono di basso livello e numerose funzionalità aggiuntive. Le soluzioni integrate come MetroCluster semplificano le complesse e scalabili infrastrutture di database, applicazioni e virtualizzazione. Sostituisce diversi prodotti e strategie di protezione dati esterni con un unico semplice storage array centrale. Fornisce inoltre backup, recovery, disaster recovery e alta disponibilità (ha) integrati in un singolo sistema storage in cluster.</block>
  <block id="05be1e741eba1ac3f0b7c924f261403b" category="paragraph">SnapMirror Business Continuity (SM-BC) si basa su SnapMirror Synchronous, Con MetroCluster, ogni controller ONTAP è responsabile della replica dei dati dell'unità in una posizione remota. Con SM-BC, avrai essenzialmente due sistemi ONTAP diversi che mantengono copie indipendenti dei tuoi dati LUN, ma cooperano per presentare una singola istanza di tale LUN. Dal punto di vista dell'host, si tratta di una singola entità LUN.</block>
  <block id="70f47db03a0843fec433c8cc41a54635" category="paragraph">Anche se SM-BC e MetroCluster funzionano in modo molto diverso internamente, per un host il risultato è molto simile. La differenza principale è la granularità. Se devi solo selezionare i workload da replicare sincroni, SM-BC è l'opzione migliore. MetroCluster è l'opzione migliore per replicare interi ambienti o persino data center. Inoltre, SM-BC è attualmente solo PER SAN, mentre MetroCluster è multiprotocollo, inclusi SAN, NFS e SMB.</block>
  <block id="7389dc8e47495ffdde7fd2e0fc19df20" category="summary">Failover Oracle con SM-BC</block>
  <block id="0a54809bbd5dc721967217b79aa04429" category="paragraph">Il motivo principale per ospitare un database Oracle su SM-BC è fornire il failover trasparente durante gli eventi di storage pianificati e non.</block>
  <block id="cfb8f86af03363ef2c73933e34108390" category="summary">Oracle - istanza singola su ONTAP con SM-BC</block>
  <block id="f25228759326d365adf4dca6b7b2cb8b" category="doc">Oracle a singola istanza con SM-BC</block>
  <block id="a38cb04f35bd24313f90398cdc07e149" category="paragraph">Il diagramma seguente mostra un semplice modello di distribuzione in cui sono presenti dispositivi di storage con zoning o connessi dai cluster di storage primari e remoti per un database Oracle.</block>
  <block id="ac38db4f14e512b48d088eedb84cd611" category="paragraph">Oracle è configurato solo sul primario. Questo modello risolve il failover dello storage perfetto in caso di disastri sul lato dello storage, senza perdita di dati e senza downtime applicativi. Questo modello, tuttavia, non fornirebbe un'elevata disponibilità dell'ambiente di database durante un errore del sito. Questo tipo di architettura è utile per i clienti che cercano una soluzione senza perdita di dati con alta disponibilità dei servizi di storage, ma accettano che una perdita totale del cluster di database richieda lavoro manuale.</block>
  <block id="ccc53ca027c7d8fb1e0d647249fd67cd" category="paragraph"><block ref="ccc53ca027c7d8fb1e0d647249fd67cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e072ef2eba1c46e59475046cd4fb880" category="paragraph">Questo approccio consente inoltre di risparmiare sui costi di licenza Oracle. La preconfigurazione dei nodi di database Oracle nel sito remoto richiede la licenza di tutti i core in base alla maggior parte dei contratti di licenza Oracle. Se il ritardo causato dal tempo richiesto per installare un server di database Oracle e montare la copia di dati rimanente è accettabile, questa progettazione può essere molto conveniente.</block>
  <block id="5e2dd7c2fa063e6d7af964efc0e488a0" category="summary">Oracle RAC su ONTAP con SM-BC</block>
  <block id="f7d366254f13816be07d3c8dff4ef00c" category="doc">Oracle RAC con SM-BC</block>
  <block id="67bbc9e19672ee6c9c548cae8a472396" category="paragraph">SM-BC offre un controllo granulare sulla replica del set di dati per scopi quali il bilanciamento del carico o il failover di una singola applicazione. L'architettura complessiva è simile a un cluster RAC esteso, ma alcuni database sono dedicati a siti specifici e il carico complessivo viene distribuito.</block>
  <block id="9331b3ad2bcf259818157930e1c82ad3" category="paragraph">Ad esempio, puoi costruire un cluster Oracle RAC che ospita sei singoli database. Lo storage per tre dei database è principalmente ospitato sul sito A e quello per gli altri tre database sul sito B. Questa configurazione garantisce le migliori prestazioni possibili riducendo al minimo il traffico tra siti. Inoltre, le applicazioni vengono configurate in modo da utilizzare le istanze del database locali del sistema storage con percorsi attivi. In questo modo si riduce al minimo il traffico di interconnessione RAC. Infine, questa progettazione complessiva garantisce che tutte le risorse di calcolo vengano utilizzate in modo uniforme. Con il variare dei carichi di lavoro, è possibile eseguire selettivamente il failover dei database fra diversi siti, in modo da garantire un caricamento uniforme.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC su MetroCluster</block>
  <block id="1c6753ccdcc6629af3e1febabbf271b5" category="paragraph">A parte la granularità, i principi e le opzioni di base per Oracle RAC che utilizza SM-BC sono gli stessi di <block ref="f7453402f1e4779ea0ec67d873358932" category="inline-link-macro-rx"></block></block>
  <block id="7e544b57620f5cdeb71865606eab0549" category="summary">Oracle con SnapMirror Business Continuity (SM-BC)</block>
  <block id="33aa8b7a84723347d228956fab2a4de8" category="doc">Business continuity per Oracle e SnapMirror</block>
  <block id="41eec95e0dbb542c5cd25248ec5759d5" category="paragraph">SM-BC permette un mirroring sincrono selettivo RPO=0 per singoli database Oracle e ambienti applicativi.</block>
  <block id="563d0bf19fd5d623a031d90c30128dc1" category="summary">Scenari di errore di Oracle SM-BC</block>
  <block id="3c1ea312a3c6648fc3f94a1ccd12bebc" category="doc">Scenari di guasti di Oracle SM-BC</block>
  <block id="87777c84375810d8b6fd65f604dd2561" category="paragraph">Esistono diversi scenari di guasti a SnapMirror Business Continuity (SM-BC), ciascuno con risultati differenti.</block>
  <block id="8eea62084ca7e541d918e823422bd82e" category="cell">Risultato</block>
  <block id="ee70ac41df7240931fee4110b599c39f" category="cell">Errore del collegamento di replica</block>
  <block id="e79e76eca171f3e596eb56ba4bb24743" category="cell">Mediatore riconosce questo scenario split-brain e riprende l'i/o sul nodo che contiene la copia master. Quando la connettività tra i siti è di nuovo online, il sito alternativo esegue la risincronizzazione automatica.</block>
  <block id="98a638ba6cee257a8f751bcf8d30e1f2" category="cell">Guasto allo storage della sede principale</block>
  <block id="b92af6cefecfe68535bbd851b797379f" category="cell">Il failover non pianificato automatizzato viene avviato da Mediator.

Nessuna interruzione di i/O.</block>
  <block id="ce9a584219636ca5b159a27f2dd8c445" category="cell">Errore dello storage nel sito remoto</block>
  <block id="68a293bd16c4e2589057d43506a5afbd" category="cell">Non si verifica alcuna interruzione di i/O. Si verifica una pausa momentanea a causa della rete che causa l'interruzione della replica di sincronizzazione e il master che stabilisce che è il legittimo proprietario continuare a servire i/o (consensus). Pertanto, si verifica una pausa i/o di alcuni secondi, quindi l'i/o riprenderà.

Quando il sito è in linea, viene eseguita una risincronizzazione automatica.</block>
  <block id="64f4e3573d0b569ef7b5a08476fb9f7d" category="cell">Perdita di Mediator o collegamento tra Mediator e gli array di storage</block>
  <block id="7e7abe23ef8e465ee1b6879b35e6bab3" category="cell">L'i/o continua e rimane sincronizzato con il cluster remoto, ma in assenza di Mediator non è possibile eseguire il failover e il failback pianificati/non pianificati automatici.</block>
  <block id="96b352ebd03c8c5b7589a527b18f1a2d" category="cell">Perdita di uno degli storage controller nel cluster ha</block>
  <block id="426c4468c3cc76191842240593fcfec3" category="cell">Il nodo partner nel cluster di ha tenta un takeover (NDO). Se il takeover ha esito negativo, Mediator nota che entrambi i nodi nello storage sono inattivi ed esegue un failover non pianificato automatico nel cluster remoto.</block>
  <block id="0e578c93ab393c3d449d484e9fa4b84e" category="cell">Perdita di dischi</block>
  <block id="3d5fea5d89ec844fc92c08a585050e4e" category="cell">L'io continua per un massimo di tre guasti consecutivi al disco. Questo fa parte di RAID-TEC.</block>
  <block id="bd300f92769c0ee071832cadaff91f04" category="cell">Perdita dell'intero sito in un'implementazione tipica</block>
  <block id="9cfa40a514d333ea10de6fc8a75ac663" category="cell">I server sul sito in errore non saranno più disponibili. Le applicazioni che supportano il clustering possono essere configurate per l'esecuzione in entrambi i siti e la continuità delle operazioni sul sito alternativo, anche se la maggior parte di tali applicazioni richiede un tiebreaker a 3rd siti, come SM-BC richiede il mediatore.

Senza cluster a livello di applicazione, le applicazioni dovranno essere avviate nel sito rimasto. Ciò influisce sulla disponibilità, ma viene mantenuto RPO=0. Non si perderebbero dati.</block>
  <block id="f2762385d394491398659925e75d5d01" category="summary">Architettura fisica di MetroCluster - Oracle</block>
  <block id="5be41b602a41d06df45e8986ec09a8dc" category="doc">Architettura fisica di MetroCluster - Oracle</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Per comprendere il funzionamento dei database Oracle in un ambiente MetroCluster è necessario spiegare la progettazione fisica di un sistema MetroCluster.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4592: Oracle su MetroCluster._</block>
  <block id="bdec122112fe3ad35d588380dc643e48" category="summary">Architettura logica MetroCluster - Oracle</block>
  <block id="141402e8d9fa946970f252a09a01a462" category="doc">Architettura logica MetroCluster - Oracle</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Per comprendere il funzionamento dei database Oracle in un ambiente MetroCluster alsop è necessario spiegare alcune delle funzionalità logiche di un sistema MetroCluster.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL</block>
  <block id="6ddd3d6bc3ad92b983699970b1596e0f" category="summary">Oracle con MetroCluster</block>
  <block id="c1fac7a72cd91bcd345e567f6d6d93a3" category="doc">Failover di Oracle con MetroCluster</block>
  <block id="7a60cb119af7ddcdfe38fc872d2027a1" category="paragraph">L'utilizzo di MetroCluster non aggiunge né modifica necessariamente le Best practice per il funzionamento di applicazioni e database aziendali.</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Le normali Best practice vengono comunque applicate e se le tue esigenze richiedono solo RPO=0:1 di data Protection, allora MetroCluster ne soddisfa l'esigenza. Tuttavia, la maggior parte dei clienti utilizza MetroCluster non solo per la protezione dei dati con RPO=0, ma anche per migliorare l'RTO in scenari di disastro, oltre a fornire un failover trasparente come parte delle attività di manutenzione del sito.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Failover con un sistema operativo preconfigurato</block>
  <block id="9bd9ad7f296a0e8ac3df804b3c6a392f" category="paragraph">SyncMirror fornisce una copia sincrona dei dati nel sito di disaster recovery, ma per renderli disponibili sono necessari un sistema operativo e le applicazioni associate. L'automazione di base può migliorare notevolmente il tempo di failover dell'ambiente complessivo. I prodotti Clusterware come Oracle RAC, Veritas Cluster Server (VCS) o VMware ha vengono spesso utilizzati per creare un cluster in tutti i siti, e in molti casi il processo di failover può essere guidato da semplici script.</block>
  <block id="c5a2f3b867d990c681a218d29a55fcfa" category="paragraph">In caso di perdita dei nodi primari, il clusterware (o gli script) viene configurato in modo da portare le applicazioni online nel sito alternativo. Un'opzione è creare server di standby preconfigurati per le risorse NFS o SAN che costituiscono l'applicazione. Se il sito primario non funziona, il clusterware o l'alternativa con script esegue una sequenza di azioni simile alle seguenti:</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Forzare uno switchover su MetroCluster</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Rilevamento di LUN FC (solo SAN)</block>
  <block id="6f3fd86521759fc98ed93853eaf8a03a" category="list-text">Montaggio di file system</block>
  <block id="9d9ea7a9c532a3cec63305130018a45b" category="list-text">Avvio dell'applicazione</block>
  <block id="b8eca7b573624230962095fcadb03ddf" category="paragraph">Il requisito principale di questo approccio è rappresentato da un sistema operativo in esecuzione sul sito remoto. Deve essere preconfigurato con file binari delle applicazioni, il che significa anche che attività come l'applicazione di patch devono essere eseguite sul sito primario e di standby. In alternativa, è possibile eseguire il mirroring dei file binari dell'applicazione nel sito remoto e montarli se viene dichiarato un disastro.</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">La procedura di attivazione effettiva è semplice. Comandi come il rilevamento delle LUN richiedono solo pochi comandi per ogni porta FC. Il montaggio del file system non è altro che un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> E sia i database che ASM possono essere avviati e arrestati dalla CLI con un unico comando. Se i volumi e i file system non vengono utilizzati nel sito di disaster recovery prima dello switchover, non è necessario impostare alcun requisito<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sui volumi.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Failover con un sistema operativo virtualizzato</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">Il failover degli ambienti di database può essere esteso per includere il sistema operativo stesso. In teoria, questo failover può essere eseguito con le LUN di avvio, ma nella maggior parte dei casi con un sistema operativo virtualizzato. La procedura è simile ai seguenti passaggi:</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Montaggio dei datastore che ospitano le macchine virtuali del server di database</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Avvio delle macchine virtuali</block>
  <block id="ba2f22f63087151f0a0694be5f35fcf2" category="list-text">Avviare i database manualmente o configurare le macchine virtuali per avviare automaticamente i database</block>
  <block id="810078f3b19b93e24de8638d68f727b5" category="paragraph">Ad esempio, un cluster ESX può estendersi su diversi siti. In caso di disastro, dopo lo switchover, è possibile portare online le macchine virtuali nel sito di disaster recovery. Fino a quando i datastore che ospitano i database server virtualizzati non saranno in uso in occasione di un evento di emergenza, non sarà necessario impostare alcun valore<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sui volumi associati.</block>
  <block id="681afe3bdc351138642f233429d64762" category="summary">Oracle e SyncMirror</block>
  <block id="bc8a6c6eac662831d2ddce97adbd4324" category="doc">SyncMirror - Oracle</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">La base della protezione dei dati di Oracle con un sistema MetroCluster è SyncMirror, una tecnologia di mirroring sincrono scale-out dalle performance massime.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle RAC esteso con MetroCluster</block>
  <block id="dbcedb2fd86e6012347a3c9ad111f3a8" category="doc">Oracle RAC esteso su MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">Molti clienti ottimizzano il proprio RTO estendendo un cluster Oracle RAC tra i vari siti, ottenendo una configurazione completamente Active-Active. La progettazione complessiva diventa più complicata perché deve includere la gestione del quorum di Oracle RAC. Inoltre, entrambi i siti accedono ai dati, il che significa che uno switchover forzato può portare all'utilizzo di una copia dei dati non aggiornata.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Sebbene una copia dei dati sia presente in entrambi i siti, solo il controller attualmente proprietario di un aggregato può fornire i dati. Pertanto, con i cluster RAC estesi, i nodi remoti devono eseguire l'i/o attraverso una connessione site-to-site. Il risultato è un'aggiunta di latenza i/o, ma generalmente questa latenza non rappresenta un problema. Anche la rete di interconnessione RAC deve essere estesa su più siti, il che significa che è comunque necessaria una rete ad alta velocità e a bassa latenza. Se la latenza aggiunta causa un problema, il cluster può essere azionato in maniera Active-passive. Quindi, le operazioni i/o-intensive devono essere indirizzate ai nodi RAC locali del controller proprietario degli aggregati. I nodi remoti eseguono quindi operazioni i/o più chiare o vengono utilizzati esclusivamente come server warm standby.</block>
  <block id="375c3caa97162bd0c2c07869d9c5b026" category="paragraph">Se è necessario un RAC esteso Active-Active, è necessario considerare il mirroring ASM al posto di MetroCluster. Il mirroring ASM consente di preferire una replica specifica dei dati. Pertanto, può essere integrato un cluster RAC esteso in cui tutte le letture avvengono localmente. Gli i/o in lettura non attraversano mai i siti, offrendo la minore latenza possibile. Tutte le attività di scrittura devono comunque transito sulla connessione tra siti, ma tale traffico è inevitabile con qualsiasi soluzione di mirroring sincrono.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC con ONTAP</block>
  <block id="59d934fc4614a6275fef2828bfab30cf" category="admonition">Se le LUN di avvio, compresi i dischi di avvio virtualizzati, vengono utilizzati con Oracle RAC, l'<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> potrebbe essere necessario modificare il parametro. Per ulteriori informazioni sui parametri di timeout RAC, vedere <block ref="75080d28a1748f78cf8a666ababf51af" category="inline-link-macro-rx"></block>.</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Configurazione a due siti</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Una configurazione RAC estesa a due siti può fornire servizi di database Active-Active che possono sopravvivere a molti scenari ma non a tutti.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">File di voto RAC</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">La prima considerazione da prendere in considerazione per la distribuzione di RAC esteso su MetroCluster deve essere la gestione del quorum. Oracle RAC dispone di due meccanismi per gestire il quorum: Heartbeat del disco e heartbeat della rete. L'heartbeat del disco controlla l'accesso allo storage utilizzando i file di voto. Con una configurazione RAC a sito singolo, una singola risorsa di voto è sufficiente fintanto che il sistema storage sottostante offre funzionalità ha.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">Nelle versioni precedenti di Oracle, i file di voto erano posizionati su dispositivi di archiviazione fisici, ma nelle versioni correnti di Oracle i file di voto sono memorizzati in gruppi di dischi ASM.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC è supportato con NFS. Durante il processo di installazione della griglia, viene creata una serie di processi ASM per presentare la posizione NFS utilizzata per i file della griglia come un gruppo di dischi ASM. Il processo è quasi trasparente per l'utente finale e non richiede alcuna gestione ASM continua al termine dell'installazione.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">Il primo requisito di una configurazione a due siti è garantire che ogni sito possa sempre accedere a più della metà dei file di voto in modo da garantire un processo di disaster recovery senza interruzioni. Questa attività era semplice prima che i file di voto fossero memorizzati in gruppi di dischi ASM, ma oggi gli amministratori devono comprendere i principi di base della ridondanza ASM.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">I gruppi di dischi ASM hanno tre opzioni di ridondanza<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, e.<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. In altre parole, senza mirror, con mirroring e a 3 vie con mirroring. Un'opzione più recente chiamata<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> è anche disponibile, ma raramente utilizzato. Il livello di ridondanza e il posizionamento dei dispositivi ridondanti controllano ciò che accade negli scenari di errore. Ad esempio:</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> la risorsa di ridondanza garantisce l'eliminazione di un sito se la connettività tra siti viene persa.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> La ridondanza con un solo disco ASM per sito garantisce l'eliminazione dei nodi su entrambi i siti se la connettività tra i siti viene persa perché nessuno dei due siti dispone di un quorum di maggioranza.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Posizionamento dei file di votazione su un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> la ridondanza con due dischi su un sito e un singolo disco sull'altro sito consente operazioni active-active quando entrambi i siti sono operativi e reciprocamente raggiungibili. Tuttavia, se il sito a disco singolo è isolato dalla rete, il sito viene eliminato.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">Heartbeat rete RAC</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">L'heartbeat della rete Oracle RAC monitora la raggiungibilità dei nodi in tutta l'interconnessione cluster. Per rimanere nel cluster, un nodo deve essere in grado di contattare più della metà degli altri nodi. In un'architettura a due siti, questo requisito crea le seguenti scelte per il numero di nodi RAC:</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">Il posizionamento di un numero uguale di nodi per sito comporta l'espulsione in un sito nel caso in cui la connettività di rete venga persa.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">Il posizionamento di N nodi su un sito e N+1 nodi sul sito opposto garantisce che la perdita di connettività intersito determini nel sito con il maggior numero di nodi rimanenti nel quorum di rete e nel sito con meno nodi evicting.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Prima di Oracle 12cR2, non era fattibile controllare quale lato avrebbe subito un'eviction durante la perdita del sito. Quando ogni sito ha un numero uguale di nodi, l'evocazione è controllata dal nodo master, che in generale è il primo nodo RAC da avviare.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 introduce la funzionalità di ponderazione dei nodi. Questa funzionalità consente agli amministratori di controllare in che modo Oracle risolve le condizioni split-brain. Ad esempio, il seguente comando imposta la preferenza per un nodo specifico in un RAC:</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Dopo aver riavviato Oracle High-Availability Services, la configurazione si presenta come segue:</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> è ora designato come server critico. Se i due nodi RAC sono isolati,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> sopravvive, e.<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> è sfrattato.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Per informazioni dettagliate, consultare il white paper Oracle "Panoramica tecnica su Oracle Clusterware 12c Release 2. "</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Per le versioni di Oracle RAC precedenti a 12cR2, il nodo master può essere identificato controllando i registri CRS come segue:</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Questo registro indica che il nodo master è<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> e il nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Ha un ID di<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Questo significa che<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> non è il nodo master. L'identità del nodo master può essere confermata con il comando<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">Il nodo con un ID di<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> è<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, che è il nodo master. In una configurazione con un numero uguale di nodi su ogni sito, il sito con<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> è il sito che sopravvive se i due set perdono la connettività di rete per qualsiasi motivo.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">È possibile che la voce di log che identifica il nodo master rimanga fuori dal sistema. In questa situazione, è possibile utilizzare i timestamp dei backup OCR (Oracle Cluster Registry).</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">Questo esempio mostra che il nodo master è<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. Indica anche una modifica nel nodo master da<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> a.<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Da qualche parte tra il 2:05 e il 21:39 maggio 4. Questo metodo di identificazione del nodo master è sicuro da utilizzare solo se sono stati controllati anche i log CRS, poiché è possibile che il nodo master sia cambiato dal precedente backup OCR. Se questa modifica si è verificata, dovrebbe essere visibile nei registri OCR.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">La maggior parte dei clienti sceglie un singolo gruppo di dischi di voto che gestisce l'intero ambiente e un numero uguale di nodi RAC su ciascun sito. Il gruppo di dischi deve essere collocato nel sito che contiene il database. Il risultato è che la perdita di connettività provoca sfratto sul sito remoto. Il sito remoto non dispone più del quorum né avrebbe accesso ai file di database, ma il sito locale continua a funzionare normalmente. Quando la connettività viene ripristinata, l'istanza remota può essere riportata nuovamente in linea.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">In caso di emergenza, è necessario uno switchover per portare online i file di database e il gruppo di dischi di voto sul sito rimasto. Se il disastro consente AD AUSO di attivare lo switchover, NVFAIL non viene attivato perché il cluster è sincronizzato e le risorse di storage vengono normalmente online. AUSO è un'operazione molto veloce e dovrebbe essere completata prima del<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> il periodo scade.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Poiché ci sono solo due siti, non è possibile utilizzare alcun tipo di software di rottura automatica esterna, il che significa che lo switchover forzato deve essere un'operazione manuale.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Configurazioni a tre siti</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Un cluster RAC esteso è molto più semplice da progettare con tre siti. I due siti che ospitano ciascuna metà del sistema MetroCluster supportano anche i carichi di lavoro del database, mentre il terzo sito funge da tiebreaker sia per il database che per il sistema MetroCluster. La configurazione di Oracle Tiebreaker può essere semplice come collocare un membro del gruppo di dischi ASM utilizzato per il voto su un sito 3rd e può anche includere un'istanza operativa sul sito 3rd per garantire che vi sia un numero dispari di nodi nel cluster RAC.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Per informazioni importanti sull'utilizzo di NFS in una configurazione RAC estesa, consultare la documentazione Oracle relativa al "gruppo di errori del quorum". In sintesi, potrebbe essere necessario modificare le opzioni di montaggio NFS per includere l'opzione soft per garantire che la perdita di connettività alle risorse quorum di hosting del sito 3rd non blocchi i server Oracle primari o i processi Oracle RAC.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster e NVFAIL</block>
  <block id="ee6c613c07239c0923d940dfd448493f" category="paragraph">NVFAIL è una funzionalità generale di integrità dei dati di ONTAP, particolarmente critica per i carichi di lavoro del database.</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Singola istanza di Oracle su MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Come indicato in precedenza, la presenza di un sistema MetroCluster non implica necessariamente l'aggiunta o la modifica delle Best practice per l'utilizzo di un database. La maggior parte dei database attualmente in esecuzione sui sistemi MetroCluster dei clienti è a singola istanza e segue le raccomandazioni contenute nella documentazione relativa a Oracle su ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror fornisce una copia sincrona dei dati nel sito di disaster recovery, ma per renderli disponibili sono necessari un sistema operativo e le applicazioni associate. L'automazione di base può migliorare notevolmente il tempo di failover dell'ambiente complessivo. I prodotti Clusterware come Veritas Cluster Server (VCS) vengono spesso utilizzati per creare un cluster in tutti i siti e in molti casi il processo di failover può essere guidato con semplici script.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">In caso di perdita dei nodi primari, il clusterware (o gli script) viene configurato in modo da portare i database online nel sito alternativo. Un'opzione è creare server di standby preconfigurati per le risorse NFS o SAN che compongono il database. Se il sito primario non funziona, il clusterware o l'alternativa con script esegue una sequenza di azioni simile alle seguenti:</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Montaggio di file system e/o montaggio di gruppi di dischi ASM</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Avvio del database</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">Il requisito principale di questo approccio è rappresentato da un sistema operativo in esecuzione sul sito remoto. Deve essere preconfigurato con i file binari di Oracle, il che significa anche che attività come l'applicazione delle patch Oracle devono essere eseguite sul sito primario e di standby. In alternativa, è possibile eseguire il mirroring dei file binari di Oracle nel sito remoto e montarli se viene dichiarato un disastro.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Avvio manuale dei database o configurazione delle macchine virtuali per avviare automaticamente i database, ad esempio, un cluster ESX può estendersi su diversi siti. In caso di disastro, dopo lo switchover, è possibile portare online le macchine virtuali nel sito di disaster recovery. Fino a quando i datastore che ospitano i database server virtualizzati non saranno in uso in occasione di un evento di emergenza, non sarà necessario impostare alcun valore<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sui volumi associati.</block>
  <block id="6c2e01aca4f10a83d34e3f3046435e82" category="summary">SnapMirror e SyncMirror</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Quasi tutte le applicazioni richiedono la replica dei dati.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">A livello di base, la replica può significare una copia su nastro archiviata fuori sede o una replica a livello di applicazione in una posizione di standby. Il disaster recovery si riferisce all'utilizzo di queste copie di replica per portare un servizio online in caso di perdita catastrofica del servizio.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP offre numerose opzioni di replica per soddisfare numerosi requisiti in maniera nativa all'interno dello storage array e soddisfare una vasta gamma di esigenze. Queste opzioni includono la replica semplice dei backup su un sito remoto fino a una soluzione sincrona e completamente automatizzata che fornisce disaster recovery e alta disponibilità nella stessa piattaforma.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Le principali tecnologie di replica ONTAP applicabili alle applicazioni sono le tecnologie SnapMirror e NetApp SyncMirror di NetApp. Non si tratta di prodotti aggiuntivi, bensì di prodotti completamente integrati in ONTAP e attivati tramite la semplice aggiunta di una chiave di licenza. Anche la replica a livello di storage non è l'unica opzione possibile. La replica a livello di applicazione, come ad esempio Oracle DataGuard, può anche integrarsi in una strategia di protezione dei dati basata su ONTAP.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">La scelta giusta dipende dai requisiti specifici di replica, recovery e conservazione.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">SnapMirror di ONTAP</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror è la soluzione di replica asincrona di NetApp, idealmente creata per proteggere set di dati grandi, complicati e dinamici come database e le loro applicazioni associate. I valori chiave sono i seguenti:</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">*Gestibilità.* SnapMirror è facile da configurare e gestire perché è una parte nativa del software di storage. Non sono richiesti prodotti aggiuntivi. Le relazioni di replica possono essere stabilite in pochi minuti e possono essere gestite direttamente nel sistema storage.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Semplicità.* la replica si basa su volumi FlexVol, ovvero container di LUN o file replicati come unico gruppo coerente.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Efficienza.* dopo aver stabilito la relazione di replica iniziale, vengono replicate solo le modifiche. Inoltre, funzionalità di efficienza come deduplica e compressione sono preservate, riducendo ulteriormente la quantità di dati da trasferire in un sito remoto.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flessibilità.* i mirror possono essere temporaneamente interrotti per consentire il test delle procedure di ripristino di emergenza, e quindi il mirroring può essere facilmente ristabilito senza la necessità di un rimirroring completo. Solo i dati modificati devono essere applicati per riportare i mirror in sincronizzazione. Il mirroring può anche essere invertito per consentire una rapida risincronizzazione dopo il termine del disastro e il sito originale di nuovo in servizio. Infine, sono disponibili per test e sviluppo cloni in lettura e scrittura dei dati replicati.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP offre diverse tecnologie di replica, ma la più flessibile è SnapMirror, un'opzione di mirroring asincrono da volume a volume.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Come accennato in precedenza, un volume FlexVol è l'unità di gestione di base per i backup basati su Snapshot e il ripristino basato su SnapRestore. Un volume FlexVol è anche l'unità di base per la replica basata su SnapMirror. Il primo passaggio consiste nel determinare il mirror di base del volume di origine rispetto al volume di destinazione. Dopo l'inizializzazione di questa relazione mirror, tutte le operazioni successive si basano solo sulla replica dei dati modificati.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Dal punto di vista del ripristino, i valori chiave di SnapMirror sono i seguenti:</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">Le operazioni di SnapMirror sono semplici da comprendere e possono essere facilmente automatizzate.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Un semplice aggiornamento di una replica SnapMirror richiede la replica solo delle modifiche delta, riducendo i requisiti di larghezza di banda e consentendo aggiornamenti più frequenti.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror è altamente granulare. Si basa su semplici relazioni da volume a volume, consentendo la creazione di centinaia di repliche e intervalli di replica gestiti in modo indipendente. Non è necessario che la replica sia adatta a ogni scenario.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">La direzione di specchiatura può essere facilmente invertita, pur mantenendo la capacità di aggiornare la relazione in base alle sole modifiche. In questo modo è possibile usufruire di una rapida funzionalità di failback dopo che il sito primario viene ripristinato in servizio dopo un evento disastroso, ad esempio un'interruzione dell'alimentazione. Solo le modifiche devono essere sincronizzate di nuovo all'origine.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Gli specchi possono essere facilmente rotti e risincronizzati in modo efficiente per consentire la ripetizione delle procedure di ripristino di emergenza.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">SnapMirror in modalità di replica completa a livello di blocco replica non solo i dati di un volume, ma anche gli Snapshot. Questa funzionalità fornisce una copia dei dati e una serie completa di backup sul sito di disaster recovery.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">SnapMirror in modalità flessibile della versione consente la replica di snapshot specifiche, consentendo diversi tempi di conservazione nei siti primario e secondario.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror sincrono</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror Synchronous (SM-S) è una versione avanzata di SnapMirror che offre replica sincrona RPO=0. Viene più spesso utilizzato nelle architetture storage in cui solo il sottoinsieme dei dati totali richiede il mirroring sincrono.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S può operare in due modalità leggermente diverse, Sync e StrictSync.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">In modalità di sincronizzazione, le modifiche vengono replicate prima di essere confermate. Questo garantisce un RPO pari a zero, a condizione che la replica sia operativa. Se la modifica non può essere replicata, SM-S può uscire dalla modalità sincrona e consentire il proseguimento delle operazioni. In questo modo è possibile ottenere RPO=0 in circostanze normali, ma i processi dei dati non si interrompono completamente se la destinazione di replica non è disponibile.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantisce un RPO=0. Un errore di replica delle modifiche causa un errore di i/o, che in genere provoca l'arresto dell'applicazione.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Per una spiegazione completa di SM-S, vedere<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> E la documentazione ufficiale di ONTAP. Le nuove versioni di ONTAP vengono continuamente aggiunte alle nuove funzioni.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Gruppi di coerenza</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP consente la creazione di snapshot di gruppi di coerenza; a partire da 9.13.1, ONTAP può replicare gruppi di volumi (ricorda che un volume nella terminologia ONTAP non è una LUN, ma un container di gestione costituito da uno o più file o LUN) come gruppo coerente.</block>
  <block id="80c6d3e933105ad9a2c104ec78444b8c" category="paragraph">La replica di SnapMirror e l'interruzione della relazione CG SnapMirror preserva la coerenza tra i volumi, mentre SnapMirror Synchronous e SnapMirror Business Continuity preservano la coerenza tra i volumi costituenti.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">Il risultato è che è possibile replicare un set di dati multi-volume e assicurare che tutti i volumi siano cross-coerenti. Tra le altre cose, questo consente operazioni di DR "breaking the mirror and go" senza la necessità di fasi aggiuntive di ripristino del database o delle applicazioni.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster e SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster è anche una soluzione di replica sincrona dedicata a workload mission-critical su larga scala. Replica basata su SyncMirror. Al livello più semplice, SyncMirror crea due set completi di dati con protezione RAID in due posizioni diverse. Potrebbero trovarsi in camere comunicanti all'interno di un data center o a una distanza di molti chilometri.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror è completamente integrato con ONTAP e funziona appena al di sopra del livello RAID. Pertanto, tutte le consuete funzionalità di ONTAP, come le copie Snapshot, SnapRestore e NetApp FlexClone, funzionano perfettamente. Il prodotto rimane ONTAP e include un livello aggiuntivo di mirroring sincrono dei dati.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Una raccolta di controller ONTAP che gestiscono i dati SyncMirror viene chiamata configurazione NetApp MetroCluster. Lo scopo principale di MetroCluster è fornire accesso con high Availability ai dati con mirroring sincrono in una varietà di scenari tipici di errore di disaster recovery.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Di seguito sono riportati i valori chiave della protezione dei dati con MetroCluster e SyncMirror:</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">Nelle operazioni normali, SyncMirror offre mirroring sincrono garantito tra siti. Un'operazione di scrittura non viene riconosciuta fino a quando non è presente su supporti non volatili in entrambi i siti.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">Se si verifica un guasto nella connettività tra i siti, SyncMirror passa automaticamente alla modalità asincrona per mantenere il sito primario che fornisce dati fino al ripristino della connettività. Una volta ripristinato, garantisce una rapida risincronizzazione aggiornando in modo efficiente le modifiche accumulate sul sito primario. La reinizializzazione completa non è necessaria.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror è inoltre completamente compatibile con sistemi basati su SyncMirror. Ad esempio, è possibile che un database primario venga eseguito su un cluster MetroCluster distribuito in due siti geografici. Questo database può anche replicare i backup su un terzo sito come archivi a lungo termine o per la creazione di cloni in un ambiente DevOps.</block>
  <block id="0660b44d1a6d7e0d905c3fe28eef63ab" category="summary">Procedura di Oracle su ONTAP DR con spedizione dei log</block>
  <block id="54bae719e8fa53582d5b2781b4952c6b" category="doc">Disaster recovery con riproduzione dei log</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Le procedure di replica per un database Oracle sono essenzialmente le stesse delle procedure di backup. Il requisito principale è che gli snapshot che costituiscono un backup recuperabile debbano essere replicati nel sistema di storage remoto.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Come discusso in precedenza nella documentazione sulla protezione locale dei dati, è possibile creare un backup ripristinabile con il processo di hot backup o sfruttando i backup ottimizzati per le istantanee.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Layout dei dati</block>
  <block id="30394da99a39ca8264b8f7c0e6f679e0" category="paragraph">Il requisito più importante è l'isolamento dei dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. Il motivo è accertarsi che la replica dei file dati sia completamente indipendente dalla replica di altri tipi di dati, come i registri di archivio. Per ulteriori informazioni sui layout dei file e per informazioni importanti su come garantire che il layout di archiviazione sia di facile utilizzo, vedere  <block ref="5a4fdf6a1fc411e544cf6d70d47a8289" category="inline-link-macro-rx"></block>.</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Supponendo che i file di dati siano incapsulati in volumi dedicati, la domanda successiva è come gestire i log di ripristino, i log di archivio e i file di controllo. L'approccio più semplice consiste nel posizionare tutti questi tipi di dati in un singolo volume. Il vantaggio è che i log di ripristino replicati, i log di archivio e i controlfile sono perfettamente sincronizzati. Non è necessario un ripristino incompleto o l'utilizzo di un controlfile di backup, sebbene sia consigliabile creare script anche per la creazione di file di controllo di backup per altri scenari di ripristino potenziali.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Layout a due volumi</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">Il layout più semplice è illustrato nella figura seguente.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">Questo è l'approccio più comune. Dal punto di vista dei DBA, potrebbe sembrare insolito colocare tutte le copie dei log di ripristino e dei log di archivio sullo stesso volume. Tuttavia, la separazione non offre molta protezione extra quando file e LUN si trovano tutti sullo stesso set di dischi sottostante.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Layout a tre volumi</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">A volte è necessaria la separazione dei log di ripristino a causa di problemi relativi alla protezione dei dati o della necessità di distribuire i/o dei log di ripristino tra i controller. In tal caso, il layout a tre volumi illustrato nella figura seguente può essere utilizzato per la replica, evitando tuttavia qualsiasi necessità di eseguire un ripristino incompleto o di fare affidamento su file di controllo di backup.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Ciò consente lo striping dei log di redo e dei file di controllo attraverso insiemi indipendenti di mandrini e controllori sulla sorgente. Tuttavia, i log di archivio e una serie di file di controllo e i log di ripristino possono ancora essere replicati in uno stato sincronizzato con i log di archivio.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">In questo modello, il volume Redo Log B non viene replicato.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Procedura di disaster recovery: Backup a caldo</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Per eseguire il ripristino di emergenza utilizzando i backup a caldo, attenersi alla seguente procedura di base:</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prerequisiti</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">I file binari Oracle vengono installati sul server di disaster recovery.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Le istanze di database sono elencate nella<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">Il<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> e.<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> oppure<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> per l'esempio deve essere in<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directory. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Disaster recovery</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Interrompere i mirror per i file di dati e il volume di registro comune.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Ripristinare i volumi del file dati nello snapshot di backup a caldo più recente dei file di dati.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Se si utilizza una rete SAN, attivare gruppi di volumi e/o montare file system.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Riprodurre i log di archivio nel punto desiderato.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Se si desidera completare il ripristino, riprodurre i registri di ripristino correnti.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">L'utilizzo di NFS semplifica notevolmente la procedura poiché i file system NFS per i file di dati e di log possono essere montati sul server di disaster recovery in qualsiasi momento. Diventa lettura/scrittura quando gli specchi sono rotti.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Procedura di disaster recovery: Backup ottimizzati per le snapshot</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">Il ripristino da backup ottimizzati per snapshot è quasi identico alla procedura di ripristino hot backup con le seguenti modifiche:</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Ripristinare i volumi del file dati in uno snapshot creato prima della replica del volume del registro corrente.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Queste differenze semplificano la procedura di ripristino generale poiché non è necessario assicurarsi che uno snapshot sia stato creato correttamente sull'origine mentre il database era in modalità di backup a caldo. La procedura di disaster recovery si basa sull'ora delle snapshot nel sito di disaster recovery. Lo stato del database al momento della creazione degli snapshot non è importante.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Disaster recovery con snapshot di backup a caldo</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Questo è un esempio di strategia di disaster recovery basata sulla replica delle snapshot di backup hot. E costituisce anche un esempio di strategia di backup locale semplice e scalabile.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">Il database di esempio si trova in un'architettura di base a due volumi.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene i file di dati e.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> viene utilizzato per i log di ripristino combinati, i log di archivio e i file di controllo.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Sono necessarie due pianificazioni, una per i backup notturni dei file dati e una per i backup dei file di registro. Questi sono chiamati rispettivamente mezzanotte e 15minutes.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Queste pianificazioni vengono quindi utilizzate all'interno dei criteri di snapshot<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> e.<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, come mostrato di seguito:</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Infine, queste policy di snapshot vengono applicate ai volumi,</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Definisce la pianificazione del backup dei volumi. Le snapshot dei file dati vengono create a mezzanotte e conservate per 60 giorni. Il volume di registro contiene 72 snapshot create a intervalli di 15 minuti, con un massimo di 18 ore di copertura.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">Quindi, assicurarsi che il database sia in modalità hot backup quando viene creata una snapshot del file dati. Questo viene fatto con un piccolo script che accetta alcuni argomenti di base che avviano e interrompono la modalità di backup sul SID specificato.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">Questo passaggio garantisce che il database sia in modalità di backup a caldo durante una finestra di quattro minuti che circonda lo snapshot di mezzanotte.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">La replica nel sito di disaster recovery viene configurata come segue:</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">La destinazione del volume del registro viene aggiornata ogni 15 minuti. Questo garantisce un RPO di circa 15 minuti. L'intervallo di aggiornamento preciso varia leggermente a seconda del volume totale dei dati che devono essere trasferiti durante l'aggiornamento.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">La destinazione del volume del file dati viene aggiornata ogni sei ore. Ciò non influisce su RPO o RTO. Qualora fosse necessario un ripristino di emergenza, uno dei primi passaggi consiste nel ripristinare il volume del file dati in uno snapshot di backup a caldo. Lo scopo dell'intervallo di aggiornamento più frequente è di regolare la velocità di trasferimento di questo volume. Se l'aggiornamento è programmato una volta al giorno, tutte le modifiche accumulate durante il giorno devono essere trasferite contemporaneamente. Con aggiornamenti più frequenti, le modifiche vengono replicate più gradualmente nel corso della giornata.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">In caso di disastro, il primo passo è quello di interrompere i mirror per entrambi i volumi:</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Le repliche sono ora in lettura-scrittura. Il passaggio successivo consiste nel verificare la data e l'ora del volume di registro.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">La copia più recente del volume di registro è il 14th marzo alle ore 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">Quindi, identificare lo snapshot di backup a caldo creato immediatamente prima dello stato del volume di registro. Questa operazione è necessaria in quanto il processo di riproduzione dei log richiede la creazione di tutti i log di archivio in modalità hot backup. Pertanto, la replica del volume di registro deve essere precedente alle immagini di backup a caldo oppure non deve contenere i registri richiesti.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">L'istantanea creata più di recente è<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Questa è l'immagine di backup a caldo più recente dei file di dati e viene quindi ripristinata nel modo seguente:</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">A questo punto, il database è pronto per essere recuperato. Se si trattasse di un ambiente SAN, il passaggio successivo includerebbe l'attivazione di gruppi di volumi e il montaggio di file system, un processo facilmente automatizzato. Poiché questo esempio utilizza NFS, i file system sono già montati e diventano in lettura-scrittura senza ulteriore necessità di montaggio o attivazione nel momento in cui i mirror sono stati rotti.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">A questo punto il database può essere ripristinato al punto desiderato oppure può essere completamente recuperato in relazione alla copia dei log di ripristino replicati. In questo esempio viene illustrato il valore del registro di archiviazione combinato, controlfile e del volume del registro di ripristino. Il processo di ripristino è notevolmente più semplice in quanto non è necessario fare affidamento su file di controllo di backup o su file di registro di ripristino.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Disaster recovery con backup ottimizzati per le snapshot</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">La procedura di disaster recovery che utilizza backup ottimizzati per le istantanee è quasi identica alla procedura di disaster recovery per il backup a caldo. Come per la procedura di snapshot di backup a caldo, si tratta essenzialmente anche di un'estensione di un'architettura di backup locale in cui i backup vengono replicati per essere utilizzati per il disaster recovery. Nell'esempio seguente viene illustrata la procedura di configurazione e ripristino dettagliata. Questo esempio richiama inoltre le principali differenze tra i backup hot e quelli ottimizzati per le istantanee.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">Il database di esempio si trova in un'architettura di base a due volumi.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene file di dati, e.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> viene utilizzato per i log di ripristino combinati, i log di archivio e i file di controllo.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Sono necessarie due pianificazioni: Una per i backup notturni dei file dati e una per i backup dei file di registro. Questi sono chiamati rispettivamente mezzanotte e 15minutes.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">Questo controlla la pianificazione di backup finale dei volumi. Le snapshot vengono create a mezzanotte e conservate per 60 giorni. Il volume di registro contiene 72 snapshot create a intervalli di 15 minuti, con un massimo di 18 ore di copertura.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">La destinazione del volume del registro viene aggiornata ogni 15 minuti. In questo modo si ottiene un RPO di circa 15 minuti, con un intervallo di aggiornamento preciso che varia leggermente a seconda del volume totale dei dati che devono essere trasferiti durante l'aggiornamento.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">La destinazione del volume del file dati viene aggiornata ogni 6 ore. Ciò non influisce su RPO o RTO. Se è necessario un ripristino di emergenza, è necessario ripristinare prima il volume del file dati in una snapshot di backup a caldo. Lo scopo dell'intervallo di aggiornamento più frequente è di regolare la velocità di trasferimento di questo volume. Se l'aggiornamento è stato pianificato una volta al giorno, tutte le modifiche accumulate durante il giorno devono essere trasferite contemporaneamente. Con aggiornamenti più frequenti, le modifiche vengono replicate più gradualmente nel corso della giornata.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">In caso di disastro, innanzitutto occorre interrompere i mirror per tutti i volumi:</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">La copia più recente del volume di registro è il 14th marzo alle ore 13:30. Quindi, identificare lo snapshot del file dati creato immediatamente prima dello stato del volume di registro. Ciò è necessario in quanto il processo di riproduzione dei log richiede tutti i log di archivio appena precedenti allo snapshot nel punto di ripristino desiderato.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">L'istantanea creata più di recente è<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Ripristinare questa istantanea.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">Il database è ora pronto per essere recuperato. Se si trattasse di un ambiente SAN, si attiverebbero quindi gruppi di volumi e si montassero file system, un processo facilmente automatizzato. Tuttavia, questo esempio utilizza NFS, quindi i file system sono già montati e sono diventati lettura-scrittura senza ulteriore necessità di montaggio o attivazione nel momento in cui i mirror sono stati rotti.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">A questo punto il database può essere ripristinato al punto desiderato oppure può essere completamente recuperato in relazione alla copia dei log di ripristino replicati. In questo esempio viene illustrato il valore del registro di archiviazione combinato, controlfile e del volume del registro di ripristino. Il processo di recupero è notevolmente più semplice in quanto non è necessario fare affidamento su file di controllo di backup o su file di registro di ripristino.</block>
  <block id="d6597945276340ba33115e737eb4b489" category="summary">Replica di gruppo di coerenza per i database Oracle</block>
  <block id="fc506ae4ea109f50758acc176bcb5341" category="doc">Disaster recovery di gruppo di coerenza</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">La replica di un gruppo di coerenza può essere semplice come la pianificazione della replica di un singolo volume tramite SnapMirror. Sono inclusi file di dati, file di controllo, log di archivio e log di ripristino. Ogni aggiornamento SnapMirror crea una nuova copia del database nel sito di destinazione coerente e pronta per l'attivazione tramite la rottura del mirror.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Se un database deve span volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot).</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Un ulteriore vantaggio di questa strategia, se utilizzata con SnapMirror in modalità di replica a livello di blocco, è la replica completa di tutti gli snapshot nel sistema di storage di origine. La serie completa di backup viene replicata oltre alla copia di disaster recovery.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Tiering del log di archivio Oracle</block>
  <block id="113d9dffdeb8fa14877fc8cf8ca7c9d5" category="doc">Tiering dei log Oracle</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">Forse l'utilizzo più importante per FabricPool è il miglioramento dell'efficienza dei dati cold noti, come i log delle transazioni dei database.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Tiering del backup Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">I backup delle applicazioni tradizionali includono prodotti come Oracle Recovery Manager, che creano backup basati su file al di fuori della posizione del database originale.</block>
  <block id="6cddb309df5eb8791dc990f72ef2deb2" category="summary">Criteri di tiering di Oracle</block>
  <block id="7ba3322dbc0b3c33a66f1963e80b7a2a" category="doc">Policy di tiering dei database Oracle</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">In ONTAP sono disponibili quattro criteri che controllano il modo in cui i dati Oracle sul livello di prestazioni diventano candidati per il trasferimento al livello di capacità.</block>
  <block id="47f6817eca23122cc683f7c2759e6ecb" category="summary">Tiering completo delle sezioni Oracle</block>
  <block id="1def0ac22a738b54cce584e969065918" category="doc">Tiering completo dei file Oracle</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">Anche se il tiering FabricPool opera a livello di blocco, in alcuni casi può essere utilizzato per fornire un tiering a livello di file.</block>
  <block id="468853d9ed2134af17ede5fd165a8dff" category="summary">Tiering parziale dei file con FabricPool</block>
  <block id="5638b2f30ee966b3ff84bac350092971" category="doc">Tiering parziale dei file Oracle</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Poiché FabricPool opera a livello di blocchi, i file soggetti a modifiche possono essere parzialmente suddivisi in Tier nello storage a oggetti e rimanere parzialmente anche nel Tier di performance.</block>
  <block id="dd22ff2cf158f98efbd92f4522b3064b" category="summary">Accesso al database durante le interruzioni di accesso agli archivi di oggetti</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Interruzioni di accesso agli archivi di oggetti</block>
  <block id="bbb21240a2cc48eb7a229ec824e70cdf" category="summary">Panoramica sul tiering di Oracle con FabricPool</block>
  <block id="ec2ffb259f21d115e5481eb0f215aa0d" category="doc">Panoramica sul tiering Oracle</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">La comprensione dell'impatto del tiering FabricPool su Oracle e altri database richiede una conoscenza dell'architettura FabricPool di basso livello.</block>
  <block id="cd6b77e4d343896571bc445479f24588" category="summary">Criteri di recupero per il tiering Pracle</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">Criteri di recupero</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">I criteri di tiering controllano i blocchi di database Oracle sottoposti a tiering dal Tier di performance al Tier di capacità. I criteri di recupero controllano ciò che accade quando viene letto un blocco a cui è stato eseguito il tiering.</block>
  <block id="95ab96ac5aaeae15f7b499d0fa0313cf" category="summary">Tiering delle snapshot Oracle</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Linee guida per il dimensionamento e il numero di LUN dei database Oracle</block>
  <block id="b9e88e2eb3d5eef807fc42db706d866a" category="doc">Dimensionamento e numero di LUN di Oracle</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">La scelta delle dimensioni ottimali e del numero di LUN da utilizzare è un elemento critico per ottenere performance e gestibilità ottimali dei database Oracle.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">I database Oracle e NFS vengono affittati e bloccati</block>
  <block id="472f36eb81330c2c27f02245ce8a911e" category="doc">Locazioni e blocchi di NFS - Oracle</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 è stateless. Ciò significa che il server NFS (ONTAP) non tiene traccia di quali file system sono montati, da chi, o quali blocchi sono realmente presenti.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP dispone di alcune funzionalità che registreranno i tentativi di mount, quindi si ha un'idea di quali client possono accedere ai dati e potrebbero essere presenti blocchi di avvisi, ma non è garantito che le informazioni siano complete al 100%. Non può essere completo, perché il tracciamento dello stato del client NFS non fa parte dello standard NFSv3.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">NFSv4 statefulness</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">Al contrario, NFSv4 è stateful. Il server NFSv4 tiene traccia di quali client utilizzano i file system, quali file esistono, quali file e/o aree di file sono bloccati, ecc. Ciò significa che è necessaria una comunicazione regolare tra un server NFSv4 per mantenere aggiornati i dati di stato.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Gli stati più importanti gestiti dal server NFS sono NFSv4 Locks e NFSv4 Leasing, e sono molto interconnessi. Dovete capire come ognuno funziona da se stesso e come si relazionano l'uno con l'altro.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">NFSv4 serrature</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Con NFSv3, i blocchi sono indicativi. Un client NFS può comunque modificare o eliminare un file "bloccato". Un blocco NFSv3 non scade da solo, deve essere rimosso. Questo crea problemi. Ad esempio, se si dispone di un'applicazione in cluster che crea blocchi NFSv3 e uno dei nodi ha esito negativo, come procedere? È possibile codificare l'applicazione sui nodi sopravvissuti per rimuovere i blocchi, ma come si fa a sapere che questo è sicuro? Il nodo "guasto" potrebbe essere operativo, ma non comunica con il resto del cluster?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Con NFSv4, i blocchi hanno una durata limitata. Finché il client che mantiene i blocchi continua il check-in con il server NFSv4, nessun altro client è autorizzato ad acquisire tali blocchi. Se un client non riesce a eseguire il check in con NFSv4, i blocchi vengono revocati dal server e gli altri client potranno richiedere e ottenere i blocchi.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">NFSv4 leasing</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">I blocchi NFSv4 sono associati a un lease NFSv4. Quando un client NFSv4 stabilisce una connessione con un server NFSv4, ottiene un lease. Se il client ottiene un blocco (ci sono molti tipi di blocchi) allora il blocco è associato al lease.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Questo lease ha un timeout definito. Per impostazione predefinita, ONTAP imposta il valore di timeout su 30 secondi:</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Ciò significa che un client NFSv4 deve effettuare il check-in con il server NFSv4 ogni 30 secondi per rinnovare i propri leasing.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">Il leasing viene rinnovato automaticamente da qualsiasi attività, quindi se il client sta lavorando non è necessario eseguire operazioni di aggiunta. Se un'applicazione diventa silenziosa e non sta svolgendo un lavoro reale, sarà necessario eseguire una sorta di operazione keep-alive (chiamata SEQUENZA). In sostanza, è solo dire "sono ancora qui, ti prego di rinnovare i miei contratti di leasing".</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 è stateless. Non si aspetta la comunicazione dai clienti. NFSv4 è stateful, e una volta trascorso il periodo di leasing, il lease scade, i blocchi vengono revocati e i file bloccati vengono resi disponibili ad altri client.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Con NFSv3, è possibile spostare i cavi di rete, riavviare gli switch di rete, apportare modifiche alla configurazione e assicurarsi che non si verifichi alcun problema. Normalmente, le applicazioni aspettavano solo pazientemente che la connessione di rete funzionasse di nuovo.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Con NFSv4, avete 30 secondi (a meno che non abbiate aumentato il valore di quel parametro all'interno di ONTAP) per completare il vostro lavoro. Se si supera questo limite, il tempo di leasing è scaduto. In genere si verificano arresti anomali delle applicazioni.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Ad esempio, se si dispone di un database Oracle e si verifica una perdita di connettività di rete (talvolta chiamata "partizione di rete") che supera il timeout del lease, il database verrà arrestato.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">Di seguito viene riportato un esempio di ciò che accade nel registro degli avvisi di Oracle:</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Se si esaminano i syslogs, si dovrebbero vedere alcuni di questi errori:</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">I messaggi di registro sono in genere il primo segno di un problema, diverso dal blocco dell'applicazione. In genere, durante l'interruzione della rete non viene visualizzato nulla, poiché i processi e il sistema operativo stesso sono bloccati e tentano di accedere al file system NFS.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Gli errori vengono visualizzati dopo che la rete è nuovamente operativa. Nell'esempio precedente, una volta ristabilita la connettività, il sistema operativo tentava di riacquisire i blocchi, ma era troppo tardi. Il leasing era scaduto e i blocchi sono stati rimossi. Ciò genera un errore che si propaga fino al livello Oracle e causa il messaggio nel registro degli avvisi. È possibile che vengano visualizzate variazioni su questi modelli a seconda della versione e della configurazione del database.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">Riassumendo, NFSv3 tollera l'interruzione di rete, ma NFSv4 è più sensibile e impone un periodo di leasing definito.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">Cosa succede se un timeout di 30 secondi non è accettabile? Cosa succede se si gestisce una rete a variazione dinamica in cui gli switch vengono riavviati o i cavi vengono ricollocati e il risultato è un'interruzione occasionale della rete? È possibile scegliere di estendere il periodo di leasing, ma se si desidera farlo richiede una spiegazione di NFSv4 periodi di tolleranza.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">NFSv4 periodi di grazia</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Se un server NFSv3 viene riavviato, è pronto a servire i/o quasi istantaneamente. Non manteneva alcun tipo di stato sui client. Il risultato è che un'operazione di takeover della ONTAP spesso sembra quasi istantanea. Quando un controller è pronto a iniziare a servire i dati, invia un ARP alla rete che segnala la modifica della topologia. I client normalmente rilevano questo quasi istantaneamente e i dati riprendono a fluire.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4, tuttavia, produrrà una breve pausa. È solo una parte di come funziona NFSv4.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">I server NFSv4 devono tenere traccia dei lease, dei blocchi e di chi utilizza i dati. Se un server NFS si riavvia o perde potenza per un momento o viene riavviato durante l'attività di manutenzione, il risultato è il lease/lock e le altre informazioni del client vengono perse. Il server deve individuare quale client utilizza i dati prima di riprendere le operazioni. È qui che entra in gioco il periodo di grazia.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Se all'improvviso si spegne e riaccende il server NFSv4. Quando viene eseguito il backup, i client che tentano di riprendere io riceveranno una risposta che essenzialmente dice: "Ho perso le informazioni di lease/lock. Vuoi registrare nuovamente i blocchi?" Questo è l'inizio del periodo di grazia. Il valore predefinito è 45 secondi su ONTAP:</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">Il risultato è che, dopo un riavvio, un controller sospenderà io mentre tutti i client recuperano i loro lease e blocchi. Al termine del periodo di prova, il server riprenderà le operazioni io.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Timeout leasing vs periodi di grazia</block>
  <block id="563494d7f0f6ebcb6698cac7f9705aaa" category="paragraph">Il periodo di tolleranza e il periodo di leasing sono collegati. Come menzionato sopra, il timeout di lease predefinito è di 30 secondi, il che significa che NFSv4 client devono effettuare il check-in con il server almeno ogni 30 secondi o perdere i lease e, a loro volta, i blocchi. Il periodo di tolleranza esiste per consentire a un server NFS di ricostruire i dati di lease/lock e il valore predefinito è 45 secondi. ONTAP richiede che il periodo di tolleranza sia di 15 secondi più lungo del periodo di leasing. In questo modo, un ambiente client NFS progettato per rinnovare i lease almeno ogni 30 secondi avrà la possibilità di effettuare il check-in con il server dopo un riavvio. Un periodo di tolleranza di 45 secondi assicura che tutti quei clienti che si aspettano di rinnovare i loro leasing almeno ogni 30 secondi definitivamente hanno l'opportunità di farlo.</block>
  <block id="5e6b60906bbbb9a41b140c0749591489" category="paragraph">Se un timeout di 30 secondi non è accettabile, è possibile scegliere di prolungare il periodo di leasing. Se si desidera aumentare il timeout del lease a 60 secondi per resistere a un'interruzione di rete di 60 secondi, sarà necessario aumentare il periodo di tolleranza ad almeno 75 secondi. ONTAP richiede che sia superiore di 15 secondi al periodo di leasing. Ciò significa che si verificheranno pause di i/o più lunghe durante il failover del controller.</block>
  <block id="4611c7c931fc15a6feba513fe72e22de" category="paragraph">Normalmente questo non dovrebbe essere un problema. Gli utenti tipici aggiornano i controller ONTAP solo una o due volte all'anno e il failover non pianificato dovuto a guasti hardware è estremamente raro. Inoltre, se aveste una rete in cui un'interruzione di rete di 60 secondi fosse una possibilità preoccupante e aveste bisogno di un timeout del leasing di 60 secondi, probabilmente non vi opporreste a un raro failover del sistema storage con una pausa di 75 secondi. Hai già riconosciuto che la tua rete è in pausa per più di 60 secondi piuttosto frequentemente.</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">NFS diretto di Oracle</block>
  <block id="f58bdad9659176e411f064fdb414233f" category="doc">DirectNFS di Oracle</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">I database Oracle possono utilizzare NFS in due modi.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">In primo luogo, può usare un filesystem montato usando il client NFS nativo che fa parte del sistema operativo. Questo è talvolta chiamato kernel NFS, o kNFS. Il filesystem NFS è montato e usato dal database Oracle esattamente come qualsiasi altra applicazione userebbe un filesystem NFS.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">Il secondo metodo è Oracle Direct NFS (DNFS). Si tratta di un'implementazione dello standard NFS nel software di database Oracle. Senza modificare le modalità di configurazione o gestione dei database Oracle da parte del DBA. Purché le impostazioni del sistema storage siano corrette, l'utilizzo del DNFS deve essere trasparente per il team DBA e gli utenti finali.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Un database con la funzione DNFS attivata ha ancora i consueti filesystem NFS montati. Una volta aperto il database, il database Oracle apre una serie di sessioni TCP/IP ed esegue direttamente le operazioni NFS.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">NFS diretto</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">Il valore principale di Oracle Direct NFS è quello di ignorare il client NFS host ed eseguire operazioni di file NFS direttamente su un server NFS. Per abilitarla è sufficiente modificare la libreria Oracle Disk Manager (ODM). Le istruzioni per questo processo sono fornite nella documentazione di Oracle.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">L'utilizzo di DNFS porta a un significativo miglioramento delle performance di i/o e riduce il carico sull'host e sul sistema storage poiché l'i/o viene eseguito nel modo più efficiente possibile.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">Inoltre, Oracle DNFS include un'opzione *opzionale* per il multipathing e la fault tolerance dell'interfaccia di rete. Ad esempio, è possibile associare due interfacce 10Gb in modo da ottenere una larghezza di banda di 20Gb Gbps. Un errore di un'interfaccia provoca il tentativo di i/o sull'altra interfaccia. Il funzionamento complessivo è molto simile al multipathing FC. Il multipathing era comune anni fa quando ethernet a 1Gb GB rappresentava lo standard più comune. Una NIC 10Gb è sufficiente per la maggior parte dei carichi di lavoro Oracle, ma se ne richiede di più, è possibile collegare 10Gb NIC.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Quando si utilizza DNFS, è fondamentale che tutte le patch descritte in Oracle Doc 1495104,1 siano installate. Se non è possibile installare una patch, è necessario valutare l'ambiente per assicurarsi che i bug descritti in quel documento non causino problemi. In alcuni casi, l'impossibilità di installare le patch necessarie impedisce l'utilizzo di DNFS.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">Non utilizzare DNFS con alcun tipo di risoluzione dei nomi round-robin, compresi DNS, DDNS, NIS o qualsiasi altro metodo. Ciò include la funzione di bilanciamento del carico DNS disponibile in ONTAP. Quando un database Oracle che utilizza DNFS risolve un nome host in un indirizzo IP, non deve cambiare nelle ricerche successive. Ciò può causare arresti anomali del database Oracle e possibili danni ai dati.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Accesso diretto NFS e file system host</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">L'utilizzo di DNFS può causare occasionalmente problemi per le applicazioni o le attività degli utenti che si basano sui file system visibili montati sull'host perché il client DNFS accede al file system fuori banda dal sistema operativo host. Il client DNFS può creare, eliminare e modificare i file senza conoscere il sistema operativo.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Quando vengono utilizzate le opzioni di montaggio per i database a istanza singola, consentono la memorizzazione nella cache degli attributi di file e directory, il che significa anche che il contenuto di una directory viene memorizzato nella cache. Pertanto, DNFS può creare un file, e c'è un breve ritardo prima che il sistema operativo rilegga il contenuto della directory e il file diventi visibile all'utente. Questo non è generalmente un problema, ma, in rare occasioni, utility come SAP BR*Tools potrebbero avere problemi. In questo caso, risolvere il problema modificando le opzioni di montaggio in modo da utilizzare le raccomandazioni per Oracle RAC. Questa modifica comporta la disabilitazione di tutta la cache dell'host.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Modificare le opzioni di montaggio solo quando (a) viene utilizzato DNFS e (b) un problema deriva da un ritardo nella visibilità dei file. Se DNFS non è in uso, l'utilizzo delle opzioni di montaggio di Oracle RAC su un database a singola istanza comporta un peggioramento delle prestazioni.</block>
  <block id="b1ced01e4bbcd95ec43a2756131f8f9d" category="admonition">Vedere la nota su<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> poll <block ref="657185beb26ec14433f7e083717fa98b" category="inline-link-macro-rx"></block> Per un problema DNFS specifico di Linux che può produrre risultati insoliti.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Configurazione NFS per database Oracle</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp offre storage NFS Enterprise da oltre 30 anni e il suo utilizzo cresce insieme alla spinta verso infrastrutture basate sul cloud grazie alla sua semplicità.</block>
  <block id="95e0ac965f4d3a739263ba13584b6411" category="inline-link-macro">Best practice NFS su NetApp ONTAP TR-4067</block>
  <block id="c46e4d65876bc5d9253e8e293f59b613" category="paragraph">Il protocollo NFS include diverse versioni con diversi requisiti. Per una descrizione completa della configurazione NFS con ONTAP, vedere <block ref="e3fa0577f1d5ea8870d93a30eb76667f" category="inline-link-macro-rx"></block>. Le sezioni seguenti descrivono alcuni dei requisiti più critici e gli errori comuni degli utenti.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">Versioni di NFS</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">Il client NFS del sistema operativo deve essere supportato da NetApp.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 è supportato con sistemi operativi che seguono lo standard NFSv3.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 è supportato con il client Oracle DNFS.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 è supportato con tutti i sistemi operativi che seguono lo standard NFSv4.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">I sistemi NFSv4,1 e NFSv4,2 richiedono supporto specifico per il sistema operativo. Consultare <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Per i sistemi operativi supportati.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">Il supporto di Oracle DNFS per NFSv4,1 richiede Oracle 12.2.0.2 o versione successiva.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">Matrice di supporto di NetApp</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">Il <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Per NFSv3 e NFSv4 non sono inclusi sistemi operativi specifici. Tutti i sistemi operativi che rispettano la RFC sono generalmente supportati. Quando si cerca il supporto NFSv3 o NFSv4 nel IMT online, non selezionare un sistema operativo specifico perché non verranno visualizzate corrispondenze. Tutti i sistemi operativi sono implicitamente supportati dalla policy generale.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Tabelle degli slot TCP per Linux NFSv3</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">Le tabelle degli slot TCP sono l'equivalente di NFSv3 della profondità della coda degli HBA (host Bus Adapter). Queste tabelle controllano il numero di operazioni NFS che possono essere in sospeso in qualsiasi momento. Il valore predefinito è di solito 16, che è troppo basso per ottenere prestazioni ottimali. Il problema opposto si verifica sui kernel Linux più recenti, che possono aumentare automaticamente il limite della tabella degli slot TCP a un livello che satura il server NFS con le richieste.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Per prestazioni ottimali e per evitare problemi di prestazioni, regolare i parametri del kernel che controllano le tabelle degli slot TCP.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Eseguire<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> e osservare i seguenti parametri:</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Tutti i sistemi Linux dovrebbero includere<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, ma solo alcuni includono<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Entrambi devono essere impostati su 128.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">La mancata impostazione di questi parametri può avere effetti significativi sulle prestazioni. In alcuni casi, le prestazioni sono limitate poiché il sistema operativo linux non fornisce i/o sufficienti In altri casi, le latenze i/o aumentano quando il sistema operativo linux tenta di emettere più i/o di quanto possa essere gestito.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR e NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Alcuni clienti hanno segnalato problemi di prestazioni derivanti da una quantità eccessiva di i/o sui dati in<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> posizione. Il problema generalmente non si verifica finché non si sono accumulati molti dati sulle prestazioni. Il motivo dell'eccessivo i/o è sconosciuto, ma questo problema sembra essere dovuto ai processi Oracle che eseguono ripetutamente la scansione della directory di destinazione per rilevare eventuali modifiche.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Smontaggio del<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> e/o.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Le opzioni di montaggio consentono il caching del sistema operativo host e riducono i livelli di i/o dello storage.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp consiglia* di non piazzare<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> dati su un file system con<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> oppure<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> perché è probabile che si verifichino problemi di prestazioni. Separare<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> dati in un punto di montaggio diverso, se necessario.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">nfs-rootonly e mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP include un'opzione NFS denominata<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Che controlla se il server accetta connessioni di traffico NFS da porte elevate. Come misura di sicurezza, solo l'utente root è autorizzato ad aprire connessioni TCP/IP utilizzando una porta di origine inferiore a 1024, poiché tali porte sono normalmente riservate all'uso del sistema operativo, non ai processi utente. Questa restrizione aiuta a garantire che il traffico NFS provenga da un client NFS del sistema operativo effettivo e non da un processo dannoso che emula un client NFS. Il client Oracle DNFS è un driver userspace, ma il processo viene eseguito come root, quindi in genere non è necessario modificare il valore di<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. I collegamenti sono costituiti da porte basse.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">Il<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> L'opzione è valida solo per NFSv3. Controlla se la chiamata di MONTAGGIO RPC può essere accettata dalle porte superiori a 1024. Quando si utilizza DNFS, il client viene nuovamente eseguito come root, in modo da poter aprire le porte al di sotto di 1024. Questo parametro non ha alcun effetto.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">I processi che aprono connessioni con DNFS su NFS versione 4,0 e successive non vengono eseguiti come root e quindi richiedono porte su 1024. Il<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Il parametro deve essere impostato su disabilitato affinché DNFS completi la connessione.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Se<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> È attivato, il risultato è un blocco durante la fase di mount che apre le connessioni DNFS. L'output di sqlplus è simile a questo:</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">Il parametro può essere modificato come segue:</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">In situazioni rare, potrebbe essere necessario modificare sia nfs-rootonly che mount-rootonly in disabled. Se un server gestisce un numero estremamente elevato di connessioni TCP, è possibile che non siano disponibili porte al di sotto di 1024 e che il sistema operativo sia costretto a utilizzare porte più elevate. Questi due parametri ONTAP devono essere modificati per consentire il completamento della connessione.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">Policy di esportazione NFS: Superuser e setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Se i file binari Oracle si trovano in una condivisione NFS, la policy di esportazione deve includere autorizzazioni superser e setuid.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Le esportazioni NFS condivise utilizzate per servizi file generici come le home directory dell'utente spesso fanno uso dell'utente root. Ciò significa che una richiesta da parte dell'utente root su un host che ha montato un filesystem viene rimappata come un altro utente con privilegi inferiori. In questo modo è possibile proteggere i dati impedendo a un utente root di un determinato server di accedere ai dati del server condiviso. Il bit setuid può anche essere un rischio per la protezione in un ambiente condiviso. Il bit setuid consente di eseguire un processo come un utente diverso da quello che richiama il comando. Ad esempio, uno script della shell di proprietà di root con il bit setuid viene eseguito come root. Se lo script della shell potrebbe essere modificato da altri utenti, qualsiasi utente non root potrebbe eseguire un comando come root aggiornando lo script.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">I file binari di Oracle includono file di proprietà di root e utilizzano il bit setuid. Se i file binari Oracle sono installati su una condivisione NFS, la policy di esportazione deve includere le autorizzazioni appropriate per superutente e setuid. Nell'esempio seguente, la regola include entrambi<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> e permessi<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> Accesso root per client NFS utilizzando l'autenticazione di sistema.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Configurazione NFSv4/4,1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Per la maggior parte delle applicazioni, la differenza tra NFSv3 e NFSv4 è minima. L'i/o delle applicazioni è di solito un i/o molto semplice e non trae alcun vantaggio significativo da alcune delle funzionalità avanzate disponibili in NFSv4. Le versioni più elevate di NFS non devono essere considerate come un "aggiornamento" dal punto di vista dello storage dei database, ma come versioni di NFS che includono funzionalità aggiuntive. Ad esempio, se è richiesta la protezione end-to-end della modalità di privacy Kerberos (krb5p), è necessario NFSv4.</block>
  <block id="5cee42a6ee353ec8d6538898f8e63d2d" category="inline-link">Best practice TR-4067 NFS su NetApp ONTAP</block>
  <block id="1ca271e9db310f8a7fb925b114fd6811" category="paragraph">Il passaggio a NFSv4 è più complicato che cambiare semplicemente le opzioni di montaggio da vers=3 a vers=4,1. Una spiegazione più completa della configurazione NFSv4 con ONTAP, incluse le istruzioni sulla configurazione del sistema operativo, vedere<block ref="2d2395ce3ab8a9852abebca9822b9553" category="inline-link-rx"></block>. Le seguenti sezioni di questo TR spiegano alcuni dei requisiti di base per l'utilizzo di NFSv4.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">Dominio NFSv4</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Una spiegazione completa della configurazione NFSv4/4,1 esula dall'ambito di questo documento, ma un problema comunemente riscontrato è una mancata corrispondenza nella mappatura del dominio. Dal punto di vista di sysadmin, i file system NFS sembrano comportarsi normalmente, ma le applicazioni segnalano errori relativi ai permessi e/o setuid su determinati file. In alcuni casi, gli amministratori hanno concluso erroneamente che le autorizzazioni dei binari dell'applicazione sono state danneggiate e hanno eseguito comandi chown o chmod quando il problema effettivo era il nome di dominio.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">Il nome di dominio NFSv4 viene impostato sulla SVM ONTAP:</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">Il nome di dominio NFSv4 sull'host è impostato in<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">I nomi di dominio devono corrispondere. In caso contrario, vengono visualizzati errori di mappatura simili a quelli riportati di seguito nella<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">I file binari delle applicazioni, come i file binari dei database Oracle, includono i file di proprietà di root con il bit setuid, il che significa che una mancata corrispondenza nei nomi di dominio NFSv4 causa errori nell'avvio di Oracle e un avviso sulla proprietà o sulle autorizzazioni di un file chiamato<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, che si trova nella<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> directory. Dovrebbe comparire come segue:</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Se questo file viene visualizzato con proprietà di nessuno, potrebbe esserci un problema di mappatura del dominio NFSv4.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Per risolvere questo problema, controllare<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Eseguire il file in base all'impostazione del dominio id v4 in ONTAP e assicurarsi che siano coerenti. In caso contrario, apportare le modifiche necessarie, eseguire<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, e attendere un momento per la propagazione delle modifiche. La proprietà del file dovrebbe quindi essere riconosciuta correttamente come root. Se un utente aveva tentato di eseguire<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Su questo file prima che la configurazione dei domini NFS sia stata corretta, potrebbe essere necessario eseguire<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> di nuovo.</block>
  <block id="51fb8677d45bb006235a9f8cbe477f6f" category="summary">Database di caching degli attributi NFS</block>
  <block id="4da0a3b9c2e8fc0df8844a41ac133401" category="doc">Caching NFS con i database</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">La presenza di una delle seguenti opzioni di montaggio causa la disattivazione della cache host:</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Queste impostazioni possono avere un grave effetto negativo sulla velocità di installazione del software, l'applicazione di patch e le operazioni di backup/ripristino. In alcuni casi, in particolare con le applicazioni in cluster, queste opzioni sono necessarie come conseguenza inevitabile della necessità di garantire la coerenza della cache in tutti i nodi del cluster. In altri casi, i clienti utilizzano erroneamente questi parametri e il risultato è un inutile danno alle prestazioni.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">Molti clienti rimuovono temporaneamente queste opzioni di montaggio durante l'installazione o l'applicazione di patch dei file binari. Questa rimozione può essere eseguita in modo sicuro se l'utente verifica che nessun altro processo stia utilizzando attivamente la directory di destinazione durante il processo di installazione o di applicazione delle patch.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Configurazione dello stripe LVM per database Oracle</block>
  <block id="7844f2cc495a938f3039da5801958506" category="doc">Striping LVM con database Oracle</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">Lo striping LVM si riferisce alla distribuzione dei dati su più LUN. Il risultato è un significativo miglioramento delle performance per molti database.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Allineamento di LUN con i database Oracle</block>
  <block id="c4cb2c6af5d7b6c38cd7e588d846e8b4" category="doc">Allineamento LUN per i/o Oracle</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">L'allineamento delle LUN si riferisce all'ottimizzazione dell'i/o in relazione al layout del file system sottostante.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Efficienza</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Avvertenze di disallineamento</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">Configurazione host SAN ONTAP</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">L'allineamento negli ambienti Solaris è più complicato. Fare riferimento a.<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Negli ambienti Solaris x86, prestare ulteriore attenzione al corretto allineamento poiché la maggior parte delle configurazioni prevede diversi livelli di partizioni. Le sezioni di partizione di Solaris x86 si trovano solitamente in cima a una tabella di partizioni del record di avvio master standard.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Dimensioni di trasferimento di NFS con Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Dimensioni di trasferimento NFS con database Oracle</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">Per impostazione predefinita, ONTAP limita le dimensioni i/o NFS a 64K.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">L'i/o casuale con la maggior parte delle applicazioni e dei database utilizza blocchi di dimensioni molto inferiori, ben al di sotto del limite massimo di 64K KB. L'i/o a blocchi di grandi dimensioni è solitamente a parallelismo, pertanto anche il massimo di 64K Gbps non costituisce un limite all'ottenimento della massima larghezza di banda.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Ci sono alcuni carichi di lavoro in cui il massimo di 64K crea un limite. In particolare, le operazioni single-threaded, come l'operazione di backup o ripristino o la scansione di un database completa della tabella, vengono eseguite più velocemente e in modo più efficiente se il database è in grado di eseguire un numero di i/o inferiore ma maggiore. Le dimensioni ottimali per la gestione i/o per ONTAP sono 256K KB.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">Le dimensioni massime di trasferimento per una SVM ONTAP possono essere modificate come segue:</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">Non diminuire mai la dimensione massima di trasferimento consentita su ONTAP al di sotto del valore rsize/wsize dei file system NFS attualmente montati. In alcuni sistemi operativi, ciò può causare blocchi o addirittura danni ai dati. Ad esempio, se i client NFS sono attualmente impostati su un valore rsize/wsize di 65536, la dimensione massima di trasferimento ONTAP potrebbe essere regolata tra 65536 e 1048576 senza alcun effetto perché i client stessi sono limitati. La riduzione della dimensione massima di trasferimento inferiore a 65536 GB può danneggiare la disponibilità o i dati.</block>
  <block id="a5c97d9c3645b9a26e3febeb4bc95e24" category="summary">Utilità di recupero ASM con ONTAP</block>
  <block id="861a5ecc95a8478c750be41bf2ddd6f5" category="doc">ASM Reclamation Utility e rilevamento zero-block</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP rimuove in modo efficiente i blocchi azzerati scritti su un file o LUN quando la compressione inline è abilitata. Utility come Oracle ASM Reclamation Utility (ASRU) funzionano scrivendo zero in estensioni ASM non utilizzate.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Dal punto di vista del database, il gruppo di dischi ASM contiene zero; la lettura di tali aree del LUN produce un flusso di zero, tuttavia ONTAP non memorizza gli zero sui dischi. Vengono invece apportate semplici modifiche ai metadati che contrassegnano internamente le aree azzerate del LUN come vuote di qualsiasi dato.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Per motivi simili, il test delle performance che implica dati azzerati non è valido, in quanto i blocchi di zero non vengono effettivamente elaborati come scritture all'interno dello storage array.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Quando si utilizza ASRU, assicurarsi che tutte le patch consigliate da Oracle siano installate.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">LUN e LVM vengono ridimensionati con database Oracle</block>
  <block id="e0327f97ac271a738dd1ac6b182a4369" category="doc">Ridimensionamento LUN e ridimensionamento basato su LVM</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Quando un file system basato su SAN ha raggiunto il limite di capacità, sono disponibili due opzioni per aumentare lo spazio disponibile:</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Configurazione di NVFAIL per proteggere i database Oracle</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle e NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL è una funzionalità di ONTAP che garantisce l'integrità in scenari di failover catastrofici.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">I database sono vulnerabili al danneggiamento durante gli eventi di failover dello storage perché mantengono grandi cache interne. Se un evento catastrofico richiede l'imposizione di un failover ONTAP o il forzamento dello switchover MetroCluster, a prescindere dallo stato di salute della configurazione complessiva, il risultato viene riconosciuto in precedenza che le modifiche potrebbero essere effettivamente scartate. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco. Questa incoerenza provoca il danneggiamento dei dati.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">La memorizzazione nella cache può avvenire a livello di applicazione o di server. Ad esempio, una configurazione Oracle Real Application Cluster (RAC) con server attivi sia su un sito primario che su un sito remoto memorizza nella cache i dati all'interno di Oracle SGA. Un'operazione di switchover forzata che comportava la perdita di dati rischierebbe di danneggiare il database poiché i blocchi archiviati nell'SGA potrebbero non corrispondere ai blocchi su disco.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">Un uso meno ovvio della memorizzazione nella cache è a livello del file system del sistema operativo. I blocchi di un file system NFS montato possono essere memorizzati nella cache del sistema operativo. In alternativa, un file system in cluster basato su LUN che si trovano nel sito primario può essere montato sui server nel sito remoto e, ancora una volta, i dati possono essere memorizzati nella cache. In queste situazioni, un errore della NVRAM, un takeover forzato o uno switchover forzato possono danneggiare il file system.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP protegge i database e i sistemi operativi da questo scenario con NVFAIL e le relative impostazioni.</block>
  <block id="45293b650c7dacd88d269bebf219b8ef" category="summary">Il ripristino rapido del database Oracle in ONTAP da una copia Snapshot è fornito dalla tecnologia NetApp SnapRestore.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">La tecnologia NetApp SnapRestore offre il ripristino rapido dei dati in ONTAP a partire da una snapshot.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Quando un set di dati critico non è disponibile, le operazioni di business critiche non sono attive. I nastri possono interrompersi e persino i ripristini da backup basati su disco possono essere lenti da trasferire sulla rete. SnapRestore consente di evitare questi problemi grazie al ripristino quasi istantaneo dei set di dati. Anche i database di diversi petabyte possono essere ripristinati completamente con pochi minuti di lavoro.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Esistono due forme di SnapRestore: Basata su file/LUN e basata su volume.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Singoli file o LUN possono essere ripristinati in pochi secondi, sia in una LUN da 2TB GB che in un file da 4KB GB.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">Il container di file o LUN può essere ripristinato in pochi secondi, siano essi 10GB o 100TB TB di dati.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Un "contenitore di file o LUN" generalmente si riferisce a un volume FlexVol. Ad esempio, potresti avere 10 LUN che costituiscono un gruppo di dischi LVM in un singolo volume, oppure un volume potrebbe archiviare le home directory NFS di 1000 utenti. Invece di eseguire un'operazione di ripristino per ogni singolo file o LUN, è possibile ripristinare l'intero volume come un'unica operazione. Questo processo funziona anche con container scale-out che includono volumi multipli, come FlexGroup o un gruppo di coerenza ONTAP.</block>
  <block id="a8d6a4d1b7fc6e1f60bb0ab716b4e72f" category="paragraph">Il motivo del funzionamento così rapido ed efficiente di SnapRestore è dovuto alla natura di una copia Snapshot, che è essenzialmente una vista parallela di sola lettura dei contenuti di un volume in uno specifico istante temporale. I blocchi attivi sono i blocchi reali che è possibile modificare, mentre lo snapshot è una vista di sola lettura dello stato dei blocchi che costituiscono i file e le LUN al momento della creazione dello snapshot.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP consente solo l'accesso in sola lettura ai dati snapshot, ma i dati possono essere riattivati con SnapRestore. Lo snapshot viene riabilitato come visualizzazione lettura-scrittura dei dati, riportando i dati allo stato precedente. SnapRestore può operare a livello di volume o di file. La tecnologia è essenzialmente la stessa con alcune differenze minori nel comportamento.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">SnapRestore volume</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">La SnapRestore basata su volume riporta l'intero volume di dati a uno stato precedente. Questa operazione non richiede lo spostamento dei dati, il che significa che il processo di ripristino è essenzialmente istantaneo, sebbene l'elaborazione delle operazioni API o CLI possa richiedere alcuni secondi. Il ripristino di 1GB TB di dati non è più complicato o richiede molto tempo rispetto al ripristino di 1PB TB di dati. Questa funzionalità è il motivo principale per cui molti clienti aziendali migrano ai sistemi storage ONTAP. Offre un RTO misurato in secondi anche per i set di dati più grandi.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">Uno svantaggio di SnapRestore basato su volumi è causato dal fatto che le modifiche all'interno di un volume sono cumulative nel tempo. Pertanto, ogni snapshot e i dati del file attivo dipendono dalle modifiche che hanno portato a quel punto. Ripristinare uno stato precedente di un volume significa ignorare tutte le modifiche successive apportate ai dati. Ciò che è meno ovvio, tuttavia, è che questo include gli snapshot creati successivamente. Ciò non è sempre desiderabile.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Ad esempio, uno SLA di conservazione dei dati può specificare 30 giorni di backup notturni. Il ripristino di un set di dati in uno snapshot creato cinque giorni fa con Volume SnapRestore scaricherebbe tutti gli snapshot creati nei cinque giorni precedenti, violando lo SLA.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Sono disponibili diverse opzioni per risolvere questo limite:</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">I dati possono essere copiati da una snapshot precedente, invece di eseguire un SnapRestore dell'intero volume. Questo metodo funziona meglio con set di dati più piccoli.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">È possibile clonare una snapshot invece di ripristinarla. Il limite a questo approccio è che lo snapshot di origine è una dipendenza del clone. Pertanto, non può essere eliminato a meno che il clone non venga anch'esso eliminato o diviso in un volume indipendente.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Utilizzo di SnapRestore basati su file.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">File SnapRestore (Stato file)</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">SnapRestore basato su file è un processo di ripristino più granulare e basato su snapshot. Invece di ripristinare lo stato di un intero volume, viene ripristinato lo stato di un singolo file o LUN. Non è necessario eliminare gli snapshot, né questa operazione crea alcuna dipendenza da uno snapshot precedente. Il file o LUN diventa immediatamente disponibile nel volume attivo.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">Durante il ripristino di SnapRestore di un file o LUN non è necessario alcuno spostamento dei dati. Tuttavia, alcuni aggiornamenti dei metadati interni sono necessari per riflettere il fatto che i blocchi sottostanti in un file o LUN ora esistono sia in una snapshot che nel volume attivo. Non dovrebbe avere alcun effetto sulle prestazioni, ma questo processo blocca la creazione di snapshot fino al completamento. La velocità di elaborazione è di circa 5Gbps MB (18TB MB/ora) in base alla dimensione totale dei file ripristinati.</block>
  <block id="a68b31b502bf7555cda2514354e553c2" category="summary">Strategie di protezione dei dati di ONTAP</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">Pianificazione della protezione dei dati</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">La corretta architettura di protezione dei dati aziendali dipende dai requisiti di business correlati a conservazione dei dati, ripristinabilità e tolleranza per le interruzioni durante i vari eventi.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Ad esempio, consideriamo il numero di applicazioni, database e set di dati importanti inclusi nell'ambito della fornitura. La costruzione di una strategia di backup per un singolo set di dati che garantisca la conformità con gli SLA tipici è piuttosto semplice, perché non ci sono molti oggetti da gestire. Con l'aumento del numero di set di dati, il monitoraggio diventa più complicato e gli amministratori potrebbero essere costretti a spendere una crescente quantità di tempo nella risoluzione degli errori di backup. Quando un ambiente raggiunge il cloud e scala un service provider, è necessario un approccio completamente diverso.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">Anche le dimensioni del set di dati influiscono sulla strategia. Ad esempio, esistono molte opzioni per il backup e il ripristino con un database da 100GB TB perché il set di dati è così piccolo. La semplice copia dei dati dai supporti di backup con gli strumenti tradizionali in genere offre un RTO sufficiente per il recovery. Un database 100TB ha normalmente bisogno di una strategia completamente diversa, a meno che l'RTO non consenta un'interruzione di più giorni, nel qual caso una tradizionale procedura di backup e ripristino basata sulla copia potrebbe essere accettabile.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Infine, vi sono alcuni fattori che esulano dal processo di backup e ripristino stesso. Ad esempio, esistono database che supportano attività di produzione critiche e che rendono il ripristino una rara eventualità che viene eseguita solo da DBA esperti? In alternativa, i database fanno parte di un grande ambiente di sviluppo in cui il ripristino è un evento frequente e gestito da un team IT generico?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">Uno snapshot è un backup?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">Un'obiezione comunemente sollevata all'utilizzo delle snapshot come strategia di protezione dei dati è rappresentata dal fatto che i dati "reali" e i dati snapshot si trovano sugli stessi dischi. La perdita di tali unità causerebbe la perdita sia dei dati primari che del backup.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Si tratta di un problema valido. Le snapshot locali vengono utilizzate per le esigenze di backup e ripristino quotidiane, e in questo senso la snapshot è un backup. Quasi il 99% di tutti gli scenari di ripristino in ambienti NetApp si affida alle snapshot per soddisfare anche i requisiti RTO più aggressivi.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Gli snapshot locali non dovrebbero, tuttavia, mai essere l'unica strategia di backup, ragione per cui NetApp offre tecnologie come la replica SnapMirror per replicare in modo rapido ed efficiente le snapshot su un set indipendente di dischi. In una soluzione adeguatamente progettata con istantanee e replica snapshot, l'utilizzo del nastro può essere ridotto a icona in un archivio trimestrale o eliminato del tutto.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Backup di gruppi di coerenza</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">Il backup di un gruppo di coerenza implica l'acquisizione dello stato di un dataset (o di più dataset) in un singolo punto atomico nel tempo. Come esempio di database, questo include tutti i componenti del database, come file di dati, file di log e altri file direttamente associati al database. Funziona con quasi tutti i prodotti di database relazionali, tra cui Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL e MariaDB. La protezione di una configurazione VMware con un backup di gruppo di coerenza sarebbe simile: L'acquisizione di tutti gli archivi dati e potenzialmente delle LUN di avvio ESX in un singolo punto atomico nel tempo.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">La creazione di una snapshot di un gruppo di coerenza di questo tipo sta essenzialmente simulando un arresto anomalo, motivo per cui tali backup vengono spesso chiamati backup coerenti con i crash. Talvolta il supporto per gli scenari di ripristino è fonte di preoccupazioni, ma è importante comprendere che in genere non è necessaria alcuna procedura di ripristino. Quando l'applicazione si avvia dopo il ripristino di un backup di un gruppo di coerenza, esegue i consueti processi di recupero dei log, le repliche del journal del file system e altre attività per riprodurre qualsiasi i/o in fase di trasferimento al punto del backup. L'applicazione viene quindi avviata come di consueto.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">In sostanza, qualsiasi applicazione in grado di resistere a un'interruzione dell'alimentazione o a un arresto anomalo del server senza danneggiamento dei dati può essere protetta in questo modo. Ciò può essere dimostrato anche dal numero elevato di applicazioni protette con prodotti di mirroring sincrono e asincrono di numerosi vendor. Se un disastro colpisce improvvisamente il sito primario, il sito di replica contiene un'immagine coerente dell'ambiente originale al momento del disastro. Ancora una volta, non è necessaria alcuna procedura di recupero speciale.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">L'RPO per questo approccio è in genere limitato al punto del backup. In generale, l'RPO minimo per le snapshot a volume singolo è di un'ora. Ad esempio, 48 snapshot ogni ora e altri 30 giorni di snapshot ogni notte sono ragionevoli e non richiederebbero la conservazione di un numero eccessivo di snapshot. Un RPO inferiore a un'ora diventa più difficile da raggiungere e non è consigliato senza la prima consulenza dei servizi professionali NetApp comprendere i requisiti di ambiente, scalabilità e data Protection.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">L'RTO può in genere essere misurato in pochi secondi. R un'applicazione viene arrestata, i volumi vengono ripristinati e l'applicazione viene riavviata.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">L'approccio più semplice consiste nel posizionare tutti i file o le LUN in un singolo gruppo di coerenza del volume, che consente di pianificare la creazione di una snapshot direttamente in ONTAP. Se un set di dati deve occupare più volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot). È possibile configurarlo tramite System Manager o chiamate API RESTful, inoltre SnapCenter è in grado di creare un semplice snapshot del gruppo di coerenza su un elenco definito di volumi.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Architettura di replica e disaster recovery</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="7b8111b0a2fc76252bbacbbc9de542a4" category="inline-link-macro">Continuità aziendale di SnapMirror</block>
  <block id="96a7c86d5bc52a478876c48dc6dcc9f0" category="paragraph">Questa sezione riguarda la protezione dei dati remoti, per la quale i dati vengono replicati in un sito remoto ai fini di uno storage offsite sicuro e di un disaster recovery. Si noti che queste tabelle non riguardano la protezione dei dati di mirroring sincrono. Per questo requisito, consultare la documentazione di NetApp MetroCluster, tra cui <block ref="5c964f26ec7fbbad5ac67aaa5dcf9269" category="inline-link-macro-rx"></block> e. <block ref="30831ec866621e18e7521d6c2750acaa" category="inline-link-macro-rx"></block></block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">L'RPO di DR è limitato dalla larghezza di banda della rete disponibile e dalle dimensioni totali dei dati da proteggere. Dopo la creazione del trasferimento di base iniziale, gli aggiornamenti si basano solo sui dati modificati, che in genere rappresentano una bassa percentuale dell'impatto totale dei dati, sebbene esistano delle eccezioni.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Ad esempio, un database 10TB con un tasso di modifica settimanale del 10% ha una media di circa 6GB TB all'ora delle modifiche totali. Con 10Gb GB di connettività, il trasferimento di questo database richiede circa sei minuti. Il tasso di modifica varia in base alla fluttuazione del tasso di modifica del database, ma nel complesso dovrebbe essere possibile ottenere un intervallo di aggiornamento di 15 minuti e un RPO di 15 minuti. Se sono presenti 100 database di questo tipo, sono necessari 600 minuti per trasferire i dati. Pertanto, non è possibile un RPO di un'ora. Allo stesso modo, una replica di un singolo database 100TB con un tasso di modifica settimanale del 10% non può essere aggiornata in modo affidabile in un'ora.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">Altri fattori possono influire sulla replica, ad esempio l'overhead e le limitazioni del numero di operazioni di replica simultanee. Tuttavia, la pianificazione globale di una strategia di replica a singolo volume può basarsi sulla larghezza di banda disponibile e generalmente si ottiene un RPO di replica di un'ora. Un RPO inferiore a un'ora diventa più difficile da raggiungere e dovrebbe essere eseguito solo dopo aver consultato i servizi professionali di NetApp. In alcuni casi, è possibile effettuare 15 minuti con un'ottima connettività di rete da sito a sito. Tuttavia, nel complesso, quando è necessario un RPO inferiore a un'ora, l'architettura di riproduzione log multi-volume offre risultati migliori.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">L'RTO con replica di gruppo di coerenza in uno scenario di disaster recovery è eccellente, generalmente misurato in secondi dal punto di vista dello storage. L'approccio più semplice è quello di rompere il mirror e il database è pronto per essere avviato. Il tempo di avvio del database è generalmente di circa 10 secondi, ma database di grandi dimensioni con molte transazioni registrate potrebbero richiedere alcuni minuti.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">Il fattore più importante per determinare l'RTO non è il sistema storage, ma piuttosto l'applicazione e il sistema operativo host in cui viene eseguito. Ad esempio, i dati replicati possono essere resi disponibili in un secondo o due, ma questo rappresenta solo i dati. Deve inoltre essere presente un sistema operativo correttamente configurato con file binari delle applicazioni disponibili per l'utilizzo dei dati.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">In alcuni casi, i clienti hanno preparato istanze di disaster recovery in anticipo con lo storage prerilevato sui sistemi operativi. In questi casi, l'attivazione dello scenario di disaster recovery può richiedere solo la rottura di un mirror e l'avvio dell'applicazione. In altri casi, è possibile eseguire il mirroring del sistema operativo e delle applicazioni associate insieme al database come VMDK (ESX Virtual Machine Disk). In questi casi, l'RPO è determinato dall'investimento effettuato da un cliente nell'automazione per l'avvio rapido del VMDK e la possibilità di avviare le applicazioni.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">Il tempo di conservazione è controllato in parte dal limite dello snapshot. Ad esempio, i volumi in ONTAP hanno un limite di 1024 snapshot. In alcuni casi, i clienti hanno la replica multiplex per aumentare il limite. Ad esempio, se sono necessari 2000 giorni di backup, un'origine può essere replicata su due volumi con aggiornamenti che avvengono in giorni alternativi. Ciò richiede un aumento dello spazio iniziale necessario, ma costituisce comunque un approccio molto più efficiente rispetto a un sistema di backup tradizionale, che prevede l'esecuzione di più backup completi.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Gruppo di coerenza del singolo volume</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">L'approccio più semplice consiste nel posizionare tutti i file o le LUN in un singolo gruppo di coerenza dei volumi, che consente di pianificare gli update di SnapMirror e SnapVault direttamente nel sistema storage. Non è richiesto alcun software esterno.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Gruppo di coerenza multi-volume</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Quando un database deve occupare più volumi, è necessario uno snapshot del gruppo di coerenza (cg-snapshot). Come sopra menzionato, è possibile configurarlo tramite chiamate di API RESTful o di System Manager, mentre SnapCenter è in grado di creare una semplice snapshot del gruppo di coerenza in un elenco definito di volumi.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">È inoltre prevista un'ulteriore considerazione sull'utilizzo di snapshot coerenti e multi-volumi ai fini del disaster recovery. Quando si esegue un aggiornamento di più volumi, è possibile che si verifichi un disastro mentre è ancora in corso un trasferimento. Il risultato sarebbe un insieme di volumi che non sono coerenti l'uno con l'altro. Se ciò si verificasse, alcuni volumi devono essere ripristinati allo stato di snapshot precedente per fornire un'immagine di database coerente con il crash e pronta per l'uso.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Disaster recovery: Attivazione</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">Il processo di attivazione della copia di disaster recovery dipende dal tipo di storage. Con NFS, i file system possono essere premontati sul server di disaster recovery. Sono in uno stato di sola lettura e diventano lettura-scrittura quando il mirror è rotto. Ciò offre un RPO estremamente basso e il processo generale di disaster recovery è più affidabile, poiché ci sono meno parti da gestire.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">L'attivazione delle configurazioni SAN in caso di disaster recovery diventa più complicata. L'opzione più semplice è in genere quella di rompere temporaneamente i mirror e montare le risorse SAN, tra cui passaggi come il rilevamento della configurazione LVM (incluse funzioni specifiche dell'applicazione come Oracle Automatic Storage Management [ASM]) e l'aggiunta di voci a /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">Il risultato è che i percorsi dei dispositivi LUN, i nomi dei gruppi di volumi e gli altri percorsi dei dispositivi vengono resi noti al server di destinazione. Tali risorse possono quindi essere chiuse e, successivamente, i mirror possono essere ripristinati. Il risultato è un server che si trova in uno stato in grado di portare rapidamente l'applicazione online. I passaggi per attivare gruppi di volumi, montare file system o avviare database e applicazioni sono facilmente automatizzati.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">È necessario assicurarsi che l'ambiente di disaster recovery sia aggiornato. Ad esempio, è probabile che vengano aggiunti nuovi LUN al server di origine, il che significa che è necessario rilevare preventivamente i nuovi LUN sulla destinazione per garantire che il piano di disaster recovery funzioni come previsto.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Disaster recovery Oracle</block>
  <block id="7fe779a487e8f113f1ffdff0fb80353f" category="summary">Backup del gruppo di coerenza per Oracle su ONTAP</block>
  <block id="773f9afa3df0cf82ed853c988183c73f" category="doc">Backup di gruppo di coerenza Oracle</block>
  <block id="5afd3dc3f8d489d47587e10e6663c512" category="paragraph">Per un backup il più semplice possibile, posiziona l'intero database Oracle in un singolo volume.</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">Proteggere i file di dati, i log di archivio, i log di ripristino e i file di controllo con un'unica istantanea è un metodo di backup, ripristino e replica valido.  Tuttavia, l'RPO è limitato al punto del backup stesso. È adatto per un RPO di un'ora o superiore. Se un database si estende su volumi, è necessario creare snapshot cg utilizzando uno degli strumenti descritti in precedenza.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">Ad esempio, l'intero database può trovarsi in un singolo volume con la seguente pianificazione degli snapshot:</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 snapshot ogni ora</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 istantanee notturne</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 snapshot mensili</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Questo garantisce un RPO di un'ora nel periodo corrente delle 72 ore precedenti, più backup notturni e mensili aggiuntivi. È possibile includere più database o file applicativi nel singolo volume o set di snapshot cg per offrire backup coerenti in un ambiente più ampio.</block>
  <block id="5eb532bcede5a8d57b8fb4429d5cc7ec" category="summary">Massimizzazione della disponibilità con Oracle su ONTAP</block>
  <block id="b4343a8438e1b9cc9e9486f85831f2a1" category="doc">Disponibilità dei dati Oracle con ONTAP</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP è progettato per garantire la massima disponibilità dei database Oracle. Una descrizione completa delle funzioni di alta disponibilità di ONTAP esula dall'ambito di questo documento. Tuttavia, come per la protezione dei dati, una conoscenza di base di questa funzionalità è importante quando si progetta un'infrastruttura di database.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">Coppie HA</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">L'unità di base dell'alta disponibilità è la coppia ha. Ciascuna coppia contiene collegamenti ridondanti per supportare la replica dei dati nella NVRAM. NVRAM non è una cache di scrittura. La RAM all'interno del controller funge da cache di scrittura. Lo scopo della NVRAM è quello di memorizzare temporaneamente i dati come salvaguardia da errori di sistema imprevisti. A questo proposito, è simile a un log di ripristino del database.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">Sia la NVRAM che il redo log del database consentono di memorizzare i dati rapidamente, consentendo il commit delle modifiche ai dati il più rapidamente possibile. L'aggiornamento ai dati persistenti sulle unità (o file di dati) viene eseguito solo in un secondo momento durante un processo chiamato checkpoint sulle piattaforme ONTAP e sulla maggior parte dei database. Durante le normali operazioni, non vengono letti i dati della NVRAM né i log di ripristino del database.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Se un controller si guasta bruscamente, è probabile che vi siano modifiche in sospeso memorizzate nella NVRAM che non sono ancora state scritte sulle unità. Il partner controller rileva il guasto, assume il controllo dei dischi e applica le modifiche richieste che sono state memorizzate nella NVRAM.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Takeover e giveback</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Il takeover e il giveback fanno riferimento al processo di trasferimento della responsabilità delle risorse di storage fra i nodi di una coppia ha. L'acquisizione e il giveback presentano due aspetti:</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Gestione della connettività di rete che consente l'accesso alle unità</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Gestione delle unità stesse</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Le interfacce di rete che supportano il traffico CIFS e NFS sono configurate sia con una posizione home che di failover. Un takeover include lo spostamento delle interfacce di rete nella loro abitazione temporanea su un'interfaccia fisica situata sulla stessa subnet della posizione originale. Un giveback prevede lo spostamento delle interfacce di rete nelle posizioni originali. Il comportamento esatto può essere regolato come richiesto.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Le interfacce di rete che supportano i protocolli a blocchi SAN, come iSCSI e FC, non vengono ricollocate durante il takeover e lo giveback. È invece necessario eseguire il provisioning delle LUN attraverso percorsi che includano una coppia ha completa che si traduce in un percorso primario e un percorso secondario.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">È possibile configurare anche percorsi aggiuntivi per controller aggiuntivi in modo da supportare la riallocazione dei dati tra i nodi di un cluster più grande, non facente parte del processo di ha.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Il secondo aspetto del takeover e dello sconto è il trasferimento della proprietà del disco. Il processo esatto dipende da diversi fattori, tra cui il motivo del takeover/giveback e le opzioni della riga di comando emesse. L'obiettivo è quello di eseguire l'operazione nel modo più efficiente possibile. Anche se il processo complessivo potrebbe richiedere diversi minuti, il momento effettivo in cui la proprietà dell'unità viene trasferita da nodo a nodo può generalmente essere misurato in secondi.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Tempo di takeover</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">L'i/o dell'host subisce una breve pausa in i/o durante le operazioni di takeover e giveback, senza tuttavia alcuna interruzione dell'applicazione in un ambiente configurato correttamente. L'effettivo processo di transizione in cui l'i/o subisce un ritardo viene generalmente misurato in secondi, ma l'host potrebbe richiedere tempo aggiuntivo per riconoscere la modifica nei percorsi di dati e inviare di nuovo le operazioni i/O.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">La natura dell'interruzione dipende dal protocollo:</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Un'interfaccia di rete che supporta il traffico NFS e CIFS emette una richiesta ARP (Address Resolution Protocol) alla rete dopo la transizione a una nuova posizione fisica. Ciò fa sì che gli switch di rete aggiornino le tabelle degli indirizzi MAC (Media Access Control) e riprendano l'elaborazione i/O. Le interruzioni nel caso di takeover e giveback pianificati vengono di solito misurate in secondi e in molti casi non sono rilevabili. Alcune reti potrebbero essere più lente a riconoscere completamente la modifica del percorso di rete e alcuni sistemi operativi potrebbero mettere in coda molti i/o in un breve periodo di tempo che deve essere rieseguito. Ciò può estendere il tempo necessario per riprendere l'i/O.</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Un'interfaccia di rete che supporta i protocolli SAN non passa a una nuova posizione. Un sistema operativo host deve modificare il percorso o i percorsi in uso. La pausa in i/o osservata dall'host dipende da diversi fattori. Dal punto di vista del sistema storage, il periodo in cui non è possibile fornire i/o è di pochi secondi. Tuttavia, sistemi operativi host diversi potrebbero richiedere tempo aggiuntivo per consentire un timeout i/o prima di riprovare. I sistemi operativi più recenti sono in grado di riconoscere un cambiamento di percorso molto più rapidamente, ma i sistemi operativi più vecchi in genere richiedono fino a 30 secondi per riconoscere un cambiamento.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">La seguente tabella illustra i tempi di takeover previsti durante i quali il sistema storage non può fornire i dati a un ambiente applicativo. Non dovrebbero esserci errori in alcun ambiente applicativo, il takeover dovrebbe invece apparire come una breve pausa nell'elaborazione io.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Takeover pianificato</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 sec.</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 sec.</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 sec.</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Takeover non pianificato</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 sec.</block>
  <block id="a4985782267828ce03a3d13f37392de1" category="summary">Checksum e protezione dei dati di Oracle</block>
  <block id="407941abab873f61b271b481e105eb33" category="doc">Checksum e integrità dei dati Oracle</block>
  <block id="b93232347a11497969d0ea20d34cd16e" category="paragraph">Una domanda comunemente rivolta a NetApp è come proteggere l'integrità dei dati di un database Oracle.</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">La protezione dei dati logici all'interno di ONTAP è costituita da tre requisiti principali:</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">I dati devono essere protetti dalla corruzione.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">I dati devono essere protetti da guasti al disco.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Le modifiche ai dati devono essere protette dalla perdita.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Queste tre esigenze sono discusse nelle sezioni seguenti.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Corruzione della rete: Checksum</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">Il livello più basilare di protezione dei dati è il checksum, che è uno speciale codice di rilevamento degli errori memorizzato insieme ai dati. La corruzione dei dati durante la trasmissione di rete viene rilevata con l'utilizzo di un checksum e, in alcuni casi, di checksum multipli.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Ad esempio, un frame FC include una forma di checksum chiamata CRC (Cyclic Redundancy Check) per assicurarsi che il payload non sia corrotto durante il transito. Il trasmettitore invia sia i dati che il CRC dei dati. Il ricevitore di un frame FC ricalcola il CRC dei dati ricevuti per assicurarsi che corrisponda al CRC trasmesso. Se il CRC appena calcolato non corrisponde al CRC collegato al frame, i dati sono corrotti e il frame FC viene scartato o rifiutato. Un'operazione i/o iSCSI include checksum ai livelli TCP/IP ed Ethernet e, per una maggiore protezione, può anche includere la protezione CRC opzionale al livello SCSI. Qualsiasi corruzione di bit sul filo viene rilevata dal livello TCP o IP, che porta alla ritrasmissione del pacchetto. Come nel caso di FC, gli errori nel CRC SCSI determinano un'eliminazione o un rifiuto dell'operazione.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Corruzione dei dischi: Checksum</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">I checksum vengono utilizzati anche per verificare l'integrità dei dati memorizzati sui dischi. I blocchi di dati scritti sui dischi vengono memorizzati con una funzione di checksum che produce un numero imprevedibile e legato ai dati originali. Quando i dati vengono letti dall'unità, il checksum viene ricalcolato e confrontato con il checksum memorizzato. Se non corrisponde, i dati sono corrotti e devono essere recuperati dal livello RAID.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Corruzione dei dati: Scritture perse</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">Uno dei tipi più difficili di corruzione da rilevare è una scrittura persa o posizionata erroneamente. Quando una scrittura viene confermata, deve essere scritta sul supporto nella posizione corretta. La corruzione dei dati sul posto è relativamente semplice da rilevare utilizzando un semplice checksum memorizzato con i dati. Tuttavia, se la scrittura viene semplicemente persa, la versione precedente dei dati potrebbe ancora esistere e il checksum sarebbe corretto. Se la scrittura viene posizionata nella posizione fisica errata, il checksum associato sarebbe ancora una volta valido per i dati memorizzati, anche se la scrittura ha distrutto altri dati.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">La soluzione a questa sfida è la seguente:</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Un'operazione di scrittura deve includere metadati che indicano la posizione in cui dovrebbe essere trovata la scrittura.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Un'operazione di scrittura deve includere un tipo di identificatore di versione.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Quando ONTAP scrive un blocco, include i dati sulla posizione di appartenenza del blocco. Se una lettura successiva identifica un blocco, ma i metadati indicano che esso appartiene alla posizione 123 quando è stato trovato nella posizione 456, allora la scrittura è stata erroneamente posizionata.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Rilevare una scrittura totalmente persa è più difficile. La spiegazione è molto complicata, ma essenzialmente ONTAP memorizza i metadati in modo che un'operazione di scrittura determini aggiornamenti a due posizioni diverse sulle unità. Se una scrittura viene persa, una successiva lettura dei dati e dei metadati associati mostra due diverse identità di versione. Ciò indica che la scrittura non è stata completata dall'unità.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">La corruzione in scrittura persa e posizionata erroneamente è estremamente rara, ma con il continuo aumento dei dischi e la diminuzione dei set di dati nella scala di exabyte, il rischio aumenta. Il rilevamento delle operazioni di scrittura perse deve essere incluso in qualsiasi sistema storage che supporti i carichi di lavoro del database.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Guasti del disco: RAID, RAID DP e RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Se un blocco di dati su un'unità viene rilevato come danneggiato o se l'intera unità si guasta e non è completamente disponibile, i dati devono essere ricostituiti. Questo viene fatto in ONTAP utilizzando unità di parità. Lo striping dei dati viene eseguito su più unità dati, quindi vengono generati i dati di parità. I dati vengono memorizzati separatamente dai dati originali.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP utilizzava in origine RAID 4, che utilizza un singolo disco di parità per ciascun gruppo di unità dati. Il risultato è che un'unità del gruppo potrebbe guastarsi senza causare una perdita di dati. Se l'unità di parità non funziona correttamente, non sono stati danneggiati dati ed è stato possibile costruire una nuova unità di parità. Se si è verificato un errore in una singola unità dati, è possibile utilizzare le unità rimanenti con l'unità di parità per rigenerare i dati mancanti.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Quando le unità erano di piccole dimensioni, la possibilità statistica di due unità che si guastavano contemporaneamente era trascurabile. Con la progressiva crescita della capacità del disco aumentano anche il tempo necessario per ricostruire i dati in seguito a un guasto al disco. Ciò ha aumentato la finestra in cui un guasto di una seconda unità causerebbe la perdita di dati. Inoltre, il processo di ricostruzione crea numerosi i/o aggiuntivi sui dischi ancora in uso. Man mano che i dischi diventano obsoleti, aumenta anche il rischio di carico aggiuntivo che potrebbe causare un guasto al secondo disco. Infine, anche se il rischio di perdita di dati non aumentasse con il continuo utilizzo di RAID 4, le conseguenze della perdita di dati diventerebbero più gravi. Maggiore è la quantità di dati che andrebbero persi in caso di guasto a un gruppo RAID, più tempo occorrerebbe per ripristinare i dati, prolungando l'interruzione del business.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Questi problemi hanno portato NetApp a sviluppare la tecnologia NetApp RAID DP, una variante di RAID 6. Questa soluzione include due unità di parità, il che significa che due unità in un gruppo RAID possono guastarsi senza creare perdite di dati. Le dimensioni dei dischi hanno continuato a crescere, portando infine NetApp a sviluppare la tecnologia NetApp RAID-TEC, che introduce un disco a terza parità.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Alcune procedure consigliate per i database storici consigliano l'uso di RAID-10, noto anche come mirroring con striping. Ciò offre una protezione dei dati inferiore rispetto a quella dei sistemi RAID DP, in quanto vi sono più scenari di guasto a due dischi, mentre in RAID DP non ve ne sono nessuno.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">Esistono inoltre alcune procedure consigliate per i database storici che indicano che le opzioni RAID-10 sono preferite a quelle RAID-4/5/6 a causa di problemi di prestazioni. Queste raccomandazioni a volte fanno riferimento a una penalizzazione RAID. Sebbene queste raccomandazioni siano generalmente corrette, non sono applicabili alle implementazioni di RAID all'interno di ONTAP. Il problema di prestazioni è relativo alla rigenerazione di parità. Con le implementazioni RAID tradizionali, l'elaborazione delle random write di routine eseguite da un database richiede letture multiple del disco per rigenerare i dati di parità e completare la scrittura. La penalità viene definita come gli IOPS in lettura aggiuntivi necessari per eseguire le operazioni di scrittura.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">ONTAP non subisce alcuna penalizzazione RAID perché le scritture vengono organizzate in memoria dove la parità viene generata e quindi scritta su disco come singolo stripe RAID. Non sono richieste letture per completare l'operazione di scrittura.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">In sintesi, rispetto al RAID 10, RAID DP e RAID-TEC offrono una capacità utilizzabile molto maggiore, una migliore protezione contro i guasti ai dischi e nessun compromesso in termini di performance.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Protezione da errori hardware: NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Qualsiasi storage array che gestisce un carico di lavoro del database deve eseguire le operazioni di scrittura il più rapidamente possibile. Inoltre, un'operazione di scrittura deve essere protetta dalla perdita da un evento imprevisto, come un'interruzione dell'alimentazione. Ciò significa che qualsiasi operazione di scrittura deve essere conservata in modo sicuro in almeno due posizioni.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">I sistemi AFF e FAS si affidano alla NVRAM per soddisfare questi requisiti. Il processo di scrittura funziona come segue:</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">I dati di scrittura in entrata sono memorizzati nella RAM.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Le modifiche che devono essere apportate ai dati sul disco vengono registrate nella NVRAM sia sul nodo locale che sul nodo partner. NVRAM non è una cache di scrittura, ma un journal simile a un log di ripristino dei database. In condizioni normali, non viene letta. Viene utilizzata solo per il ripristino, ad esempio in seguito a un'interruzione dell'alimentazione durante l'elaborazione i/O.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">La scrittura viene quindi riconosciuta all'host.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">Il processo di scrittura in questa fase è completo dal punto di vista dell'applicazione e i dati sono protetti dalla perdita, perché vengono memorizzati in due posizioni diverse. Alla fine, le modifiche vengono scritte su disco, ma il processo risulta fuori banda dal punto di vista dell'applicazione perché si verifica dopo il riconoscimento della scrittura e quindi non influisce sulla latenza. Questo processo è ancora una volta simile alla registrazione del database. Una modifica al database viene registrata nei registri di ripristino il più rapidamente possibile e la modifica viene quindi riconosciuta come confermata. Gli aggiornamenti ai file di dati avvengono molto più tardi e non influenzano direttamente la velocità di elaborazione.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">In caso di guasto a un controller, il partner controller assume la proprietà dei dischi richiesti e riproduce i dati registrati nella NVRAM per ripristinare le operazioni di i/o in corso quando si è verificato il guasto.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Protezione da errori hardware: NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Come discusso in precedenza, una scrittura non viene riconosciuta fino a quando non è stata registrata nella NVRAM locale e nella NVRAM su almeno un altro controller. Questo approccio garantisce che un guasto dell'hardware o un'interruzione di corrente non comporti la perdita dell'i/o in-flight In caso di guasto della NVRAM locale o di guasto della connettività al partner di ha, i dati in-flight non verranno più mirrorati.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Se la NVRAM locale riporta un errore, il nodo si arresta. Questo arresto determina il failover su un controller partner ha. Nessun dato viene perso perché il controller che presenta il guasto non ha confermato l'operazione di scrittura.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP non consente un failover quando i dati non sono sincronizzati, a meno che il failover non sia forzato. La forzatura di una modifica delle condizioni in questo modo riconosce che i dati potrebbero essere lasciati indietro nel controllore originale e che la perdita di dati è accettabile.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">I database sono particolarmente vulnerabili al danneggiamento se un failover viene forzato perché mantengono grandi cache interne di dati su disco. In caso di failover forzato, le modifiche precedentemente riconosciute vengono effettivamente eliminate. Il contenuto dell'array di storage torna indietro nel tempo e lo stato della cache del database non riflette più lo stato dei dati su disco.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Per proteggere i dati da questa situazione, ONTAP consente di configurare i volumi per una protezione speciale contro gli errori della NVRAM. Quando attivato, questo meccanismo di protezione determina l'ingresso di un volume nello stato chiamato NVFAIL. Questo stato causa errori di i/o che causano l'arresto di un'applicazione in modo che non utilizzino dati obsoleti. I dati non devono essere persi perché qualsiasi scrittura riconosciuta deve essere presente sull'array di storage.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Ogni set di unità su un dato sito viene configurato automaticamente come uno o più gruppi RAID-DP o RAID-TEC completamente ridondanti, indipendentemente dall'utilizzo del mirroring. In questo modo si garantisce una protezione dei dati continua, anche dopo la perdita di un sito.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">La figura precedente illustra una configurazione SyncMirror di esempio. È stato creato un aggregato di 24 dischi sul controller con 12 dischi da uno shelf allocato sul sito A e 12 dischi da uno shelf allocato sul sito B. I dischi sono stati raggruppati in due gruppi RAID con mirroring. Il gruppo RAID 0 include un plesso A 6 unità sul sito A con mirroring su un plesso A 6 unità sul sito B. Analogamente, il gruppo RAID 1 include un plesso A 6 unità sul sito A con mirroring su un plesso A 6 unità sul sito B.</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">Di norma, SyncMirror viene utilizzato per fornire il mirroring remoto con i sistemi MetroCluster, con una copia dei dati in ciascun sito. A volte, è stato utilizzato per fornire un livello di ridondanza extra in un unico sistema. In particolare, fornisce ridondanza a livello di shelf. Uno shelf di dischi contiene già doppi controller e alimentatori e nel complesso è poco più di una lamiera, ma in alcuni casi è consigliabile garantire una protezione extra. Ad esempio, un cliente NetApp ha implementato SyncMirror per una piattaforma mobile di analytics in tempo reale utilizzata durante i test nel settore automobilistico. Il sistema è stato separato in due rack fisici forniti da alimentatori indipendenti da sistemi UPS indipendenti.</block>
  <block id="95a3cc99b05998d49d8e035b994815bc" category="paragraph">==checksum</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">L'argomento dei checksum è di particolare interesse per i DBA abituati all'utilizzo dei backup in streaming Oracle RMAN che migrano a backup basati su snapshot. Una caratteristica di RMAN è che esegue controlli di integrità durante le operazioni di backup. Sebbene questa funzionalità offra un certo valore, il suo vantaggio principale è quello di un database non utilizzato su uno storage array moderno. Quando si utilizzano dischi fisici per un database Oracle, è quasi certo che il danneggiamento si verifica anche in caso di invecchiamento dei dischi, un problema che viene risolto dai checksum basati su array negli storage array reali.</block>
  <block id="58d7088c13cf2013ef373d85e3c27de7" category="paragraph">Con un vero storage array, l'integrità dei dati è protetta utilizzando checksum a livelli multipli. Se i dati sono corrotti in una rete basata su IP, il livello TCP (Transmission Control Protocol) rifiuta i dati a pacchetto e richiede la ritrasmissione. Il protocollo FC include i checksum, così come i dati SCSI incapsulati. Dopo essere stato inserito nell'array, ONTAP dispone della protezione RAID e checksum. Il danneggiamento può verificarsi, ma, come nella maggior parte degli array Enterprise, viene rilevato e corretto. In genere, si verifica un guasto di un intero disco, che richiede una ricostruzione RAID e l'integrità del database rimane inalterata. Meno spesso, ONTAP rileva un errore di checksum, il che significa che i dati sull'unità sono danneggiati. L'unità è quindi guasta e viene avviata una ricostruzione RAID. Ancora una volta, l'integrità dei dati non viene influenzata.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">L'architettura dei log di ripristino e file dati di Oracle è inoltre progettata per offrire il massimo livello di integrità dei dati possibile, anche in circostanze estreme. A livello massimo, i blocchi Oracle includono il checksum e controlli logici di base con quasi ogni i/O. Se Oracle non è in crash o non ha portato offline uno spazio di tabella, i dati saranno intatti. Il grado di controllo dell'integrità dei dati è regolabile e Oracle può anche essere configurato per confermare le operazioni di scrittura. Di conseguenza, è possibile ripristinare quasi tutti gli scenari di crash e di guasto e, nel caso estremamente raro di una situazione irreversibile, viene immediatamente rilevata la corruzione.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">La maggior parte dei clienti NetApp che utilizzano database Oracle interrompe l'utilizzo di RMAN e di altri prodotti di backup dopo la migrazione a backup basati su snapshot. Esistono ancora opzioni in cui RMAN può essere utilizzato per eseguire un ripristino a livello di blocco con SnapCenter. Tuttavia, ogni giorno, RMAN, NetBackup e altri prodotti vengono utilizzati solo occasionalmente per creare copie di archivio mensili o trimestrali.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Alcuni clienti scelgono di eseguire<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> eseguire periodicamente controlli di integrità dei database esistenti. NetApp scoraggia questa pratica perché crea un carico i/o non necessario. Come illustrato in precedenza, se il database non presentava problemi, la possibilità di<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> Il rilevamento di un problema è prossimo allo zero e questa utility crea un carico i/o sequenziale molto elevato sulla rete e sul sistema di storage. A meno che non vi sia motivo di ritenere che esista una corruzione, come l'esposizione a un bug Oracle noto, non c'è motivo di eseguire<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="db97518eeb3e040b5a78c451efd4b252" category="summary">Backup ottimizzato per le snapshot</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Backup ottimizzati per le snapshot di storage Oracle</block>
  <block id="52fb042c0d82d8e7bdf9ae239c387729" category="paragraph">Con Oracle 12c, il backup e il ripristino basati su snapshot diventano ancora più semplici, poiché non è necessario posizionare un database in modalità hot backup. Il risultato è la possibilità di pianificare backup basati su snapshot direttamente in un sistema storage, preservando comunque la capacità di eseguire ripristini completi o point-in-time.</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Sebbene la procedura di ripristino con backup a caldo sia più familiare per gli amministratori di database, da molto tempo è stato possibile utilizzare istantanee che non sono state create mentre il database era in modalità di backup a caldo. Per rendere il database coerente, sono stati necessari ulteriori passaggi manuali con Oracle 10g e 11g durante il ripristino. Con Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> e.<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> contenere la logica aggiuntiva per riprodurre i log di archivio sui backup dei file dati che non erano in modalità hot backup.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Come indicato in precedenza, il ripristino di un backup a caldo basato su snapshot richiede due set di dati:</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Un'istantanea dei file di dati creati in modalità backup</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">I log di archivio generati mentre i file di dati erano in modalità hot backup</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Durante il ripristino, il database legge i metadati dai file di dati per selezionare i log di archivio richiesti per il ripristino.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">Per ottenere gli stessi risultati, il recovery ottimizzato per le snapshot di storage richiede set di dati leggermente diversi:</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Un'istantanea dei file di dati, più un metodo per identificare l'ora in cui è stata creata l'istantanea</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archiviare i log dall'ora del checkpoint del file dati più recente all'ora esatta dello snapshot</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Durante il ripristino, il database legge i metadati dai file di dati per identificare il registro di archivio più recente richiesto. È possibile eseguire il ripristino completo o point-in-time. Quando si esegue un ripristino point-in-time, è fondamentale conoscere l'ora dello snapshot dei file di dati. Il punto di ripristino specificato deve essere successivo all'ora di creazione degli snapshot. NetApp consiglia di aggiungere almeno alcuni minuti all'ora dello snapshot per tenere conto della variazione dell'orologio.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Per informazioni dettagliate, vedere la documentazione di Oracle sull'argomento "Recovery Using Storage Snapshot Optimization" disponibile in varie versioni della documentazione di Oracle 12c. Inoltre, consultare l'ID documento Oracle Doc ID 604683,1 relativo al supporto per le istantanee di terze parti di Oracle.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Layout dei dati</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">Il layout più semplice consiste nell'isolare i file di dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. In questo modo si garantisce che i volumi dei file dati possano essere ripristinati rapidamente con un'operazione SnapRestore senza distruggere un log di ripristino, controlfile o un log di archivio importante.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">LE SAN hanno requisiti simili per l'isolamento dei file dati all'interno di volumi dedicati. Con un sistema operativo come Microsoft Windows, un singolo volume potrebbe contenere più LUN di file dati, ciascuno con un file system NTFS. Con altri sistemi operativi, esiste in genere anche un volume manager logico. Ad esempio, con Oracle ASM, l'opzione più semplice sarebbe quella di limitare i gruppi di dischi a un singolo volume di cui è possibile eseguire il backup e il ripristino come unità. Se per motivi di gestione delle performance o della capacità sono necessari volumi aggiuntivi, la creazione di un gruppo di dischi aggiuntivo sul nuovo volume semplifica la gestione.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Se si seguono queste linee guida, gli snapshot possono essere pianificati direttamente su ONTAP senza che sia necessario eseguire uno snapshot del gruppo di coerenza. Il motivo è che i backup ottimizzati per le istantanee non richiedono che venga eseguito contemporaneamente il backup dei file di dati.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Una complicazione si verifica in situazioni come un gruppo di dischi ASM distribuito tra i volumi. In questi casi, è necessario eseguire uno snapshot cg per assicurarsi che i metadati ASM siano coerenti in tutti i volumi costituenti.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Note]verificare che i file ASM spfile e passwd non siano nel gruppo di dischi che ospita i file di dati. Ciò interferisce con la capacità di ripristinare selettivamente i dati e solo i file di dati.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Procedura di ripristino locale: NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Questa procedura può essere gestita manualmente o tramite un'applicazione come SnapCenter. La procedura di base è la seguente:</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Recuperare i volumi di file dati nello snapshot immediatamente prima del punto di ripristino desiderato.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio, o.<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> oppure<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> può essere indirizzato ai dati in<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directory.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">Inoltre, per i database di dimensioni inferiori, i file di dati possono essere recuperati da un utente finale direttamente da<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Senza l'assistenza di tool di automazione o di un amministratore dello storage per eseguire un comando SnapRestore.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Procedura di ripristino locale: SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Chiudere i gruppi di dischi che ospitano i file di dati. La procedura varia a seconda del volume manager logico scelto. Con ASM, il processo richiede lo smontaggio del gruppo di dischi. Con Linux, i file system devono essere smontati e i volumi logici e i gruppi di volumi sono disattivati. L'obiettivo è quello di interrompere tutti gli aggiornamenti del gruppo di volumi di destinazione da ripristinare.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Ripristinare i gruppi di dischi del file dati nello snapshot immediatamente prima del punto di ripristino desiderato.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Riattivare i gruppi di dischi appena ripristinati.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio portando i LUN del registro di archivio offline ed eseguendo un ripristino. Questo è anche un esempio in cui è utile dividere i log di archivio in volumi dedicati. Se i log dell'archivio condividono un gruppo di volumi con i log di ripristino, i log di ripristino devono essere copiati in un altro punto prima del ripristino del set complessivo di LUN, per evitare di perdere le transazioni finali registrate.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Esempio di recupero completo</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Si supponga che i file di dati siano stati corrotti o distrutti e che sia necessario un ripristino completo. La procedura da seguire è la seguente:</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Esempio di recupero point-in-time</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">L'intera procedura di ripristino è un singolo comando:<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Se è necessario un ripristino point-in-time, l'indicatore data e ora degli snapshot deve essere noto e può essere identificato come segue:</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">L'ora di creazione dell'istantanea è indicata come marzo 9th e 10:10:06. Per essere sicuri, viene aggiunto un minuto all'ora dell'istantanea:</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">Il ripristino viene avviato. È stato specificato un tempo di snapshot di 10:11:00, un minuto dopo il tempo registrato per tenere conto della possibile varianza dell'orologio e un tempo di recupero target di 10:44. Successivamente, sqlplus richiede i registri di archivio necessari per raggiungere il tempo di ripristino desiderato di 10:44.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Completare il ripristino di un database utilizzando gli snapshot utilizzando<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> command non richiede licenze specifiche, ma utilizza un ripristino point-in-time<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Richiede la licenza Oracle Advanced Compression.</block>
  <block id="87161b635cff9308859c719a20929913" category="summary">Strumenti di backup di Oracle e NetApp</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter e altri strumenti</block>
  <block id="400937771ac8b3d4e7be82bf39033db5" category="paragraph">Il valore primario di ONTAP in un ambiente applicativo deriva dalle tecnologie principali di ONTAP, come ad esempio copie Snapshot istantanee, semplice replica di SnapMirror e creazione efficiente dei volumi FlexClone.</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">In alcuni casi, una semplice configurazione di queste funzionalità chiave direttamente su ONTAP soddisfa i requisiti, ma esigenze più complesse richiedono un livello di orchestrazione.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter è il prodotto di punta della protezione dei dati di NetApp. A un livello molto basso, è simile ai prodotti SnapManager in termini di modalità di esecuzione dei backup del database, ma è stato creato da zero per fornire un singolo pannello di controllo per la gestione della protezione dati sui sistemi di storage NetApp.</block>
  <block id="e538db970e1ed1ffe018725fdf223f9e" category="paragraph">SnapCenter include le funzioni di base come backup e ripristini basati su copie Snapshot, la replica SnapMirror e SnapVault e altre funzionalità necessarie per operare su larga scala per le grandi imprese. Queste funzionalità avanzate includono una funzionalità estesa di controllo degli accessi in base al ruolo (RBAC), API RESTful per l'integrazione con prodotti di orchestrazione di terze parti, gestione centrale senza interruzioni dei plug-in SnapCenter sugli host di database e un'interfaccia utente progettata per ambienti cloud-scale.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">RIPOSO</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP contiene anche un ricco set di API RESTful. Questo consente a 3rd vendor di creare data Protection e altre applicazioni di gestione con una profonda integrazione con ONTAP. Inoltre, l'API RESTful è facile da utilizzare da parte dei clienti che desiderano creare i propri flussi di lavoro e utility di automazione.</block>
  <block id="e4cea644160fe9fa4ccd92ab3f079363" category="summary">Backup e ripristino basati su snapshot Oracle</block>
  <block id="9adc36f162691b8ed14a886b6068f368" category="doc">Backup Oracle in linea</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Per proteggere e ripristinare un database Oracle in modalità backup sono richiesti due set di dati. Si noti che questa non è l'unica opzione di backup di Oracle, ma è la più comune.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Un'istantanea dei file di dati in modalità di backup</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">I registri di archivio creati mentre i file di dati erano in modalità backup</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Se è richiesto il recupero completo, comprese tutte le transazioni impegnate, è necessario un terzo elemento:</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Una serie di registri di ripristino correnti</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Esistono diversi modi per eseguire il ripristino di un backup online. Molti clienti ripristinano le snapshot utilizzando l'interfaccia CLI di ONTAP e quindi Oracle RMAN o sqlplus per completare il ripristino. Ciò è particolarmente comune negli ambienti di produzione di grandi dimensioni, in cui la probabilità e la frequenza dei ripristini dei database sono estremamente ridotte e qualsiasi procedura di ripristino viene gestita da un DBA esperto. Per un'automazione completa, soluzioni come NetApp SnapCenter includono un plug-in Oracle con interfacce sia a riga di comando che grafiche.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Alcuni clienti su larga scala hanno adottato un approccio più semplice configurando script di base sugli host per impostare i database in modalità di backup in un momento specifico in preparazione a uno snapshot pianificato. Ad esempio, pianificare il comando<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> alle 23:58,<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> alle 00:02, quindi programmare le snapshot direttamente sul sistema storage a mezzanotte. Il risultato è una strategia di backup semplice e altamente scalabile che non richiede licenze o software esterni.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">Il layout più semplice consiste nell'isolare i file di dati in uno o più volumi dedicati. Non devono essere contaminati da alcun altro tipo di file. In questo modo si garantisce che i volumi dei file dati possano essere ripristinati rapidamente tramite un'operazione SnapRestore senza distruggere un log di ripristino, controlfile o un log di archivio importante.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">LE SAN hanno requisiti simili per l'isolamento dei file dati all'interno di volumi dedicati. Con un sistema operativo come Microsoft Windows, un singolo volume potrebbe contenere più LUN di file dati, ciascuno con un file system NTFS. Con altri sistemi operativi, in genere esiste un volume manager logico. Ad esempio, con Oracle ASM, l'opzione più semplice sarebbe limitare i LUN di un gruppo di dischi ASM a un singolo volume che può essere sottoposto a backup e ripristinato come unità. Se per motivi di gestione delle performance o della capacità sono necessari volumi aggiuntivi, la creazione di un gruppo di dischi aggiuntivo sul nuovo volume semplifica la gestione.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Se vengono seguite queste linee guida, le snapshot possono essere pianificate direttamente sul sistema di storage, senza che sia necessario eseguire uno snapshot del gruppo di coerenza. Il motivo è che i backup Oracle non richiedono il backup dei file di dati contemporaneamente. La procedura di backup online è stata progettata per consentire ai file di dati di continuare ad essere aggiornati, poiché vengono lentamente trasmessi su nastro nel corso delle ore.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Una complicazione si verifica in situazioni come l'utilizzo di un gruppo di dischi ASM distribuito tra i volumi. In questi casi, è necessario eseguire uno snapshot cg per assicurarsi che i metadati ASM siano coerenti in tutti i volumi costituenti.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Attenzione:* verificare che l'ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> e.<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> i file non si trovano nel gruppo di dischi che ospita i file di dati. Ciò interferisce con la capacità di ripristinare selettivamente i dati e solo i file di dati.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i log di archivio oppure è possibile indirizzare rman/sqlplus ai dati nella directory snapshot.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">Inoltre, per i database di dimensioni inferiori, i file di dati possono essere recuperati da un utente finale direttamente da<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directory senza l'assistenza di tool di automazione o amministratori dello storage per eseguire una<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> comando.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Chiudere i gruppi di dischi che ospitano i file di dati. La procedura varia a seconda del volume manager logico scelto. Con ASM, il processo richiede lo smontaggio del gruppo di dischi. Con Linux, i file system devono essere smontati e i volumi logici e i gruppi di volumi devono essere disattivati. L'obiettivo è quello di interrompere tutti gli aggiornamenti del gruppo di volumi di destinazione da ripristinare.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Se si desidera eseguire il ripristino completo, riprodurre tutti i registri di ripristino.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">Questa procedura presuppone che i log di archivio desiderati siano ancora presenti nel file system attivo. In caso contrario, è necessario ripristinare i registri di archivio portando i LUN del registro di archivio offline ed eseguendo un ripristino. Questo è anche un esempio in cui è utile dividere i log di archivio in volumi dedicati. Se i log dell'archivio condividono un gruppo di volumi con log di ripristino, i log di ripristino devono essere copiati in un altro punto prima di ripristinare il set complessivo di LUN. Questa fase impedisce la perdita di tali transazioni finali registrate.</block>
  <block id="1536f0d3e3ee227abdec76f432b89cae" category="summary">SLA di data Protection Oracle</block>
  <block id="e9c8b7044dfae7a21f1a9c4d08628a66" category="doc">Recovery time objective, recovery point objective e service level agreement</block>
  <block id="020e620c60ad38b75f0ff2a2fe4067b0" category="paragraph">Una strategia di protezione dei dati deve essere definita dai requisiti di business.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Questi requisiti includono fattori quali la velocità del recovery, la perdita massima consentita di dati e le esigenze di conservazione del backup. Il piano di protezione dei dati deve anche tenere in considerazione i vari requisiti normativi per la conservazione e il ripristino dei dati. Infine, è necessario considerare diversi scenari di ripristino dei dati, che vanno dal recupero tipico e prevedibile derivante da errori di utenti o applicazioni fino a scenari di ripristino di emergenza che includono la perdita completa di un sito.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Piccole modifiche alle policy di protezione e ripristino dei dati possono avere un effetto significativo sull'architettura generale dello storage, del backup e del ripristino. È fondamentale definire e documentare gli standard prima di iniziare il lavoro di progettazione, per evitare di complicare un'architettura di protezione dati. Le funzioni o i livelli di protezione non necessari comportano costi e costi di gestione inutili, mentre un requisito inizialmente trascurato può condurre un progetto nella direzione sbagliata o richiedere modifiche di progettazione dell'ultimo minuto.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Recovery time objective</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">L'obiettivo RTO (Recovery Time Objective) definisce il tempo massimo consentito per il ripristino di un servizio. Ad esempio, un database di risorse umane potrebbe avere un RTO di 24 ore perché, sebbene sarebbe molto scomodo perdere l'accesso a questi dati durante la giornata lavorativa, l'azienda può comunque operare. Al contrario, un database che supporta la contabilità generale di una banca avrebbe un RTO misurato in minuti o anche secondi. Un RTO di zero non è possibile, perché deve esserci un modo per distinguere tra un'effettiva interruzione del servizio e un evento di routine, come un pacchetto di rete perso. Tuttavia, un RTO prossimo allo zero è un requisito tipico.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Obiettivo RPO</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">Il recovery point objective (RPO) definisce la massima perdita di dati tollerabile. In molti casi, l'RPO è determinato unicamente dalla frequenza delle snapshot o degli aggiornamenti di snapmirror.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">In alcuni casi, l'RPO può essere reso più aggressivo proteggendo determinati dati con maggiore frequenza. In un contesto di database, l'RPO è in genere una questione di quanti dati di registro possono essere persi in una situazione specifica. In uno scenario di ripristino tipico in cui un database viene danneggiato a causa di un bug del prodotto o di un errore dell'utente, l'RPO deve essere pari a zero, il che significa che non ci devono essere perdite di dati. La procedura di ripristino prevede il ripristino di una copia precedente dei file di database e la riproduzione dei file di registro per portare lo stato del database al momento desiderato. I file di registro necessari per questa operazione dovrebbero essere già presenti nella posizione originale.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">In scenari insoliti, i dati del registro potrebbero andare persi. Ad esempio, un accidentale o dannoso<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> di file di database potrebbe causare l'eliminazione di tutti i dati. L'unica opzione sarebbe il ripristino dal backup, inclusi i file di registro, e alcuni dati andrebbero inevitabilmente persi. L'unica opzione per migliorare gli RPO in un ambiente di backup tradizionale sarebbe l'esecuzione di backup ripetuti dei dati di log. Questo comporta dei limiti, tuttavia, a causa dello spostamento costante dei dati e della difficoltà di mantenere un sistema di backup come servizio in esecuzione costante. Uno dei benefici dei sistemi storage avanzati è la capacità di proteggere i dati da danni accidentali o dannosi ai file e garantire quindi un RPO migliore senza spostamento dei dati.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">Il ripristino di emergenza include l'architettura IT, i criteri e le procedure necessarie per il ripristino di un servizio in caso di emergenza fisica. Tra questi, inondazioni, incendi o persone che agiscono con intento doloso o negligente.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">Il disaster recovery non è solo una serie di procedure di ripristino. Si tratta del processo completo di identificazione dei vari rischi, definizione dei requisiti di ripristino dei dati e continuità del servizio e realizzazione della giusta architettura con le relative procedure.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Durante la definizione dei requisiti di protezione dei dati, è fondamentale differenziare tra i requisiti tipici di RPO e RTO e quelli di RPO e RTO necessari per il disaster recovery. Alcuni ambienti applicativi richiedono un RPO pari a zero e un RTO prossimo allo zero per situazioni di perdita di dati che vanno da errori utente relativamente normali a incendi che distruggono un data center. Tuttavia, vi sono conseguenze amministrative e di costo per questi elevati livelli di protezione.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">In generale, i requisiti di ripristino dei dati non di emergenza devono essere rigorosi per due motivi. Innanzitutto, i bug applicativi e gli errori degli utenti che danneggiano i dati sono prevedibili al punto che sono quasi inevitabili. In secondo luogo, non è difficile progettare una strategia di backup in grado di offrire un RPO pari a zero e un RTO basso finché il sistema storage non viene distrutto. Non c'è motivo di non affrontare un rischio significativo che sia facilmente risolvibile, motivo per cui gli obiettivi di RPO e RTO per il ripristino locale dovrebbero essere aggressivi.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">I requisiti di RTO e RPO per il disaster recovery variano in modo più ampio in base alla probabilità di un disastro e alle conseguenze della perdita di dati associata o dell'interruzione di un business. I requisiti di RPO e RTO devono essere basati sulle effettive esigenze di business e non su principi generali. Devono tenere conto di più scenari di emergenza logici e fisici.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Disastri logici</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">I disastri logici includono la corruzione dei dati causata da utenti, bug delle applicazioni o del sistema operativo e malfunzionamenti del software. I disastri logici possono includere anche attacchi dannosi da parte di terzi con virus o worm o sfruttando le vulnerabilità delle applicazioni. In questi casi, l'infrastruttura fisica rimane intatta, ma i dati sottostanti non sono più validi.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Un tipo sempre più comune di disastro logico è noto come ransomware, in cui un vettore di attacco viene utilizzato per crittografare i dati. La crittografia non danneggia i dati, ma li rende non disponibili fino a quando non viene effettuato il pagamento a terzi. Un numero sempre crescente di aziende è specificatamente preso di mira con gli hack ransomware. A causa di questa minaccia, NetApp offre snapshot a prova di manomissione, in cui nemmeno l'amministratore dello storage può modificare i dati protetti prima della data di scadenza configurata.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Disastri fisici</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">I disastri fisici includono l'errore di componenti di un'infrastruttura che superano le sue capacità di ridondanza e causano una perdita di dati o un'estesa perdita di servizio. Ad esempio, la protezione RAID fornisce la ridondanza dell'unità disco e l'utilizzo di HBA fornisce la ridondanza di porte FC e cavi FC. I guasti hardware di tali componenti sono prevedibili e non influiscono sulla disponibilità.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">In un ambiente aziendale, è generalmente possibile proteggere l'infrastruttura di un intero sito con componenti ridondanti fino al punto in cui l'unico scenario di emergenza fisica prevedibile è la perdita completa del sito. Quindi, il piano di disaster recovery dipende dalla replica sito-sito.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Protezione dei dati sincrona e asincrona</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">In un mondo ideale, tutti i dati verrebbero replicati in modo sincrono tra siti dispersi geograficamente. Tale replicazione non è sempre fattibile o addirittura possibile per diversi motivi:</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">La replica sincrona aumenta inevitabilmente la latenza di scrittura, perché tutte le modifiche devono essere replicate in entrambe le posizioni prima che l'applicazione/database possa procedere con l'elaborazione. L'effetto sulle prestazioni risultante è talvolta inaccettabile, escludendo l'uso del mirroring sincrono.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">La maggiore adozione di storage SSD al 100% implica maggiore probabilità di ottenere una latenza di scrittura aggiuntiva, poiché le aspettative di performance includono centinaia di migliaia di IOPS e latenza sotto al millisecondo. Ottenere tutti i benefici dell'utilizzo di SSD al 100% può richiedere la revisione della strategia di disaster recovery.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">I set di dati continuano a crescere in termini di byte, creando difficoltà per garantire una larghezza di banda sufficiente a sostenere la replica sincrona.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">I set di dati crescono anche in termini di complessità, creando problemi con la gestione della replica sincrona su larga scala.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Le strategie basate sul cloud spesso implicano maggiori distanze di replica e latenza, precludendo ulteriormente l'utilizzo di mirroring sincrono.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp offre soluzioni che includono replica sincrona per le più esigenti richieste di recovery di dati e soluzioni asincrone che consentono performance e flessibilità migliori. Inoltre, la tecnologia NetApp si integra perfettamente con molte soluzioni di replica di terze parti, come Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Tempo di conservazione</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">L'ultimo aspetto di una strategia di protezione dei dati è il tempo di conservazione dei dati, che può variare drasticamente.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Un requisito tipico è rappresentato da 14 giorni di backup notturni sul sito primario e 90 giorni di backup memorizzati su un sito secondario.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">Molti clienti creano archivi trimestrali autonomi archiviati su supporti diversi.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Un database costantemente aggiornato potrebbe non richiedere i dati storici e i backup devono essere conservati solo per alcuni giorni.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">I requisiti normativi potrebbero richiedere la possibilità di recupero fino al punto in cui avviene una transazione arbitraria nell'arco di 365 giorni.</block>
  <block id="a83f7a3ea63946cbdc1977d641e8460c" category="summary">Oracle su ONTAP e il ruolo delle snapshot</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Backup basati su snapshot</block>
  <block id="5e3f0537b2a1927f4a24b28e9157cc0b" category="paragraph">La base della protezione dei dati di Oracle su ONTAP è la tecnologia Snapshot di NetApp.</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">I valori chiave sono i seguenti:</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Semplicità.* Uno snapshot è una copia di sola lettura del contenuto di un contenitore di dati in un determinato momento.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Efficienza.* le istantanee non richiedono spazio al momento della creazione. Lo spazio viene occupato solo quando i dati vengono modificati.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Gestibilità.* Una strategia di backup basata sugli snapshot è facile da configurare e gestire perché gli snapshot sono parte nativa del sistema operativo di storage. Se il sistema di archiviazione è acceso, è pronto per creare dei backup.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Scalabilità.* è possibile conservare fino a 1024 backup di un singolo contenitore di file e LUN. Per set di dati complessi, più container di dati possono essere protetti da un singolo set coerente di snapshot.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">Le prestazioni non sono influenzate, indipendentemente dal fatto che un volume contenga 1024 snapshot o nessuno.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Sebbene molti vendor di soluzioni storage offrano la tecnologia Snapshot, la tecnologia Snapshot all'interno di ONTAP è unica e offre benefici significativi per gli ambienti applicativi aziendali e di database:</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Le copie snapshot fanno parte del layout file WAFL (Write-Anywhere file Layout) sottostante. Non si tratta di una tecnologia aggiuntiva o esterna. Questo semplifica la gestione, perché il sistema storage è il sistema di backup.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Le copie Snapshot non influiscono sulle prestazioni, ad eccezione di alcuni casi edge, come ad esempio quando una quantità così elevata di dati viene memorizzata nelle snapshot che il sistema storage sottostante si riempie.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">Il termine "gruppo di coerenza" viene spesso utilizzato per fare riferimento a un raggruppamento di oggetti di storage che vengono gestiti come una raccolta coerente di dati. Uno snapshot di un particolare volume ONTAP costituisce il backup del gruppo di coerenza.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">Le snapshot ONTAP offrono anche una scalabilità migliore rispetto alle tecnologie della concorrenza. I clienti possono memorizzare 5, 50 o 500 snapshot senza influire sulle performance. Il numero massimo di snapshot attualmente consentiti in un volume è 1024. Se è necessaria una conservazione aggiuntiva degli snapshot, sono disponibili opzioni per trasferire gli snapshot in cascata ad altri volumi.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Di conseguenza, la protezione di un set di dati ospitato su ONTAP è semplice e altamente scalabile. I backup non richiedono lo spostamento dei dati, pertanto una strategia di backup può essere personalizzata in base alle esigenze dell'azienda piuttosto che alle limitazioni delle velocità di trasferimento di rete, del numero elevato di unità a nastro o delle aree di staging del disco.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">Una domanda comunemente posta sull'utilizzo delle istantanee come strategia di protezione dei dati è il fatto che i dati "reali" e i dati snapshot si trovano sulle stesse unità. La perdita di tali unità causerebbe la perdita sia dei dati primari che del backup.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Gli snapshot locali, tuttavia, non dovrebbero mai rappresentare l'unica strategia di backup, motivo per cui NetApp offre tecnologie come SnapMirror e la replica SnapVault per replicare in modo rapido ed efficiente le snapshot su un set indipendente di dischi. In una soluzione adeguatamente progettata con istantanee e replica snapshot, l'utilizzo del nastro può essere ridotto a icona in un archivio trimestrale o eliminato del tutto.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Le copie Snapshot di ONTAP sono disponibili diverse opzioni per la protezione dei dati, mentre le snapshot sono alla base di molte altre funzionalità di ONTAP, tra cui replica, disaster recovery e cloning. Una descrizione completa della tecnologia snapshot non rientra nell'ambito di questo documento, ma le sezioni seguenti forniscono una panoramica generale.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Esistono due approcci principali per creare uno snapshot di un dataset:</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Backup coerenti con il crash</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Backup coerenti con le applicazioni</block>
  <block id="7733cc553d118547b64c858cb4281f24" category="paragraph">Un backup coerente con i crash di un set di dati si riferisce all'acquisizione dell'intera struttura di set di dati in un singolo point-in-time. Se il set di dati è memorizzato in un singolo volume NetApp FlexVol, il processo è semplice ed è possibile creare una Snapshot in qualsiasi momento. Se un set di dati si estende tra i volumi, è necessario creare uno snapshot del gruppo di coerenza (CG). Esistono diverse opzioni per la creazione di snapshot CG, tra cui il software NetApp SnapCenter, le funzionalità native del gruppo di coerenza ONTAP e gli script gestiti dagli utenti.</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">I backup coerenti con i crash vengono utilizzati principalmente quando è sufficiente un ripristino point-of-the-backup. Quando è richiesto un ripristino più granulare, sono in genere necessari backup coerenti con l'applicazione.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">La parola "coerente" in "coerente con l'applicazione" è spesso un nome scorretto. Ad esempio, l'inserimento di un database Oracle in modalità di backup viene definito backup coerente con l'applicazione, ma i dati non vengono resi coerenti o disattivati in alcun modo. I dati continuano a cambiare durante il backup. Al contrario, la maggior parte dei backup di MySQL e Microsoft SQL Server disattivano i dati prima di eseguire il backup. VMware può o non può rendere certi file coerenti.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">Il termine "gruppo di coerenza" si riferisce alla capacità di un array di archiviazione di gestire più risorse di archiviazione come una singola immagine. Ad esempio, un database può essere composto da 10 LUN. L'array deve essere in grado di eseguire il backup, il ripristino e la replica delle 10 LUN in modo coerente. Il ripristino non è possibile se le immagini dei LUN non erano coerenti nel punto di backup. La replica di queste 10 LUN richiede che tutte le repliche siano perfettamente sincronizzate l'una con l'altra.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">Il termine "gruppo di coerenza" non viene spesso utilizzato quando si parla di ONTAP perché la coerenza è sempre stata una funzione di base dell'architettura di volumi e aggregati all'interno di ONTAP. Molti altri storage array gestiscono LUN o file system come unità singole. Possono quindi essere configurati facoltativamente come "gruppo di coerenza" ai fini della protezione dei dati, ma questo è un passaggio aggiuntivo nella configurazione.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP è sempre stata in grado di acquisire immagini di dati coerenti locali e replicate. Anche se i vari volumi su un sistema ONTAP non vengono in genere formalmente descritti come un gruppo di coerenza, è proprio questo lo sono. Una snapshot di tale volume è un'immagine del gruppo di coerenza, il ripristino di tale snapshot è un ripristino di un gruppo di coerenza e sia SnapMirror che SnapVault offrono la replica di un gruppo di coerenza.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshot di gruppo di coerenza</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Le snapshot di gruppo di coerenza (cg-Snapshot) sono un'estensione della tecnologia Snapshot di base di ONTAP. Un'operazione Snapshot standard crea un'immagine coerente di tutti i dati all'interno di un singolo volume, ma a volte è necessario creare un set coerente di Snapshot su più volumi e persino su sistemi di storage multipli. Ne risulta una serie di snapshot che possono essere utilizzate allo stesso modo di uno snapshot di un solo volume. Possono essere utilizzati per il recovery locale dei dati, replicati a scopo di disaster recovery o clonati come una singola unità coerente.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">Il più grande utilizzo noto di cg-snapshot è per un ambiente di database di circa 1PB GB su 12 controller. Le cg-Snapshot create su questo sistema sono state utilizzate per il backup, il ripristino e il cloning.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">Nella maggior parte dei casi, quando un set di dati copre i volumi e l'ordine di scrittura deve essere preservato, il software di gestione scelto utilizza automaticamente uno snapshot cg. In questi casi non è necessario comprendere i dettagli tecnici delle istantanee cg. Tuttavia, in alcune situazioni, i complessi requisiti di protezione dei dati richiedono un controllo dettagliato sul processo di protezione e replica dei dati. I flussi di lavoro di automazione o l'uso di script personalizzati per richiamare le API cg-snapshot sono alcune delle opzioni disponibili. La comprensione dell'opzione migliore e del ruolo di cg-snapshot richiede una spiegazione più dettagliata della tecnologia.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">La creazione di una serie di istantanee cg è un processo in due fasi:</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Stabilire il recencing in scrittura su tutti i volumi di destinazione.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Creare Snapshot di tali volumi nello stato fenced (fenced).</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">La recinzione in scrittura viene stabilita in serie. Ciò significa che, mentre il processo di scherma viene configurato su più volumi, l'i/o in scrittura viene bloccato sul primo volume della sequenza mentre continua ad essere assegnato ai volumi che compaiono in seguito. Questo potrebbe inizialmente sembrare una violazione del requisito per il mantenimento dell'ordine di scrittura, ma ciò si applica solo all'i/o emesso in modo asincrono sull'host e non dipende da altre scritture.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Ad esempio, un database potrebbe eseguire numerosi aggiornamenti asincroni del file dati, consentendo al sistema operativo di riordinare l'i/o e completarli in base alla propria configurazione dell'utilità di pianificazione. L'ordine di questo tipo di i/o non può essere garantito perché l'applicazione e il sistema operativo hanno già rilasciato il requisito di mantenere l'ordine di scrittura.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Come esempio di contatore, la maggior parte delle attività di registrazione del database è sincrona. Il database non procede con ulteriori scritture di registro fino a quando l'i/o non viene riconosciuto e l'ordine di tali scritture deve essere conservato. Se un i/o di registro arriva su un volume fenced, non viene riconosciuto e le applicazioni vengono bloccate in ulteriori scritture. Analogamente, l'i/o di metadati del file system è di solito sincrono. Ad esempio, un'operazione di eliminazione file non deve essere persa. Se un sistema operativo con un file system xfs eliminava un file e l'i/o che aggiornava i metadati del file system xfs per rimuovere il riferimento a quel file apposto su un volume recintato, l'attività del file system si interrompeva. Ciò garantisce l'integrità del file system durante le operazioni cg-snapshot.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Dopo aver configurato la funzionalità write fencing nei volumi di destinazione, sono pronti per la creazione di snapshot. Non è necessario creare esattamente gli snapshot contemporaneamente, perché lo stato dei volumi è bloccato da un punto di vista di scrittura dipendente. Per evitare un difetto nell'applicazione che crea le istantanee cg, la recinzione iniziale include un timeout configurabile in cui ONTAP rilascia automaticamente la recinzione e riprende l'elaborazione di scrittura dopo un numero definito di secondi. Se tutte le istantanee vengono create prima dello scadere del periodo di timeout, il gruppo risultante di istantanee è un gruppo di coerenza valido.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Ordine di scrittura dipendente</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Da un punto di vista tecnico, la chiave per un gruppo di coerenza è preservare l'ordine di scrittura e, nello specifico, l'ordine di scrittura dipendente. Ad esempio, un database in scrittura su 10 LUN scrive simultaneamente su tutte. Molte scritture vengono emesse in modo asincrono, il che significa che l'ordine in cui vengono completate non è importante e l'ordine effettivo in cui vengono completate varia in base al comportamento del sistema operativo e della rete.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Alcune operazioni di scrittura devono essere presenti sul disco prima che il database possa procedere con operazioni di scrittura aggiuntive. Queste operazioni critiche di scrittura sono chiamate scritture dipendenti. I/o di scrittura successivi dipendono dalla presenza di queste scritture sul disco. Qualsiasi snapshot, recovery o replica di queste 10 LUN deve garantire l'ordine di scrittura dipendente. Gli aggiornamenti del file system sono un altro esempio di scritture dipendenti dall'ordine di scrittura. L'ordine in cui vengono apportate le modifiche al file system deve essere mantenuto o l'intero file system potrebbe danneggiarsi.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Strategie</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Esistono due approcci principali ai backup basati su snapshot:</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Backup a caldo protetti dagli snapshot</block>
  <block id="c81725eb350a685210d69762bd5d725d" category="paragraph">Un backup coerente con i crash di un database si riferisce all'acquisizione dell'intera struttura del database, inclusi i file di dati, i log di ripristino e i file di controllo, in un singolo momento. Se il database è memorizzato in un singolo volume NetApp FlexVol, il processo è semplice ed è possibile creare una Snapshot in qualsiasi momento. Se un database si estende su volumi, è necessario creare uno snapshot del gruppo di coerenza (CG). Esistono diverse opzioni per la creazione di snapshot CG, tra cui il software NetApp SnapCenter, le funzionalità native del gruppo di coerenza ONTAP e gli script gestiti dagli utenti.</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">I backup Snapshot coerenti con i crash vengono utilizzati principalmente quando è sufficiente un recovery point-of-the-backup. In alcune circostanze è possibile applicare i registri di archivio, ma quando è necessario un ripristino point-in-time più granulare, è preferibile un backup online.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">La procedura di base per un backup online basato su snapshot è la seguente:</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Inserire il database in<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modalità.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Creare una snapshot di tutti i volumi che ospitano file di dati.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Esci<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modalità.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Eseguire il comando<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> per forzare l'archiviazione del registro.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Creare snapshot di tutti i volumi che ospitano i log di archivio.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Questa procedura produce una serie di istantanee contenenti file di dati in modalità backup e i registri di archivio critici generati in modalità backup. Questi sono i due requisiti per il ripristino di un database. I file come i file di controllo dovrebbero essere protetti per comodità, ma l'unico requisito assoluto è la protezione per i file di dati e i registri di archivio.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Sebbene i diversi clienti possano avere strategie molto diverse, quasi tutte queste strategie si basano in ultima analisi sugli stessi principi delineati di seguito.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Recovery basato su Snapshot</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Quando si progettano layout di volumi per database Oracle, la prima decisione è se utilizzare la tecnologia VBSR (Volume-Based NetApp SnapRestore).</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">La funzione SnapRestore basata su volume consente di ripristinare quasi istantaneamente un volume in un point-in-time precedente. Poiché tutti i dati sul volume vengono ripristinati, VBSR potrebbe non essere appropriato per tutti i casi di utilizzo. Ad esempio, se un intero database, inclusi file di dati, log di ripristino e log di archivio, viene memorizzato in un singolo volume e questo volume viene ripristinato con VBSR, i dati vengono persi perché i log di archivio e i dati di ripristino più recenti vengono scartati.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">VBSR non è necessario per il ripristino. Molti database possono essere ripristinati utilizzando SFSR (Single-file SnapRestore) basato su file o semplicemente copiando i file dalla snapshot nel file system attivo.</block>
  <block id="2093e578085fede0f022c4efdb79c336" category="paragraph">VBSR è preferibile quando un database è molto grande o quando deve essere recuperato il più rapidamente possibile, e l'uso di VBSR richiede l'isolamento dei file di dati. In un ambiente NFS, i file di dati di un dato database devono essere archiviati in volumi dedicati che non sono contaminati da alcun altro tipo di file. In un ambiente SAN, i file di dati devono essere memorizzati in LUN dedicate su volumi FlexVol dedicati. Se viene utilizzato un volume manager (incluso Oracle Automatic Storage Management [ASM]), il gruppo di dischi deve essere dedicato anche ai file di dati.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">L'isolamento dei file di dati in questo modo consente loro di tornare a uno stato precedente senza danneggiare altri file system.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Riserva di Snapshot</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Per ogni volume con i dati Oracle in un ambiente SAN, il<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Dovrebbe essere impostato su zero perché non è utile riservare spazio per uno snapshot in un ambiente LUN. Se la riserva frazionaria è impostata su 100, uno snapshot di un volume con LUN richiede spazio libero sufficiente nel volume, esclusa la riserva snapshot, per assorbire il 100% di turnover di tutti i dati. Se la riserva frazionaria è impostata su un valore inferiore, è necessaria una quantità di spazio libero corrispondente inferiore, ma esclude sempre la riserva istantanea. Ciò significa che viene sprecato lo spazio di riserva di Snapshot in un ambiente LUN.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">In un ambiente NFS, esistono due opzioni:</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Impostare<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> in base al consumo di spazio snapshot previsto.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Impostare<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> a zero e gestire collettivamente il consumo di spazio attivo e snapshot.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Con la prima opzione,<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> è impostato su un valore diverso da zero, in genere intorno al 20%. Questo spazio viene quindi nascosto all'utente. Tuttavia, questo valore non crea un limite di utilizzo. Se un database con una prenotazione del 20% registra un fatturato del 30%, lo spazio snapshot può crescere oltre i limiti della riserva del 20% e occupare spazio non riservato.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">Il vantaggio principale dell'impostazione di una riserva a un valore come 20% è verificare che una parte di spazio sia sempre disponibile per gli snapshot. Ad esempio, un volume da 1TB TB con una riserva del 20% consentirebbe all'amministratore di database (DBA) di memorizzare 800GB TB di dati. Questa configurazione garantisce almeno 200GB GB di spazio per il consumo di snapshot.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Quando<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> è impostato su zero, tutto lo spazio nel volume è disponibile per l'utente finale, il che garantisce una migliore visibilità. Un DBA deve capire che, se rileva un volume di 1TB GB che sfrutta le snapshot, questo 1TB GB di spazio viene condiviso tra i dati attivi e il turnover di Snapshot.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">Non esiste una chiara preferenza tra l'opzione 1 e l'opzione 2 tra gli utenti finali.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">ONTAP e snapshot di terze parti</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683,1 illustra i requisiti per il supporto di snapshot di terze parti e le varie opzioni disponibili per le operazioni di backup e ripristino.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">Il fornitore di terze parti deve garantire che le istantanee dell'azienda siano conformi ai seguenti requisiti:</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Gli snapshot devono integrarsi con le operazioni di ripristino e ripristino consigliate da Oracle.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Gli snapshot devono essere coerenti con il crash del database nel punto dello snapshot.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">L'ordine di scrittura viene mantenuto per ogni file all'interno di uno snapshot.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">I prodotti di gestione ONTAP e NetApp di Oracle sono conformi a questi requisiti.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Data Protection di Oracle con ONTAP</block>
  <block id="6f1383567177df0041e76e845c3629f2" category="paragraph">I dati più mission-critical sono presenti nei database.</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Un'azienda non può operare senza accesso ai propri dati, e a volte i dati definiscono l'azienda. Questi dati devono essere protetti; tuttavia, la protezione dei dati non è solo garanzia di un backup utilizzabile, ma consiste nell'eseguire i backup in modo rapido e affidabile, oltre a memorizzarli in modo sicuro.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">L'altro lato della protezione dei dati è la recovery. Quando i dati sono inaccessibili, l'azienda ne è interessata e potrebbe non funzionare fino a quando i dati non vengono ripristinati. Questo processo deve essere rapido e affidabile. Infine, la maggior parte dei database deve essere protetta dai disastri, il che significa mantenere una replica del database. La replica deve essere sufficientemente aggiornata. Rendere la replica un database completamente operativo deve anche essere semplice e veloce.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4591: Data Protection di Oracle: Backup, recovery e replica._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Pianificazione</block>
  <block id="0bf5784d6c307e4ee0371d46053937c0" category="summary">Test delle performance di Oracle</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Il test accurato delle performance dello storage del database è un argomento estremamente complicato. Richiede la comprensione dei seguenti problemi:</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS e throughput</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">La differenza tra le operazioni i/o in primo piano e in background</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">L'effetto della latenza sul database</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Numerose impostazioni del sistema operativo e di rete che influiscono sulle performance dello storage</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">Inoltre, occorre prendere in considerazione attività che non riguardano i database di storage. Esiste un punto in cui l'ottimizzazione delle performance dello storage non produce vantaggi utili perché le performance dello storage non sono più un fattore limitante per le performance.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">La larghezza di banda della rete è una fonte sempre più comune di limitazioni delle prestazioni. Ad esempio, le soluzioni su disco a rotazione sono spesso dei colli di bottiglia per le performance dei database perché la latenza i/o è molto elevata. Quando un array all-flash rimuove le limitazioni di latenza, spesso la barriera passa alla rete. Si tratta di un aspetto particolarmente interessante nel caso di ambienti virtualizzati e sistemi blade in cui è difficile visualizzare la vera connettività di rete. Ciò può complicare il test delle performance se il sistema di storage stesso non può essere pienamente utilizzato a causa di limitazioni della larghezza di banda.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Generalmente, il confronto delle performance di un array all-flash con un array contenente dischi rotanti non è possibile a causa dell'aumento drastico della latenza degli array all-flash. I risultati dei test in genere non sono significativi.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">Il confronto delle performance di picco degli IOPS con un array all-flash spesso non è un test utile, in quanto i database non sono limitati dall'i/o dello storage Ad esempio, si supponga che un array sia in grado di sostenere 500K IOPS casuali, mentre un altro possa sostenere 300K KB. La differenza è irrilevante nel mondo reale se un database impiega il 99% del suo tempo per l'elaborazione della CPU. I carichi di lavoro non utilizzano mai le funzionalità complete dello storage array. Al contrario, le funzionalità degli IOPS di picco potrebbero essere critiche in una piattaforma di consolidamento in cui si prevede che lo storage array venga caricato alle proprie funzionalità di picco.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">In qualsiasi test dello storage, si tiene sempre in considerazione sia la latenza che gli IOPS. Molti storage array sul mercato dichiarano livelli estremi di IOPS, ma la latenza rende quegli IOPS inutili a tali livelli. La destinazione tipica degli array all-flash è il contrassegno 1ms. Un approccio migliore al test non consiste nel misurare gli IOPS massimi possibili, ma nel determinare quanti IOPS può supportare uno storage array prima che la latenza media sia superiore a 1ms ms.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Oracle Automatic workload Repository e benchmarking</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Il gold standard per i confronti delle performance Oracle è un report Oracle Automatic workload Repository (AWR).</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Esistono diversi tipi di rapporti AWR. Da un punto di vista dello storage, un report generato dall'esecuzione di<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> È il comando più completo e utile, in quanto è destinato a una specifica istanza del database e include alcuni istogrammi dettagliati che suddividono gli eventi i/o dello storage in base alla latenza.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">Il confronto fra due array delle performance implica l'esecuzione idealmente dello stesso carico di lavoro su ciascun array e la produzione di un report AWR che punta esattamente al carico di lavoro. Nel caso di un carico di lavoro con esecuzione molto lunga, è possibile utilizzare un singolo rapporto AWR con un tempo trascorso che comprende il tempo di inizio e di fine, ma è preferibile suddividere i dati AWR come rapporti multipli. Ad esempio, se un processo batch è stato eseguito dalla mezzanotte alle 6, creare una serie di rapporti AWR di un'ora dalle 1:1 alle 2:00 e così via.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">In altri casi, è necessario ottimizzare una query molto breve. L'opzione migliore è un report AWR basato su uno snapshot AWR creato all'inizio della query e un secondo snapshot AWR creato al termine della query. Il server di database dovrebbe essere altrimenti silenzioso per ridurre al minimo l'attività in background che potrebbe oscurare l'attività della query in analisi.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Laddove i report AWR non sono disponibili, i report statspack Oracle sono una buona alternativa. Contengono la maggior parte delle stesse statistiche i/o di un rapporto AWR.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR e risoluzione dei problemi</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Un report AWR è anche lo strumento più importante per analizzare un problema di prestazioni.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Come per il benchmarking, il troubleshooting delle performance richiede la misurazione precisa di un determinato carico di lavoro. Quando possibile, fornisci dati AWR quando segnali un problema di performance al centro di supporto NetApp o quando lavori con un account team NetApp o partner in merito a una nuova soluzione.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Quando si forniscono i dati AWR, considerare i seguenti requisiti:</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Eseguire<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> per generare il report. L'output può essere di testo o HTML.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Se si utilizzano Oracle Real Application Clusters (RAC), generare report AWR per ciascuna istanza del cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Indicare l'ora specifica in cui si è verificato il problema. Il tempo massimo accettabile trascorso di un rapporto AWR è generalmente di un'ora. Se un problema persiste per più ore o richiede un'operazione multi-ora, ad esempio un processo batch, fornire più rapporti AWR di un'ora che coprono l'intero periodo da analizzare.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Se possibile, regolare l'intervallo dell'istantanea AWR su 15 minuti. Questa impostazione consente di eseguire un'analisi più dettagliata. Ciò richiede anche ulteriori esecuzioni di<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> per fornire un report per ogni intervallo di 15 minuti.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Se il problema è una query in esecuzione molto breve, fornire un report AWR basato su uno snapshot AWR creato all'inizio dell'operazione e un secondo snapshot AWR creato al termine dell'operazione. Il server di database dovrebbe essere altrimenti silenzioso per ridurre al minimo l'attività in background che oscurrebbe l'attività dell'operazione in analisi.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Se viene segnalato un problema di prestazioni in determinati momenti ma non in altri, fornire dati AWR aggiuntivi che dimostrino buone prestazioni per il confronto.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">calibra_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">Il<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> command non deve mai essere utilizzato per testare, confrontare o eseguire il benchmark dei sistemi storage. Come indicato nella documentazione di Oracle, questa procedura calibra le funzionalità i/o dello storage.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">La calibrazione non è la stessa del benchmarking. Lo scopo di questo comando è di emettere i/o per aiutare a calibrare le operazioni di database e migliorarne l'efficienza ottimizzando il livello di i/o inviato all'host. Poiché il tipo di i/o eseguito da<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> L'operazione non rappresenta l'i/o effettivo dell'utente del database, i risultati non sono prevedibili e spesso non sono nemmeno riproducibili.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, il Silly Little Oracle Benchmark, è diventato lo strumento preferito per la valutazione delle prestazioni del database. È stato sviluppato da Kevin Closson ed è disponibile su <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. Occorrono pochi minuti per installare e configurare, oltre a utilizzare un database Oracle effettivo per generare schemi di i/o su una tablespace definibile dall'utente. È una delle poche opzioni di test disponibili in grado di saturare un array all-flash con l'i/O. È utile anche per generare livelli molto inferiori di i/o per simulare carichi di lavoro di storage che sono IOPS bassi ma sensibili alla latenza.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Panca di rotazione</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench può essere utile per testare le prestazioni del database, ma è estremamente difficile utilizzare Swingbench in un modo che mette a dura prova lo storage. NetApp non ha riscontrato test da Swingbench che hanno dato i/o sufficienti per essere un carico significativo su qualsiasi array AFF. In casi limitati, è possibile utilizzare Order Entry Test (OET) per valutare lo storage dal punto di vista della latenza. Ciò può essere utile in situazioni in cui un database ha una dipendenza di latenza nota per determinate query. Assicurarsi che l'host e la rete siano configurati correttamente per realizzare i potenziali di latenza di un array all-flash.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB è uno strumento di test del database che simula, tra gli altri, i benchmark TPC-C e TPC-H. La creazione di un set di dati di dimensioni sufficienti per eseguire correttamente un test può richiedere molto tempo, ma può rivelarsi uno strumento efficace per valutare le prestazioni delle applicazioni OLTP e di data warehouse.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orion</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">Lo strumento Oracle Orion è stato comunemente utilizzato con Oracle 9, ma non è stato mantenuto per garantire la compatibilità con le modifiche in vari sistemi operativi host. Viene raramente utilizzato con Oracle 10 o Oracle 11 a causa di incompatibilità con il sistema operativo e la configurazione dello storage.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle ha riscritto lo strumento e viene installato per impostazione predefinita con Oracle 12c. Sebbene questo prodotto sia stato migliorato e utilizzi molte delle stesse chiamate utilizzate da un database Oracle reale, non utilizza esattamente lo stesso percorso di codice o lo stesso comportamento i/o utilizzato da Oracle. Ad esempio, la maggior parte degli i/o Oracle viene eseguita in modo sincrono, il che significa che il database si arresta finché l'i/o non viene completato quando l'operazione i/o viene completata in primo piano. Il semplice flooding di un sistema storage con i/o casuali non rappresenta una riproduzione di i/o Oracle reali e non offre un metodo diretto per confrontare gli array di storage o misurare l'effetto delle modifiche alla configurazione.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Detto questo, ci sono alcuni casi d'utilizzo per Orion, come la misurazione generale delle massime prestazioni possibili di una particolare configurazione host-rete-storage, o per misurare lo stato di un sistema storage. Con un test accurato, è possibile ideare test Orion utilizzabili per confrontare gli storage array o valutare l'effetto di una modifica della configurazione, a condizione che i parametri includano la considerazione di IOPS, throughput e latenza e cercare di replicare fedelmente un carico di lavoro realistico.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Allineamento di WAFL per database Oracle</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Verifica dell'allineamento di WAFL per i database Oracle</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">Il corretto allineamento dell'WAFL è fondamentale per garantire buone prestazioni. Sebbene ONTAP gestisca blocchi in 4KB unità, questo fatto non significa che ONTAP esegua tutte le operazioni in 4KB unità. Infatti, ONTAP supporta operazioni a blocchi di diverse dimensioni, ma la contabilità sottostante è gestita da WAFL in 4KB unità.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">Il termine "allineamento" si riferisce al modo in cui l'i/o Oracle corrisponde a queste unità 4KB. Per ottenere prestazioni ottimali è necessario che un blocco Oracle 8KB risieda su due blocchi fisici da 4KB WAFL su un'unità. Se un blocco è sfalsato di 2KB, questo blocco risiede su metà di un blocco 4KB, un blocco 4KB completo separato e quindi sulla metà di un terzo blocco 4KB. Questa disposizione causa un peggioramento delle prestazioni.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">L'allineamento non è un problema con i file system NAS. I file di dati Oracle sono allineati all'inizio del file in base alle dimensioni del blocco Oracle. Pertanto, le dimensioni dei blocchi di 8KB, 16KB e 32KB sono sempre allineate. Tutte le operazioni di blocco sono sfalsate dall'inizio del file in unità di 4 kilobyte.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">I LUN, al contrario, contengono generalmente qualche tipo di intestazione del driver o metadati del file system all'inizio che creano un offset. L'allineamento è raramente un problema nei sistemi operativi moderni, perché questi sistemi operativi sono progettati per unità fisiche che potrebbero utilizzare un settore 4KB nativo, che richiede anche l'allineamento dell'i/o ai confini del 4KB per ottenere prestazioni ottimali.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Ci sono, tuttavia, alcune eccezioni. È possibile che un database sia stato migrato da un sistema operativo meno recente non ottimizzato per i/o 4KB o che un errore utente durante la creazione della partizione abbia causato un offset che non è in unità di 4KB.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">I seguenti esempi sono specifici per Linux, ma la procedura può essere adattata per qualsiasi sistema operativo.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Allineato</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">L'esempio seguente mostra un controllo dell'allineamento su un singolo LUN con una singola partizione.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">Innanzitutto, creare la partizione che utilizza tutte le partizioni disponibili sul disco.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">L'allineamento può essere controllato matematicamente con il seguente comando:</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">L'output mostra che le unità sono 512 byte, e l'inizio della partizione è 32 unità. Si tratta di un totale di 32 x 512 = 16.834 byte, ovvero un multiplo intero di 4KB blocchi WAFL. Questa partizione è allineata correttamente.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Per verificare il corretto allineamento, attenersi alla seguente procedura:</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identificare l'UUID (Universal Unique Identifier) del LUN.</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Immettere la shell del nodo sul controller ONTAP.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Avviare le raccolte statistiche sull'UUID di destinazione identificato nel primo passaggio.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Eseguire alcuni i/O. È importante utilizzare<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argomento per assicurarsi che i/o sia sincrono e non bufferizzato.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Prestare molta attenzione con questo comando. Inversione del<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> e.<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> gli argomenti distruggono i dati.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Arrestare le statistiche e visualizzare l'istogramma di allineamento. Tutti i i/o devono trovarsi in<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket, che indica i/o allineato al limite di un blocco 4KB.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Disallineato</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">L'esempio seguente mostra i/o disallineati:</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Creare una partizione che non si allinea a un confine 4KB. Questo non è il comportamento predefinito sui sistemi operativi moderni.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">Il disallineamento è chiaro. L'i/o rientra principalmente in* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> benna, che corrisponde all'offset previsto. Quando la partizione è stata creata, è stata spostata di 512 byte più avanti nel dispositivo rispetto al valore predefinito ottimizzato, il che significa che l'istogramma è spostato di 512 byte.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">Inoltre, il<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> Le statistiche sono diverse da zero, il che significa che è stato eseguito l'i/o che non ha riempito l'intero blocco da 4KB KB.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Ripristina la logging</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Le procedure qui spiegate sono applicabili ai file di dati. I log di ripristino e gli archivi di Oracle hanno modelli di i/o diversi. Ad esempio, il redo logging è una sovrascrittura circolare di un singolo file. Se si utilizza la dimensione predefinita del blocco da 512 byte, le statistiche di scrittura sono simili a queste:</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">L'i/o viene distribuito in tutti i bucket di istogramma, ma non si tratta di un problema di prestazioni. Velocità di redo-logging estremamente elevate potrebbero, tuttavia, trarre vantaggio dall'utilizzo di dimensioni del blocco di 4KB KB. In questo caso, è consigliabile assicurarsi che i LUN di redo-logging siano allineati correttamente. Tuttavia, questo non è importante per le buone prestazioni come l'allineamento dei file dati.</block>
  <block id="f64f1c647516f5a47c00be152fdbf488" category="summary">Oracle e stantio NFSv3 Locks</block>
  <block id="91d9710c9fee248ae3e9c4b810ae704f" category="doc">Blocchi NFSv3 obsoleti e database Oracle</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Se un server di database Oracle si blocca, potrebbe essersi verificato un problema con blocchi NFS obsoleti al riavvio. Questo problema può essere evitato prestando particolare attenzione alla configurazione della risoluzione dei nomi sul server.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Questo problema si verifica perché la creazione di un blocco e la cancellazione di un blocco utilizzano due metodi di risoluzione dei nomi leggermente diversi. Sono coinvolti due processi: Network Lock Manager (NLM) e il client NFS. NLM utilizza<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> per determinare il nome host, mentre la<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> usi di processo<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Questi nomi host devono corrispondere affinché il sistema operativo elimini correttamente i blocchi obsoleti. Ad esempio, l'host potrebbe cercare i blocchi di proprietà di<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, ma i blocchi sono stati registrati dall'host come<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Se<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> non restituisce lo stesso valore di<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, quindi il processo di rilascio del blocco non ha avuto esito positivo.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">Il seguente script di esempio verifica se la risoluzione dei nomi è completamente coerente:</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Se<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> non corrisponde<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, è probabile che siano presenti blocchi obsoleti. Ad esempio, questo risultato rivela un potenziale problema:</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">La soluzione viene generalmente trovata modificando l'ordine in cui gli host vengono visualizzati<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Ad esempio, si supponga che il file hosts includa questa voce:</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Per risolvere il problema, modificare l'ordine di visualizzazione del nome di dominio completo e del nome host breve:</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> ora restituisce il breve<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> nome host, che corrisponde all'output di<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. I blocchi vengono quindi cancellati automaticamente dopo un arresto anomalo del server.</block>
  <block id="547b870352d8464aadbe7bee63d6f3d1" category="summary">Introduzione alla virtualizzazione del database</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Virtualizzazione</block>
  <block id="4a478889a2e46bee771126a78eda2911" category="paragraph">La virtualizzazione dei database con VMware ESX, Oracle OVM o KVM è una scelta sempre più comune per i clienti NetApp che hanno scelto la virtualizzazione anche per i database mission-critical.</block>
  <block id="0f976e587b1e7af0949904e76d91384b" category="paragraph">Esistono numerosi preconcetti sui criteri di supporto per la virtualizzazione, in particolare per i prodotti VMware. In effetti, non è raro che Oracle non supporti in alcun modo la virtualizzazione. Questa nozione non è corretta e causa la perdita di opportunità per la virtualizzazione. Oracle Doc ID 249212,1 descrive i problemi noti in un ambiente Oracle e specifica anche il supporto per RAC.</block>
  <block id="02ea3d7754e6bc1c99ff77393e49e373" category="paragraph">A un cliente con un problema sconosciuto a Oracle potrebbe essere richiesto di riprodurre il problema su hardware fisico. Un cliente Oracle che utilizza una versione all'avanguardia di un prodotto potrebbe non voler utilizzare la virtualizzazione a causa della possibilità di individuare nuovi bug. Tuttavia, questa situazione non ha rappresentato un problema nella pratica per i clienti che utilizzano versioni di prodotti generalmente disponibili.</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Presentazione storage</block>
  <block id="8fdbc6d55014a06c15b9f130e5bedd12" category="paragraph">I clienti che stanno considerando la virtualizzazione dei propri database devono basare le proprie decisioni di storage sulle esigenze aziendali. Sebbene questa affermazione sia generalmente vera per tutte le decisioni IT, è particolarmente importante per la virtualizzazione, poiché le dimensioni e l'ambito dei progetti variano notevolmente.</block>
  <block id="6cf53ad2948792abdf4a8668365b8396" category="paragraph">Sono disponibili quattro opzioni di base per la presentazione dello storage:</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">LUN iSCSI gestite dall'iniziatore iSCSI sulla macchina virtuale, non dall'hypervisor</block>
  <block id="73014dc1e7381cfd107ba79742a873e3" category="list-text">File system NFS montati dalla macchina virtuale, non su disco della macchina virtuale (VMDK)</block>
  <block id="810f0004f0e8e215c676ac0621d5836b" category="list-text">Datastore di hypervisor</block>
  <block id="8e2a0eba3eaebd64066d020ab225dd78" category="paragraph">In generale, evitare di utilizzare datastore per file Oracle. Questa raccomandazione è motivata da numerosi motivi:</block>
  <block id="98b171e836c6656f9cf88835666c6345" category="list-text">*Trasparenza.* quando una VM possiede i propri file system, è più facile per un amministratore di database o un amministratore di sistema identificare l'origine dei file system per i propri dati.</block>
  <block id="ec6a3b593d5584a2e15651852e384082" category="list-text">*Performance.* i test hanno dimostrato che esiste un effetto sulle prestazioni derivante dal canale di tutti i/o attraverso un archivio dati di hypervisor.</block>
  <block id="47464ddf615c138c6c06d3bfea555b2d" category="list-text">*Gestibilità.* quando una VM possiede i propri file system, l'utilizzo o il mancato utilizzo di un livello di hypervisor influisce sulla gestibilità. È possibile utilizzare le stesse procedure per il provisioning, il monitoraggio, la protezione dei dati e così via nell'intero ambiente, inclusi ambienti virtualizzati e non.</block>
  <block id="3d04d7019fbc0d27880dcc5c0881f87b" category="list-text">*Stabilità e risoluzione dei problemi.* quando una VM possiede i propri file system, fornire prestazioni buone e stabili e risolvere i problemi sono molto più semplici perché l'intero stack di storage è presente sulla VM. L'unico ruolo dell'hypervisor è il trasporto di frame FC o IP. Quando un datastore è incluso in una configurazione, complica la configurazione introducendo un altro insieme di timeout, parametri, file di log e potenziali bug.</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilità.* quando una VM è proprietaria dei suoi file system, il processo di spostamento di un ambiente Oracle diventa molto più semplice. I file system possono essere spostati facilmente tra guest virtualizzati e non.</block>
  <block id="cb90f9e52412940f028394174f31ec2f" category="list-text">*Vendor lock-in.* dopo il posizionamento dei dati in un datastore, utilizzando un hypervisor diverso o estraendo i dati dall'ambiente virtualizzato diventa del tutto molto difficile.</block>
  <block id="4308dde96d1bdae6ac436a611c834331" category="list-text">*Abilitazione snapshot.* in alcuni casi, i backup in un ambiente virtualizzato possono diventare un problema a causa della larghezza di banda relativamente limitata. Ad esempio, un trunk 10GbE a quattro porte potrebbe essere sufficiente per supportare le esigenze quotidiane di prestazioni di molti database virtualizzati. Tuttavia, tale trunk non sarebbe sufficiente per eseguire backup utilizzando RMAN o altri prodotti di backup che richiedono lo streaming di una copia di dimensioni complete dei dati.</block>
  <block id="872c95c8713fd14a0bef21fe92a55ab7" category="paragraph">L'utilizzo di file system proprietari di VM semplifica l'utilizzo di backup e ripristini basati su Snapshot. Un file system di proprietà delle macchine virtuali alleggerisce il carico del lavoro di esecuzione dei backup nel sistema storage. Non è necessario esagerare la configurazione dell'hypervisor solo per supportare i requisiti di larghezza di banda e CPU nella finestra di backup.</block>
  <block id="3522f960cdbaf08c375bd70214f8db2f" category="admonition">*NetApp consiglia* di evitare di posizionare i dati Oracle in un datastore per ottenere performance e gestibilità ottimali. Utilizzare file system di proprietà dei guest, come file system NFS o iSCSI, gestiti dal guest o con RDM.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Driver paravirtualizzati</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Per prestazioni ottimali, l'uso di driver di rete paravirtualizzati è fondamentale. Quando si utilizza un datastore, è necessario un driver SCSI paravirtualizzato. Un driver di dispositivo paravirtualizzato consente a un guest di integrarsi più profondamente nell'hypervisor, invece di un driver emulato in cui l'hypervisor spende più tempo CPU che imita il comportamento dell'hardware fisico.</block>
  <block id="59b3d62404749c3e899b7e4c9ee10146" category="paragraph">Le performance della maggior parte dei database sono limitate dallo storage. Pertanto, la latenza supplementare introdotta da un driver di rete o SCSI è particolarmente evidente. L'assistenza clienti NetApp ha riscontrato molti problemi di prestazioni risolti installando driver paravirtualizzati. Durante una proof of concept realizzata da un cliente, i database hanno mostrato prestazioni migliori con ESX rispetto alla stessa apparecchiatura hardware in esecuzione come bare metal. I test richiedevano molto i/o e la differenza di prestazioni veniva attribuita all'utilizzo dei driver di rete paravirtualizzati ESX.</block>
  <block id="4e27b04a271416c5701a99234f8a23e6" category="admonition">*NetApp consiglia* di utilizzare sempre driver di rete paravirtualizzati e driver SCSI.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">Overcommit RAM</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">L'overcommit della RAM implica la configurazione di una quantità di RAM virtualizzata su vari host superiore a quella presente sull'hardware fisico. In caso contrario, si potrebbero verificare problemi di prestazioni imprevisti. Quando si virtualizza un database, i blocchi sottostanti di Oracle SGA non devono essere sostituiti con lo storage dall'hypervisor. Ciò causa risultati di prestazioni altamente instabili.</block>
  <block id="31db92967e891f0a122e0329d819842e" category="admonition">*NetApp consiglia* di non configurare un hypervisor in modo da consentire lo scambio dei blocchi SGA di Oracle.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792 fornisce indicazioni per l'utilizzo di NetApp HCI 615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI per l'infrastruttura di desktop virtuale con VMware Horizon 7: Potenzia i tuoi utenti più esperti con la grafica 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792 fornisce indicazioni sull'utilizzo del nodo di calcolo NetApp H615C per carichi di lavoro di grafica 3D in un ambiente VMware Horizon con unità di elaborazione grafica NVIDIA (GPU) e software di virtualizzazione. Fornisce inoltre i risultati dei test preliminari di SPECviewperf 13 per H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Questo documento illustra la sicurezza dei prodotti per gli strumenti ONTAP per VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Utilizzo di vVol con ONTAP</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">La chiave per utilizzare vVol con ONTAP è il software del provider VASA incluso negli strumenti ONTAP per l'appliance virtuale VMware vSphere.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">Gli strumenti ONTAP includono anche le estensioni dell'interfaccia utente di vCenter, il server REST API, l'adattatore di replica dello storage per VMware Site Recovery Manager, i tool di monitoraggio e configurazione degli host e una serie di report che consentono di gestire al meglio l'ambiente VMware.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Prodotti e documentazione</block>
  <block id="4fc5e15c4dc0d227bc5f8f26e4337083" category="paragraph">La licenza FlexClone di ONTAP (inclusa con ONTAP One) e l'appliance ONTAP Tools sono gli unici prodotti aggiuntivi necessari per utilizzare vVol con NetApp ONTAP. Le release recenti dei tool ONTAP sono fornite come singola appliance unificata che viene eseguita su ESXi, fornendo le funzionalità di quelle che in precedenza erano tre appliance e server diversi. Per i vVol, è importante utilizzare le estensioni dell'interfaccia utente di vCenter o LE API REST degli strumenti ONTAP come strumenti di gestione generali e interfacce utente per le funzioni ONTAP con vSphere, insieme al provider VASA che fornisce funzionalità vVol specifiche. Il componente SRA è incluso per gli archivi dati tradizionali, ma VMware Site Recovery Manager non utilizza SRA per vVol, implementando invece nuovi servizi in SRM 8.3 e versioni successive che sfruttano il provider VASA per la replica di vVol.</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">ONTAP Tools architettura del provider VASA quando si utilizza iSCSI o FCP</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">ONTAP Tools architettura del provider VASA,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Installazione del prodotto</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">Per le nuove installazioni, implementa l'appliance virtuale nel tuo ambiente vSphere. Le versioni correnti dei tool ONTAP si registreranno automaticamente con vCenter e abiliteranno il provider VASA per impostazione predefinita. Oltre alle informazioni su host ESXi e vCenter Server, sono necessari anche i dettagli di configurazione dell'indirizzo IP per l'appliance. Come indicato in precedenza, il provider VASA richiede che la licenza FlexClone di ONTAP sia già installata su qualsiasi cluster ONTAP che si intende utilizzare per vVol. L'appliance dispone di un watchdog integrato per garantire la disponibilità e, come Best practice, deve essere configurata con le funzionalità VMware High Availability e, facoltativamente, Fault Tolerance. Per ulteriori dettagli, vedere la sezione 4.1. Non installare o spostare l'appliance ONTAP Tools o l'appliance vCenter Server (VCSA) sullo storage vVol, in quanto ciò potrebbe impedire il riavvio delle appliance.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">Gli aggiornamenti in-place dei tool ONTAP sono supportati utilizzando il file ISO di aggiornamento disponibile per il download sul sito del supporto NetApp (NSS). Per aggiornare l'appliance, seguire le istruzioni della Guida all'installazione e alla distribuzione.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">Guida al dimensionamento degli strumenti ONTAP per VMware vSphere</block>
  <block id="e4e51979718d88ce483f9477be981a76" category="paragraph">Per il dimensionamento dell'appliance virtuale e la comprensione dei limiti di configurazione, consultare questo articolo della Knowledge base:<block ref="a75738ed95b0811ed0edd1b8ef0d9568" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentazione del prodotto</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La seguente documentazione è disponibile per facilitare l'implementazione degli strumenti ONTAP.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">Per il repository&amp;amp completo della documentazione;#44; visitare questo link a docs.netapp.com</block>
  <block id="7f21741a70426baea3ee41488da86af4" category="paragraph"><block ref="56b49132b20e341764c8aa067751e8a5" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Inizia subito</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Note di rilascio</block>
  <block id="2645deadffb8af180b8a35da3d034ad8" category="list-text"><block ref="2645deadffb8af180b8a35da3d034ad8" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">Scopri i tool ONTAP per VMware vSphere</block>
  <block id="a0aaeda90fe2ef02fba791bc7c35645c" category="list-text"><block ref="a0aaeda90fe2ef02fba791bc7c35645c" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">ONTAP Tools Avvio rapido</block>
  <block id="324b0410f22fb210bbf88e1ee7e97428" category="list-text"><block ref="324b0410f22fb210bbf88e1ee7e97428" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Implementare gli strumenti ONTAP</block>
  <block id="354336d78d1f0a156dcd5221d341dfd0" category="list-text"><block ref="354336d78d1f0a156dcd5221d341dfd0" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Aggiornare i tool ONTAP</block>
  <block id="33a77e1014f1325d6ba19639a6c95d48" category="list-text"><block ref="33a77e1014f1325d6ba19639a6c95d48" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilizzare gli strumenti ONTAP</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">Provisioning di datastore tradizionali</block>
  <block id="f27fe8f858d8a91950e214753b95722c" category="list-text"><block ref="f27fe8f858d8a91950e214753b95722c" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">Provisioning degli archivi dati vVol</block>
  <block id="0c2552c3930f472b2d120f30d7aa0415" category="list-text"><block ref="0c2552c3930f472b2d120f30d7aa0415" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configurare il controllo degli accessi in base al ruolo</block>
  <block id="644ae78061acbb2254be4de3ea454b06" category="list-text"><block ref="644ae78061acbb2254be4de3ea454b06" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">Configurare la diagnostica remota</block>
  <block id="fc0330812838aba14025bd70d41b943d" category="list-text"><block ref="fc0330812838aba14025bd70d41b943d" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configurare la disponibilità elevata</block>
  <block id="5027a18a60c68e05df84cd699af74497" category="list-text"><block ref="5027a18a60c68e05df84cd699af74497" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Proteggere e gestire i datastore</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">Proteggere i datastore tradizionali</block>
  <block id="c8ac931d575d89c007212a35c8dde74c" category="list-text"><block ref="8f91d2113ff32de18906bad1cd446b0d" category="inline-link-rx"></block> Con SRM</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">Proteggere le macchine virtuali basate su vVol</block>
  <block id="710b15d782f0c2c0411066b86644a12d" category="list-text"><block ref="7741c74d7508dc983fa4af0dff0bdda1" category="inline-link-rx"></block> Con SRM</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">Monitoraggio di datastore e macchine virtuali tradizionali</block>
  <block id="bac3b262bb348a54f9986c2b5dbf6024" category="list-text"><block ref="bac3b262bb348a54f9986c2b5dbf6024" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">Monitorare datastore e macchine virtuali di vVol</block>
  <block id="75c07b623699e1947d011983a7823584" category="list-text"><block ref="75c07b623699e1947d011983a7823584" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">Oltre alla documentazione del prodotto, sono disponibili articoli della Knowledge base di supporto che potrebbero essere utili.</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Dashboard del provider VASA</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">Il provider VASA include una dashboard con informazioni su performance e capacità per le singole VM vVol. Queste informazioni provengono direttamente da ONTAP per i file vVol e le LUN, tra cui latenza, IOPS, throughput e uptime per le prime 5 macchine virtuali, latenza e IOPS per i primi 5 datastore. Questa opzione è attivata per impostazione predefinita quando si utilizza ONTAP 9.7 o versione successiva. Il recupero e la visualizzazione dei dati iniziali nella dashboard possono richiedere fino a 30 minuti.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">Dashboard di ONTAP Tools vVol</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">Dashboard di ONTAP Tools vVol,400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Best Practice</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Limiti*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Valori massimi di configurazione</block>
  <block id="bc8259e306c73b2969e7ac6297000e64" category="paragraph">In generale, ONTAP supporta i limiti vVol definiti da VMware (vedere pubblicato<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). La seguente tabella riassume i limiti ONTAP specifici in termini di dimensione e numero di vVol. Controllare sempre<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Per i limiti aggiornati su numeri e dimensioni di LUN e file.</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">*Limiti di ONTAP vVol*</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacità/funzionalità</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN (SCSI o NVMe-of)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">Dimensione massima vVol</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62 TIB*</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">Numero massimo di vVol per volume FlexVol</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">2 miliardi</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">Numero massimo di vVol per nodo ONTAP</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">Fino a 12,288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">50 miliardi di dollari</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">Numero massimo di vVol per coppia ONTAP</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">Fino a 24.576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">Numero massimo di vVol per cluster ONTAP</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">Fino a 98.304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">Nessun limite specifico del cluster</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">Numero massimo di oggetti QoS (gruppo di policy condiviso e livello di servizio vVol singolo)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">Da 12,000 a ONTAP 9.3; 40,000 con ONTAP 9.4 e versioni successive</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">Limite di dimensione basato sui sistemi ASA o AFF e FAS con ONTAP 9.12.1P2 e versioni successive.</block>
  <block id="d27c43bb3cdcbfa3852bb91192ffb849" category="list-text">Il numero di vVol SAN (NVMe namespace o LUN) varia in base alla piattaforma. Controllare sempre<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Per i limiti aggiornati su numeri e dimensioni di LUN e file.</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">L'utilizzo di ONTAP vVol con vSphere è semplice e segue i metodi vSphere pubblicati (per la versione di ESXi in uso, vedere utilizzo dei volumi virtuali in vSphere Storage nella documentazione VMware). Di seguito sono riportate alcune procedure aggiuntive da prendere in considerazione in combinazione con ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilizzare i tool ONTAP per le estensioni dell'interfaccia utente di VMware vSphere o le API REST per eseguire il provisioning degli archivi dati vVol* *e degli endpoint del protocollo.*</block>
  <block id="9507d4f97aceb8d05fc962dd53f082af" category="cell">Anche se è possibile creare datastore vVol con l'interfaccia generale vSphere, utilizzando i tool ONTAP sarà possibile creare automaticamente gli endpoint del protocollo in base alle necessità, e creare volumi FlexVol utilizzando le Best practice ONTAP e in conformità con i profili di funzionalità dello storage definiti. È sufficiente fare clic con il pulsante destro del mouse sull'host/cluster/data center, quindi selezionare _ONTAP tools_ e _provisioning datastore_. Da qui, è sufficiente scegliere le opzioni vVol desiderate nella procedura guidata.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Non memorizzare mai l'appliance ONTAP Tools o l'appliance vCenter Server (VCSA) su un datastore vVol gestito.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Questo può causare una "situazione a base di uova e pollo" se occorre riavviare le appliance perché non saranno in grado di ricollegare i propri vVol durante il riavvio. È possibile memorizzarli in un datastore vVol gestito da un diverso tool ONTAP e da una distribuzione vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Evitare le operazioni vVol in diverse release di ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Le funzionalità di storage supportate, come QoS, personalità e molto altro, sono cambiate in varie versioni del provider VASA e alcune dipendono dalla release di ONTAP. L'utilizzo di release diverse in un cluster ONTAP o lo spostamento di vVol tra cluster con release diverse può causare comportamenti imprevisti o allarmi di compliance.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">*Prima di utilizzare NVMe/FC o FCP per i vVol, è necessario eseguire un'area del fabric Fibre Channel.*</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Zoning initiator singolo con quattro nodi,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 Best practice per la MODERNA SAN ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 implementazione e configurazione delle moderne SAN con NVMe-of_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Pianificare FlexVol di supporto in base alle proprie esigenze.*</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">È consigliabile aggiungere diversi volumi di backup al datastore vVol per distribuire il carico di lavoro nel cluster ONTAP, supportare diverse opzioni di policy o aumentare il numero di LUN o file consentiti. Tuttavia, se è richiesta la massima efficienza dello storage, posizionare tutti i volumi di backup su un singolo aggregato. In alternativa, se sono richieste le massime prestazioni di cloning, prendere in considerazione l'utilizzo di un singolo volume FlexVol e la conservazione dei modelli o della libreria di contenuti nello stesso volume. Il provider VASA trasferisce molte operazioni di storage vVol a ONTAP, tra cui migrazione, cloning e snapshot. Quando questa operazione viene eseguita all'interno di un singolo volume FlexVol, vengono utilizzati cloni di file efficienti in termini di spazio e sono quasi immediatamente disponibili. Quando questo viene eseguito su volumi FlexVol, le copie sono rapidamente disponibili e utilizzano la deduplica e la compressione inline, ma la massima efficienza dello storage potrebbe non essere ripristinata fino a quando i processi in background non vengono eseguiti su volumi che utilizzano la deduplica e la compressione in background. A seconda dell'origine e della destinazione, un certo livello di efficienza potrebbe risultare degradato.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">*Mantieni semplici gli SCP (Storage Capability Profiles).*</block>
  <block id="33e2905cb722c14575a9bff81ba78b39" category="cell">Evitare di specificare le funzionalità non necessarie impostandole su nessuna. In questo modo si riducono al minimo i problemi durante la selezione o la creazione di volumi FlexVol. Ad esempio, con il provider VASA 7.1 e versioni precedenti, se la compressione viene lasciata all'impostazione SCP predefinita No, tenterà di disattivare la compressione, anche su un sistema AFF.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">*Utilizzare gli SCP predefiniti come modelli di esempio per creare i propri.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Seguire tutte le Best practice del protocollo.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configurazione di rete con vVol su NFS v3.500</block>
  <block id="6cacb3f1edd09835a2ad07d72f488e2a" category="paragraph">Il software NetApp ONTAP è una soluzione storage leader per gli ambienti VMware vSphere da oltre vent'anni e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi.</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Questo documento tratta le funzionalità di ONTAP per i volumi virtuali VMware vSphere (vVol), incluse le informazioni più recenti sui prodotti e i casi di utilizzo, oltre a Best practice e altre informazioni per semplificare l'implementazione e ridurre gli errori.</block>
  <block id="c7448b194ba68bddce48f1d11d5d7db7" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4400: Volumi virtuali VMware vSphere (vVol) con NetApp ONTAP_</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche che funzionano o sono supportate, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">Questo documento è stato aggiornato per includere le nuove funzionalità vVol di vSphere 8.0 update 1, supportate con la release 9.12 di ONTAP Tools.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Panoramica dei volumi virtuali (vVol)</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">Nel 2012, NetApp ha iniziato a collaborare con VMware per supportare le API vSphere per la consapevolezza dello storage (VASA) per vSphere 5. Questo primo provider VASA consentiva la definizione delle funzionalità di storage in un profilo che poteva essere utilizzato per filtrare i datastore durante il provisioning e per verificare successivamente la conformità con la policy. Nel corso del tempo, questo si è evoluto per aggiungere nuove funzionalità per consentire una maggiore automazione nel provisioning, oltre all'aggiunta di volumi virtuali o vVol, in cui i singoli oggetti storage vengono utilizzati per i file delle macchine virtuali e i dischi virtuali. Questi oggetti potrebbero essere LUN, file, e ora con vSphere 8 - NVMe namespaces.NetApp ha lavorato a stretto contatto con VMware come partner di riferimento per vVol rilasciato con vSphere 6 nel 2015, e ancora come partner di progettazione per vVol utilizzando NVMe su fabric in vSphere 8. NetApp continua a migliorare vVol per sfruttare le più recenti funzionalità di ONTAP.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Esistono diversi componenti di cui tenere conto:</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">*Provider VASA*</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Questo è il componente software che gestisce la comunicazione tra VMware vSphere e il sistema storage. Per ONTAP, il provider VASA viene eseguito in un'appliance nota come tool ONTAP per VMware vSphere (in breve, strumenti ONTAP). Gli strumenti ONTAP includono anche un plugin vCenter, un adattatore per la replica dello storage (SRA) per VMware Site Recovery Manager e un server API REST per la creazione di automazione. Una volta configurati e registrati gli strumenti ONTAP con vCenter, non è più necessario interagire direttamente con il sistema ONTAP, poiché quasi tutte le esigenze di storage possono essere gestite direttamente dall'interfaccia utente di vCenter o tramite l'automazione delle API REST.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">*Protocol Endpoint (PE)*</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">L'endpoint del protocollo è un proxy per i/o tra gli host ESXi e il datastore vVols. Il provider ONTAP VASA crea automaticamente questi elementi, scegliendo una LUN endpoint di protocollo (4MB GB) per volume FlexVol del datastore vVol o un punto di montaggio NFS per interfaccia NFS (LIF) sul nodo storage che ospita un volume FlexVol nel datastore. L'host ESXi monta questi endpoint di protocollo direttamente piuttosto che singoli LUN vVol e file di dischi virtuali. Non è necessario gestire gli endpoint del protocollo poiché vengono creati, montati, rimossi ed eliminati automaticamente dal provider VASA, insieme a eventuali gruppi di interfacce o policy di esportazione necessari.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">*Virtual Protocol Endpoint (VPE)*</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Novità di vSphere 8: Quando si utilizza NVMe over Fabrics (NVMe-of) con vVol, il concetto di endpoint del protocollo non è più rilevante in ONTAP. Al contrario, l'host ESXi crea automaticamente un'istanza di PE virtuale per ciascun gruppo ANA non appena viene accesa la prima macchina virtuale. ONTAP crea automaticamente gruppi ANA per ogni volume FlexVol utilizzato dall'archivio dati.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Un ulteriore vantaggio dell'utilizzo di NVMe-of per vVol è che non sono richieste di bind da parte del provider VASA. L'host ESXi gestisce invece la funzionalità di binding vVol internamente in base a VPE. In questo modo si riduce l'opportunità di un vVol bind storm di impatto sul servizio.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe e volumi virtuali</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Per ulteriori informazioni, vedere<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> acceso<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="61def0b14af00df4eb90bcd79d858a8b" category="cell">*Archivio dati volume virtuale*</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">Il datastore del volume virtuale è una rappresentazione logica del datastore di un container vVol creato e gestito da un provider VASA. Il container rappresenta un pool di capacità di storage fornito dai sistemi storage gestiti dal provider VASA. Gli strumenti ONTAP supportano l'allocazione di più volumi FlexVol (noti come volumi di backup) a un singolo datastore vVols e questi datastore vVols possono estendersi su più nodi in un cluster ONTAP, combinando sistemi flash e ibridi con funzionalità diverse. L'amministratore può creare nuovi volumi FlexVol utilizzando la procedura guidata di provisioning o l'API REST oppure selezionare volumi FlexVol pre-creati per il backup dello storage, se disponibili.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">*Volumi virtuali (vVol)*</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">I vVol sono i file e i dischi della macchina virtuale memorizzati nel datastore vVols. Il termine vVol (singolo) si riferisce a un singolo file, LUN o namespace specifico. ONTAP crea spazi dei nomi NVMe, LUN o file a seconda del protocollo utilizzato dal datastore. Esistono diversi tipi distinti di vVol; i più comuni sono Config (file di metadati), Data (disco virtuale o VMDK) e Swap (creato all'accensione della macchina virtuale). I vVol protetti dalla crittografia delle macchine virtuali VMware sono di tipo Altro. La crittografia di VMware VM non deve essere confusa con la crittografia aggregata o del volume ONTAP.</block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Gestione basata su criteri</block>
  <block id="34d2b7d8b570ede7a638d070656b7b81" category="paragraph">Le API VMware vSphere per la consapevolezza dello storage (VASA) semplificano l'utilizzo da parte di un amministratore delle macchine virtuali delle funzionalità di storage necessarie per il provisioning delle macchine virtuali senza dover interagire con il proprio team di storage. Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con gli amministratori dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, gli amministratori di vCenter con le autorizzazioni appropriate possono definire una serie di funzionalità di storage che gli utenti di vCenter possono utilizzare per eseguire il provisioning delle macchine virtuali. La mappatura tra policy di storage delle macchine virtuali e profilo di funzionalità di storage del datastore consente a vCenter di visualizzare un elenco di datastore compatibili per la selezione, nonché di abilitare altre tecnologie come aria (precedentemente nota come vRealize) Automation o Tanzu Kubernetes Grid per selezionare automaticamente lo storage da una policy assegnata. Questo approccio è noto come gestione basata su criteri di storage. Anche se i profili e le policy delle funzionalità di storage possono essere utilizzati anche con i datastore tradizionali, la nostra attenzione qui è dedicata agli archivi dati vVols.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">Esistono due elementi:</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">*Storage Capability Profile (SCP)*</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">Un SCP (Storage Capability Profile) è un modello di storage che consente all'amministratore di vCenter di definire le funzionalità di storage necessarie senza dover comprendere come gestire tali funzionalità in ONTAP. Adottando un approccio basato su modelli, l'amministratore può fornire facilmente servizi di storage in modo coerente e prevedibile. Le funzionalità descritte in un SCP includono performance, protocollo, efficienza dello storage e altre funzionalità. Le funzionalità specifiche variano in base alla versione. Vengono creati utilizzando il menu ONTAP Tools per VMware vSphere all'interno dell'interfaccia utente di vCenter. È inoltre possibile utilizzare le API REST per creare SCP. Possono essere creati manualmente selezionando singole funzionalità o generati automaticamente da datastore esistenti (tradizionali).</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">*Criterio di storage delle macchine virtuali*</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">I criteri di storage delle macchine virtuali vengono creati in vCenter in Criteri e profili. Per i vVol, creare un set di regole utilizzando le regole del provider del tipo di storage NetApp vVols. Gli strumenti di ONTAP offrono un approccio semplificato, consentendo di selezionare semplicemente un SCP piuttosto che obbligare a specificare singole regole.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">Come indicato in precedenza, l'utilizzo delle policy consente di ottimizzare l'attività di provisioning di un volume. È sufficiente selezionare una policy appropriata e il provider VASA mostrerà gli archivi dati vVol che supportano tale policy e inserirà vVol in un singolo volume FlexVol conforme (Figura 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Implementare la macchina virtuale utilizzando i criteri di storage</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">Una volta eseguito il provisioning di una macchina virtuale, il provider VASA continua a controllare la conformità e avvisa l'amministratore della macchina virtuale con un allarme in vCenter quando il volume di backup non è più conforme al criterio (Figura 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Conformità delle policy di storage delle macchine virtuali</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Conformità alle policy di storage delle macchine virtuali</block>
  <block id="e08bc5b354c3e8058003a662e0f7cade" category="section-title">Supporto vVol NetApp</block>
  <block id="234ad0324c313ec05d0fa6fe8d430967" category="paragraph">NetApp ONTAP ha supportato la specifica VASA dalla sua release iniziale nel 2012. Sebbene altri sistemi storage NetApp possano supportare VASA, questo documento si concentra sulle versioni attualmente supportate di ONTAP 9.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="4d53a8e49ac64213ffccdd970a35171e" category="paragraph">Oltre a ONTAP 9 su sistemi AFF, ASA e FAS, NetApp supporta i workload VMware su ONTAP Select, Amazon FSX per NetApp ONTAP con VMware Cloud su AWS, Azure NetApp Files con Azure VMware, Cloud Volumes Service con Google Cloud VMware Engine e NetApp Private Storage in Equinix, tuttavia, le funzionalità specifiche possono variare in base al provider di servizi e alla connettività di rete disponibile. È inoltre disponibile l'accesso dai guest vSphere ai dati memorizzati in tali configurazioni e a Cloud Volumes ONTAP.</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Al momento della pubblicazione, gli ambienti hyperscaler sono limitati solo agli archivi dati NFS v3 tradizionali, pertanto i vVol sono disponibili solo con sistemi ONTAP on-premise o con sistemi connessi al cloud che offrono la funzionalità completa di sistemi on-premise come quelli ospitati da partner e provider di servizi NetApp in tutto il mondo.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentazione del prodotto ONTAP</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Per ulteriori informazioni su ONTAP, vedere<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="9a03bb7ec5329e35d98c7b12b63c4df0" category="paragraph">_Per ulteriori informazioni sulle Best practice di ONTAP e VMware vSphere, vedere<block ref="fc9815e7b1405959c49ad47e9a23e3a5" category="inline-link-rx"></block>_</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Vantaggi dell'utilizzo di vVol con ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Quando VMware ha introdotto il supporto vVol con VASA 2.0 nel 2015, lo ha descritto come "un framework di integrazione e gestione che offre un nuovo modello operativo per lo storage esterno (SAN/NAS)". Questo modello operativo offre diversi vantaggi insieme allo storage ONTAP.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Come descritto nella sezione 1,2, la gestione basata su criteri consente di eseguire il provisioning delle macchine virtuali e di gestirle successivamente utilizzando criteri predefiniti. Questo può aiutare le operazioni IT in diversi modi:</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Aumentare la velocità.* i tool ONTAP eliminano il requisito per l'amministratore di vCenter di aprire i ticket con il team di storage per le attività di provisioning dello storage. Tuttavia, i ruoli RBAC dei tool ONTAP in vCenter e nel sistema ONTAP consentono ancora ai team indipendenti (come i team di storage) o alle attività indipendenti dello stesso team limitando l'accesso a funzioni specifiche, se necessario.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Provisioning più intelligente.* le funzionalità del sistema di storage possono essere esposte attraverso le API VASA, consentendo ai flussi di lavoro di provisioning di sfruttare funzionalità avanzate senza che l'amministratore delle macchine virtuali debba comprendere come gestire il sistema di storage.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Provisioning più rapido.* diverse funzionalità di storage possono essere supportate in un singolo datastore e selezionate automaticamente in base alla policy della macchina virtuale.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Evitare errori.* le policy di storage e macchine virtuali vengono sviluppate in anticipo e applicate in base alle necessità senza dover personalizzare lo storage ogni volta che viene eseguito il provisioning di una macchina virtuale. Gli allarmi di compliance vengono generati quando le funzionalità dello storage si scostano dalle policy definite. Come accennato in precedenza, gli SCP rendono il provisioning iniziale prevedibile e ripetibile, mentre basare le policy di storage delle macchine virtuali sugli SCP garantisce un posizionamento preciso.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">*Migliore gestione della capacità.* i tool VASA e ONTAP consentono di visualizzare la capacità dello storage fino al livello di aggregato induviale, se necessario, e di fornire più livelli di avviso nel caso in cui la capacità inizi a diminuire.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Gestione granulare delle macchine virtuali nella moderna SAN</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">I sistemi storage SAN che utilizzano Fibre Channel e iSCSI sono stati i primi ad essere supportati da VMware per ESX, ma non hanno la capacità di gestire singoli file e dischi VM dal sistema storage. Al contrario, vengono forniti i LUN e VMFS gestisce i singoli file. Questo rende difficile per il sistema storage gestire direttamente le performance, la clonazione e la protezione dello storage delle singole macchine virtuali. VVol offre una granularità dello storage di cui già godono i clienti che utilizzano lo storage NFS, con le solide funzionalità SAN ad alte performance di ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Ora, con gli strumenti vSphere 8 e ONTAP per VMware vSphere 9.12 e versioni successive, gli stessi controlli granulari utilizzati da vVol per i protocolli basati su SCSI legacy sono ora disponibili nella MODERNA SAN Fibre Channel che utilizza NVMe over Fabrics per ottenere performance ancora maggiori su larga scala. Con vSphere 8.0 update 1, è ora possibile implementare una soluzione NVMe end-to-end completa utilizzando vVol senza alcuna traduzione i/o nello stack di storage dell'hypervisor.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Maggiori funzionalità di offload dello storage</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garanzia di efficienza</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">Mentre VAAI offre una varietà di operazioni che vengono trasferite allo storage, ci sono alcune lacune che vengono affrontate dal provider VASA. SAN VAAI non è in grado di trasferire le snapshot gestite da VMware al sistema storage. NFS VAAI è in grado di trasferire le snapshot gestite da macchine virtuali, ma esistono dei limiti per una macchina virtuale con snapshot native dello storage. Poiché i vVol utilizzano LUN, spazi dei nomi o file singoli per i dischi delle macchine virtuali, ONTAP può clonare in modo rapido ed efficiente i file o le LUN per creare snapshot granulari delle macchine virtuali che non richiedono più file delta. Inoltre, NFS VAAI non supporta operazioni di offload dei cloni per le migrazioni vMotion di storage a caldo (attivate). La macchina virtuale deve essere spenta per consentire l'offload della migrazione quando si utilizza VAAI con datastore NFS tradizionali. Il provider VASA negli strumenti ONTAP consente cloni quasi istantanei ed efficienti in termini di storage per le migrazioni a caldo e a freddo e supporta anche copie quasi istantanee per le migrazioni tra volumi di vVol. Grazie a questi significativi vantaggi in termini di efficienza dello storage, è possibile sfruttare al meglio i carichi di lavoro vVol in base a.<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programma. Allo stesso modo, se i cloni cross-volume con VAAI non soddisfano i tuoi requisiti, sarai in grado di risolvere le sfide per il tuo business grazie ai miglioramenti nell'esperienza di copia con i vVol.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Casi di utilizzo comuni per i vVol</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Oltre a questi vantaggi, vediamo anche questi casi di utilizzo comuni per lo storage vVol:</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Provisioning su richiesta delle VM*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privato o provider di servizi IaaS.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Sfrutta l'automazione e l'orchestrazione tramite la suite aria (in precedenza vRealize), OpenStack, ecc.</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Dischi di prima classe (FCD)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">VMware Tanzu Kubernetes Grid [TKG] volumi persistenti.</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Fornire servizi di Amazon EBS attraverso una gestione indipendente del ciclo di vita VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Provisioning on-demand delle macchine virtuali temporanee*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratori di test/sviluppo</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Ambienti di training</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Vantaggi comuni con vVol</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Se utilizzato a pieno vantaggio, come nei casi di utilizzo precedenti, i vVol forniscono i seguenti miglioramenti specifici:</block>
  <block id="13491b3af50183642ea0035b2d1f95f9" category="list-text">I cloni vengono creati rapidamente all'interno di un singolo volume o su più volumi in un cluster ONTAP, un vantaggio rispetto ai cloni abilitati VAAI tradizionali. Sono inoltre efficienti in termini di storage. I cloni all'interno di un volume utilizzano il clone del file ONTAP, simile ai volumi FlexClone, e memorizzano solo le modifiche dal file/LUN/namespace vVol di origine. In questo modo, le macchine virtuali a lungo termine per la produzione o altri scopi applicativi vengono create rapidamente, occupano poco spazio e possono beneficiare della protezione a livello di macchine virtuali (utilizzando il plug-in NetApp SnapCenter per VMware vSphere, le snapshot gestite da VMware o il backup VADP) e della gestione delle performance (con QoS ONTAP).</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">I vVol sono la tecnologia di storage ideale quando si utilizza TKG con vSphere CSI, fornendo classi di storage e capacità discrete gestite dall'amministratore di vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Amazon EBS-like Services può essere fornito attraverso FCD perché un FCD VMDK, come suggerisce il nome, è un cittadino di prima classe in vSphere e ha un ciclo di vita che può essere gestito in modo indipendente separato dalle macchine virtuali a cui potrebbe essere collegato.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protezione di vVol</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">ALTA disponibilità del provider VASA</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">NetApp VASA Provider viene eseguito come parte dell'appliance virtuale insieme al plug-in vCenter, al server REST API (precedentemente noto come Virtual Storage Console [VSC]) e allo Storage Replication Adapter. Se il provider VASA non è disponibile, le VM che utilizzano vVol continueranno a funzionare. Tuttavia, non è possibile creare nuovi datastore vVol e non è possibile creare o vinare vVol da vSphere. Ciò significa che le macchine virtuali che utilizzano vVol non possono essere attivate poiché vCenter non sarà in grado di richiedere la creazione dello swap vVol. Inoltre, le macchine virtuali in esecuzione non possono utilizzare vMotion per la migrazione a un altro host perché i vVol non possono essere associati al nuovo host.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7.1 e versioni successive supportano nuove funzionalità per garantire la disponibilità dei servizi quando necessario. Include nuovi processi di controllo che monitorano il provider VASA e i servizi di database integrati. Se rileva un errore, aggiorna i file di registro e riavvia automaticamente i servizi.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">L'amministratore di vSphere deve configurare un'ulteriore protezione utilizzando le stesse funzionalità di disponibilità utilizzate per proteggere le altre macchine virtuali mission-critical da guasti del software, dell'hardware host e della rete. Non è richiesta alcuna configurazione aggiuntiva sull'appliance virtuale per utilizzare queste funzionalità; è sufficiente configurarle utilizzando gli approcci standard vSphere. Sono stati testati e supportati da NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Strumenti ONTAP per la documentazione di VMware vSphere (configurare l'alta disponibilità per i tool ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability è facilmente configurabile per riavviare una macchina virtuale su un altro host nel cluster host in caso di guasto. VSphere Fault Tolerance offre una maggiore disponibilità creando una macchina virtuale secondaria che viene continuamente replicata e che può assumere il controllo in qualsiasi momento. Ulteriori informazioni su queste funzioni sono disponibili nella<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Oltre alla documentazione VMware vSphere (cercare vSphere Availability sotto ESXi e vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Il provider VASA di ONTAP Tools esegue automaticamente il backup della configurazione vVol in tempo reale sui sistemi ONTAP gestiti in cui le informazioni vVol vengono memorizzate nei metadati dei volumi FlexVol. Nel caso in cui l'appliance ONTAP Tools non fosse disponibile per qualsiasi motivo, è possibile implementarne una nuova e importarne la configurazione in modo semplice e rapido. Fare riferimento a questo articolo della Knowledge base per ulteriori informazioni sulle fasi di ripristino del provider VASA:</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Come eseguire un Disaster Recovery provider VASA - Guida alla risoluzione</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Replica di vVol</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">Molti clienti ONTAP replicano i propri datastore tradizionali su sistemi storage secondari utilizzando NetApp SnapMirror, quindi utilizzano il sistema secondario per ripristinare singole macchine virtuali o un intero sito in caso di disastro. Nella maggior parte dei casi, i clienti utilizzano uno strumento software per la gestione di questo tipo, ad esempio un prodotto software di backup come il plug-in NetApp SnapCenter per VMware vSphere o una soluzione di disaster recovery come Site Recovery Manager di VMware (insieme all'adattatore di replica dello storage negli strumenti ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Questo requisito per uno strumento software è ancora più importante per gestire la replica di vVol. Sebbene alcuni aspetti possano essere gestiti da funzionalità native (ad esempio, le snapshot gestite da VMware di vVol vengono trasferite su ONTAP, che utilizza cloni di file o LUN rapidi ed efficienti), in generale l'orchestrazione è necessaria per gestire la replica e il ripristino. I metadati relativi ai vVol sono protetti da ONTAP e dal provider VASA, ma è necessaria un'ulteriore elaborazione per utilizzarli in un sito secondario.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">I tool ONTAP 9.7.1, insieme alla release 8.3 di VMware Site Recovery Manager (SRM), hanno aggiunto il supporto per il disaster recovery e l'orchestrazione del flusso di lavoro di migrazione sfruttando la tecnologia SnapMirror di NetApp.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">Nella versione iniziale del supporto SRM con i tool ONTAP 9.7.1 era necessario pre-creare FlexVol e abilitare la protezione SnapMirror prima di utilizzarli come volumi di backup per un datastore vVol. A partire dagli strumenti ONTAP 9.10, questo processo non è più necessario. È ora possibile aggiungere la protezione SnapMirror ai volumi di backup esistenti e aggiornare le policy di storage delle macchine virtuali per sfruttare la gestione basata su policy con disaster recovery, orchestrazione e automazione della migrazione integrate con SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Attualmente, VMware SRM è l'unica soluzione di disaster recovery e automazione della migrazione per vVol supportata da NetApp e i tool ONTAP verificheranno l'esistenza di un server SRM 8.3 o successivo registrato con vCenter prima di consentire la replica di vVol, Sebbene sia possibile sfruttare le API REST degli strumenti ONTAP per creare i propri servizi.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Replica di vVol con SRM</block>
  <block id="4d30574e6d5bc9a71718858eeb30774c" category="inline-image-macro">Replica di vVol con SRM,300</block>
  <block id="5844b0ec1ad8db5185ec67effeb9a7b7" category="paragraph"><block ref="5844b0ec1ad8db5185ec67effeb9a7b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Supporto MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Sebbene gli strumenti ONTAP non siano in grado di attivare uno switchover MetroCluster, supportano i sistemi NetApp MetroCluster per il backup dei volumi in una configurazione vMSC (vSphere Metro Storage Cluster) uniforme. La commutazione di un sistema MetroCluster viene gestita normalmente.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Anche se NetApp SnapMirror Business Continuity (SM-BC) può essere utilizzato come base per una configurazione vMSC, al momento non è supportato con vVol.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Consulta queste guide per ulteriori informazioni su NetApp MetroCluster:</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_Architettura e progettazione della soluzione IP TR-4689 MetroCluster_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 architettura e progettazione della soluzione NetApp MetroCluster_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 supporto VMware vSphere con NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Panoramica del backup di vVol</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Esistono diversi approcci per la protezione delle macchine virtuali, ad esempio l'utilizzo di agenti di backup in-guest, l'aggiunta di file di dati delle macchine virtuali a un proxy di backup o l'utilizzo di API definite come VMware VADP. I vVol possono essere protetti utilizzando gli stessi meccanismi e molti partner NetApp supportano i backup delle macchine virtuali, inclusi i vVol.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Come accennato in precedenza, le snapshot gestite da VMware vCenter vengono trasferite a cloni di file/LUN ONTAP efficienti in termini di spazio e veloci. Questi possono essere utilizzati per backup manuali e rapidi, ma sono limitati da vCenter a un massimo di 32 snapshot. È possibile utilizzare vCenter per creare snapshot e ripristinarli in base alle necessità.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">A partire dal plug-in SnapCenter per VMware vSphere (SCV) 4.6, se utilizzato insieme ai tool ONTAP 9.10 e versioni successive, aggiunge il supporto per backup e ripristino coerenti in caso di crash delle macchine virtuali basate su vVol, sfruttando le snapshot dei volumi ONTAP FlexVol con il supporto per SnapMirror e la replica SnapVault. Sono supportati fino a 1023 snapshot per volume. SCV può anche memorizzare più snapshot con una maggiore conservazione sui volumi secondari utilizzando SnapMirror con una policy di vault mirror.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">Il supporto di vSphere 8.0 è stato introdotto con SCV 4.7, che utilizzava un'architettura di plug-in locale isolata. Il supporto di vSphere 8.0U1 è stato aggiunto a SCV 4.8, che ha completato la transizione alla nuova architettura di plug-in remoto.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">Backup vVol con plug-in SnapCenter per VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Con NetApp SnapCenter puoi ora creare gruppi di risorse per i vVol basati su tag e/o cartelle per sfruttare automaticamente le snapshot basate su FlexVol di ONTAP per macchine virtuali basate su vVol. Ciò consente di definire servizi di backup e ripristino che proteggeranno automaticamente le macchine virtuali man mano che vengono sottoposte a provisioning dinamico all'interno dell'ambiente.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Il plug-in SnapCenter per VMware vSphere viene implementato come appliance standalone registrata come estensione vCenter, gestita tramite l'interfaccia utente di vCenter o tramite API REST per l'automazione dei servizi di backup e recovery.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architettura SnapCenter</block>
  <block id="3b345c0fb5d2f0451ef84d991b21dcac" category="inline-image-macro">Architettura SnapCenter,300</block>
  <block id="af9bca7d8452705ba7f607cd036dba01" category="paragraph"><block ref="af9bca7d8452705ba7f607cd036dba01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Poiché gli altri plug-in di SnapCenter non supportano ancora i vVol al momento di questa scrittura, in questo documento ci concentreremo sul modello di distribuzione standalone.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Poiché SnapCenter utilizza snapshot ONTAP FlexVol, non è previsto alcun overhead su vSphere, né penalità in termini di performance, come si può vedere con le macchine virtuali tradizionali che utilizzano snapshot gestite da vCenter. Inoltre, poiché le funzionalità di SCV sono esposte attraverso le API REST, è semplice creare workflow automatizzati utilizzando tool come VMware aria Automation, Ansible, Terraform e virtualmente qualsiasi altro tool di automazione in grado di utilizzare le API REST standard.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Panoramica delle API REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Per informazioni sulle API REST di SnapCenter, vedere<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">Plug-in SnapCenter per le API REST di VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Per informazioni sulle API REST del plug-in SnapCenter per VMware vSphere, vedere<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Le seguenti Best practice possono aiutarti a ottenere il massimo dalla tua implementazione SnapCenter.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV supporta sia vCenter Server RBAC che ONTAP RBAC e include ruoli vCenter predefiniti che vengono creati automaticamente al momento della registrazione del plug-in. Ulteriori informazioni sui tipi di RBAC supportati<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Utilizzare l'interfaccia utente di vCenter per assegnare l'accesso agli account con privilegi minimi utilizzando i ruoli predefiniti descritti<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Se si utilizza SCV con il server SnapCenter, è necessario assegnare il ruolo _SnapCenterAdmin_.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC si riferisce all'account utente utilizzato per aggiungere e gestire i sistemi di storage utilizzati da SCV. Il role-based access control ONTAP non si applica ai backup basati su vVol. Scopri di più su ONTAP RBAC e SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Replica i set di dati di backup su un secondo sistema utilizzando SnapMirror per repliche complete dei volumi di origine. Come indicato in precedenza, è anche possibile utilizzare policy di vault mirror per la conservazione a lungo termine dei dati di backup indipendentemente dalle impostazioni di conservazione delle snapshot del volume di origine. Entrambi i meccanismi sono supportati con vVol.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Poiché SCV richiede anche strumenti ONTAP per la funzionalità vVol di VMware vSphere, controllare sempre lo strumento matrice di interoperabilità NetApp (IMT) per verificare la compatibilità delle versioni specifiche</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Se si utilizza la replica vVol con VMware SRM, prestare attenzione all'RPO delle policy e alla pianificazione del backup</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Progettare le policy di backup con impostazioni di conservazione che soddisfino gli obiettivi dei punti di ripristino (RPO) definiti dall'organizzazione</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configurare le impostazioni di notifica sui gruppi di risorse per ricevere una notifica dello stato durante l'esecuzione dei backup (vedere la figura 10 di seguito)</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Opzioni di notifica del gruppo di risorse</block>
  <block id="c728df76dc3609672a7969e320e39e32" category="inline-image-macro">Opzioni di notifica del gruppo di risorse,300</block>
  <block id="45281309785094533b5880fe6d0fd1ea" category="paragraph"><block ref="45281309785094533b5880fe6d0fd1ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Iniziare a utilizzare SCV utilizzando questi documenti</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">Scopri di più sul plug-in SnapCenter per VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Implementare il plug-in SnapCenter per VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Risoluzione dei problemi</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Sito di supporto NetApp</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">Strumenti ONTAP per VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Oltre a una serie di articoli della Knowledge base per i prodotti di virtualizzazione NetApp, il sito del supporto NetApp offre anche una comoda landing page per<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> prodotto. Questo portale fornisce link ad articoli, download, report tecnici e discussioni sulle soluzioni VMware sulla community NetApp. È disponibile all'indirizzo:</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Sito di supporto NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">La documentazione aggiuntiva sulla soluzione è disponibile qui:</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_Soluzioni NetApp per la virtualizzazione_</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Risoluzione dei problemi del prodotto</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">I vari componenti degli strumenti ONTAP, come il plugin vCenter, il provider VASA e l'adattatore di replica dello storage, sono tutti documentati insieme nell'archivio dei documenti NetApp. Tuttavia, ciascuno di essi dispone di una sottosezione separata della Knowledge base e può disporre di procedure specifiche per la risoluzione dei problemi. Queste soluzioni risolvono i problemi più comuni che potrebbero verificarsi con il provider VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problemi dell'interfaccia utente del provider VASA</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">articolo</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Occasionalmente, il client Web vCenter vSphere incontra problemi con i componenti di Serenity, causando la mancata visualizzazione delle voci di menu del provider VASA per ONTAP. Consultare la sezione risoluzione dei problemi di registrazione del provider VASA nella Guida all'implementazione o nella presente Knowledge base<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Il provisioning del datastore di vVol non riesce</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Occasionalmente, i servizi vCenter potrebbero subire un timeout durante la creazione del datastore vVols. Per correggerlo, riavviare il servizio vmware-sps e rimontare il datastore vVols utilizzando i menu vCenter (Storage &gt; New Datastore). Questo argomento viene trattato in vVols datastore provisioning fails with vCenter Server 6.5 nella Administration Guide.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">L'aggiornamento di Unified Appliance non riesce a montare ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">A causa di un bug in vCenter, l'ISO utilizzato per aggiornare Unified Appliance da una release alla successiva potrebbe non essere in grado di eseguire il montaggio. Se è possibile collegare l'ISO all'appliance in vCenter, seguire la procedura descritta in questa Knowledge base<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> per risolvere il problema.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Implementazione dello storage vVol</block>
  <block id="2a5f3dc8d46246216b293c9e41979269" category="paragraph">I primi due passaggi potrebbero non essere necessari per un ambiente vSphere esistente che utilizza ONTAP per i datastore tradizionali. Potreste già utilizzare strumenti ONTAP per gestire, automatizzare e creare rapporti con il vostro sistema di storage basato su VMFS o su NFS tradizionale. Questi passaggi sono descritti in modo più dettagliato nella sezione seguente.</block>
  <block id="841db3655338a0c3dc36cf2761bfdafd" category="list-text">Creare la Storage Virtual Machine (SVM) e la relativa configurazione del protocollo. È possibile selezionare NVMe/FC, NFSv3, NFSv4,1, iSCSI, FCP, o un mix di queste opzioni. È possibile utilizzare le procedure guidate di ONTAP System Manager o la riga di comando della shell del cluster.</block>
  <block id="10818a8ad4f650a48d78d728278d4cb3" category="list-text">Almeno un LIF per nodo per ogni connessione switch/fabric. Come Best practice, creare due o più per nodo per i protocolli basati su FCP, iSCSI o NVMe.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">È possibile creare i volumi in questo momento, ma è più semplice consentire la creazione guidata _Provision Datastore_. L'unica eccezione a questa regola è rappresentata dall'utilizzo della replica vVol con VMware Site Recovery Manager. Questa operazione è più semplice da configurare con volumi FlexVol preesistenti con relazioni SnapMirror esistenti. Prestare attenzione a non abilitare la qualità del servizio su alcun volume da utilizzare per i vVol, in quanto questa operazione deve essere gestita dai tool SPBM e ONTAP.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">Implementare i tool ONTAP per VMware vSphere utilizzando il software OVA scaricato dal sito del supporto NetApp.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">Configurare gli strumenti ONTAP per il proprio ambiente.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">Aggiungere il cluster ONTAP agli strumenti ONTAP in _sistemi storage_</block>
  <block id="731ce7392ae254e2050191ae92cafb14" category="list-text">Mentre gli strumenti e gli SRA di ONTAP supportano sia le credenziali a livello di cluster che quelle a livello di SVM, il provider VASA supporta solo le credenziali a livello di cluster per i sistemi storage. Ciò è dovuto al fatto che molte delle API utilizzate per i vVol sono disponibili solo a livello di cluster. Pertanto, se intendi utilizzare vVol, devi aggiungere i cluster ONTAP utilizzando credenziali cluster-scoped.</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">Se i dati ONTAP si trovano su sottoreti diverse dagli adattatori VMkernel, è necessario aggiungere le subnet dell'adattatore VMkernel all'elenco delle subnet selezionate nel menu delle impostazioni degli strumenti ONTAP. Per impostazione predefinita, gli strumenti ONTAP proteggono il traffico di storage consentendo solo l'accesso alla subnet locale.</block>
  <block id="5a6d084090f063797fc6b863d2817d98" category="list-text">Gli strumenti ONTAP sono dotati di diverse policy predefinite che è possibile utilizzare o vedere <block ref="434866eb159632a70c4db034544336ef" category="inline-xref-macro-rx"></block> Per istruzioni sulla creazione di SCP.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">Utilizzare il menu _ONTAP tools_ di vCenter per avviare la procedura guidata _provisioning datastore_.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">Fornire un nome significativo e selezionare il protocollo desiderato. È anche possibile fornire una descrizione del datastore.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">Selezionare uno o più SCP da supportare dal datastore vVols. In questo modo, i sistemi ONTAP che non sono in grado di corrispondere al profilo verranno filtrati. Dall'elenco visualizzato, selezionare il cluster e la SVM desiderati.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">Utilizzare la procedura guidata per creare nuovi volumi FlexVol per ciascuno degli SCP specificati o utilizzare volumi esistenti selezionando il pulsante di opzione appropriato.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">Creare policy VM per ogni SCP che verrà utilizzato nell'archivio dati dal menu _Policies and Profiles_ dell'interfaccia utente di vCenter.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">Scegliere il set di regole di storage "NetApp.Clustered.Data.ONTAP.VP.vvol". Il set di regole di storage "NetApp.Clustered.Data.ONTAP.VP.VASA10" è per il supporto SPBM con datastore non vVols</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">Quando si crea un criterio di storage VM, specificare il profilo di capacità dello storage in base al nome. In questa fase, è possibile configurare anche la corrispondenza dei criteri di SnapMirror utilizzando la scheda di replica e la corrispondenza basata su tag utilizzando la scheda dei tag. Tenere presente che i tag devono essere già creati per essere selezionabili.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Creare le macchine virtuali, selezionando la policy di storage delle macchine virtuali e il datastore compatibile in Select storage (Seleziona storage).</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migrazione di macchine virtuali da datastore tradizionali a vVol</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">La migrazione delle macchine virtuali dai datastore tradizionali a un datastore vVol è semplice quanto lo spostamento delle macchine virtuali tra datastore tradizionali. È sufficiente selezionare le macchine virtuali, quindi Migrate (Migra) dall'elenco delle azioni e selezionare un tipo di migrazione di _change storage only_. Le operazioni di copia della migrazione verranno trasferite con vSphere 6.0 e versioni successive per le migrazioni DA SAN VMFS a vVol, ma non da NAS VMDK a vVol.</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Gestione delle VM mediante policy</block>
  <block id="4b746813f1085683be4f71c8affea233" category="paragraph">Per automatizzare il provisioning dello storage con una gestione basata su criteri, dobbiamo:</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">Definire le funzionalità dello storage (nodo ONTAP e volume FlexVol) con SCP (Storage Capability Profiles).</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">Creare policy di storage delle macchine virtuali mappate alle SCP definite.</block>
  <block id="67c819108c4ef294ac28a51197046dfc" category="paragraph">NetApp ha semplificato le funzionalità e la mappatura a partire dal provider VASA 7.2 con continui miglioramenti nelle versioni successive. Questa sezione si concentra su questo nuovo approccio. Le versioni precedenti supportavano un maggior numero di funzionalità e consentiva di mapparle singolarmente alle policy di storage, ma questo approccio non è più supportato.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">Funzionalità di profilo della capacità dello storage con la release di tool ONTAP</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">*Funzionalità SCP*</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">*Valori di capacità*</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">*Versione supportata*</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">*Note*</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">*Compressione*</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">Sì, No, qualsiasi</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">Obbligatorio per AFF nel 7.2 e versioni successive.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">*Deduplica*</block>
  <block id="6868f879256c802b106616a006671848" category="cell">M andatory for AFF nel 7.2 e versioni successive.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">*Crittografia*</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7,2 e successivi</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">Seleziona/crea un volume FlexVol crittografato. È richiesta la licenza ONTAP.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">*IOPS max*</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7.1 e versioni successive, ma le differenze</block>
  <block id="c0f84018aff4ff4a1cf4012a8b82e509" category="cell">Elencato in QoS Policy Group per 7.2 e versioni successive. Vedere <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">*Personalità*</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS include anche altri sistemi non AFF, come ONTAP Select. AFF include ASA.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">*Protocollo*</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4.1, iSCSI, FCP, NVMe/FC, Qualsiasi</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7.1 e versioni precedenti, 9.10 e versioni successive</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7.2-9.8 è effettivamente "qualsiasi". Ricominciare dal 9.10, dove NFS 4.1 e NVMe/FC sono stati aggiunti all'elenco originale.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">*Riserva di spazio (Thin Provisioning)*</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">Sottile, spesso (qualsiasi)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">Tutto, ma le differenze</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">Definito Thin Provisioning nel 7.1 e nelle versioni precedenti, che consentiva anche il valore di qualsiasi. Chiamata Space Reserve nel 7.2. Per impostazione predefinita, tutte le release sono impostate su Thin.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">*Policy di tiering*</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">Qualsiasi, Nessuno, Snapshot, Auto</block>
  <block id="00917abc35f0d57db6562a886997c4e8" category="cell">Utilizzato per FabricPool - richiede AFF o ASA con ONTAP 9,4 o versione successiva. Si consiglia di utilizzare solo Snapshot, a meno che non si utilizzi una soluzione S3 on-premise come NetApp StorageGRID.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">Creazione di profili di funzionalità storage</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">Il NetApp VASA Provider viene fornito con diversi SCP predefiniti. I nuovi SCP possono essere creati manualmente, utilizzando l'interfaccia utente di vCenter o tramite automazione utilizzando le API REST. Specificando le funzionalità in un nuovo profilo, clonando un profilo esistente o generando automaticamente profili da datastore tradizionali esistenti. Questa operazione viene eseguita utilizzando i menu in ONTAP Tools (Strumenti di Windows). Utilizzare _Storage Capability Profiles_ per creare o clonare un profilo e _Storage Mapping_ per generare automaticamente un profilo.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">Funzionalità di storage per gli strumenti ONTAP 9.10 e versioni successive</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">"Funzionalità di storage per gli strumenti ONTAP 9.10 e versioni successive"0,300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="049b6d7b78dd8ffebadb5a0be2261637" category="paragraph">*Creazione di archivi dati vVol*
Una volta creati, gli SCP necessari possono essere utilizzati per creare il datastore vVols (e, facoltativamente, i volumi FlexVol per il datastore). Fare clic con il pulsante destro del mouse sull'host, sul cluster o sul data center su cui si desidera creare il datastore vVols, quindi selezionare _ONTAP Tools_ &gt; _Provision Datastore_. Selezionare uno o più SCP da supportare dall'archivio dati, quindi scegliere tra i volumi FlexVol esistenti e/o eseguire il provisioning di nuovi volumi FlexVol per l'archivio dati. Infine, specificare l'SCP predefinito per l'archivio dati, che verrà utilizzato per le macchine virtuali che non dispongono di un SCP specificato dal criterio, nonché per i vVol di swap (che non richiedono uno storage dalle performance elevate).</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Creazione di policy di storage delle macchine virtuali</block>
  <block id="b4f6f65777757af7630fae901718e51e" category="paragraph">Le versioni precedenti sono simili, ma come menzionato in <block ref="68072d20e775e4558feadbec7ba8f768" category="inline-xref-macro-rx"></block>, le opzioni disponibili variano.</block>
  <block id="52896487a6472798e1d6cbc9a95ec51e" category="section-title">Creazione di policy di storage delle macchine virtuali con tool ONTAP VASA Provider 9,10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">"Creazione dei criteri di storage delle macchine virtuali con i tool ONTAP Provider VASA 9.10",300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">Gestione delle performance con gli strumenti ONTAP 9.10 e versioni successive</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP Tools 9.10 utilizza il proprio algoritmo di posizionamento bilanciato per inserire un nuovo vVol nel miglior volume FlexVol all'interno di un datastore vVol. Il posizionamento si basa sui volumi SCP specificati e FlexVol corrispondenti. In questo modo si garantisce che il datastore e lo storage di backup soddisfino i requisiti di performance specificati.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">La modifica delle funzionalità delle performance, ad esempio IOPS min e max, richiede un'attenzione particolare alla configurazione specifica.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">*I valori minimo e massimo di IOPS* possono essere specificati in un SCP e utilizzati in una policy VM.</block>
  <block id="404e0fefd61512a9f144586382a62641" category="list-text">La modifica degli IOPS in SCP non modificherà la QoS sui vVol fino a quando il criterio della VM non viene modificato e quindi riapplicato alle VM che lo utilizzano (vedere la) <block ref="2358041c73953300d39d98366deee80d" category="inline-xref-macro-rx"></block>). Oppure creare un nuovo SCP con gli IOPS desiderati e modificare il criterio per utilizzarlo (e riapplicarlo alle macchine virtuali). In genere, si consiglia di definire semplicemente criteri di storage di SCP e VM separati per diversi livelli di servizio e di modificare semplicemente la policy di storage delle macchine virtuali sulla macchina virtuale.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">Le personalità AFF e FAS hanno impostazioni IOPS diverse. Sia min che Max sono disponibili su AFF. Tuttavia, i sistemi non AFF possono utilizzare solo le impostazioni relative al numero massimo di IOPS.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">In alcuni casi, potrebbe essere necessario migrare un vVol dopo una modifica di policy (manualmente o automaticamente dal provider VASA e da ONTAP):</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">Alcune modifiche non richiedono alcuna migrazione (ad esempio, la modifica di Max IOPS, che può essere applicata immediatamente alla macchina virtuale come descritto sopra).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">Se la modifica del criterio non può essere supportata dal volume FlexVol corrente che memorizza il vVol (ad esempio, la piattaforma non supporta il criterio di crittografia o di tiering richiesto), sarà necessario migrare manualmente la macchina virtuale in vCenter.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Gli strumenti ONTAP creano policy QoS individuali non condivise con le versioni attualmente supportate di ONTAP. Pertanto, ogni singolo VMDK riceverà la propria allocazione di IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Riapplicazione dei criteri di storage delle macchine virtuali</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">"Riapplicazione della policy di storage delle macchine virtuali"0,300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP supporta tutti i principali protocolli di storage utilizzati per la virtualizzazione, come iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) o non-volatile Memory Express over Fibre Channel (NVMe/FC) per ambienti SAN, oltre a NFS (v3 e v4.1) e SMB o S3 per connessioni guest. I clienti sono liberi di scegliere ciò che funziona meglio per il proprio ambiente e possono combinare i protocolli in base alle esigenze su un singolo sistema.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Strumenti di virtualizzazione per ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp offre diversi tool software standalone che possono essere utilizzati insieme a ONTAP e vSphere per gestire l'ambiente virtualizzato.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">I seguenti strumenti sono inclusi con la licenza ONTAP senza costi aggiuntivi. Vedere la Figura 1 per un'illustrazione del funzionamento di questi strumenti nell'ambiente vSphere.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">ONTAP Tools per VMware vSphere è un insieme di strumenti per l'utilizzo dello storage ONTAP insieme a vSphere. Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia di utilizzare questi tool ONTAP come Best practice quando si utilizza vSphere con sistemi che eseguono il software ONTAP. Include un'appliance server, estensioni dell'interfaccia utente per vCenter, VASA Provider e Storage Replication Adapter. Quasi tutto ciò che è contenuto negli strumenti ONTAP può essere automatizzato utilizzando semplici API REST, utilizzabili dalla maggior parte dei moderni strumenti di automazione.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">Le estensioni dell'interfaccia utente di vCenter.* le estensioni dell'interfaccia utente di ONTAP Tools semplificano il lavoro dei team operativi e degli amministratori di vCenter, integrando menu facili da utilizzare e sensibili al contesto per la gestione di host e storage, portlet informativi e funzionalità di avviso native direttamente nell'interfaccia utente di vCenter per flussi di lavoro semplificati.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*Provider VASA per ONTAP.* il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). Viene fornito come parte dei tool ONTAP per VMware vSphere come singola appliance virtuale per una maggiore facilità di implementazione. IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol), la gestione dei profili di capacità dello storage e delle performance di VM vVol individuali e gli allarmi per il monitoraggio della capacità e della conformità con i profili.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* SRA viene utilizzato insieme a VMware Site Recovery Manager (SRM) per gestire la replica dei dati tra siti di produzione e disaster recovery e testare le repliche DR senza interruzioni. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figura seguente mostra gli strumenti ONTAP per vSphere.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS per VMware VAAI</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">Il plug-in NetApp NFS per VMware VAAI è un plug-in per gli host ESXi che consente loro di utilizzare le funzionalità VAAI con gli archivi dati NFS su ONTAP. Supporta l'offload delle copie per le operazioni di cloning, lo space reservation per i file di dischi virtuali con thick provisioning e l'offload delle snapshot. L'offload delle operazioni di copia sullo storage non è necessariamente più veloce da completare, ma riduce i requisiti di larghezza di banda della rete e scarica le risorse host come cicli CPU, buffer e code. È possibile utilizzare i tool ONTAP per VMware vSphere per installare il plug-in sugli host ESXi o, se supportato, vSphere Lifecycle Manager (vLCM).</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Essi consentono una selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di mettere in pausa l'i/o prima di scattare una snapshot VMware.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Gestione basata su criteri di archiviazione e vVol</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">Le API VMware vSphere per Storage Awareness (VASA) semplificano la configurazione dei datastore da parte di un amministratore dello storage con funzionalità ben definite e consentono all'amministratore delle macchine virtuali di utilizzarle quando necessario per eseguire il provisioning delle macchine virtuali senza dover interagire tra loro.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Vale la pena di dare un'occhiata a questo approccio per scoprire in che modo può semplificare le operazioni di virtualizzazione dello storage ed evitare un lavoro molto banale.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Prima di VASA, gli amministratori delle macchine virtuali potevano definire le policy di storage delle macchine virtuali, ma dovevano collaborare con l'amministratore dello storage per identificare gli archivi dati appropriati, spesso utilizzando la documentazione o le convenzioni di denominazione. Con VASA, l'amministratore dello storage può definire una serie di funzionalità di storage, tra cui performance, tiering, crittografia e replica. Un insieme di funzionalità per un volume o un set di volumi viene definito SCP (Storage Capability Profile).</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">SCP supporta la qualità del servizio minima e/o massima per i vVol di dati di una VM. La QoS minima è supportata solo sui sistemi AFF. Gli strumenti ONTAP per VMware vSphere includono una dashboard che visualizza le performance granulari delle macchine virtuali e la capacità logica per i vVol sui sistemi ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figura seguente mostra i tool ONTAP per il dashboard di VMware vSphere 9.8 vVol.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Una volta definito il profilo di capacità dello storage, è possibile utilizzarlo per eseguire il provisioning delle macchine virtuali utilizzando la policy di storage che ne identifica i requisiti. La mappatura tra il criterio di storage delle macchine virtuali e il profilo di capacità dello storage del datastore consente a vCenter di visualizzare un elenco di datastore compatibili per la selezione. Questo approccio è noto come gestione basata su criteri di storage.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">VASA offre la tecnologia per eseguire query sullo storage e restituire un set di funzionalità di storage a vCenter. I vendor provider VASA forniscono la traduzione tra le API e i costrutti del sistema storage e le API VMware comprese da vCenter. Il provider VASA di NetApp per ONTAP viene offerto come parte dei tool ONTAP per macchina virtuale dell'appliance VMware vSphere, mentre il plug-in vCenter fornisce l'interfaccia per il provisioning e la gestione dei datastore vVol, nonché la capacità di definire profili di funzionalità dello storage (SCP).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP supporta gli archivi dati VMFS e NFS vVol. L'utilizzo di vVol con datastore SAN offre alcuni dei vantaggi di NFS, come la granularità a livello di macchine virtuali. Di seguito sono riportate alcune Best practice da prendere in considerazione e ulteriori informazioni sono disponibili in<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vVol può essere costituito da più volumi FlexVol su più nodi del cluster. L'approccio più semplice è un singolo datastore, anche quando i volumi hanno funzionalità diverse. SPBM garantisce l'utilizzo di un volume compatibile per la macchina virtuale. Tuttavia, tutti i volumi devono far parte di una singola SVM ONTAP e devono essere accessibili utilizzando un singolo protocollo. È sufficiente una LIF per nodo per ogni protocollo. Evitare di utilizzare più release di ONTAP all'interno di un singolo datastore vVol, poiché le funzionalità dello storage potrebbero variare tra le varie release.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilizza i tool ONTAP per il plug-in VMware vSphere per creare e gestire datastore vVol. Oltre a gestire il datastore e il relativo profilo, crea automaticamente un endpoint del protocollo per accedere ai vVol, se necessario. Se si utilizzano LUN, tenere presente che i LUN PES vengono mappati utilizzando LUN ID 300 e superiori. Verificare che l'impostazione di sistema avanzata dell'host ESXi sia corretta<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Consente un numero di ID LUN superiore a 300 (il valore predefinito è 1,024). Eseguire questa operazione selezionando l'host ESXi in vCenter, quindi la scheda Configura e trova<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Nell'elenco delle Advanced System Settings (Impostazioni di sistema avanzate).</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">Non installare o migrare il provider VASA, il server vCenter (basato su appliance o Windows) o i tool ONTAP per VMware vSphere in sé su un datastore vVols, perché in tal caso sono dipendenti reciprocamente, limitando la possibilità di gestirli in caso di interruzione dell'alimentazione o di altre interruzioni del data center.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Articolo della Knowledge base</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Eseguire regolarmente il backup della VM del provider VASA. Crea almeno snapshot orarie del datastore tradizionale che contiene il provider VASA. Per ulteriori informazioni sulla protezione e il ripristino del provider VASA, consulta questa sezione<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figura seguente mostra i componenti di vVol.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Questa pagina descrive le Best practice per l'implementazione di una soluzione di storage NetApp ONTAP in un ambiente VMware vSphere.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes (vVol) e Storage Policy Based Management (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">A proposito di vVol e SPBM</block>
  <block id="a42f13867ea459821488608dc4d1b7c4" category="paragraph">NetApp è stato un primo partner di progettazione di VMware nello sviluppo di vVol (vSphere Virtual Volumes), fornendo input architetturale e supporto iniziale per vVol e API VMware vSphere per la consapevolezza dello storage (VASA). Questo approccio non solo ha portato la gestione granulare dello storage delle macchine virtuali a VMFS, ma ha anche supportato l'automazione del provisioning dello storage tramite Storage Policy Based Management (SPBM).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM fornisce un framework che funge da layer di astrazione tra i servizi di storage disponibili per l'ambiente di virtualizzazione e gli elementi di storage sottoposti a provisioning tramite policy. Questo approccio consente agli architetti dello storage di progettare pool di storage con diverse funzionalità che possono essere facilmente utilizzate dagli amministratori delle macchine virtuali. Gli amministratori possono quindi associare i requisiti di carico di lavoro delle macchine virtuali ai pool di storage con provisioning, consentendo un controllo granulare delle varie impostazioni a livello di macchina virtuale o disco virtuale.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP è leader nel settore dello storage in termini di scalabilità vVol, supportando centinaia di migliaia di vVol in un singolo cluster, mentre i vendor di array Enterprise e flash array più piccoli supportano solo diverse migliaia di vVol per array. NetApp sta inoltre guidando l'evoluzione della gestione granulare delle macchine virtuali con funzionalità imminenti a supporto di vVol 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: Volumi virtuali VMware vSphere con ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Per ulteriori informazioni su VMware vSphere Virtual Volumes, SPBM e ONTAP, vedere<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Utilizza le snapshot per creare copie rapide della tua macchina virtuale o del datastore senza influire sulle performance, quindi inviale a un sistema secondario utilizzando SnapMirror per la data Protection off-site a lungo termine. Questo approccio riduce al minimo lo spazio di storage e la larghezza di banda della rete memorizzando solo le informazioni modificate.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">consigliato</block>
  <block id="022e604112aa3d1870f0da5e7806f48b" category="paragraph">SnapCenter consente di creare policy di backup che possono essere applicate a più processi. Questi criteri possono definire pianificazione, conservazione, replica e altre funzionalità. Essi consentono una selezione opzionale di snapshot coerenti con le macchine virtuali, che sfrutta la capacità dell'hypervisor di mettere in pausa l'i/o prima di scattare una snapshot VMware. Tuttavia, a causa dell'effetto delle performance delle snapshot VMware, in genere non sono consigliate, a meno che non sia necessario interrompere il file system guest. Utilizza invece le snapshot per la protezione generale e utilizza strumenti applicativi come i plug-in SnapCenter per proteggere i dati transazionali come SQL Server o Oracle. Questi snapshot sono diversi dalle snapshot VMware (coerenza) e sono adatti per una protezione a lungo termine.  Le snapshot VMware sono solo<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> per uso a breve termine a causa delle performance e di altri effetti.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Questi plug-in offrono funzionalità estese per proteggere i database in ambienti fisici e virtuali. Con vSphere, è possibile utilizzarli per proteggere i database SQL Server o Oracle in cui i dati vengono memorizzati su LUN RDM, LUN iSCSI direttamente connessi al sistema operativo guest o file VMDK su datastore VMFS o NFS. I plug-in consentono di specificare diversi tipi di backup del database, supportando backup online o offline e proteggendo i file di database insieme ai file di log. Oltre al backup e al ripristino, i plug-in supportano anche la clonazione dei database a scopo di sviluppo o test.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figura seguente mostra un esempio di implementazione di SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Per funzionalità avanzate di disaster recovery, è consigliabile utilizzare NetApp SRA per ONTAP con VMware Site Recovery Manager. Oltre al supporto per la replica di datastore in un sito di DR, consente anche test senza interruzioni nell'ambiente di DR mediante il cloning dei datastore replicati. Anche il ripristino da un disastro e la riconprotezione della produzione dopo la risoluzione dell'interruzione sono semplificabili grazie all'automazione integrata in SRA.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Infine, per ottenere il massimo livello di protezione dei dati, prendere in considerazione una configurazione vMSC (Metro Storage Cluster) di VMware vSphere che utilizza NetApp MetroCluster. VMSC è una soluzione certificata da VMware che combina la replica sincrona con il clustering basato su array, offrendo gli stessi vantaggi di un cluster ad alta disponibilità ma distribuito su siti separati per la protezione dai disastri del sito. NetApp MetroCluster offre configurazioni convenienti per la replica sincrona con ripristino trasparente da qualsiasi guasto a un singolo componente dello storage e ripristino a comando singolo in caso di disastro del sito. VMSC è descritto in maggiore dettaglio nella<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Il software NetApp ONTAP è da quasi vent'anni una soluzione di storage leader per gli ambienti VMware vSphere e continua ad aggiungere funzionalità innovative per semplificare la gestione e ridurre i costi. Questo documento presenta la soluzione ONTAP per vSphere, incluse le informazioni più recenti sui prodotti e le Best practice, per ottimizzare l'implementazione, ridurre i rischi e semplificare la gestione.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Storage unificato</block>
  <block id="8b02311a9d2f587eb4c447455c3df68f" category="paragraph">I sistemi che eseguono il software ONTAP sono unificati in diversi modi significativi.</block>
  <block id="7242358e2514a48e7044717140cacb4b" category="paragraph">In origine, questo approccio si riferiva al supporto dei protocolli NAS e SAN su un unico sistema di storage e ONTAP continua a essere una piattaforma leader per SAN insieme alla sua forza originale nel NAS.</block>
  <block id="4947dc197f31edea82b3fdab9dc68fdc" category="paragraph">Una macchina virtuale per lo storage (SVM) è un costrutto logico che consente l'accesso del client ai sistemi che eseguono il software ONTAP. Le SVM possono servire i dati contemporaneamente attraverso più protocolli di accesso ai dati tramite le interfacce logiche (LIF). Le SVM forniscono l'accesso ai dati a livello di file attraverso protocolli NAS, come CIFS e NFS, e l'accesso ai dati a livello di blocco attraverso protocolli SAN, come iSCSI, FC/FCoE e NVMe. Le SVM possono fornire dati ai client SAN e NAS in modo indipendente allo stesso tempo.</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c46d272642e0999c025f67e9de315c9" category="paragraph">Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono il software ONTAP sono in genere meno costosi per VSI rispetto agli array aziendali tradizionali e dispongono tuttavia di funzionalità avanzate di efficienza dello storage per gestire VDI nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un array SATA per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualizzazione dello storage</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Per ulteriori informazioni su SVM, storage unificato e accesso client, vedere<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Nel centro di documentazione di ONTAP 9.</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">VMware Storage Distributed Resource Scheduler</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware Storage Distributed Resource Scheduler (SDR) è una funzionalità vSphere che consente di posizionare le macchine virtuali sullo storage in base alla latenza i/o corrente e all'utilizzo dello spazio.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">Quindi, sposta le VM o i VMDK senza interruzioni tra gli archivi dati in un cluster di datastore (noto anche come pod), selezionando il migliore datastore in cui posizionare le VM o i VMDK nel cluster di datastore. Un cluster di datastore è un insieme di datastore simili che vengono aggregati in una singola unità di consumo dal punto di vista dell'amministratore di vSphere.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Quando si utilizzano GLI SDR con i tool NetApp ONTAP per VMware vSphere, è necessario prima creare un datastore con il plug-in, utilizzare vCenter per creare il cluster del datastore e quindi aggiungervi il datastore. Una volta creato il cluster di datastore, è possibile aggiungere ulteriori datastore al cluster di datastore direttamente dalla procedura guidata di provisioning nella pagina Dettagli.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Altre Best practice ONTAP per I DSP includono:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tutti gli archivi dati del cluster devono utilizzare lo stesso tipo di storage (ad esempio SAS, SATA o SSD), tutti gli archivi dati VMFS o NFS e avere le stesse impostazioni di replica e protezione.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Considerare l'utilizzo DEGLI SDR in modalità predefinita (manuale). Questo approccio consente di rivedere i suggerimenti e decidere se applicarli o meno. Tenere presente i seguenti effetti delle migrazioni VMDK:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Quando GLI SDR spostano i VMDK tra datastore, qualsiasi risparmio di spazio derivante dalla clonazione o deduplica ONTAP viene perso. È possibile rieseguire la deduplica per recuperare questi risparmi.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Dopo che LE SDR spostano i VMDK, NetApp consiglia di ricreare gli snapshot nel datastore di origine, poiché lo spazio è altrimenti bloccato dalla VM che è stata spostata.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Lo spostamento di VMDK tra datastore sullo stesso aggregato ha pochi benefici e GLI SDR non hanno visibilità su altri carichi di lavoro che potrebbero condividere l'aggregato.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere con ONTAP</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Questa documentazione sostituisce i report tecnici precedentemente pubblicati _TR-4597: VMware vSphere for ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Le Best practice integrano altri documenti come guide ed elenchi di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. Potrebbero non essere le uniche pratiche supportate che funzionano in ogni ambiente, ma sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Tool di matrice di interoperabilità NetApp</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guida alla compatibilità VMware</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Questo documento si concentra sulle funzionalità delle versioni recenti di ONTAP (9.x) in esecuzione su vSphere 7,0 o versioni successive. Vedere<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> e.<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> per dettagli relativi a release specifiche.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Perché scegliere ONTAP per vSphere?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">Sono molti i motivi per cui decine di migliaia di clienti hanno scelto ONTAP come soluzione storage per vSphere, ad esempio un sistema storage unificato che supporta protocolli SAN e NAS, solide funzionalità di protezione dei dati che utilizzano snapshot efficienti in termini di spazio e molti strumenti per aiutarti a gestire i dati delle applicazioni. L'utilizzo di un sistema storage separato dall'hypervisor consente di trasferire molte funzioni e massimizzare l'investimento nei sistemi host vSphere. Questo approccio non solo garantisce che le risorse host siano incentrate sui carichi di lavoro delle applicazioni, ma evita anche effetti casuali sulle performance delle applicazioni derivanti dalle operazioni di storage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'utilizzo di ONTAP insieme a vSphere è un'ottima combinazione che consente di ridurre le spese relative all'hardware host e al software VMware. Puoi anche proteggere i tuoi dati a un costo inferiore con performance elevate e costanti. Poiché i carichi di lavoro virtualizzati sono mobili, è possibile esplorare diversi approcci utilizzando Storage vMotion per spostare le macchine virtuali tra datastore VMFS, NFS o vVol, tutti sullo stesso sistema storage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Ecco i fattori chiave che i clienti apprezzano oggi:</block>
  <block id="442c1f0ac31c3d71b638125e0a8b51da" category="list-text">*Storage unificato.* i sistemi che eseguono il software ONTAP sono unificati in diversi modi significativi. In origine, questo approccio si riferiva ai protocolli NAS e SAN e ONTAP continua a essere una piattaforma leader per SAN insieme alla sua forza originale nel NAS. Nel mondo vSphere, questo approccio potrebbe anche significare un sistema unificato per l'infrastruttura di desktop virtuale (VDI) insieme all'infrastruttura di server virtuale (VSI). I sistemi che eseguono il software ONTAP sono in genere meno costosi per VSI rispetto agli array aziendali tradizionali e dispongono tuttavia di funzionalità avanzate di efficienza dello storage per gestire VDI nello stesso sistema. ONTAP unifica inoltre una vasta gamma di supporti storage, da SSD a SATA, e può estenderli facilmente nel cloud. Non è necessario acquistare un flash array per le performance, un array SATA per gli archivi e sistemi separati per il cloud. ONTAP li lega tutti insieme.</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Volumi virtuali e gestione basata su policy dello storage.* NetApp è stato un partner di progettazione iniziale di VMware nello sviluppo di vVol (vSphere Virtual Volumes), che offre input architetturali e supporto precoce di vVol e API di VMware vSphere per Storage Awareness (VASA). Questo approccio non solo ha portato a VMFS una gestione granulare dello storage delle macchine virtuali, ma ha anche supportato l'automazione del provisioning dello storage tramite la gestione basata su criteri dello storage. Questo approccio consente agli architetti dello storage di progettare pool di storage con diverse funzionalità che possono essere facilmente utilizzate dagli amministratori delle macchine virtuali. ONTAP è leader nel settore dello storage in termini di scalabilità vVol, supportando centinaia di migliaia di vVol in un singolo cluster, mentre i vendor di array Enterprise e flash array più piccoli supportano solo diverse migliaia di vVol per array. NetApp sta inoltre guidando l'evoluzione della gestione granulare delle macchine virtuali con funzionalità imminenti a supporto di vVol 3.0.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Efficienza dello storage.* sebbene NetApp sia stata la prima a fornire la deduplica per carichi di lavoro di produzione, questa innovazione non è stata la prima o l'ultima in quest'area. Il prodotto è partito dalle snapshot, un meccanismo di protezione dei dati efficiente in termini di spazio, senza effetti sulle performance, e dalla tecnologia FlexClone per creare istantaneamente copie in lettura/scrittura delle macchine virtuali per l'utilizzo in produzione e nel backup. NetApp ha continuato a offrire funzionalità inline, tra cui deduplica, compressione e deduplica a blocchi zero, per eliminare il maggior numero di storage dai costosi SSD. Più di recente, ONTAP ha aggiunto la possibilità di inserire file e operazioni i/o più piccole in un blocco di dischi utilizzando la compattazione. La combinazione di queste funzionalità ha consentito ai clienti di ottenere risparmi fino a 5:1 per VSI e fino a 30:1 per VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud ibrido.* sia che venga utilizzato per il cloud privato on-premise, l'infrastruttura di cloud pubblico o un cloud ibrido che combina il meglio di entrambi, le soluzioni ONTAP ti aiutano a costruire il tuo data fabric per ottimizzare e ottimizzare la gestione dei dati. Inizia con i sistemi all-flash dalle performance elevate, quindi accoppiali con sistemi di storage su disco o cloud per la protezione dei dati e il cloud computing. Scegli tra cloud Azure, AWS, IBM o Google per ottimizzare i costi ed evitare il lock-in. Sfrutta il supporto avanzato per le tecnologie OpenStack e container in base alle esigenze. NetApp offre inoltre backup basato sul cloud (SnapMirror Cloud, Cloud Backup Service e Cloud Sync) e tool di archiviazione e tiering dello storage (FabricPool) per ONTAP per ridurre le spese operative e sfruttare l'ampia portata del cloud.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">*E altro ancora.* sfrutta le performance estreme degli array NetApp AFF Serie A per accelerare l'infrastruttura virtualizzata e gestire i costi. Operazioni senza interruzioni, dalla manutenzione agli aggiornamenti fino alla sostituzione completa del sistema storage, utilizzando cluster ONTAP scale-out. Proteggi i dati inattivi con le funzionalità di crittografia NetApp senza costi aggiuntivi. Assicurati che le performance soddisfino i livelli di servizio di business grazie a funzionalità di qualità dei servizi. Fanno tutti parte dell'ampia gamma di funzionalità offerte da ONTAP, il software di Enterprise data management leader del settore.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Host ESXi consigliato e altre impostazioni ONTAP</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp ha sviluppato un set di impostazioni di multipathing host ESXi e timeout HBA per un comportamento corretto con ONTAP in base ai test NetApp. Questi sono facilmente impostabili utilizzando i tool ONTAP per VMware vSphere. Dalla dashboard Riepilogo, fare clic su Modifica impostazioni nel portlet sistemi host o fare clic con il pulsante destro del mouse sull'host in vCenter, quindi selezionare ONTAP Tools &gt; Set Recommended Values (Strumenti di configurazione &gt; Imposta valori consigliati). Di seguito sono riportate le impostazioni host attualmente consigliate per la versione 9.8.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Impostazione host*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valore consigliato da NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Riavvio richiesto*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configurazione avanzata ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratedLocking</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Mantieni predefinito (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">Tastiera VMware 2007427</block>
  <block id="3aca64366573d9850e0148ce2a38164c" category="cell">Mantenere l'impostazione predefinita (0), ma può essere modificata se necessario.
Per ulteriori informazioni, vedere <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Unmap</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">API VMware vSphere: Integrazione degli array (VAAI)</block>
  <block id="e385d2442208cc1e23ca841b1f217380" category="cell">Mantieni predefinito (1)
Per ulteriori informazioni, vedere <block ref="d124e203790e5f214a195f69cd068c6d" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Impostazioni NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipelHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 o versione successiva, impostato su 32.
Tutte le altre configurazioni NFS, impostate su 30</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sì</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipelHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Impostato su 512 MB per la maggior parte delle release di vSphere 6.X.
Impostare su 1024 MB per 6.5U3, 6.7U3 e 7.0 o versioni successive.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6,0 o versioni successive, impostare su 256
Tutte le altre configurazioni NFS, impostate su 64.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6,0 o versioni successive, impostare su 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 o versione successiva, impostato su 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Impostare su 10 per tutte le configurazioni NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Impostato su 12 per tutte le configurazioni NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Impostare su 5 per tutte le configurazioni NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7,0 o versioni successive, impostare su 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Impostazioni FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Policy di selezione del percorso</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Impostare su RR (round robin) quando si utilizzano percorsi FC con ALUA. Impostare su FISSO per tutte le altre configurazioni.
L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati.
Il valore FISSO è per le configurazioni precedenti non ALUA e aiuta a prevenire i/o proxy In altre parole, consente di evitare che l'i/o venga collegato all'altro nodo di una coppia ad alta disponibilità (ha) in un ambiente con Data ONTAP in 7-Mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Impostare su 32 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Impostare su 8 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Timeout HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilizzare il valore predefinito.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Timeout HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Impostazioni iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Impostare su RR (round robin) per tutti i percorsi iSCSI.
L'impostazione di questo valore su RR consente di fornire il bilanciamento del carico in tutti i percorsi attivi/ottimizzati.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Impostare su 32 per tutte le configurazioni.
L'impostazione di questo valore aiuta a prevenire gli errori di i/O.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">Tastiera VMware 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 - l'opzione di configurazione avanzata di NFS MaxQueueDepth potrebbe non funzionare come previsto quando si utilizzano VMware vSphere ESXi 7.0.1 e VMware vSphere ESXi 7.0.2. Fare riferimento a. <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> per ulteriori informazioni.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Gli strumenti ONTAP specificano anche alcune impostazioni predefinite durante la creazione di ONTAP FlexVol Volumes e LUN:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Strumento ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Impostazione predefinita*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Riserva di Snapshot (-percento-spazio-snapshot)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Riserva frazionaria (-riserva frazionaria)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Access time update (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falso</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Readahead minimo (-min-readahead)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Istantanee pianificate</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficienza dello storage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Attivato</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garanzia di volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Nessuno (con thin provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Dimensionamento automatico del volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Prenotazione di spazio LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Disattivato</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocazione dello spazio del LUN</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Impostazioni multipath per performance superiori</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Sebbene non sia attualmente configurato dagli strumenti ONTAP disponibili, NetApp suggerisce le seguenti opzioni di configurazione:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">In ambienti dalle performance elevate o quando si testano le performance con un singolo datastore LUN, si consiglia di modificare l'impostazione del bilanciamento del carico del criterio di selezione del percorso (PSP) round-robin (VMW_PSP_RR) dall'impostazione IOPS predefinita di 1000 a un valore di 1. Consulta la Knowledge base di VMware<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Plug-in e policy per la selezione del percorso</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">In vSphere 6.7 Update 1, VMware ha introdotto un nuovo meccanismo di bilanciamento del carico di latenza per la PSP Round Robin. La nuova opzione prende in considerazione la larghezza di banda i/o e la latenza del percorso quando si seleziona il percorso ottimale per i/O. Potrebbe essere utile utilizzarlo in ambienti con connettività di percorso non equivalente, ad esempio nei casi in cui vi sono più salti di rete su un percorso rispetto a un altro, o quando si utilizza un sistema NetApp All SAN Array. Vedere<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Documentazione aggiuntiva</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Utilizzo di VMware vSphere 7.x con ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Utilizzo di VMware vSphere 8.x con ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Per NVMe-of, ulteriori dettagli sono disponibili nella pagina NVMe-of host Configuration per ESXi 7.x con ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Per NVMe-of, ulteriori dettagli sono disponibili nella pagina NVMe-of host Configuration per ESXi 8.x con ONTAP</block>
  <block id="842acd8b4932f6c9329df8e0fefe8b9b" category="paragraph">Per FCP e iSCSI con vSphere 7, è possibile trovare ulteriori dettagli all'indirizzo<block ref="f3eae508de4d3c1748a9c65337197b21" category="inline-link-rx"></block>
Per FCP e iSCSI con vSphere 8, è possibile trovare ulteriori dettagli all'indirizzo<block ref="3f8db75ee0177b85df9cdf31ddb51abe" category="inline-link-rx"></block>
Per NVMe-of con vSphere 7, è possibile trovare ulteriori dettagli all'indirizzo<block ref="6c040a6e611e78bb9d0ad92946e613ea" category="inline-link-rx"></block>
Per NVMe-of con vSphere 8, è possibile trovare ulteriori dettagli all'indirizzo<block ref="030788e4c7bbe3137759b534ea62d7d9" category="inline-link-rx"></block></block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Clonazione di VM e datastore</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">In vSphere, è possibile clonare una macchina virtuale, un disco virtuale, un vVol o un datastore. Dopo essere stato clonato, l'oggetto può essere ulteriormente personalizzato, spesso attraverso un processo automatizzato. VSphere supporta entrambi i cloni di copia completa e i cloni collegati, in cui tiene traccia delle modifiche separatamente dall'oggetto originale.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">I cloni collegati sono ideali per risparmiare spazio, ma aumentano la quantità di i/o che vSphere gestisce per la macchina virtuale, influenzando le performance di quella macchina virtuale e forse dell'host in generale. Ecco perché i clienti di NetApp spesso utilizzano cloni basati su sistemi storage per ottenere il meglio di entrambi i mondi: Un utilizzo efficiente dello storage e maggiori performance.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La seguente figura illustra la clonazione ONTAP.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">La clonazione può essere scaricata su sistemi che eseguono il software ONTAP attraverso diversi meccanismi, in genere a livello di VM, vVol o datastore. Questi includono quanto segue:</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">VVol che utilizzano le API di NetApp vSphere per il provider di consapevolezza dello storage (VASA).  I cloni ONTAP sono utilizzati per supportare le snapshot vVol gestite da vCenter, che sono efficienti in termini di spazio con effetto i/o minimo per crearle ed eliminarle.  Le VM possono anche essere clonate utilizzando vCenter e vengono anche trasferite in ONTAP, sia all'interno di un singolo datastore/volume che tra datastore/volumi.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonazione e migrazione di vSphere con API vSphere – integrazione array (VAAI). Le operazioni di cloning delle macchine virtuali possono essere trasferite su ONTAP in ambienti SAN e NAS (NetApp fornisce un plug-in ESXi per abilitare VAAI per NFS).  VSphere scarica solo le operazioni su macchine virtuali fredde (spente) in un datastore NAS, mentre le operazioni su macchine virtuali hot (cloning e storage vMotion) vengono anche scaricate per LA SAN. ONTAP utilizza l'approccio più efficiente in base all'origine, alla destinazione e alle licenze dei prodotti installate. Questa funzionalità viene utilizzata anche da VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilizzato con VMware Site Recovery Manager). In questo caso, i cloni vengono utilizzati per testare il ripristino della replica DR senza interruzioni.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup e recovery con strumenti NetApp come SnapCenter. I cloni delle macchine virtuali vengono utilizzati per verificare le operazioni di backup e per montare un backup delle macchine virtuali in modo che i singoli file possano essere copiati.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">La clonazione offload di ONTAP può essere invocata da VMware, NetApp e da strumenti di terze parti. I cloni che vengono scaricati su ONTAP presentano diversi vantaggi. Nella maggior parte dei casi, sono efficienti in termini di spazio e richiedono storage solo per le modifiche all'oggetto; non vi sono effetti aggiuntivi sulle performance per la lettura e la scrittura e in alcuni casi le performance sono migliorate grazie alla condivisione dei blocchi nelle cache ad alta velocità. Inoltre, consentono di trasferire cicli CPU e i/o di rete dal server ESXi. L'offload delle copie all'interno di un datastore tradizionale utilizzando un volume FlexVol può essere rapido ed efficiente con FlexClone concesso in licenza, ma le copie tra volumi FlexVol potrebbero essere più lente. Se si mantengono i modelli di macchine virtuali come origine dei cloni, è consigliabile posizionarli all'interno del volume datastore (utilizzare cartelle o librerie di contenuti per organizzarli) per cloni veloci ed efficienti in termini di spazio.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">È inoltre possibile clonare un volume o un LUN direttamente in ONTAP per clonare un datastore. Con gli archivi di dati NFS, la tecnologia FlexClone può clonare un intero volume e il clone può essere esportato da ONTAP e montato da ESXi come altro archivio di dati. Per gli archivi di dati VMFS, ONTAP può clonare un LUN all'interno di un volume o di un intero volume, inclusi uno o più LUN. Un LUN contenente un VMFS deve essere mappato a un gruppo di iniziatori ESXi (igroup) e quindi rassegnato da ESXi per essere montato e utilizzato come datastore regolare. Per alcuni casi di utilizzo temporaneo, è possibile montare un VMFS clonato senza disdire. Dopo aver clonato un datastore, è possibile registrare, riconfigurare e personalizzare le macchine virtuali all'interno dell'IT come se fossero macchine virtuali clonate singolarmente.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">In alcuni casi, è possibile utilizzare funzionalità aggiuntive con licenza per migliorare la clonazione, ad esempio SnapRestore per il backup o FlexClone. Queste licenze sono spesso incluse nei bundle di licenze senza costi aggiuntivi. È necessaria una licenza FlexClone per le operazioni di cloning di vVol e per supportare le snapshot gestite di un vVol (offload dall'hypervisor a ONTAP). Una licenza FlexClone può anche migliorare alcuni cloni basati su VAAI se utilizzati all'interno di un datastore/volume (crea copie istantanee ed efficienti in termini di spazio invece di copie a blocchi).  Viene inoltre utilizzato dall'SRA per il test del ripristino di una replica DR e da SnapCenter per le operazioni di clonazione e per sfogliare le copie di backup per ripristinare singoli file.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Configurazione di rete</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Ecco alcuni aspetti da considerare:</block>
  <block id="b3752ab8dec37db2e30f4bf37fbdc112" category="list-text">Separare il traffico di rete dello storage dalle altre reti. È possibile ottenere una rete separata utilizzando una VLAN dedicata o switch separati per lo storage. Se la rete di storage condivide percorsi fisici come gli uplink, potrebbe essere necessario QoS o porte di uplink aggiuntive per garantire una larghezza di banda sufficiente. Non connettere gli host direttamente allo storage; utilizzare gli switch per disporre di percorsi ridondanti e consentire a VMware ha di funzionare senza alcun intervento.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">I frame jumbo possono essere utilizzati se lo si desidera e supportati dalla rete, in particolare quando si utilizza iSCSI. Se vengono utilizzati, assicurarsi che siano configurati in modo identico su tutti i dispositivi di rete, VLAN e così via nel percorso tra lo storage e l'host ESXi. In caso contrario, potrebbero verificarsi problemi di connessione o di prestazioni. La MTU deve essere impostata in modo identico anche sullo switch virtuale ESXi, sulla porta VMkernel e anche sulle porte fisiche o sui gruppi di interfacce di ciascun nodo ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp consiglia di disattivare il controllo del flusso di rete solo sulle porte di rete del cluster all'interno di un cluster ONTAP. NetApp non fornisce altri consigli sulle Best practice per le restanti porte di rete utilizzate per il traffico dati. Attivare o disattivare secondo necessità. Vedere<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> per ulteriori informazioni sul controllo di flusso.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Quando gli array di storage ESXi e ONTAP sono collegati a reti di storage Ethernet, NetApp consiglia di configurare le porte Ethernet a cui questi sistemi si connettono come porte edge RSTP (Rapid Spanning Tree Protocol) o utilizzando la funzione PortFast di Cisco. NetApp consiglia di abilitare la funzione di trunk PortFast Spanning-Tree in ambienti che utilizzano la funzionalità Cisco PortFast e che dispongono di un trunking VLAN 802.1Q abilitato per il server ESXi o gli array di storage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp consiglia le seguenti Best practice per l'aggregazione dei collegamenti:</block>
  <block id="301c77ecc6cdfa6ebde6c8164cffae0c" category="list-text">Utilizzare switch che supportano l'aggregazione di collegamenti di porte su due chassis switch separati utilizzando un approccio a gruppi di aggregazione di collegamenti multi-chassis, ad esempio Virtual PortChannel (VPC) di Cisco.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Disattivare LACP per le porte dello switch connesse a ESXi, a meno che non si utilizzi dvSwitch 5.1 o versioni successive con LACP configurato.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilizzare LACP per creare aggregati di link per sistemi storage ONTAP con gruppi di interfacce multimodali dinamiche con hash IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilizzare un criterio di raggruppamento hash IP su ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">La seguente tabella fornisce un riepilogo degli elementi di configurazione di rete e indica la posizione in cui vengono applicate le impostazioni.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Elemento</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Switch</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Indirizzo IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">No**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Aggregazione dei collegamenti</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Switch virtuale</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">No*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Gruppi di porte VMkernel e VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Controllo di flusso</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (per frame jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Switch virtuale e porta VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Sì (impostato su max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Sì (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Gruppi di failover</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Sì (creare)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Sì (selezionare)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Le LIF SVM si connettono a porte, gruppi di interfacce o interfacce VLAN con VLAN, MTU e altre impostazioni. Tuttavia, le impostazioni non vengono gestite a livello di SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Questi dispositivi dispongono di indirizzi IP propri per la gestione, ma non vengono utilizzati nel contesto dello storage di rete ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">In vSphere, esistono tre modi per utilizzare le LUN dello storage a blocchi:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Con datastore VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Con RDM (raw device mapping)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">Come LUN accessibile e controllato da un iniziatore software da un sistema operativo guest VM</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS è un file system in cluster dalle performance elevate che fornisce datastore che sono pool di storage condivisi. Gli archivi dati VMFS possono essere configurati con LUN a cui si accede utilizzando spazi dei nomi FC, iSCSI, FCoE o NVMe a cui si accede dal protocollo NVMe/FC. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. La dimensione massima del LUN ONTAP è generalmente di 16 TB; pertanto, un datastore VMFS 5 di 64 TB (vedere la prima tabella di questa sezione) viene creato utilizzando quattro LUN da 16 TB (tutti i sistemi array SAN supportano la dimensione massima del LUN VMFS di 64 TB). Poiché l'architettura LUN di ONTAP non ha una profondità di coda singola ridotta, gli archivi dati VMFS in ONTAP possono scalare in maniera relativamente semplice rispetto alle architetture di array tradizionali.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere include il supporto integrato per più percorsi verso i dispositivi storage, definito NMP (Native Multipathing). NMP è in grado di rilevare il tipo di storage per i sistemi storage supportati e di configurare automaticamente lo stack NMP per supportare le funzionalità del sistema storage in uso.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Sia NMP che NetApp ONTAP supportano l'accesso ad unità logica asimmetrico (ALUA) per negoziare percorsi ottimizzati e non ottimizzati. In ONTAP, un percorso ottimizzato per ALUA segue un percorso di dati diretto, utilizzando una porta di destinazione sul nodo che ospita il LUN a cui si accede. ALUA è attivato per impostazione predefinita sia in vSphere che in ONTAP. NMP riconosce il cluster ONTAP come ALUA e utilizza il plug-in del tipo di array di storage ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) e seleziona il plug-in di selezione del percorso round robin <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 supporta fino a 256 LUN e fino a 1,024 percorsi totali verso LUN. I LUN o i percorsi che superano questi limiti non sono visti da ESXi. Supponendo il numero massimo di LUN, il limite di percorso consente quattro percorsi per LUN. In un cluster ONTAP più grande, è possibile raggiungere il limite di percorso prima del limite di LUN. Per risolvere questo limite, ONTAP supporta la mappa LUN selettiva (SLM) nella versione 8.3 e successive.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="e9e7de5d01d51034d9114fd8f16c9144" category="paragraph">SLM limita i nodi che pubblicizzano i percorsi a una determinata LUN. È una Best practice di NetApp avere almeno una LIF per nodo per SVM e utilizzare SLM per limitare i percorsi pubblicizzati al nodo che ospita la LUN e il suo partner ha. Sebbene esistano altri percorsi, essi non vengono pubblicizzati per impostazione predefinita. È possibile modificare i percorsi pubblicizzati con gli argomenti del nodo di reporting add e remove all'interno di SLM. Tenere presente che le LUN create nelle release precedenti alla 8.3 pubblicizzano tutti i percorsi e devono essere modificate solo per pubblicizzare i percorsi alla coppia ha di hosting. Per ulteriori informazioni su SLM, vedere la sezione 5.9 di<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. Il precedente metodo di portset può essere utilizzato anche per ridurre ulteriormente i percorsi disponibili per un LUN. I portset aiutano a ridurre il numero di percorsi visibili attraverso i quali gli iniziatori in un igroup possono vedere le LUN.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM è attivato per impostazione predefinita. A meno che non si utilizzino portset, non è necessaria alcuna configurazione aggiuntiva.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Per i LUN creati prima di Data ONTAP 8.3, applicare manualmente SLM eseguendo<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando per rimuovere i nodi di reporting del LUN e limitare l'accesso del LUN al nodo proprietario del LUN e al partner ha.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">I protocolli a blocchi (iSCSI, FC e FCoE) accedono alle LUN utilizzando ID LUN e numeri di serie, insieme a nomi univoci. FC e FCoE utilizzano nomi in tutto il mondo (WWNN e WWPN), mentre iSCSI utilizza nomi iSCSI qualificati (IQN). Il percorso delle LUN all'interno dello storage è privo di significato per i protocolli a blocchi e non viene presentato in alcun punto del protocollo. Pertanto, un volume che contiene solo LUN non deve essere montato internamente e non è necessario un percorso di giunzione per i volumi che contengono LUN utilizzati negli archivi dati. Il sottosistema NVMe in ONTAP funziona in modo simile.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Altre Best practice da prendere in considerazione:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Assicurarsi che venga creata un'interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP per garantire la massima disponibilità e mobilità. La Best practice PER LE SAN ONTAP consiste nell'utilizzare due porte fisiche e LIF per nodo, una per ciascun fabric. ALUA viene utilizzato per analizzare i percorsi e identificare i percorsi attivi ottimizzati (diretti) rispetto ai percorsi attivi non ottimizzati. ALUA viene utilizzato per FC, FCoE e iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Per le reti iSCSI, utilizzare più interfacce di rete VMkernel su diverse subnet di rete con raggruppamento NIC quando sono presenti più switch virtuali. È inoltre possibile utilizzare più NIC fisiche collegate a più switch fisici per fornire ha e un throughput maggiore. La figura seguente mostra un esempio di connettività multipath. In ONTAP, configurare un gruppo di interfacce single-mode per il failover con due o più collegamenti connessi a due o più switch oppure utilizzare LACP o un'altra tecnologia di aggregazione dei collegamenti con gruppi di interfacce multimodali per fornire ha e i vantaggi dell'aggregazione dei collegamenti.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Se il protocollo CHAP (Challenge-Handshake Authentication Protocol) viene utilizzato in ESXi per l'autenticazione di destinazione, deve essere configurato anche in ONTAP utilizzando la CLI <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) O con System Manager (modificare Initiator Security in Storage &gt; SVM &gt; SVM Settings &gt; Protocols &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilizza i tool ONTAP per VMware vSphere per creare e gestire LUN e igroups. Il plug-in determina automaticamente le WWPN dei server e crea gli igroups appropriati. Inoltre, configura i LUN in base alle Best practice e li associa agli igroups corretti.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">modalità di compatibilità fisica e virtuale</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilizzare con cautela gli RDM poiché possono essere più difficili da gestire e utilizzano anche percorsi limitati come descritto in precedenza. I LUN ONTAP supportano entrambi<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guida alla configurazione degli host NVMe/FC di ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Per ulteriori informazioni sull'utilizzo di NVMe/FC con vSphere 7.0, consulta questo articolo<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> e.<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figura seguente mostra la connettività multipath da un host vSphere a un LUN ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere consente ai clienti di utilizzare array NFS di livello Enterprise per fornire l'accesso simultaneo agli archivi dati a tutti i nodi di un cluster ESXi. Come indicato nella sezione datastore, l'utilizzo di NFS con vSphere offre alcuni vantaggi in termini di facilità d'uso e visibilità dell'efficienza dello storage.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Quando si utilizza ONTAP NFS con vSphere, si consiglia di seguire le seguenti Best practice:</block>
  <block id="c05061b6d3055b83136fa96cb38f0f9a" category="list-text">Utilizzare una singola interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP. Le raccomandazioni precedenti di un LIF per datastore non sono più necessarie. Benché l'accesso diretto (LIF e datastore sullo stesso nodo) sia migliore, non preoccuparti dell'accesso indiretto perché l'effetto sulle performance è generalmente minimo (microsecondi).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware supporta NFSv3 da VMware Infrastructure 3. VSphere 6.0 ha aggiunto il supporto per NFSv4.1, che abilita alcune funzionalità avanzate come la sicurezza Kerberos. Dove NFSv3 utilizza il blocco lato client, NFSv4.1 utilizza il blocco lato server. Anche se un volume ONTAP può essere esportato attraverso entrambi i protocolli, ESXi può essere montato solo attraverso un protocollo. Questo montaggio di protocollo singolo non impedisce ad altri host ESXi di montare lo stesso datastore attraverso una versione diversa. Assicurarsi di specificare la versione del protocollo da utilizzare durante il montaggio in modo che tutti gli host utilizzino la stessa versione e, di conseguenza, lo stesso stile di blocco. Non mischiare versioni NFS tra gli host. Se possibile, utilizzare i profili host per verificare la conformità.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Poiché non esiste alcuna conversione automatica del datastore tra NFSv3 e NFSv4.1, creare un nuovo datastore NFSv4.1 e utilizzare Storage vMotion per migrare le macchine virtuali nel nuovo datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Tool NetApp Interoperability Matrix</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Fare riferimento alle note della tabella di interoperabilità NFS v4.1 nella<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Per i livelli di patch ESXi specifici richiesti per il supporto.</block>
  <block id="24aaa4a688e881fa13d31656a85d40a9" category="list-text">Le policy di esportazione NFS vengono utilizzate per controllare l'accesso da parte degli host vSphere. È possibile utilizzare un criterio con più volumi (datastore). Con NFSv3, ESXi utilizza lo stile di sicurezza sys (UNIX) e richiede l'opzione di montaggio root per eseguire le macchine virtuali. In ONTAP, questa opzione viene definita superutente e, quando viene utilizzata l'opzione superutente, non è necessario specificare l'ID utente anonimo. Tenere presente che le regole dei criteri di esportazione con valori diversi per<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> e.<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Può causare problemi di rilevamento SVM con gli strumenti ONTAP. Ecco un esempio di politica:</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol (protocollo di accesso): Nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Specifiche di corrispondenza del client: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Regola di accesso RO: SIS</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW Access Rule (regola di accesso RW): SIS</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonimo</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superutente: SIS</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Se si utilizza il plug-in NetApp NFS per VMware VAAI, il protocollo deve essere impostato su<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> quando viene creata o modificata la regola dei criteri di esportazione. Il protocollo NFSv4 è necessario per l'offload delle copie VAAI e per specificare il protocollo come<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Include automaticamente le versioni NFSv3 e NFSv4.</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">I volumi del datastore NFS vengono svincoli dal volume root di SVM; pertanto, ESXi deve anche avere accesso al volume root per navigare e montare i volumi del datastore. La policy di esportazione per il volume root e per qualsiasi altro volume in cui la giunzione del volume del datastore è nidificata deve includere una regola o regole per i server ESXi che concedono loro l'accesso in sola lettura. Ecco un esempio di policy per il volume root, utilizzando anche il plug-in VAAI:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Access Protocol: nfs (che include sia nfs3 che nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW Access Rule: Never (miglior sicurezza per il volume root)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutente: SYS (richiesto anche per il volume root con VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilizza i tool ONTAP per VMware vSphere (la Best practice più importante):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilizza i tool ONTAP per VMware vSphere per eseguire il provisioning degli archivi dati, poiché semplifica automaticamente la gestione delle policy di esportazione.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Quando si creano datastore per cluster VMware con il plug-in, selezionare il cluster anziché un singolo server ESX. Questa opzione attiva il montaggio automatico del datastore su tutti gli host del cluster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilizzare la funzione di montaggio del plug-in per applicare i datastore esistenti ai nuovi server.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Quando non si utilizzano gli strumenti ONTAP per VMware vSphere, utilizzare una singola policy di esportazione per tutti i server o per ciascun cluster di server in cui è necessario un controllo aggiuntivo degli accessi.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Sebbene ONTAP offra una struttura flessibile dello spazio dei nomi dei volumi per organizzare i volumi in un albero utilizzando le giunzioni, questo approccio non ha alcun valore per vSphere. Crea una directory per ogni VM nella directory principale dell'archivio dati, indipendentemente dalla gerarchia dello spazio dei nomi dello storage. Pertanto, la Best practice consiste nel montare semplicemente il percorso di giunzione per i volumi per vSphere nel volume root della SVM, che è il modo in cui i tool ONTAP per VMware vSphere prevedono il provisioning dei datastore. La mancanza di percorsi di giunzione nidificati significa anche che nessun volume dipende da un volume diverso dal volume root e che la sua eliminazione o la sua eliminazione, anche intenzionalmente, non influisce sul percorso verso altri volumi.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Una dimensione del blocco di 4K è adatta per le partizioni NTFS negli archivi dati NFS. La figura seguente mostra la connettività da un host vSphere a un datastore NFS ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">La seguente tabella elenca le versioni di NFS e le funzionalità supportate.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funzionalità di vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4,1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion e Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Alta disponibilità</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolleranza agli errori</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profili host</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS dello storage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Controllo i/o dello storage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumi virtuali</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accelerazione hardware (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Autenticazione Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Sì (ottimizzato con vSphere 6.5 e versioni successive per supportare AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Supporto multipathing</block>
  <block id="8a18e0a50dc5755c294477cb16507a6c" category="doc">Gruppi flessibili</block>
  <block id="f9ac230f370c7937167d25093c4ce9b9" category="paragraph">FlexGroup semplifica la creazione di datastore di grandi dimensioni e crea automaticamente una serie di volumi costituenti per ottenere le massime performance da un sistema ONTAP. Utilizza FlexGroup con vSphere per un singolo datastore vSphere scalabile con la potenza di un cluster ONTAP completo.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">Oltre ai test di sistema estesi con carichi di lavoro vSphere, ONTAP 9.8 aggiunge anche un nuovo meccanismo di offload delle copie per gli archivi dati FlexGroup. Questo utilizza un motore di copia migliorato per copiare i file tra i componenti in background, consentendo l'accesso sia all'origine che alla destinazione. Copie multiple utilizzano cloni di file immediatamente disponibili ed efficienti in termini di spazio all'interno di un costituente, se necessario, in base alla scala.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 aggiunge inoltre nuove metriche delle performance basate su file (IOPS, throughput e latenza) per i file FlexGroup, che possono essere visualizzate nei report del dashboard e delle macchine virtuali di ONTAP Tools. Il plug-in ONTAP Tools per VMware vSphere consente inoltre di impostare le regole di qualità del servizio (QoS) utilizzando una combinazione di IOPS massimo e/o minimo. Questi possono essere impostati su tutte le macchine virtuali in un datastore o singolarmente per macchine virtuali specifiche.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Ecco alcune Best practice aggiuntive sviluppate da NetApp:</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Utilizza le impostazioni predefinite di provisioning FlexGroup. Mentre i tool ONTAP per VMware vSphere sono consigliati perché creano e montano il FlexGroup all'interno di vSphere, è possibile utilizzare Gestione di sistema ONTAP o la riga di comando per esigenze speciali. Anche in questo caso, utilizza le impostazioni predefinite, ad esempio il numero di membri costitutivi per nodo, perché questo è ciò che è stato testato con vSphere.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Quando si ridimensiona un datastore FlexGroup, tenere presente che FlexGroup è costituito da più volumi FlexVol più piccoli che creano uno spazio dei nomi più grande. Di conseguenza, dimensionare l'archivio dati in modo che sia almeno 8 volte più grande della macchina virtuale più grande. Ad esempio, se nell'ambiente si dispone di una macchina virtuale da 6 TB, dimensionare il datastore FlexGroup non inferiore a 48 TB.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Consentire a FlexGroup di gestire lo spazio del datastore. Il dimensionamento automatico e il dimensionamento elastico sono stati testati con datastore vSphere. Nel caso in cui il datastore si avvicini alla capacità massima, utilizzare i tool ONTAP per VMware vSphere o un altro tool per ridimensionare il volume FlexGroup. FlexGroup mantiene la capacità e gli inode bilanciati tra i componenti, assegnando la priorità ai file all'interno di una cartella (VM) sullo stesso costituente, se la capacità lo consente.</block>
  <block id="b48b55db402c8085e1d333cad214232b" category="list-text">VMware e NetApp attualmente non supportano un approccio di rete multipath comune. Per NFSv4.1, NetApp supporta pNFS, mentre VMware supporta il trunking di sessione. NFSv3 non supporta percorsi fisici multipli per un volume. Per FlexGroup con ONTAP 9.8, la Best practice consigliata consiste nel consentire ai tool ONTAP per VMware vSphere di eseguire il montaggio singolo, poiché l'effetto dell'accesso indiretto è generalmente minimo (microsecondi). È possibile utilizzare il DNS round-robin per distribuire gli host ESXi attraverso le LIF su nodi diversi in FlexGroup, ma ciò richiederebbe la creazione e il montaggio di FlexGroup senza strumenti ONTAP per VMware vSphere. Le funzionalità di gestione delle performance non sarebbero quindi disponibili.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">Il supporto del datastore FlexGroup vSphere è stato testato fino a 1500 macchine virtuali con la release 9.8.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Utilizzare il plug-in NFS per VMware VAAI per l'offload delle copie. Si noti che, sebbene il cloning sia migliorato all'interno di un datastore FlexGroup, ONTAP non offre vantaggi significativi in termini di performance rispetto alla copia host ESXi durante la copia di macchine virtuali tra volumi FlexVol e/o FlexGroup.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Utilizza gli strumenti ONTAP per VMware vSphere 9.8 per monitorare le performance delle macchine virtuali FlexGroup utilizzando metriche ONTAP (report dashboard e macchine virtuali) e per gestire la qualità del servizio su singole macchine virtuali. Queste metriche non sono attualmente disponibili tramite i comandi o le API ONTAP.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS (IOPS max/min) può essere impostato su singole macchine virtuali o su tutte le macchine virtuali in un datastore in quel momento. L'impostazione della QoS su tutte le macchine virtuali sostituisce le impostazioni separate per ogni macchina virtuale. Le impostazioni non si estendono alle macchine virtuali nuove o migrate in futuro; impostare la QoS sulle nuove macchine virtuali o riapplicare la QoS a tutte le macchine virtuali nel datastore.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Il plug-in SnapCenter per VMware vSphere release 4.4 supporta il backup e il ripristino delle macchine virtuali in un datastore FlexGroup sul sistema di storage primario. Mentre SnapMirror può essere utilizzato manualmente per replicare un FlexGroup su un sistema secondario, SCV 4.4 non gestisce le copie secondarie.</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">Qualità del servizio (QoS)</block>
  <block id="8fdd6138f63aa45f1c51b48d9a01b19d" category="paragraph">I limiti di throughput sono utili per controllare i carichi di lavoro sconosciuti o di test prima della distribuzione per assicurarsi che non influiscano su altri carichi di lavoro. Possono anche essere utilizzati per limitare un carico di lavoro ingombrante dopo l'identificazione. Sono supportati anche i livelli minimi di servizio basati sugli IOPS per fornire performance costanti per gli oggetti SAN in ONTAP 9.2 e per gli oggetti NAS in ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Con un datastore NFS, è possibile applicare una policy di QoS all'intero volume FlexVol o ai singoli file VMDK al suo interno. Con gli archivi di dati VMFS che utilizzano LUN ONTAP, è possibile applicare i criteri di qualità del servizio al volume FlexVol che contiene LUN o LUN singoli, ma non singoli file VMDK, poiché ONTAP non è consapevole del file system VMFS. Quando si utilizza vVol, è possibile impostare la QoS minima e/o massima su singole macchine virtuali utilizzando il profilo di capacità dello storage e la policy di storage delle macchine virtuali.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Il limite massimo di throughput QoS su un oggetto può essere impostato in Mbps e/o IOPS. Se vengono utilizzati entrambi, il primo limite raggiunto viene applicato da ONTAP. Un carico di lavoro può contenere più oggetti e una policy QoS può essere applicata a uno o più carichi di lavoro. Quando una policy viene applicata a più carichi di lavoro, i carichi di lavoro condividono il limite totale della policy. Gli oggetti nidificati non sono supportati (ad esempio, i file all'interno di un volume non possono avere una propria policy). I valori minimi di QoS possono essere impostati solo in IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">I seguenti strumenti sono attualmente disponibili per la gestione delle policy di qualità del servizio ONTAP e per applicarle agli oggetti:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">Gestore di sistema di ONTAP</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit di strumenti NetApp PowerShell per ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Strumenti ONTAP per il provider VMware vSphere VASA</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Per assegnare un criterio QoS a un VMDK su NFS, attenersi alle seguenti linee guida:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La policy deve essere applicata a<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> che contiene l'immagine effettiva del disco virtuale, non il<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (file di descrizione del disco virtuale) o.<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (File descrittore VM).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">Non applicare policy ad altri file di macchine virtuali, ad esempio file di swap virtuali <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Quando si utilizza il client Web vSphere per trovare i percorsi di file (datastore &gt; file), tenere presente che combina le informazioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> e.<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> e mostra semplicemente un file con il nome di<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> ma le dimensioni di<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Aggiungi<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> nel nome del file per ottenere il percorso corretto.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Per assegnare una policy di QoS a un LUN, inclusi VMFS e RDM, è possibile ottenere la SVM di ONTAP (visualizzata come Vserver), il percorso del LUN e il numero di serie dal menu dei sistemi storage nella home page degli strumenti ONTAP per VMware vSphere. Seleziona il sistema storage (SVM), quindi gli oggetti correlati &gt; SAN.  Utilizzare questo approccio quando si specifica la qualità del servizio utilizzando uno degli strumenti ONTAP.</block>
  <block id="cc97a1a52adc0bd6f188de1545eea887" category="paragraph">La QoS massima e minima può essere facilmente assegnata a una macchina virtuale basata su vVol con gli strumenti ONTAP per VMware vSphere o la console di storage virtuale 7.1 e versioni successive. Durante la creazione di un profilo di capacità storage per il container vVol, specifica un valore IOPS max e/o min in termini di performance, quindi fai riferimento a questo SCP con la policy storage delle macchine virtuali. Utilizzare questo criterio quando si crea la macchina virtuale o si applica il criterio a una macchina virtuale esistente.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Gli archivi dati FlexGroup offrono funzionalità QoS avanzate quando si utilizzano gli strumenti ONTAP per VMware vSphere 9.8 e versioni successive. È possibile impostare facilmente la QoS su tutte le macchine virtuali di un datastore o su macchine virtuali specifiche. Per ulteriori informazioni, consultare la sezione FlexGroup di questo report.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP e SIOC VMware</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">Il QoS di ONTAP e il controllo i/o dello storage VMware vSphere sono tecnologie complementari che vSphere e gli amministratori dello storage possono utilizzare insieme per gestire le performance delle macchine virtuali vSphere ospitate su sistemi che eseguono il software ONTAP. Ogni strumento ha i propri punti di forza, come mostrato nella tabella seguente. A causa dei diversi ambiti di VMware vCenter e ONTAP, alcuni oggetti possono essere visti e gestiti da un sistema e non dall'altro.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Proprietà</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Se attivo</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La policy è sempre attiva</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Attivo quando esiste un conflitto (latenza dell'archivio dati oltre la soglia)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Tipo di unità</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mbps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, condivisioni</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">VCenter o ambito applicativo</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Più ambienti vCenter, altri hypervisor e applicazioni</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Singolo server vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Impostare QoS su VM?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK solo su NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK su NFS o VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Impostare QoS su LUN (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Impostare la qualità del servizio su LUN (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Impostare QoS sul volume (datastore NFS)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Impostare QoS su SVM (tenant)?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">Approccio basato su policy?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Sì; può essere condiviso da tutti i carichi di lavoro della policy o applicato in toto a ciascun carico di lavoro della policy.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Sì, con vSphere 6.5 e versioni successive.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licenza richiesta</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Incluso con ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware Storage Distributed Resource Scheduler (SDR) è una funzionalità vSphere che consente di posizionare le macchine virtuali sullo storage in base alla latenza i/o corrente e all'utilizzo dello spazio. Quindi, sposta le VM o i VMDK senza interruzioni tra gli archivi dati in un cluster di datastore (noto anche come pod), selezionando il migliore datastore in cui posizionare le VM o i VMDK nel cluster di datastore. Un cluster di datastore è un insieme di datastore simili che vengono aggregati in una singola unità di consumo dal punto di vista dell'amministratore di vSphere.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">Le API VMware vSphere per Storage Awareness (VASA) semplificano la configurazione dei datastore da parte di un amministratore dello storage con funzionalità ben definite e consentono all'amministratore delle macchine virtuali di utilizzarle quando necessario per eseguire il provisioning delle macchine virtuali senza dover interagire tra loro. Vale la pena di dare un'occhiata a questo approccio per scoprire in che modo può semplificare le operazioni di virtualizzazione dello storage ed evitare un lavoro molto banale.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migrazione e backup del cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Un altro punto di forza di ONTAP è l'ampio supporto per il cloud ibrido, che unisce i sistemi nel tuo cloud privato on-premise con funzionalità di cloud pubblico. Ecco alcune soluzioni cloud NetApp che possono essere utilizzate insieme a vSphere:</block>
  <block id="e18ab5f123ad4ce169202479f07f3f0f" category="list-text">*Cloud Volumes* NetApp Cloud Volumes Service per Amazon Web Services o Google Cloud Platform e Azure NetApp Files per ANF offrono servizi di storage gestiti multiprotocollo dalle performance elevate negli ambienti di cloud pubblico leader. Possono essere utilizzati direttamente dai guest delle macchine virtuali VMware Cloud.</block>
  <block id="9625e7e8b7b951b4ac75beee0139b407" category="list-text">*Cloud Volumes ONTAP.* il software per la gestione dei dati NetApp Cloud Volumes ONTAP offre controllo, protezione, flessibilità ed efficienza ai tuoi dati sul cloud di tua scelta. Cloud Volumes ONTAP è un software per la gestione dei dati nativo del cloud basato sul software di storage NetApp ONTAP. Utilizzare insieme a Cloud Manager per implementare e gestire le istanze di Cloud Volumes ONTAP insieme ai sistemi ONTAP on-premise. Sfrutta le funzionalità NAS e SAN iSCSI avanzate insieme a una gestione dei dati unificata, incluse le snapshot e la replica SnapMirror.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Servizi cloud.* Usa Cloud Backup Service o SnapMirror Cloud per proteggere i dati dai sistemi on-premise utilizzando lo storage di cloud pubblico. Cloud Sync consente di migrare e mantenere sincronizzati i dati tra NAS, archivi di oggetti e storage Cloud Volumes Service.</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Memorizzazione di più snapshot delle macchine virtuali</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool offre tiering rapido e semplice per i dati ONTAP. È possibile migrare i blocchi cold in un archivio di oggetti nei cloud pubblici o in un archivio di oggetti StorageGRID privato e vengono richiamati automaticamente quando si accede nuovamente ai dati ONTAP. Oppure utilizzare il Tier di oggetti come terzo livello di protezione per i dati già gestiti da SnapVault. Questo approccio può consentirti di farlo<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> Sui sistemi storage ONTAP primari e/o secondari.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilizza lo storage software-defined di NetApp per estendere il tuo cloud privato attraverso Internet a sedi e uffici remoti, dove puoi utilizzare ONTAP Select per supportare i servizi di file e blocchi e le stesse funzionalità di gestione dei dati vSphere presenti nel tuo data center aziendale.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Quando si progettano le applicazioni basate su macchine virtuali, considerare la futura mobilità del cloud. Ad esempio, invece di mettere insieme file di applicazioni e dati, utilizza un'esportazione LUN o NFS separata per i dati. Ciò consente di migrare la macchina virtuale e i dati separatamente ai servizi cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Crittografia per i dati vSphere</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Oggi, la necessità di proteggere i dati inattivi è in aumento grazie alla crittografia. Sebbene l'attenzione iniziale fosse concentrata sulle informazioni finanziarie e sanitarie, c'è sempre più interesse a proteggere tutte le informazioni, che siano archiviate in file, database o altri tipi di dati.</block>
  <block id="f131c8f285a9ebc44140235877aecbe5" category="paragraph">I sistemi che eseguono il software ONTAP semplificano la protezione dei dati con la crittografia a riposo. NetApp Storage Encryption (NSE) utilizza dischi con crittografia automatica e ONTAP per proteggere i dati SAN e NAS. NetApp offre inoltre NetApp Volume Encryption e NetApp aggregate Encryption come approccio semplice e basato su software per crittografare i volumi su qualsiasi disco. Questa crittografia software non richiede unità disco speciali o gestori di chiavi esterne ed è disponibile per i clienti ONTAP senza costi aggiuntivi. È possibile eseguire l'upgrade e iniziare a utilizzarlo senza alcuna interruzione per i client o le applicazioni e sono validati in base allo standard FIPS 140-2 livello 1, incluso il gestore delle chiavi integrato.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Esistono diversi approcci per la protezione dei dati delle applicazioni virtualizzate in esecuzione su VMware vSphere. Un approccio consiste nel proteggere i dati con il software all'interno della macchina virtuale a livello di sistema operativo guest. Gli hypervisor più recenti, come vSphere 6.5, ora supportano la crittografia a livello di VM come alternativa. Tuttavia, la crittografia del software NetApp è semplice e offre i seguenti vantaggi:</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Nessun effetto sulla CPU del server virtuale.* alcuni ambienti di server virtuali richiedono ogni ciclo di CPU disponibile per le proprie applicazioni, tuttavia i test hanno dimostrato che sono necessarie fino a 5 risorse di CPU con crittografia a livello di hypervisor. Anche se il software di crittografia supporta il set di istruzioni AES-NI di Intel per l'offload del carico di lavoro di crittografia (come fa la crittografia del software NetApp), questo approccio potrebbe non essere fattibile a causa del requisito di nuove CPU che non sono compatibili con i server meno recenti.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Onboard Key Manager incluso.* la crittografia software NetApp include un gestore delle chiavi integrato senza costi aggiuntivi, il che rende semplice iniziare senza server di gestione delle chiavi ad alta disponibilità complessi da acquistare e utilizzare.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Nessun effetto sull'efficienza dello storage.* le tecniche di efficienza dello storage, come deduplica e compressione, sono ampiamente utilizzate oggi e sono fondamentali per utilizzare i supporti su disco flash in modo conveniente. Tuttavia, i dati crittografati non possono in genere essere deduplicati o compressi. La crittografia dello storage e dell'hardware NetApp opera a un livello inferiore e consente l'utilizzo completo delle funzionalità di efficienza dello storage NetApp leader del settore, a differenza di altri approcci.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Crittografia granulare semplice del datastore.* con NetApp Volume Encryption, ogni volume ottiene la propria chiave AES a 256 bit. Se è necessario modificarlo, è possibile farlo con un singolo comando. Questo approccio è ideale se hai più tenant o hai bisogno di dimostrare una crittografia indipendente per diversi reparti o applicazioni. Questa crittografia viene gestita a livello di datastore, il che è molto più semplice della gestione di singole macchine virtuali.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">Iniziare a utilizzare la crittografia del software è semplice. Una volta installata la licenza, è sufficiente configurare il gestore delle chiavi integrato specificando una passphrase e quindi creare un nuovo volume o spostare un volume lato storage per abilitare la crittografia. NetApp sta lavorando per aggiungere un supporto più integrato per le funzionalità di crittografia nelle versioni future dei suoi strumenti VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager offre visibilità sulle macchine virtuali dell'infrastruttura virtuale e consente il monitoraggio e la risoluzione dei problemi relativi a storage e performance nell'ambiente virtuale.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Una tipica implementazione di un'infrastruttura virtuale su ONTAP include diversi componenti distribuiti tra livelli di calcolo, rete e storage. Eventuali ritardi nelle performance in un'applicazione VM potrebbero verificarsi a causa di una combinazione di latenze affrontate dai vari componenti nei rispettivi layer.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La seguente schermata mostra la vista macchine virtuali Active IQ Unified Manager.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager presenta il sottosistema sottostante di un ambiente virtuale in una vista topologica per determinare se si è verificato un problema di latenza nel nodo di calcolo, nella rete o nello storage. La vista evidenzia anche l'oggetto specifico che causa il ritardo delle performance per l'adozione di misure correttive e la risoluzione del problema sottostante.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La seguente schermata mostra la topologia espansa di AIQUM.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datastore e protocolli</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Per collegare VMware vSphere a datastore su un sistema con software ONTAP vengono utilizzati sette protocolli:</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4,1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP e iSCSI sono protocolli a blocchi che utilizzano il file system della macchina virtuale vSphere per memorizzare le macchine virtuali all'interno di LUN ONTAP o spazi dei nomi NVMe contenuti in un volume ONTAP FlexVol. A partire da vSphere 7.0, VMware non supporta più il software FCoE negli ambienti di produzione. NFS è un protocollo di file che inserisce le macchine virtuali in datastore (che sono semplicemente volumi ONTAP) senza la necessità di VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS possono essere utilizzati anche direttamente da un sistema operativo guest a ONTAP.</block>
  <block id="2b19cb432f68f1ba3dc7b0f175a14778" category="inline-link">Valori massimi di configurazione VMware</block>
  <block id="f8ca1b19553d4c965e40e9eeb1eb5aca" category="paragraph">Le tabelle seguenti presentano le funzionalità tradizionali del datastore supportate da vSphere con ONTAP. Queste informazioni non si applicano agli archivi dati vVol, ma in genere si applicano a vSphere 6.x e alle versioni successive che utilizzano le versioni supportate di ONTAP. È inoltre possibile consultare<block ref="61b579b455015dfa2bbf16bf62f07f93" category="inline-link-rx"></block> Per release specifiche di vSphere per confermare limiti specifici.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Funzionalità</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formato</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS o RDM (raw device mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS o RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N/A.</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Numero massimo di datastore o LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN per host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN per server</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 namespeces per server</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 supporti
Default NFS (NFS predefinito). MaxVolumes è 8. Utilizza i tool ONTAP per VMware vSphere per aumentare fino a 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Dimensione massima datastore</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB di volume FlexVol o superiore con volume FlexGroup</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Dimensione massima del file del datastore</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62TB con ONTAP 9.12.1P2 e versioni successive</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondità ottimale della coda per LUN o file system</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Negoziazione automatica</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Fare riferimento a NFS.MaxQueueDefelse in<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">La seguente tabella elenca le funzionalità supportate relative allo storage VMware.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware ha</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDR (Storage Distributed Resource Scheduler)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Software di backup abilitato VADP (VMware vStorage API for Data Protection)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) o clustering di failover all'interno di una macchina virtuale</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Sì*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non supportato</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolleranza agli errori</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">Solo V3**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Macchine virtuali con thin provisioning (dischi virtuali)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Sì
Si tratta dell'impostazione predefinita per tutte le macchine virtuali su NFS quando non si utilizza VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Multipathing nativo di VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Sì, utilizzando il nuovo plug-in ad alte prestazioni (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">La tabella seguente elenca le funzionalità di gestione dello storage ONTAP supportate.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Deduplica dei dati</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Risparmi nell'array</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Risparmi nel datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Thin provisioning</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore o RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Ridimensiona datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Crescere solo</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Crescita, crescita automatica e riduzione</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-in SnapCenter per applicazioni Windows e Linux (in guest)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Monitoraggio e configurazione dell'host con gli strumenti ONTAP per VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisioning con gli strumenti ONTAP per VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">La tabella seguente elenca le funzionalità di backup supportate.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">Istantanee di ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM supportato da backup replicati</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accesso all'immagine VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Software di backup abilitato per VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Software di backup abilitato VADP, vSphere Client e il browser datastore di vSphere Web Client</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accesso a livello di file VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Software di backup abilitato VADP, solo Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Software di backup abilitato VADP e applicazioni di terze parti</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularità NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore o macchina virtuale</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configurazione per il clustering di failover di Windows Server</block>
  <block id="45f7e6f7f6f0f4093754d7d48810e17f" category="paragraph">*NetApp consiglia di utilizzare iSCSI in-guest per cluster Microsoft piuttosto che VMDK abilitati per il multi-writer in un datastore VMFS. Questo approccio è completamente supportato da Microsoft e VMware, offre grande flessibilità con ONTAP (SnapMirror per sistemi ONTAP on-premise o nel cloud), è facile da configurare e automatizzare e può essere protetto con SnapCenter. VSphere 7 aggiunge una nuova opzione VMDK in cluster. Si tratta di un'operazione diversa dai VMDK abilitati per il multi-writer, che richiede un datastore presentato tramite il protocollo FC che ha attivato il supporto VMDK in cluster. Sono previste altre restrizioni. Vedere VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentazione per le linee guida di configurazione.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**I datastore che utilizzano NVMe-of e NFS v4.1 richiedono la replica vSphere. La replica basata su array non è supportata da SRM.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Selezione di un protocollo di storage</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">I sistemi che eseguono il software ONTAP supportano tutti i principali protocolli di storage, in modo che i clienti possano scegliere ciò che meglio si adatta al proprio ambiente, a seconda dell'infrastruttura di rete esistente e pianificata e delle competenze dello staff. I test di NetApp hanno generalmente mostrato poca differenza tra i protocolli eseguiti a velocità di linea simili, pertanto è meglio concentrarsi sull'infrastruttura di rete e sulle funzionalità del personale rispetto alle performance del protocollo raw.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">I seguenti fattori potrebbero essere utili per valutare una scelta di protocollo:</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Ambiente attuale del cliente.* sebbene i team IT siano generalmente esperti nella gestione dell'infrastruttura IP Ethernet, non tutti sono esperti nella gestione di un fabric SAN FC. Tuttavia, l'utilizzo di una rete IP generica non progettata per il traffico di storage potrebbe non funzionare bene. Prendi in considerazione l'infrastruttura di rete in uso, gli eventuali miglioramenti pianificati e le competenze e la disponibilità del personale per gestirli.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Facilità di configurazione.* oltre alla configurazione iniziale del fabric FC (switch e cablaggio aggiuntivi, zoning e verifica dell'interoperabilità di HBA e firmware), i protocolli a blocchi richiedono anche la creazione e la mappatura di LUN e il rilevamento e la formattazione da parte del sistema operativo guest. Una volta creati ed esportati, i volumi NFS vengono montati dall'host ESXi e pronti all'uso. NFS non dispone di specifiche qualifiche hardware o firmware da gestire.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Facilità di gestione.* con i protocolli SAN, se è necessario più spazio, sono necessari diversi passaggi, tra cui la crescita di un LUN, la ricerca di nuove dimensioni e la crescita del file system). Sebbene sia possibile aumentare un LUN, non è possibile ridurre le dimensioni di un LUN e il ripristino dello spazio inutilizzato può richiedere ulteriore impegno. NFS consente un facile dimensionamento in alto o in basso e questo ridimensionamento può essere automatizzato dal sistema storage. LA SAN offre la bonifica dello spazio attraverso i comandi TRIM/UNMAP del sistema operativo guest, consentendo di restituire spazio dai file cancellati all'array. Questo tipo di recupero dello spazio è più difficile con gli archivi dati NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Trasparenza dello spazio di storage.* l'utilizzo dello storage è in genere più semplice da visualizzare negli ambienti NFS perché il thin provisioning restituisce immediatamente risparmi. Allo stesso modo, i risparmi di deduplica e clonazione sono immediatamente disponibili per altre macchine virtuali nello stesso datastore o per altri volumi di sistemi storage. La densità delle macchine virtuali è in genere maggiore anche in un datastore NFS, che può migliorare i risparmi della deduplica e ridurre i costi di gestione grazie a un numero inferiore di datastore da gestire.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Layout del datastore</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">L'implementazione di vSphere con datastore NFS di ONTAP offre un'implementazione facile da gestire e dalle performance elevate che offre rapporti VM-datastore che non possono essere ottenuti con protocolli di storage basati su blocchi. Questa architettura può comportare un aumento di dieci volte della densità degli archivi dati con una conseguente riduzione del numero di archivi dati. Anche se un datastore più grande può trarre beneficio dall'efficienza dello storage e offrire vantaggi operativi, è consigliabile utilizzare almeno quattro datastore (volumi FlexVol) per memorizzare le macchine virtuali su un singolo controller ONTAP per ottenere le massime prestazioni dalle risorse hardware. Questo approccio consente inoltre di stabilire datastore con policy di recovery diverse. Alcuni possono essere sottoposti a backup o replicati più frequentemente rispetto ad altri in base alle esigenze aziendali. I volumi FlexGroup non richiedono più datastore per le performance, in quanto sono scalabili in base alla progettazione.</block>
  <block id="e15ed0ec7af4278259b7618024b3e7ce" category="list-text">NetApp consiglia di utilizzare i volumi FlexVol per la maggior parte dei datastore NFS. A partire da ONTAP 9,8, l'utilizzo dei volumi FlexGroup è supportato anche come datastore e generalmente è consigliato per alcuni casi d'utilizzo. Gli altri container di storage ONTAP, come i qtree, non sono generalmente consigliati, in quanto al momento non sono supportati dai tool ONTAP per VMware vSphere o dal plug-in NetApp SnapCenter per VMware vSphere. Ciò detto, implementare datastore come qtree multiple in un singolo volume potrebbe essere utile per ambienti altamente automatizzati, che possono trarre beneficio da quote a livello di datastore o cloni dei file delle macchine virtuali.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Una buona dimensione per un datastore di volumi FlexVol è di circa 4TB - 8TB. Queste dimensioni rappresentano un buon punto di equilibrio per le performance, la facilità di gestione e la protezione dei dati. Inizia in piccolo (ad esempio, 4 TB) e fai crescere il datastore in base alle necessità (fino a un massimo di 100 TB). I datastore più piccoli sono più veloci da ripristinare dal backup o dopo un disastro e possono essere spostati rapidamente nel cluster. Prendere in considerazione l'utilizzo della funzione di dimensionamento automatico di ONTAP per aumentare e ridurre automaticamente il volume in base alle modifiche dello spazio utilizzato. Per impostazione predefinita, i tool ONTAP per il provisioning guidato degli archivi dati VMware vSphere utilizzano la dimensione automatica per i nuovi archivi dati. È possibile personalizzare ulteriormente le soglie di aumento e riduzione e le dimensioni massime e minime con System Manager o la riga di comando.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">In alternativa, gli archivi dati VMFS possono essere configurati con LUN accessibili da FC, iSCSI o FCoE. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. Gli archivi di dati VMFS possono avere dimensioni fino a 64 TB e sono costituiti da un massimo di 32 LUN da 2 TB (VMFS 3) o un singolo LUN da 64 TB (VMFS 5). La dimensione massima del LUN ONTAP è 16 TB sulla maggior parte dei sistemi e 128 TB sui sistemi all-SAN-array. Pertanto, è possibile creare un datastore VMFS 5 di dimensioni massime sulla maggior parte dei sistemi ONTAP utilizzando quattro LUN da 16 TB. Sebbene i carichi di lavoro con i/o elevati possano offrire un vantaggio in termini di performance con più LUN (con sistemi FAS o AFF high-end), questo vantaggio è compensato dalla complessità di gestione aggiunta per creare, gestire e proteggere le LUN degli archivi dati e dall'aumento del rischio di disponibilità. In genere, NetApp consiglia di utilizzare un singolo LUN di grandi dimensioni per ciascun datastore e solo se è necessario andare oltre un datastore da 16 TB. Come per NFS, puoi utilizzare più datastore (volumi) per massimizzare le performance su un singolo controller ONTAP.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">I sistemi operativi guest precedenti necessitavano di un allineamento con il sistema storage per ottenere le migliori performance ed efficienza dello storage. Tuttavia, i moderni sistemi operativi supportati dai vendor dei distributori Microsoft e Linux come Red Hat non richiedono più modifiche per allineare la partizione del file system con i blocchi del sistema storage sottostante in un ambiente virtuale. Se si utilizza un sistema operativo precedente che potrebbe richiedere l'allineamento, cercare gli articoli nella Knowledge base del supporto NetApp utilizzando "allineamento delle macchine virtuali" o richiedere una copia di TR-3747 a un contatto commerciale o partner di NetApp.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Evitare l'uso di utilità di deframmentazione all'interno del sistema operativo guest, poiché ciò non offre vantaggi in termini di prestazioni e influisce sull'efficienza dello storage e sull'utilizzo dello spazio snapshot. È inoltre consigliabile disattivare l'indicizzazione della ricerca nel sistema operativo guest per i desktop virtuali.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ha guidato il settore con innovative funzionalità di efficienza dello storage, che ti consentono di sfruttare al massimo lo spazio su disco utilizzabile. I sistemi AFF aumentano ulteriormente questa efficienza con la deduplica e la compressione inline predefinite. I dati vengono deduplicati in tutti i volumi in un aggregato, quindi non è più necessario raggruppare sistemi operativi simili e applicazioni simili in un singolo datastore per massimizzare i risparmi.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Database Oracle su ONTAP</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">I dischi di prima classe (o dischi virtuali migliorati) consentono dischi gestiti da vCenter indipendenti da una macchina virtuale con vSphere 6.5 e versioni successive. Anche se gestiti principalmente da API, possono essere utili con vVol, soprattutto se gestiti da OpenStack o Kubernetes tools. Sono supportati da ONTAP e dai tool ONTAP per VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migrazione di datastore e macchine virtuali</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Quando si esegue la migrazione delle macchine virtuali da un datastore esistente su un altro sistema storage a ONTAP, è necessario tenere presente alcune procedure:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilizzare Storage vMotion per spostare la maggior parte delle macchine virtuali su ONTAP. Questo approccio non solo non è disgregativo per l'esecuzione di macchine virtuali, ma consente anche funzionalità di efficienza dello storage ONTAP come la deduplica inline e la compressione per elaborare i dati durante la migrazione. Prendere in considerazione l'utilizzo delle funzionalità di vCenter per selezionare più macchine virtuali dall'elenco di inventario e quindi pianificare la migrazione (utilizzare il tasto Ctrl mentre si fa clic su azioni) in un momento appropriato.</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Sebbene sia possibile pianificare con attenzione una migrazione verso datastore di destinazione appropriati, spesso è più semplice eseguire la migrazione in blocco e poi organizzarla in un secondo momento. Potresti voler utilizzare questo approccio per guidare la migrazione verso datastore diversi, se hai esigenze specifiche di data Protection, come ad esempio diverse pianificazioni Snapshot.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La maggior parte delle macchine virtuali e del relativo storage può essere migrata durante l'esecuzione (a caldo), ma la migrazione dello storage collegato (non nel datastore) come gli ISO, i LUN o i volumi NFS da un altro sistema storage potrebbe richiedere la migrazione a freddo.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="096f2185af16e07c387a7fbe50df957a" category="list-text">Le macchine virtuali che richiedono una migrazione più accurata includono database e applicazioni che utilizzano lo storage collegato. In generale, considerare l'utilizzo degli strumenti dell'applicazione per gestire la migrazione. Per Oracle, prendere in considerazione l'utilizzo di strumenti Oracle come RMAN o ASM per migrare i file di database. Vedere<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> per ulteriori informazioni. Allo stesso modo, per SQL Server, prendere in considerazione l'utilizzo di SQL Server Management Studio o di strumenti NetApp come SnapManager per SQL Server o SnapCenter.</block>
  <block id="09485b54473eee31422696bf0217d714" category="paragraph">La Best practice più importante per l'utilizzo di vSphere con i sistemi che eseguono il software ONTAP consiste nell'installare e utilizzare i tool ONTAP per il plug-in di VMware vSphere (precedentemente noto come console di storage virtuale). Questo plug-in vCenter semplifica la gestione dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi di dati e ottimizza le impostazioni degli host ESXi per i timeout multipath e HBA (descritti nell'Appendice B). Poiché si tratta di un plug-in vCenter, è disponibile per tutti i client web vSphere che si connettono al server vCenter.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">Il plug-in consente inoltre di utilizzare altri strumenti ONTAP in ambienti vSphere. Il prodotto consente di installare il plug-in NFS per VMware VAAI, che consente l'offload delle copie in ONTAP per le operazioni di cloning delle macchine virtuali, lo space reservation per i file di dischi virtuali con thick provisioning e l'offload delle snapshot ONTAP.</block>
  <block id="2e0fa230911ceec131e12fe7c87fc01e" category="paragraph">Il plug-in è anche l'interfaccia di gestione di molte funzionalità del provider VASA per ONTAP, con supporto per la gestione basata su policy di storage con vVol. Una volta registrati i tool ONTAP per VMware vSphere, utilizzali per creare profili di capacità storage, mapparli allo storage e garantire la conformità dei datastore con i profili nel tempo. Il provider VASA fornisce anche un'interfaccia per creare e gestire datastore vVol.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">In generale, NetApp consiglia di utilizzare i tool ONTAP per l'interfaccia di VMware vSphere all'interno di vCenter per eseguire il provisioning di datastore tradizionali e vVol per garantire il rispetto delle Best practice.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Rete generale</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configurazione delle impostazioni di rete quando si utilizza vSphere con sistemi che eseguono il software ONTAP è semplice e simile ad altre configurazioni di rete. Ecco alcuni aspetti da considerare:</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Utilizzare switch che supportano l'aggregazione di collegamenti di porte su due chassis switch separati utilizzando un approccio a gruppi di aggregazione di collegamenti multi-chassis, ad esempio Virtual PortChannel (VPC) di Cisco.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Gestione della rete</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Utilizza LACP per creare aggregati di link per sistemi di storage ONTAP con gruppi di interfacce dinamiche multimode con hash porta o IP. Fare riferimento a.<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> per ulteriori indicazioni.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Utilizzare un criterio di raggruppamento hash IP su ESXi quando si utilizza l'aggregazione di collegamenti statici (ad esempio, EtherChannel) e vSwitch standard o l'aggregazione di collegamenti basata su LACP con gli switch distribuiti vSphere. Se non si utilizza l'aggregazione dei collegamenti, utilizzare invece "Route based on the origining virtual port ID" (percorso basato sull'ID della porta virtuale di origine).</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">Volumi FlexGroup</block>
  <block id="bf985cdd1506d49ea0773c8997e0b723" category="paragraph">ONTAP 9,8 aggiunge il supporto per datastore di volumi FlexGroup in vSphere, oltre al supporto dei tool ONTAP per VMware vSphere e del plug-in SnapCenter per VMware vSphere. FlexGroup semplifica la creazione di datastore di grandi dimensioni e crea automaticamente una serie di volumi costituenti per ottenere le massime performance da un sistema ONTAP. Utilizza FlexGroup con vSphere se desideri un singolo datastore vSphere scalabile con la potenza di un cluster ONTAP completo o se disponi di carichi di lavoro di cloning molto grandi che possono sfruttare il nuovo meccanismo di cloning di FlexGroup.</block>
  <block id="83bcea036e70c0f011b083b2325b7a4b" category="paragraph">Oltre ai test di sistema estesi con carichi di lavoro vSphere, ONTAP 9.8 aggiunge anche un nuovo meccanismo di offload delle copie per gli archivi dati FlexGroup. Questo utilizza un motore di copia aggiornato che utilizza i primi cloni per popolare una cache locale in ogni volume costituente. La cache locale viene quindi utilizzata per creare rapidamente istanze dei cloni delle macchine virtuali on-demand.</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Considerare il seguente scenario:</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Hai creato un nuovo FlexGroup con 8 componenti</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">Il timeout della cache per il nuovo FlexGroup è impostato su 160 minuti</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">In questo scenario, i primi 8 cloni da completare saranno copie complete, non cloni di file locali. Qualsiasi clonazione aggiuntiva di tale macchina virtuale prima della scadenza del timeout di 160 secondi utilizzerà il motore di clonazione file all'interno di ciascun componente in modo round-robin per creare copie quasi immediate distribuite uniformemente tra i volumi costituenti.</block>
  <block id="b368b4dbd46dd778776d405dc46d2033" category="paragraph">Ogni nuovo processo di clonazione che un volume riceve ripristina il timeout. Se un volume costituente nel FlexGroup di esempio non riceve una richiesta di clone prima del timeout, la cache di quella particolare VM verrà cancellata e il volume dovrà essere popolato di nuovo. Inoltre, se l'origine del clone originale cambia (ad esempio, è stato aggiornato il modello), la cache locale di ciascun componente verrà invalidata per evitare conflitti. La cache è regolabile e può essere impostata in base alle esigenze dell'ambiente.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">In ambienti in cui non è possibile sfruttare al meglio la cache FlexGroup, ma è comunque necessario un rapido cloning cross-volume, prendere in considerazione l'utilizzo di vVol. Il cloning tra volumi con vVol è molto più rapido rispetto ai datastore tradizionali, senza fare affidamento su una cache.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI: Come funziona il caching con i volumi FlexGroup?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Per ulteriori informazioni sull'utilizzo di FlexGroup con VAAI, fare riferimento a questo articolo della KB:<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="eafcbe529f542610c50d02e4a2fffcd6" category="paragraph">ONTAP 9,8 aggiunge inoltre nuove metriche di performance basate su file (IOPS, throughput e latenza) per i file di volumi FlexGroup. Queste metriche possono essere visualizzate nei tool ONTAP per la dashboard e i report delle macchine virtuali di VMware vSphere. Il plug-in ONTAP Tools per VMware vSphere consente inoltre di impostare le regole di qualità del servizio (QoS) utilizzando una combinazione di IOPS massimo e/o minimo. Questi possono essere impostati su tutte le macchine virtuali in un datastore o singolarmente per macchine virtuali specifiche.</block>
  <block id="b8c631b88d7be5f1105be2f8c7ff3213" category="list-text">Utilizzare le impostazioni predefinite per il provisioning dei volumi FlexGroup. Mentre i tool ONTAP per VMware vSphere sono consigliati perché creano e montano il FlexGroup all'interno di vSphere, è possibile utilizzare Gestione di sistema ONTAP o la riga di comando per esigenze speciali. Anche in questo caso, utilizzare le impostazioni predefinite, ad esempio il numero di membri costituenti per nodo, poiché questo è ciò che è stato più accuratamente testato con vSphere. Detto questo, le impostazioni non predefinite, come la modifica del numero o del posizionamento dei componenti, sono ancora pienamente supportate.</block>
  <block id="301593c45668093a7eb242d138c597a3" category="list-text">Durante il dimensionamento di un datastore basato su FlexGroup, ricorda che FlexGroup è composto da diversi volumi FlexVol più piccoli che creano un namespace più grande. Pertanto, quando si utilizza un FlexGroup con otto componenti, assicurarsi di dimensionare il datastore in modo che sia almeno 8x volte superiore alle dimensioni della macchina virtuale più grande. Ad esempio, se nell'ambiente si dispone di una macchina virtuale da 6 TB, dimensionare il datastore FlexGroup non inferiore a 48 TB.</block>
  <block id="6d9993f47e7802210a05453f494513bf" category="list-text">VMware e NetApp attualmente non supportano un approccio di rete multipath comune. Per NFSv4.1, NetApp supporta pNFS, mentre VMware supporta il trunking di sessione. NFSv3 non supporta percorsi fisici multipli per un volume. Per FlexGroup con ONTAP 9,8, si consiglia di lasciare che gli strumenti ONTAP per VMware vSphere creino FlexGroup, ma poi è necessario smontarlo e rimontarlo utilizzando il DNS round robin per distribuire il carico nel cluster. Gli strumenti ONTAP usano una sola LIF per il montaggio di datastore. Dopo aver rimontato il datastore, è possibile utilizzare strumenti ONTAP per monitorarlo e gestirlo.</block>
  <block id="04cc9e0b9478cc704d42735886027630" category="list-text">Utilizzare il plug-in NFS per VMware VAAI per l'offload delle copie. Si noti che mentre il cloning è migliorato all'interno di un datastore FlexGroup, come menzionato in precedenza, ONTAP non offre significativi vantaggi in termini di performance rispetto alla copia dell'host ESXi quando si copiano le macchine virtuali tra volumi FlexVol e/o FlexGroup. Prendi in considerazione, pertanto, i workload di cloning al momento di decidere di utilizzare VAAI o FlexGroup. La modifica del numero di volumi costituenti è un modo per ottimizzare il cloning basato su FlexGroup. Come per l'ottimizzazione del timeout della cache.</block>
  <block id="b9e0a0134c0815e50bb71d8dd7e367b6" category="list-text">QoS (IOPS max/min) può essere impostato su singole macchine virtuali o su tutte le macchine virtuali in un datastore in quel momento. L'impostazione della QoS su tutte le macchine virtuali sostituisce le impostazioni separate per ogni macchina virtuale. Le impostazioni non si estendono alle macchine virtuali nuove o migrate in futuro; impostare la QoS sulle nuove macchine virtuali o riapplicare la QoS a tutte le macchine virtuali nel datastore. Né le policy di FlexGroup QoS seguono la macchina virtuale se viene migrata su un altro datastore. Questo contrasta con i vVol, che possono mantenere le proprie impostazioni di policy QoS se migrano in un altro datastore.</block>
  <block id="1133ff8355478000111c8b1969e32770" category="list-text">Il plug-in SnapCenter per VMware vSphere versione 4,4 e successive supporta il backup e recovery delle macchine virtuali in un datastore FlexGroup nel sistema storage primario. SCV 4,6 aggiunge il supporto di SnapMirror per datastore basati su FlexGroup.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Con la transizione dall'appliance virtuale legacy, gli strumenti ONTAP offrono una vasta gamma di nuove funzionalità, limiti più elevati e nuovo supporto vVol.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nuove funzionalità con gli strumenti SRM e ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Ultime versioni di vSphere e Site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Con il rilascio di SRM 8.7 e versioni successive e con le versioni 9.12 e successive dei tool ONTAP, è ora possibile proteggere le macchine virtuali in esecuzione su VMware vSphere 8 update 1.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp ha condiviso una partnership profonda con VMware da quasi vent'anni e si impegna a fornire il supporto per le ultime release il più presto possibile. Consulta sempre il tool per la matrice di interoperabilità NetApp (IMT) per scoprire le più recenti combinazioni di software qualificate.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">L'NetApp IMT è disponibile all'indirizzo <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">Supporto di vVol (e perché è importante Storage Policy Based Management (SPBM), anche con SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">A partire dalla release 8,3, SRM supporta ora la gestione basata su criteri di storage (SPBM, Storage Policy Based Management) della replica sfruttando vVol e la replica basata su array per datastore che utilizzano iSCSI, FCP e NFS v3. A tale scopo, il server SRM è stato aggiornato per includere un nuovo servizio provider vVol SRM, che comunica al servizio SMS del server vCenter per le attività correlate a VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Uno dei vantaggi di questa architettura è che un SRA non è più necessario, poiché tutto viene gestito tramite VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM è un potente strumento della toolbox vSphere che consente servizi di storage semplificati, prevedibili e coerenti per l'utilizzo da parte dei framework di automazione in ambienti cloud privati e ibridi. Fondamentalmente, SPBM consente di definire le classi di servizio che soddisfano le esigenze della vostra base clienti diversificata. SRM consente ora di esporre le funzionalità di replica ai clienti per i carichi di lavoro critici che richiedono un'efficace orchestrazione e automazione del disaster recovery standard di settore.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Esempio di architettura vVol con FCP o iSCSI:</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Supporto per server SRM basati su appliance</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">I server SRM basati su sistema operativo Photon sono ora supportati, oltre alle piattaforme legacy basate su Windows.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">È ora possibile installare gli adattatori SRA indipendentemente dal tipo di server SRM preferito.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Supporto per IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 è ora supportato con le seguenti limitazioni:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 o versione successiva</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non supportato con SRM 8.2 (8.1, 8.3 e 8. 4 sono supportati)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Tool di matrice di interoperabilità</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Controllare<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> per le ultime versioni qualificate.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Performance migliorate</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">Le performance operative sono un requisito fondamentale per l'esecuzione delle attività SRM. Per soddisfare i requisiti degli RTO e degli RPO moderni, l'SRA con gli strumenti ONTAP ha aggiunto tre nuovi miglioramenti.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Supporto per operazioni simultanee di risproteggere.* introdotto per la prima volta in SRA 9.7.1, questa funzionalità consente di eseguire la risproteggere su due o più piani di ripristino contemporaneamente, riducendo così il tempo necessario per la risproteggere i datastore dopo un failover o una migrazione e rimanendo all'interno dei parametri RTO e RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*Strumenti ONTAP 9.8 aggiunge una nuova modalità ottimizzata solo NAS.* quando si utilizzano account con ambito SVM e connessioni a cluster ONTAP con solo datastore basati su NFS, è possibile abilitare la modalità ottimizzata solo NAS per le massime performance negli ambienti supportati.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*ONTAP Tools 9.12 ha aggiunto il supporto per la funzionalità di risincronizzazione rapida di ONTAP SnapMirror.* ciò consente una rapida risincronizzazione dei mirror con l'obiettivo di dover ricalcolare i risparmi in termini di efficienza dello storage dopo il processo. Questa funzione non viene utilizzata per impostazione predefinita, ma può essere attivata in ambienti su larga scala in cui la risincronizzazione tradizionale richiede troppo tempo o sta per scadere.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Maggiore scalabilità</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Gli strumenti ONTAP SRA possono ora supportare fino a 500 gruppi di protezione (PG) se utilizzati con SRM 8.3 e versioni successive.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Una nuova funzionalità attesa da tempo e molto attesa è SnapMirror Synchronous (SM-S) con ONTAP 9.5 e versioni successive, che offre una soluzione di replica dei dati zero RPO granulare per le applicazioni mission-critical. SM-S richiede gli strumenti ONTAP 9.8 o versioni successive.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Supporto API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configurazione del server SRA può ora essere gestita dalle API REST. È stata aggiunta un'interfaccia utente Swagger per facilitare la creazione dei flussi di lavoro di automazione, disponibile sull'appliance ONTAP Tools all'indirizzo<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP è stata una soluzione storage leader per gli ambienti VMware vSphere sin dalla sua introduzione nel moderno data center nel 2002 e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi.</block>
  <block id="0a0e655ee9ba6467857ebf014a268f29" category="doc">VMware Site Recovery Manager con NetApp ONTAP</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4900: VMware Site Recovery Manager con ONTAP_</block>
  <block id="7659430738ccf1c5b8c8084a4003c709" category="paragraph">NetApp ONTAP è stata una soluzione storage leader per gli ambienti VMware vSphere sin dalla sua introduzione nel moderno data center nel 2002 e continua ad aggiungere funzionalità innovative per semplificare la gestione riducendo i costi. In questo documento viene presentata la soluzione ONTAP per VMware Site Recovery Manager (SRM), il software di disaster recovery (DR) leader del settore di VMware, che include le informazioni più recenti sui prodotti e le Best practice per semplificare la distribuzione, ridurre i rischi e semplificare la gestione continua.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Le Best practice integrano altri documenti come guide e strumenti di compatibilità. Sono sviluppati in base a test di laboratorio e a un'ampia esperienza sul campo da parte di tecnici e clienti NetApp. In alcuni casi, le Best practice consigliate potrebbero non essere adatte al tuo ambiente; tuttavia, sono generalmente le soluzioni più semplici che soddisfano le esigenze della maggior parte dei clienti.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Questo documento è incentrato sulle funzionalità delle recenti release di ONTAP 9, se utilizzato insieme ai tool ONTAP per VMware vSphere 9.12 (che include l'adattatore per la replica dello storage NetApp [SRA] e il provider VASA [VP]), nonché VMware Site Recovery Manager 8.7.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Perché utilizzare ONTAP con SRM?</block>
  <block id="36c28121fc6c9b02a38c0b6c92654e9a" category="paragraph">Le piattaforme di gestione dei dati NetApp basate sul software ONTAP sono alcune delle soluzioni di storage più diffuse per SRM. I motivi sono molteplici: Una piattaforma per la gestione dei dati sicura, dalle performance elevate e protocollo unificato (NAS e SAN insieme) che offre efficienza dello storage definita dal settore, multitenancy, controlli della qualità del servizio, protezione dei dati con snapshot efficienti in termini di spazio e replica con SnapMirror. Tutto questo sfrutta l'integrazione multi-cloud ibrida nativa per la protezione dei carichi di lavoro VMware e una vasta gamma di strumenti di automazione e orchestrazione a portata di mano.</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Utilizzando SnapMirror per la replica basata su array è possibile sfruttare una delle tecnologie ONTAP più comprovate e mature. SnapMirror offre il vantaggio di trasferimenti di dati sicuri ed altamente efficienti, copiando solo i blocchi di file system modificati, non intere macchine virtuali o datastore. Anche questi blocchi sfruttano il risparmio di spazio, come deduplica, compressione e compattazione. I moderni sistemi ONTAP utilizzano ora SnapMirror indipendente dalla versione, consentendo di scegliere i cluster di origine e di destinazione in modo flessibile. SnapMirror è diventato uno dei tool più potenti disponibili per il disaster recovery.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Sia che stiate utilizzando datastore collegati a NFS, iSCSI o Fibre Channel tradizionali (ora con supporto per datastore vVol), SRM offre una solida offerta di prima parte che sfrutta il meglio delle funzionalità ONTAP per il disaster recovery o la pianificazione e l'orchestrazione della migrazione dei data center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">In che modo SRM sfrutta ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM sfrutta le tecnologie avanzate di gestione dei dati dei sistemi ONTAP integrandosi con i tool ONTAP per VMware vSphere, un'appliance virtuale che include tre componenti principali:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Il plug-in vCenter, precedentemente noto come Virtual Storage Console (VSC), semplifica le funzionalità di gestione ed efficienza dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi dati e ottimizza le impostazioni degli host ESXi per gli ambienti di storage a blocchi e NFS. Per tutti questi vantaggi, NetApp consiglia questo plug-in quando si utilizza vSphere con sistemi che eseguono il software ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Il provider VASA per ONTAP supporta il framework VMware vStorage API for Storage Awareness (VASA). IL provider VASA connette vCenter Server a ONTAP per facilitare il provisioning e il monitoraggio dello storage delle macchine virtuali. Consente il supporto di VMware Virtual Volumes (vVol) e la gestione dei profili di capacità dello storage (incluse le funzionalità di replica di vVol) e delle performance di VM vVol individuali. Fornisce inoltre allarmi per il monitoraggio della capacità e della conformità con i profili. Se utilizzato in combinazione con SRM, il provider VASA per ONTAP consente il supporto delle macchine virtuali basate su vVol senza richiedere l'installazione di un adattatore SRA sul server SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA viene utilizzato insieme a SRM per gestire la replica dei dati delle macchine virtuali tra siti di produzione e disaster recovery per datastore VMFS e NFS tradizionali e per il test senza interruzioni delle repliche DR. Consente di automatizzare le attività di rilevamento, ripristino e protezione. Include un'appliance server SRA e adattatori SRA per server SRM Windows e appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Dopo aver installato e configurato gli adattatori SRA sul server SRM per proteggere gli archivi dati non vVols e/o aver abilitato la replica vVols nelle impostazioni del provider VASA, è possibile iniziare l'attività di configurazione dell'ambiente vSphere per il disaster recovery.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">I provider SRA e VASA offrono un'interfaccia di controllo e comando per il server SRM per gestire i FlexVol ONTAP che contengono le macchine virtuali VMware e la replica SnapMirror che li protegge.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">A partire da SRM 8.3, nel server SRM è stato introdotto un nuovo percorso di controllo SRM vVols Provider, che consente di comunicare con il server vCenter e, attraverso di esso, con il provider VASA senza la necessità di un SRA. Ciò ha consentito al server SRM di sfruttare un controllo molto più approfondito sul cluster ONTAP rispetto a quanto era possibile in precedenza, perché VASA offre un'API completa per un'integrazione strettamente accoppiata.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM può verificare il vostro piano DR senza interruzioni utilizzando la tecnologia proprietaria FlexClone di NetApp per creare cloni quasi istantanei dei datastore protetti nel sito DR. SRM crea un sandbox per eseguire test in modo sicuro in modo che la tua organizzazione e i tuoi clienti siano protetti in caso di disastro reale, offrendo la sicurezza della capacità delle organizzazioni di eseguire un failover durante un disastro.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">In caso di disastro reale o persino di migrazione pianificata, SRM consente di inviare eventuali modifiche dell'ultimo minuto al dataset tramite un aggiornamento finale di SnapMirror (se si sceglie di farlo). Quindi, interrompe il mirror e monta il datastore sugli host DR. A questo punto, le VM possono essere alimentate automaticamente in qualsiasi ordine in base alla strategia prepianificata.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM con ONTAP e altri casi di utilizzo: Cloud ibrido e migrazione</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Storage privato NetApp in Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">L'integrazione dell'implementazione SRM con le funzionalità avanzate di gestione dei dati di ONTAP consente di migliorare notevolmente scalabilità e performance rispetto alle opzioni di storage locale. Ma oltre a questo, offre la flessibilità del cloud ibrido. Il cloud ibrido ti consente di risparmiare denaro tiering dei blocchi di dati inutilizzati dal tuo array dalle performance elevate all'hyperscaler preferito utilizzando FabricPool, che potrebbe essere un store S3 on-premise come NetApp StorageGRID. È inoltre possibile utilizzare SnapMirror per sistemi edge con software-defined ONTAP Select o DR basata su cloud utilizzando Cloud Volumes ONTAP (CVO) o.<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Per Amazon Web Services (AWS), Microsoft Azure e Google Cloud Platform (GCP) per creare uno stack di storage, networking e servizi di calcolo completamente integrato nel cloud.</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Quindi, grazie a FlexClone, è possibile eseguire un failover di test nel data center di un cloud service provider con un impatto dello storage prossimo allo zero. Proteggere la tua organizzazione può ora costare meno che mai.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM può anche essere utilizzato per eseguire migrazioni pianificate sfruttando SnapMirror per trasferire in modo efficiente le macchine virtuali da un data center all'altro o anche all'interno dello stesso data center, sia esso il tuo, o tramite un numero qualsiasi di partner service provider NetApp.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">In ONTAP 9, i componenti fisici di un cluster sono visibili agli amministratori del cluster, ma non sono direttamente visibili alle applicazioni e agli host che utilizzano il cluster.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologie di replica</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">In ONTAP 9, i componenti fisici di un cluster sono visibili agli amministratori del cluster, ma non sono direttamente visibili alle applicazioni e agli host che utilizzano il cluster. I componenti fisici forniscono un pool di risorse condivise da cui vengono costruite le risorse del cluster logico. Le applicazioni e gli host accedono ai dati solo tramite SVM che contengono volumi e LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Ogni SVM NetApp viene trattata come array in VMware vCenter Site Recovery Manager. SRM supporta determinati layout di replica array-to-array (o SVM-to-SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Una singola macchina virtuale non è in grado di gestire i dati (VMDK) o RDM) su più array SRM per i seguenti motivi:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM vede solo la SVM, non un singolo controller fisico.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Una SVM può controllare LUN e volumi che si estendono su più nodi in un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Best practice</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Per determinare la supportabilità, tenere presente questa regola: Per proteggere una macchina virtuale utilizzando SRM e NetApp SRA, tutte le parti della macchina virtuale devono esistere su un solo SVM. Questa regola si applica sia al sito protetto che al sito di ripristino.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Layout SnapMirror supportati</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Le seguenti figure mostrano gli scenari di layout delle relazioni SnapMirror supportati da SRM e SRA. Ogni macchina virtuale nei volumi replicati possiede i dati su un solo array SRM (SVM) in ogni sito.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Layout di Array Manager supportati</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Quando si utilizza la replica basata su array (ABR) in SRM, i gruppi di protezione vengono isolati in una singola coppia di array, come illustrato nella seguente schermata. In questo scenario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> e.<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sono in coppia con<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> e.<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> presso il sito di recovery. Tuttavia, è possibile selezionare solo una delle due coppie di array quando si crea un gruppo di protezione.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Layout non supportati</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Le configurazioni non supportate dispongono di dati (VMDK o RDM) su più SVM di proprietà di una singola macchina virtuale. Negli esempi illustrati nelle seguenti figure,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione con SRM perché<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Dispone di dati su due SVM.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Qualsiasi relazione di replica in cui un singolo volume NetApp viene replicato da una SVM di origine a più destinazioni nella stessa SVM o in SVM differenti viene definita fan-out di SnapMirror. Fan-out non supportato con SRM. Nell'esempio illustrato nella figura seguente,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Impossibile configurare la protezione in SRM perché viene replicata con SnapMirror in due posizioni diverse.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">Cascata di SnapMirror</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM non supporta la sovrapposizione delle relazioni SnapMirror, in cui un volume di origine viene replicato in un volume di destinazione e tale volume di destinazione viene replicato anche con SnapMirror in un altro volume di destinazione. Nello scenario illustrato nella figura seguente, SRM non può essere utilizzato per il failover tra siti.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror e SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Il software NetApp SnapVault consente il backup basato su disco dei dati aziendali tra i sistemi storage NetApp. SnapVault e SnapMirror possono coesistere nello stesso ambiente; tuttavia, SRM supporta il failover solo delle relazioni SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA supporta<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> tipo di policy.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault è stato ricostruito da zero per ONTAP 8.2. Anche se gli utenti di Data ONTAP 7-Mode precedenti dovrebbero trovare delle analogie, in questa versione di SnapVault sono stati apportati importanti miglioramenti. Un importante progresso è la capacità di preservare l'efficienza dello storage sui dati primari durante i trasferimenti SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Un'importante modifica architetturale è che SnapVault in ONTAP 9 replica a livello di volume anziché a livello di qtree, come nel caso di 7-Mode SnapVault. Questa configurazione indica che l'origine di una relazione SnapVault deve essere un volume e che tale volume deve replicarsi nel proprio volume sul sistema secondario SnapVault.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">In un ambiente in cui viene utilizzato SnapVault, vengono create snapshot specificatamente denominate sul sistema di storage primario. A seconda della configurazione implementata, gli snapshot denominati possono essere creati sul sistema primario da una pianificazione SnapVault o da un'applicazione come NetApp Active IQ Unified Manager. Gli Snapshot con nome creati sul sistema primario vengono quindi replicati nella destinazione SnapMirror, da dove vengono trasferiti in un vault nella destinazione SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">È possibile creare un volume di origine in una configurazione a cascata in cui un volume viene replicato in una destinazione SnapMirror nel sito DR e da qui viene vault in una destinazione SnapVault. È possibile creare un volume di origine anche in una relazione fan-out in cui una destinazione è una destinazione SnapMirror e l'altra destinazione è una destinazione SnapVault. Tuttavia, SRA non riconfigurerà automaticamente la relazione SnapVault per utilizzare il volume di destinazione SnapMirror come origine per il vault quando si verifica il failover SRM o l'inversione della replica.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Per informazioni aggiornate su SnapMirror e SnapVault per ONTAP 9, vedere<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Se SnapVault e SRM vengono utilizzati nello stesso ambiente, NetApp consiglia di utilizzare una configurazione a cascata da SnapMirror a SnapVault in cui i backup di SnapVault vengono normalmente eseguiti dalla destinazione di SnapMirror nel sito di DR. In caso di disastro, questa configurazione rende il sito primario inaccessibile. Mantenendo la destinazione SnapVault nel sito di recovery, è possibile riconfigurare i backup SnapVault dopo il failover in modo che i backup SnapVault possano continuare mentre si opera nel sito di recovery.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">In un ambiente VMware, ogni datastore dispone di un UUID (Universal Unique Identifier) e ogni VM dispone di un MOID (Managed Object ID) univoco. Questi ID non vengono gestiti da SRM durante il failover o il failback. Poiché gli UUID degli archivi di dati e i MOID delle macchine virtuali non vengono mantenuti durante il failover da SRM, tutte le applicazioni che dipendono da questi ID devono essere riconfigurate dopo il failover di SRM. Un'applicazione di esempio è NetApp Active IQ Unified Manager, che coordina la replica SnapVault con l'ambiente vSphere.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figura seguente mostra una configurazione a cascata da SnapMirror a SnapVault. Se la destinazione SnapVault si trova nel sito di DR o in un sito terzo che non è interessato da un'interruzione nel sito primario, l'ambiente può essere riconfigurato per consentire ai backup di continuare dopo il failover.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La seguente figura illustra la configurazione dopo l'utilizzo di SRM per eseguire il reverse della replica di SnapMirror nel sito primario. L'ambiente è stato anche riconfigurato in modo che i backup di SnapVault si verifichino da quella che ora è l'origine di SnapMirror. Questa configurazione è una configurazione fan-out di SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Dopo che SRM esegue il failback e una seconda inversione delle relazioni SnapMirror, i dati di produzione vengono ripristinati nel sito primario. Questi dati sono ora protetti nello stesso modo in cui erano prima del failover al sito di DR, tramite i backup SnapMirror e SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilizzo di Qtree in ambienti Site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">I qtree sono directory speciali che consentono l'applicazione delle quote del file system per NAS. ONTAP 9 consente la creazione di qtree e qtree possono esistere in volumi replicati con SnapMirror. Tuttavia, SnapMirror non consente la replica di singoli qtree o replica a livello di qtree. Tutte le repliche di SnapMirror sono solo a livello di volume. Per questo motivo, NetApp sconsiglia l'utilizzo di qtree con SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Ambienti misti FC e iSCSI</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Con i protocolli SAN supportati (FC, FCoE e iSCSI), ONTAP 9 offre servizi LUN, ovvero la possibilità di creare e mappare LUN agli host collegati. Poiché il cluster è costituito da più controller, esistono più percorsi logici gestiti da i/o multipath verso qualsiasi LUN individuale. L'ALUA (Asymmetric Logical Unit Access) viene utilizzato sugli host in modo che il percorso ottimizzato per un LUN sia selezionato e reso attivo per il trasferimento dei dati. Se il percorso ottimizzato per qualsiasi LUN cambia (ad esempio, perché il volume contenente viene spostato), ONTAP 9 riconosce automaticamente e regola senza interruzioni per questa modifica. Se il percorso ottimizzato non è disponibile, ONTAP può passare senza interruzioni a qualsiasi altro percorso disponibile.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM e NetApp SRA supportano l'utilizzo del protocollo FC in un sito e del protocollo iSCSI nell'altro. Tuttavia, non supporta la combinazione di datastore FC-attached e datastore iSCSI-attached nello stesso host ESXi o in host diversi nello stesso cluster. Questa configurazione non è supportata con SRM perché, durante il failover SRM o il failover di test, SRM include tutti gli iniziatori FC e iSCSI negli host ESXi nella richiesta.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM e SRA supportano protocolli FC e iSCSI misti tra i siti protetti e di ripristino. Tuttavia, ogni sito deve essere configurato con un solo protocollo, FC o iSCSI, non entrambi nello stesso sito. Se esiste un requisito per la configurazione dei protocolli FC e iSCSI nello stesso sito, NetApp consiglia che alcuni host utilizzino iSCSI e altri host utilizzino FC. In questo caso, NetApp consiglia anche di configurare le mappature delle risorse SRM in modo che le macchine virtuali siano configurate per il failover in un gruppo di host o nell'altro.</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Il flusso di lavoro all'interno di SRM è significativamente diverso quando si utilizza la replica vVol da quello utilizzato con SRA e datastore tradizionali.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Risoluzione dei problemi di SRM quando si utilizza la replica vVol</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Il flusso di lavoro all'interno di SRM è significativamente diverso quando si utilizza la replica vVol da quello utilizzato con SRA e datastore tradizionali. Ad esempio, non esiste alcun concetto di gestore di array. In quanto tale,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> e.<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> i comandi non vengono mai visualizzati.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Durante la risoluzione dei problemi, è utile comprendere i nuovi flussi di lavoro, elencati di seguito:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Rileva gli accordi di replica tra due domini di errore.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Rileva la gerarchia di dominio di errore.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Consente di individuare i gruppi di replica presenti nei domini di origine o di destinazione.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Sincronizza i dati tra origine e destinazione.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Consente di rilevare le repliche point-in-time di una destinazione.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Avvia il failover del test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Termina il failover del test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Promuove un gruppo attualmente in fase di test in produzione.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PrepareFailoverReplicationGroup: Prepara per un disaster recovery.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup: Esegue il disaster recovery.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Avvia la replica inversa.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Trova i container (insieme agli host o ai gruppi di replica) che potrebbero soddisfare una richiesta di provisioning con una determinata policy.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata: Rileva i metadati di tutte le risorse dal provider VASA, l'utilizzo delle risorse può essere restituito come risposta alla funzione QueryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'errore più comune riscontrato durante la configurazione della replica di vVol è il mancato rilevamento delle relazioni di SnapMirror. Ciò si verifica perché i volumi e le relazioni di SnapMirror vengono creati al di fuori dell'ambito di applicazione degli strumenti ONTAP. Pertanto, è consigliabile assicurarsi sempre che la relazione di SnapMirror sia completamente inizializzata e che sia stata eseguita una riscoperta negli strumenti ONTAP in entrambi i siti prima di tentare di creare un datastore vVol replicato.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Ulteriori informazioni</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Per ulteriori informazioni sulle informazioni descritte in questo documento, consultare i seguenti documenti e/o siti Web:</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: VMware vSphere per ONTAP
<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: Volumi virtuali VMware vSphere con ONTAP
<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">Guida alle Best practice per la configurazione di SnapMirror TR-4015 per ONTAP 9
<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">Creatore utente RBAC per ONTAP
<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">Strumenti ONTAP per le risorse VMware vSphere
<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">Documentazione di VMware Site Recovery Manager
<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Tool di matrice di interoperabilità (IMT)</block>
  <block id="97cd1357ea4a16b44bd9e360127a1a9d" category="paragraph">Fare riferimento a.<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Sul sito del supporto NetApp per verificare che le versioni esatte dei prodotti e delle funzionalità descritte in questo documento siano supportate per il tuo ambiente specifico. NetApp IMT definisce i componenti e le versioni dei prodotti che possono essere utilizzati per costruire configurazioni supportate da NetApp. I risultati specifici dipendono dall'installazione di ciascun cliente in conformità alle specifiche pubblicate.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Best practice per l'implementazione</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Layout e segmentazione SVM per SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Con ONTAP, il concetto di storage virtual machine (SVM) offre una segmentazione rigorosa in ambienti multi-tenant sicuri. Gli utenti SVM su una SVM non possono accedere o gestire le risorse da un'altra. In questo modo, è possibile sfruttare la tecnologia ONTAP creando SVM separate per diverse business unit che gestiscono i propri flussi di lavoro SRM sullo stesso cluster per una maggiore efficienza dello storage globale.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Valutare la possibilità di gestire ONTAP utilizzando account con ambito SVM e LIF di gestione SVM per non solo migliorare i controlli di sicurezza, ma anche le performance. Le performance sono intrinsecamente maggiori quando si utilizzano connessioni con ambito SVM perché l'SRA non è richiesto per elaborare tutte le risorse di un intero cluster, incluse le risorse fisiche. Al contrario, l'IT deve solo comprendere le risorse logiche astratte dalla specifica SVM.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Quando si utilizzano solo i protocolli NAS (senza accesso SAN), è anche possibile sfruttare la nuova modalità NAS ottimizzata impostando il seguente parametro (si noti che il nome è tale perché SRA e VASA utilizzano gli stessi servizi di back-end nell'appliance):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Accedere al pannello di controllo all'indirizzo<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> E fare clic su interfaccia CLI basata su Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Eseguire il comando<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Eseguire il comando<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Eseguire il comando<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementare gli strumenti e le considerazioni di ONTAP per i vVol</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Se si intende utilizzare SRM con vVol, è necessario gestire lo storage utilizzando credenziali con ambito cluster e una LIF di gestione del cluster. Questo perché il provider VASA deve comprendere l'architettura fisica sottostante per soddisfare le policy richieste per le policy di storage delle macchine virtuali. Ad esempio, se si dispone di una policy che richiede storage all-flash, il provider VASA deve essere in grado di vedere quali sistemi sono tutti flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Un'altra Best practice per l'implementazione consiste nel non memorizzare mai l'appliance ONTAP Tools su un datastore vVols gestito dall'IT. Ciò potrebbe causare l'impossibilità di accendere il provider VASA perché non è possibile creare lo swap vVol per l'appliance perché l'appliance non è in linea.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Best practice per la gestione dei sistemi ONTAP 9</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Come indicato in precedenza, è possibile gestire i cluster ONTAP utilizzando credenziali cluster o SVM con ambito e LIF di gestione. Per performance ottimali, puoi prendere in considerazione l'utilizzo delle credenziali con ambito SVM ogni volta che non utilizzi vVol. Tuttavia, in questo modo, è necessario conoscere alcuni requisiti e perdere alcune funzionalità.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">L'account SVM vsadmin predefinito non dispone del livello di accesso richiesto per eseguire le attività degli strumenti ONTAP. Pertanto, è necessario creare un nuovo account SVM.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Se si utilizza ONTAP 9,8 o versione successiva, NetApp consiglia di creare un account utente RBAC con privilegi minimi utilizzando il menu utenti di ONTAP System Manager insieme al file JSON disponibile nell'appliance ONTAP Tools all'indirizzo<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilizzare la password di amministratore per scaricare il file JSON. Può essere utilizzato per account SVM o con ambito cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Toolchest del sito di supporto NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Se si utilizza ONTAP 9.6 o versioni precedenti, utilizzare lo strumento RBAC User Creator (RUC) disponibile in<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Poiché il plug-in dell'interfaccia utente di vCenter, il provider VASA e il server SRA sono tutti servizi completamente integrati, è necessario aggiungere storage all'adattatore SRM nello stesso modo in cui si aggiunge storage nell'interfaccia utente di vCenter per gli strumenti ONTAP. In caso contrario, il server SRA potrebbe non riconoscere le richieste inviate da SRM tramite l'adattatore SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">Il controllo del percorso NFS non viene eseguito quando si utilizzano credenziali con ambito SVM. Questo perché la posizione fisica è logicamente astratta dalla SVM. Tuttavia, questo non è motivo di preoccupazione, in quanto i sistemi ONTAP moderni non subiscono più alcun calo significativo delle performance quando si utilizzano percorsi indiretti.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il risparmio di spazio aggregato dovuto all'efficienza dello storage potrebbe non essere segnalato.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Se supportati, i mirror di condivisione del carico non possono essere aggiornati.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">La registrazione EMS potrebbe non essere eseguita sui sistemi ONTAP gestiti con credenziali SVM con ambito.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Se possibile, utilizza sempre gli strumenti ONTAP per eseguire il provisioning di datastore e volumi. In questo modo si garantisce che volumi, percorsi di giunzione, LUN, igroups, policy di esportazione, e altre impostazioni sono configurate in modo compatibile.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Best practice operative</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM supporta iSCSI, Fibre Channel e NFS versione 3 con ONTAP 9 quando si utilizza la replica basata su array tramite SRA. SRM non supporta la replica basata su array per NFS versione 4.1 con datastore tradizionali o vVols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Per confermare la connettività, verificare sempre che sia possibile montare e smontare un nuovo datastore di test sul sito DR dal cluster ONTAP di destinazione. Verificare ogni protocollo che si intende utilizzare per la connettività del datastore. Una Best practice consiste nell'utilizzare gli strumenti ONTAP per creare il datastore di test, poiché sta eseguendo tutta l'automazione del datastore come indicato da SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">I protocolli SAN devono essere omogenei per ciascun sito. È possibile combinare NFS e SAN, ma i protocolli SAN non devono essere combinati all'interno di un sito. Ad esempio, è possibile utilizzare FCP nel sito A e iSCSI nel sito B. Non utilizzare sia FCP che iSCSI nel sito A. Il motivo è che l'SRA non crea gruppi igroup misti nel sito di ripristino e l'SRM non filtra l'elenco di iniziatori fornito all'SRA.</block>
  <block id="62a631034cae40cfcee909c69c12c5b3" category="paragraph">NetApp ONTAP 9 può essere configurato in modo da rimuovere automaticamente le istantanee per preservare l'uptime in caso di esaurimento dello spazio quando il dimensionamento automatico non è in grado di fornire una capacità di emergenza sufficiente. L'impostazione predefinita di questa funzionalità non elimina automaticamente le snapshot create da SnapMirror. Se le snapshot SnapMirror vengono eliminate, il servizio SRA di NetApp non può invertire e risincronizzare la replica per il volume interessato. Per impedire a ONTAP di eliminare snapshot di SnapMirror, configurare la funzionalità di eliminazione automatica Snapshot in modo da provare.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">configurazione automatica dell'aumento o della riduzione dei volumi</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">La dimensione automatica del volume deve essere impostata su<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Per volumi contenenti datastore SAN e.<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Per datastore NFS. Scopri di più <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Gestione basata su criteri storage (SPBM, Storage Policy Based Management) e vVol</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La seguente schermata fornisce un esempio di pianificazioni SnapMirror visualizzate nella procedura guidata Crea policy di storage VM.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Il provider VASA di ONTAP supporta il failover su storage diverso. Ad esempio, il sistema può eseguire il failover da ONTAP Select in una posizione periferica a un sistema AFF nel data center principale. Indipendentemente dalla somiglianza dello storage, è necessario configurare sempre le mappature dei criteri di storage e le mappature inverse per le policy di storage delle macchine virtuali abilitate alla replica per garantire che i servizi forniti nel sito di recovery soddisfino le aspettative e i requisiti. La seguente schermata evidenzia un esempio di mappatura dei criteri.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Creare volumi replicati per gli archivi dati vVols</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Si consiglia di prestare attenzione quando si tratta di vVol e SRM. Non mischiare mai macchine virtuali protette e non protette nello stesso datastore vVols. Il motivo è che quando si utilizza SRM per eseguire il failover sul sito DR, solo le macchine virtuali che fanno parte del gruppo di protezione vengono messe in linea nel DR. Pertanto, quando si esegue una nuova protezione (reverse SnapMirror dal DR di nuovo alla produzione), è possibile sovrascrivere le macchine virtuali che non hanno eseguito il failover e che potrebbero contenere dati preziosi.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Informazioni sulle coppie di array</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Quando si configurano le coppie di array in SRM, è necessario aggiungerle sempre in SRM nello stesso modo in cui sono state aggiunte agli strumenti ONTAP, ovvero devono utilizzare lo stesso nome utente, password e LIF di gestione. Questo requisito garantisce che SRA comunichi correttamente con l'array. La seguente schermata illustra come potrebbe essere visualizzato un cluster negli strumenti ONTAP e come potrebbe essere aggiunto a un gestore di array.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Informazioni sui gruppi di replica</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">I gruppi di replica contengono raccolte logiche di macchine virtuali che vengono ripristinate insieme. Il provider VASA di ONTAP Tools crea automaticamente i gruppi di replica. Poiché la replica di ONTAP SnapMirror avviene a livello di volume, tutte le macchine virtuali di un volume si trovano nello stesso gruppo di replica.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Un'ultima considerazione per i gruppi di replica è che ciascuno di essi è per sua natura un gruppo di coerenza logica (da non confondere con i gruppi di coerenza SRM). Questo perché tutte le VM nel volume vengono trasferite insieme utilizzando lo stesso snapshot. Pertanto, se si dispone di macchine virtuali che devono essere coerenti tra loro, è consigliabile memorizzarle nello stesso FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">A proposito dei gruppi di protezione</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">I gruppi di protezione definiscono macchine virtuali e datastore in gruppi che vengono ripristinati insieme dal sito protetto. Il sito protetto è il luogo in cui esistono le macchine virtuali configurate in un gruppo di protezione durante le normali operazioni in stato stazionario. È importante notare che anche se SRM potrebbe visualizzare più gestori di array per un gruppo di protezione, un gruppo di protezione non può estendersi a più gestori di array. Per questo motivo, non è necessario estendere i file delle macchine virtuali tra gli archivi dati su macchine virtuali SVM diverse.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Sui piani di recovery</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">I piani di recovery definiscono quali gruppi di protezione vengono ripristinati nello stesso processo. È possibile configurare più gruppi di protezione nello stesso piano di ripristino. Inoltre, per abilitare più opzioni per l'esecuzione dei piani di ripristino, è possibile includere un singolo gruppo di protezione in più piani di ripristino.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">I piani di recovery consentono agli amministratori SRM di definire i flussi di lavoro di recovery assegnando le macchine virtuali a un gruppo di priorità da 1 (massimo) a 5 (minimo), con 3 (medio) come valore predefinito. All'interno di un gruppo di priorità, le VM possono essere configurate per le dipendenze.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp consiglia vivamente di collaborare con i team delle applicazioni per comprendere l'ordine delle operazioni richieste in uno scenario di failover e per costruire di conseguenza i piani di recovery.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Test del failover</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp consiglia inoltre di confermare occasionalmente la funzionalità delle applicazioni in-guest, soprattutto dopo la riconfigurazione dello storage delle macchine virtuali.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Quando viene eseguita un'operazione di test recovery, viene creata una rete bubble di test privata sull'host ESXi per le macchine virtuali. Tuttavia, questa rete non è connessa automaticamente ad alcun adattatore di rete fisico e pertanto non fornisce connettività tra gli host ESXi. Per consentire la comunicazione tra macchine virtuali in esecuzione su host ESXi diversi durante il test di DR, viene creata una rete fisica privata tra gli host ESXi nel sito di DR. Per verificare che la rete di test sia privata, è possibile separare fisicamente la rete a bolle di test oppure utilizzando VLAN o tag VLAN. Questa rete deve essere separata dalla rete di produzione, in quanto non è possibile posizionare le macchine virtuali sulla rete di produzione con indirizzi IP che potrebbero entrare in conflitto con i sistemi di produzione effettivi. Quando viene creato un piano di ripristino in SRM, la rete di test creata può essere selezionata come rete privata a cui connettere le macchine virtuali durante il test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Una volta convalidato il test e non più necessario, eseguire un'operazione di pulizia. L'esecuzione della pulizia riporta le macchine virtuali protette al loro stato iniziale e ripristina il piano di ripristino allo stato Pronta.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considerazioni sul failover</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Oltre all'ordine delle operazioni indicato in questa guida, è necessario considerare anche altri aspetti relativi al failover di un sito.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Un problema che potrebbe essere dovuto affrontare è rappresentato dalle differenze di rete tra i siti. Alcuni ambienti potrebbero essere in grado di utilizzare gli stessi indirizzi IP di rete sia nel sito primario che nel sito di DR. Questa capacità viene definita come una LAN virtuale estesa (VLAN) o una configurazione di rete estesa. Altri ambienti potrebbero richiedere l'utilizzo di indirizzi IP di rete diversi (ad esempio, in VLAN diverse) nel sito primario rispetto al sito di DR.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">Opzioni NSX-T con SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware offre diversi modi per risolvere questo problema. Per prima cosa, le tecnologie di virtualizzazione di rete come VMware NSX-T Data Center astraggono l'intero stack di rete dai livelli 2 fino a 7 dall'ambiente operativo, consentendo soluzioni più portatili. Scopri di più <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">Documentazione di VMware</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Per configurare SRM in modo che applichi impostazioni di rete diverse a più macchine virtuali senza dover modificare le proprietà di ciascuna di esse nel piano di ripristino, VMware fornisce uno strumento chiamato dr-ip-customizer. Per informazioni sull'utilizzo di questa utilità, fare riferimento alla sezione <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Proteggere di nuovo</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Dopo un ripristino, il sito di ripristino diventa il nuovo sito di produzione. Poiché l'operazione di ripristino ha rotto la replica di SnapMirror, il nuovo sito di produzione non è protetto da eventuali disastri futuri. Una Best practice consiste nel proteggere il nuovo sito di produzione in un altro sito immediatamente dopo un ripristino. Se il sito di produzione originale è operativo, l'amministratore di VMware può utilizzare il sito di produzione originale come nuovo sito di ripristino per proteggere il nuovo sito di produzione, invertendo efficacemente la direzione della protezione. La protezione è disponibile solo in caso di guasti non catastrofici. Pertanto, i server vCenter originali, i server ESXi, i server SRM e i database corrispondenti devono essere ripristinabili. Se non sono disponibili, è necessario creare un nuovo gruppo di protezione e un nuovo piano di ripristino.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Un'operazione di failback è fondamentalmente un failover in una direzione diversa rispetto a prima. Come Best practice, prima di tentare di eseguire il failback o, in altre parole, di eseguire il failover sul sito originale, è necessario verificare che il sito originale sia tornato a livelli di funzionalità accettabili. Se il sito originale è ancora compromesso, è necessario ritardare il failback fino a quando il guasto non viene risolto in modo adeguato.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Un'altra Best practice per il failback consiste nell'eseguire sempre un failover di test dopo aver completato la protezione e prima di eseguire il failback finale. In questo modo si verifica che i sistemi installati presso il sito originale possano completare l'operazione.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Protezione del sito originale</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">L'esecuzione di una nuova protezione dopo il failback riporta sostanzialmente l'ambiente nello stato in cui si trovava all'inizio, con la replica di SnapMirror nuovamente in esecuzione dal sito di produzione al sito di ripristino.</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Attività di sviluppo sicure</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">L'engineering del software con i tool NetApp ONTAP per VMware vSphere utilizza le seguenti attività di sviluppo sicuro:</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modellazione delle minacce.* lo scopo della modellazione delle minacce è quello di individuare i difetti di sicurezza in una funzionalità, un componente o un prodotto nelle prime fasi del ciclo di vita dello sviluppo software. Un modello di minaccia è una rappresentazione strutturata di tutte le informazioni che influiscono sulla sicurezza di un'applicazione. In sostanza, si tratta di una vista dell'applicazione e del suo ambiente attraverso l'obiettivo della sicurezza.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic Application Security Testing (DAST).* questa tecnologia è progettata per rilevare le condizioni vulnerabili delle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Valuta del codice di terze parti.* nell'ambito dello sviluppo di software con software open-source (OSS), è necessario risolvere le vulnerabilità di sicurezza che potrebbero essere associate a qualsiasi OSS incorporato nel prodotto. Si tratta di un'operazione continua, in quanto una nuova versione di OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Scansione delle vulnerabilità.* lo scopo della scansione delle vulnerabilità è quello di rilevare vulnerabilità di sicurezza comuni e note nei prodotti NetApp prima che vengano rilasciate ai clienti.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità di sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software simile a intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Funzionalità di sicurezza del prodotto</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">I tool NetApp ONTAP per VMware vSphere includono le seguenti funzionalità di sicurezza in ogni versione.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Login banner.* SSH è disattivato per impostazione predefinita e consente l'accesso una sola volta, se abilitato dalla console della macchina virtuale. Il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*ATTENZIONE:* l'accesso non autorizzato a questo sistema è vietato e sarà perseguito dalla legge. Accedendo a questo sistema, l'utente accetta che le proprie azioni possano essere monitorate in caso di sospetto di utilizzo non autorizzato.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Dopo che l'utente ha completato l'accesso tramite il canale SSH, viene visualizzato il seguente testo:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*RBAC (role-based access control).* due tipi di controlli RBAC sono associati ai tool ONTAP:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilegi vCenter Server nativi</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">questo link</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilegi specifici del plug-in vCenter. Per ulteriori informazioni, vedere<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando la versione 1.2 di TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Esposizione minima delle porte.* solo le porte necessarie sono aperte sul firewall.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">La seguente tabella descrive i dettagli della porta aperta.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">Porta TCP v4/v6 n.</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direzione</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Funzione</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">in entrata</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connessioni HTTPS per API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connessioni HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connessioni HTTPS
Utilizzato per connessioni SOAP su https
Questa porta deve essere aperta per consentire a un client di connettersi al server API degli strumenti ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (Disattivato per impostazione predefinita)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connessioni HTTPS - VP e SRA - connessioni interne solo da loopback</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connessioni HTTPS - VP e SRA
Utilizzato per connessioni SOAP su https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Pacchetti di trap SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">solo interno</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Porta del database Derby, solo tra questo computer e se stesso, connessioni esterne non accettate -- solo connessioni interne</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirezionale</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilizzato per le connessioni ai cluster ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">articolo della knowledge base</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* i tool ONTAP per VMware vSphere supportano i certificati firmati CA. Vedi questo<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> per ulteriori informazioni.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Registrazione audit.* i pacchetti di supporto possono essere scaricati e sono estremamente dettagliati. ONTAP Tools registra tutte le attività di login e logout degli utenti in un file di log separato. Le chiamate API VASA vengono registrate in un registro di controllo VASA dedicato (cxf.log locale).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Criteri per le password.* vengono seguite le seguenti policy per le password:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Le password non vengono registrate in alcun file di log.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Le password non vengono comunicate in testo normale.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Le password vengono configurate durante il processo di installazione.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">La cronologia delle password è un parametro configurabile.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">La durata minima della password è impostata su 24 ore.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">Il completamento automatico dei campi della password è disattivato.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Gli strumenti ONTAP crittografano tutte le informazioni sulle credenziali memorizzate utilizzando l'hashing SHA256.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">Plug-in di SnapCenter per VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Il plug-in NetApp SnapCenter per il software engineering VMware vSphere utilizza le seguenti attività di sviluppo sicuro:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Dynamic Application Security testing (DAST).* tecnologie progettate per rilevare condizioni vulnerabili sulle applicazioni in esecuzione. DAST testa le interfacce HTTP e HTML esposte delle applicazioni web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Valuta del codice di terze parti.* come parte dello sviluppo di software e dell'utilizzo di software open-source (OSS), è importante risolvere le vulnerabilità di sicurezza che potrebbero essere associate a OSS che è stato incorporato nel prodotto. Si tratta di un impegno continuo, in quanto la versione del componente OSS potrebbe presentare una vulnerabilità scoperta di recente in qualsiasi momento.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">Test di penetrazione.* il test di penetrazione è il processo di valutazione di un sistema, di un'applicazione Web o di una rete per individuare le vulnerabilità della sicurezza che potrebbero essere sfruttate da un utente malintenzionato. I test di penetrazione (test delle penne) di NetApp vengono condotti da un gruppo di aziende terze approvate e fidate. Il loro scopo di test include il lancio di attacchi contro un'applicazione o un software come intrusi o hacker ostili che utilizzano sofisticati metodi o strumenti di sfruttamento.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Attività Product Security Incident Response.* le vulnerabilità di sicurezza vengono rilevate sia internamente che esternamente all'azienda e possono rappresentare un grave rischio per la reputazione di NetAppâ™se non vengono affrontate in modo tempestivo. Per facilitare questo processo, un Product Security Incident Response Team (PSIRT) segnala e tiene traccia delle vulnerabilità.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Il plug-in NetApp SnapCenter per VMware vSphere include le seguenti funzionalità di sicurezza in ciascuna release:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accesso limitato alla shell.* SSH è disattivato per impostazione predefinita e gli accessi una tantum sono consentiti solo se sono abilitati dalla console della macchina virtuale.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avviso di accesso nel banner di accesso.* il seguente banner di accesso viene visualizzato dopo che l'utente ha inserito un nome utente nel prompt di accesso:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Una volta completato l'accesso tramite il canale SSH, viene visualizzato il seguente output:</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*RBAC (role-based access control).* due tipi di controlli RBAC sono associati ai tool NetApp ONTAP:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilegi vCenter Server nativi.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">RBAC (Role-Based Access Control)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilegi specifici del plug-in VMware vCenter. Per ulteriori informazioni, vedere<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canali di comunicazione crittografati.* tutte le comunicazioni esterne avvengono su HTTPS utilizzando TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">La seguente tabella fornisce i dettagli della porta aperta.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numero della porta TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connessioni HTTPS per GUI OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (disattivato per impostazione predefinita)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (solo connessioni interne; connessioni esterne disattivate per impostazione predefinita)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (servizi di protezione dei dati)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Come creare e/o importare un certificato SSL nel plug-in SnapCenter per VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Supporto dei certificati firmati dall'autorità di certificazione (CA).* il plug-in SnapCenter per VMware vSphere supporta la funzione dei certificati firmati dalla CA. Vedere<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Password policy.* sono in vigore i seguenti criteri relativi alle password:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Tutte le informazioni sulle credenziali vengono memorizzate utilizzando l'hashing SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Immagine del sistema operativo di base.* il prodotto viene fornito con il sistema operativo di base Debian per OVA con accesso limitato e accesso alla shell disattivato. In questo modo si riduce l'impatto degli attacchi. Ogni sistema operativo SnapCenter release base viene aggiornato con le ultime patch di sicurezza disponibili per la massima copertura di sicurezza.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp sviluppa funzionalità software e patch di sicurezza per quanto riguarda il plug-in SnapCenter per l'appliance VMware vSphere e le rilascia ai clienti come piattaforma software integrata. Poiché queste appliance includono dipendenze specifiche del sistema operativo secondario Linux e il nostro software proprietario, NetApp consiglia di non apportare modifiche al sistema operativo secondario, in quanto questo potrebbe influire sull'appliance NetApp. Ciò potrebbe influire sulla capacità di NetApp di supportare l'appliance. NetApp consiglia di testare e implementare la versione più recente del codice per le appliance, perché vengono rilasciate per correggere eventuali problemi relativi alla sicurezza.</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL su ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">Scheduler i/O.</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Il kernel Linux permette un controllo di basso livello sul modo in cui l'i/o blocca i dispositivi è programmato.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Le impostazioni predefinite su varie distribuzioni di Linux variano notevolmente. MySQL consiglia di utilizzare<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> oppure un<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Scheduler i/o con i/o asincrono nativo (AIO) su Linux. In generale, i clienti NetApp e i test interni mostrano risultati migliori con NoOps.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">Il motore di storage InnoDB di MySQL utilizza il sottosistema i/o asincrono (AIO nativo) su Linux per eseguire richieste di lettura e scrittura per le pagine dei file di dati. Questo comportamento è controllato da<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> opzione di configurazione, attivata per impostazione predefinita. Con un sistema AIO nativo, il tipo di pianificatore i/o influisce maggiormente sulle prestazioni di i/O. Esegui benchmark per determinare quale scheduler i/o offrirà i risultati migliori per il tuo carico di lavoro e l'ambiente.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Per istruzioni sulla configurazione dello scheduler i/o, consultare la documentazione relativa a Linux e MySQL.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Configurazione dello storage</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">innodb_log_file_size</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">La scelta della dimensione corretta per il file di log InnoDB è importante per le operazioni di scrittura e per avere un tempo di ripristino decente dopo un arresto anomalo del server.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Poiché molte transazioni sono registrate nel file, la dimensione del file di registro è importante per le operazioni di scrittura. Quando i record vengono modificati, la modifica non viene immediatamente riscritta nello spazio di tabella. La modifica viene invece registrata alla fine del file di registro e la pagina viene contrassegnata come sporca. InnoDB utilizza il proprio registro per convertire l'i/o casuale in i/o sequenziale</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Quando il log è pieno, la pagina sporca viene scritta nello spazio di tabella in sequenza per liberare spazio nel file di log. Ad esempio, si supponga che un server si blocchi nel corso di una transazione e che le operazioni di scrittura vengano registrate solo nel file di registro. Prima che il server possa tornare attivo, deve passare attraverso una fase di recupero in cui vengono riprodotte le modifiche registrate nel file di registro. Maggiore è il numero di voci presenti nel file di registro, maggiore sarà il tempo necessario al server per il ripristino.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">In questo esempio, la dimensione del file di registro influisce sia sul tempo di ripristino che sulle prestazioni di scrittura. Quando si sceglie il numero giusto per la dimensione del file di registro, bilanciare il tempo di ripristino rispetto alle prestazioni di scrittura. In genere, qualsiasi valore compreso tra 128M e 512M è un buon valore.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">Database MySQL su ONTAP</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL e le sue varianti, tra cui MariaDB e Percona MySQL, è il database più diffuso al mondo.</block>
  <block id="478f00c3805e92ad9e8a7cd4f335a020" category="admonition">Questa documentazione su ONTAP e il database MySQL sostituisce il database _TR-4722: MySQL pubblicato in precedenza sulle Best practice di NetApp ONTAP._</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_flush_method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">Il parametro innodb_Flush_Method specifica come InnoDB apre e svuota i file di log e di dati.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Ottimizzazioni</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">Nell'ottimizzazione InnoDB, l'impostazione di questo parametro modifica le prestazioni del database, se applicabile.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Le seguenti opzioni consentono di svuotare i file tramite InnoDB:</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema per cancellare sia i file di dati che i file di registro. Questa opzione è l'impostazione predefinita.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> possibilità di aprire e svuotare i file di log e fsync() per svuotare i file di dati. InnoDB non utilizza<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Direttamente, perché ci sono stati problemi con esso su molte varietà di UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> (oppure<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Su Solaris) per aprire i file di dati e gli usi<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> per cancellare sia i file di dati che i file di registro. Questa opzione è disponibile su alcune versioni di GNU/Linux, FreeBSD e Solaris.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB utilizza<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Durante lo spurgo dell'i/o, tuttavia, salta<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema successiva. Questa opzione non è adatta per alcuni tipi di file system (ad esempio, XFS). Se non si è certi che il file system richieda un<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> chiamata di sistema, ad esempio per conservare tutti i metadati dei file, utilizzare<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> invece.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Osservazione</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">Nei test di laboratorio di NetApp, il<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> L'opzione predefinita è stata utilizzata su NFS e SAN ed è stata un'improvvisazione per le prestazioni eccezionale rispetto a<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Mentre si utilizza il metodo di lavaggio come<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Con ONTAP, abbiamo osservato che il client scrive molte scritture a byte singolo al margine del blocco 4096 in modo seriale. Queste operazioni di scrittura hanno aumentato la latenza sulla rete e degradato le performance.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">open_file_limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">Il<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> parametro determina il numero di file che il sistema operativo consente a mysqld di aprire.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">Il valore di questo parametro in fase di esecuzione è il valore reale consentito dal sistema e potrebbe essere diverso dal valore specificato all'avvio del server. Il valore è 0 sui sistemi in cui MySQL non può modificare il numero di file aperti. L'efficace<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> il valore si basa sul valore specificato all'avvio del sistema (se presente) e sui valori di<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> e.<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> utilizzando queste formule:</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> x 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> x 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Limite del sistema operativo se positivo</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Se il limite del sistema operativo è infinito:<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> il valore viene specificato all'avvio; 5.000 se nessuno</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">Il server tenta di ottenere il numero di descrittori di file utilizzando il massimo di questi quattro valori. Se non è possibile ottenere molti descrittori, il server tenta di ottenere il numero di descrittori consentito dal sistema.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_scan_depth</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">Il<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> Parametro influenza gli algoritmi e le euristiche dell'operazione di scaricamento per il pool di buffer InnoDB.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Questo parametro è principalmente di interesse per gli esperti di performance che ottimizzano i carichi di lavoro i/o-intensive. Per ogni istanza del pool di buffer, questo parametro specifica fino a che punto nell'elenco di pagine LRU (Last Recently Used) il thread di pulitura della pagina deve continuare la scansione, cercando le pagine sporche da eliminare. Questa operazione in background viene eseguita una volta al secondo.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">È possibile regolare il valore verso l'alto o verso il basso per ridurre al minimo il numero di pagine libere. Non impostare un valore molto superiore al necessario, poiché le scansioni possono avere un costo significativo in termini di prestazioni. Inoltre, è consigliabile regolare questo parametro quando si modifica il numero di istanze del pool di buffer, perché<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> definisce la quantità di lavoro eseguito dal filo del pulitore di pagina ogni secondo.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Un'impostazione più piccola di quella predefinita è adatta per la maggior parte dei carichi di lavoro. Considerare l'aumento del valore solo se si dispone di capacità i/o di riserva con un workload tipico. Per contro, se un carico di lavoro con un numero elevato di operazioni di scrittura satura la capacità i/o, diminuirne il valore, soprattutto se si dispone di un pool di buffer di grandi dimensioni.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_buffer_pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">Il pool di buffer InnoDB è la parte più importante di qualsiasi attività di ottimizzazione.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB si affida in gran parte al pool di buffer per la memorizzazione nella cache degli indici e il reming dei dati, all'indice hash adattivo, al buffer insert e a molte altre strutture di dati utilizzate internamente. Il pool di buffer memorizza inoltre le modifiche ai dati in modo che le operazioni di scrittura non debbano essere eseguite immediatamente nello storage, migliorando così le prestazioni. Il pool di buffer è parte integrante di InnoDB e le sue dimensioni devono essere regolate di conseguenza. Per impostare le dimensioni del pool di buffer, tenere conto dei seguenti fattori:</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Per una macchina dedicata solo InnoDB, impostare la dimensione del pool di buffer su 80% o più della RAM disponibile.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">Se non si tratta di un server dedicato MySQL, impostare la dimensione al 50% della RAM.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Descrittori di file</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Le utilizza per aprire nuove connessioni, archiviare tabelle nella cache, creare tabelle temporanee per risolvere query complesse e accedere a quelle persistenti. Se mysqld non è in grado di aprire nuovi file quando necessario, può smettere di funzionare correttamente. Un sintomo comune di questo problema è l'errore 24, "troppi file aperti". Il numero di descrittori di file che mysqld può aprire simultaneamente è definito dal<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opzione impostata nel file di configurazione <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Ma<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> dipende anche dai limiti del sistema operativo. Questa dipendenza rende l'impostazione della variabile più complicata.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL non può impostare ITS<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opzione superiore a quanto specificato in<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Pertanto, è necessario impostare esplicitamente questi limiti a livello del sistema operativo per consentire a MySQL di aprire i file in base alle necessità. Ci sono due modi per controllare il limite dei file in Linux:</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">Il<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> command fornisce rapidamente una descrizione dettagliata dei parametri consentiti o bloccati. Le modifiche apportate eseguendo questo comando non sono permanenti e si cancellano dopo un riavvio del sistema.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Modifiche al<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> i file sono permanenti e non sono interessati dal riavvio del sistema.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Assicurarsi di modificare sia i limiti hard che soft per l'utente mysql. I seguenti estratti provengono dalla configurazione:</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">In parallelo, aggiornare la stessa configurazione in<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> per utilizzare completamente i limiti dei file aperti.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">In caso di modifica dei dati, la modifica non viene immediatamente scritta nell'archivio.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">I dati vengono invece registrati in un buffer di registro, che è una porzione di memoria allocata da InnoDB alle modifiche del buffer registrate nel file di registro. InnoDB svuota il buffer nel file di registro quando viene eseguito il commit di una transazione, quando il buffer diventa pieno o una volta al secondo, a seconda dell'evento che si verifica per primo. La variabile di configurazione che controlla questo processo è innodb_Flush_log_at_trx_commit. Le opzioni valore includono:</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Quando si imposta<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB scrive i dati modificati (nel pool di buffer InnoDB) nel file di log (ib_logfile) e scarica il file di log (write to storage) ogni secondo. Tuttavia, non fa nulla quando la transazione è impegnata. Se si verifica un'interruzione dell'alimentazione o un arresto anomalo del sistema, nessuno dei dati non scaricati è recuperabile perché non vengono scritti né nel file di registro né nelle unità.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Quando si imposta<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB scrive il buffer di log nel log delle transazioni e lo svuota nello storage durevole per ogni transazione. Ad esempio, per tutti i commit delle transazioni, InnoDB scrive nel registro e quindi nello storage. La lentezza dello storage influisce negativamente sulle performance, ad esempio riducendo il numero di transazioni InnoDB al secondo.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Quando si imposta<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB scrive il buffer di log nel file di log ad ogni commit; tuttavia, non scrive dati nell'archivio. InnoDB scarica i dati una volta al secondo. Anche in caso di interruzione dell'alimentazione o arresto anomalo del sistema, i dati dell'opzione 2 sono disponibili nel file di registro ed è recuperabile.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Se l'obiettivo principale è la prestazione, impostare il valore su 2. Poiché InnoDB scrive sui dischi una volta al secondo, non per ogni commit delle transazioni, le performance migliorano in modo significativo. Se si verifica un'interruzione dell'alimentazione o un arresto anomalo, i dati possono essere recuperati dal registro delle transazioni.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Se l'obiettivo principale è la sicurezza dei dati, impostare il valore su 1 in modo che per ogni commit di transazione, InnoDB si scarichi sulle unità. Tuttavia, le prestazioni potrebbero risentirne.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp recommended* impostare il valore innodb_Flush_log_trx_commit su 2 per ottenere prestazioni migliori.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">Nel plug-in InnoDB è stato aggiunto un nuovo parametro chiamato innodb_io_Capacity da MySQL 5,7.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Controlla il numero massimo di IOPS eseguiti da InnoDB (che include la velocità di scaricamento delle pagine sporche e la dimensione batch del buffer di inserimento [ibuf]). Il parametro innodb_io_Capacity imposta un limite massimo per le IOPS da parte delle attività in background di InnoDB, come il lavaggio delle pagine dal pool di buffer e l'Unione dei dati dal buffer di modifica.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Impostare il parametro innodb_io_Capacity sul numero approssimativo di operazioni di i/o che il sistema può eseguire al secondo. Idealmente, mantenere l'impostazione più bassa possibile, ma non così bassa che le attività in background rallentano. Se l'impostazione è troppo alta, i dati vengono rimossi dal pool di buffer e il buffer di inserimento troppo rapidamente per la memorizzazione nella cache, per fornire un vantaggio significativo.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp consiglia* che, se si utilizza questa impostazione su NFS, analizzi il risultato del test di IOPS (SysBench/FiO) e imposti il parametro di conseguenza. Utilizzare il valore più piccolo possibile per lo spurgo e lo spurgo per continuare a meno che non vengano visualizzate pagine modificate o sporche di quanto si desidera nel pool di buffer InnoDB.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">Non utilizzare valori estremi come 20.000 o più a meno che non si sia dimostrato che valori inferiori non sono sufficienti per il carico di lavoro.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">Il parametro InnoDB_io_Capacity regola le velocità di lavaggio e i/o correlati</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">È possibile danneggiare seriamente le prestazioni impostando questo parametro o il parametro innodb_io_Capacity_max troppo alto e sprecando le operazioni di i/o con il lavaggio prematuro.</block>
  <block id="d32067c550345cae14e678b4def6aa22" category="doc">MySQL su SAN</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">Esistono due opzioni per configurare MySQL con SAN utilizzando il solito modello a due volumi.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">È possibile collocare database di dimensioni inferiori su una coppia di LUN standard, a condizione che le richieste di i/o e capacità rientrino nei limiti di un singolo file system LUN. Ad esempio, un database che richiede circa 2K IOPS casuali può essere ospitato su un singolo file system su un singolo LUN. Analogamente, un database di sole 100GB GB di dimensioni dovrebbe adattarsi a un singolo LUN, senza creare problemi di gestione.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Database di dimensioni maggiori richiedono LUN multiple. Ad esempio, un database che richiede 100K IOPS avrà probabilmente bisogno di almeno otto LUN. Un singolo LUN sarebbe diventato un collo di bottiglia a causa del numero inadeguato di canali SCSI per le unità. Analogamente, sarebbe difficile gestire un database da 10TB TB su un singolo LUN da 10TB GB. I gestori di volumi logici sono progettati per unire le funzionalità di performance e capacità di più LUN per migliorare le prestazioni e la gestibilità.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">In entrambi i casi, dovrebbe essere sufficiente una coppia di ONTAP Volumes. Con una configurazione semplice, la LUN dei file di dati viene posizionata in un volume dedicato, come farebbe la LUN di log. Con una configurazione di volume manager logica, tutte le LUN del gruppo di volumi dei file di dati si troverebbero in un volume dedicato e le LUN del gruppo di volumi di log si troverebbero in un secondo volume dedicato.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp consiglia* di utilizzare due file system per le distribuzioni MySQL su SAN:</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">Il primo file system memorizza tutti i dati MySQL inclusi tablespace, dati e indice.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">Il secondo file system archivia tutti i log (log binari, log lenti e log delle transazioni).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Esistono diverse ragioni per separare i dati in questo modo, tra cui:</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">I modelli di i/o dei file di dati e di registro sono diversi. La loro separazione permetterebbe più opzioni con i controlli QoS.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">L'uso ottimale della tecnologia Snapshot richiede la capacità di ripristinare in maniera indipendente i file di dati. L'associazione di file di dati con file di registro interferisce con il ripristino dei file di dati.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">La tecnologia NetApp SnapMirror può essere utilizzata per fornire una semplice funzionalità di disaster recovery con RPO ridotto per un database; tuttavia, richiede diverse pianificazioni della replica per i file di dati e log.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Utilizzare questo layout di base a due volumi per rendere la soluzione a prova di futuro, in modo che tutte le funzioni di ONTAP possano essere utilizzate se necessario.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp consiglia* la formattazione dell'unità con il file system ext4, grazie alle seguenti funzioni:</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Approccio esteso alle funzioni di gestione dei blocchi utilizzate nel file system di journaling (JFS) e nelle funzioni di allocazione differita del file system esteso (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">ext4 permette file system fino a 1 exbibyte (2^60 byte) e file fino a 16 tebibyte (16 * 2^40 byte). Al contrario, il file system ext3 supporta solo file system di dimensioni massime pari a 16TB MB e file di dimensioni massime pari a 2TB MB.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">Nei file system ext4, l'allocazione di più blocchi (mballoc) alloca più blocchi per un file in un'unica operazione, invece di assegnarli uno alla volta, come in ext3. Questa configurazione riduce l'overhead di chiamata dell'allocatore di blocchi diverse volte e ottimizza l'allocazione di memoria.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Anche se XFS è il default per molte distribuzioni Linux, gestisce i metadati in modo diverso e non è adatto per alcune configurazioni MySQL.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp consiglia* di utilizzare le opzioni di dimensione del blocco 4K con l'utilità mkfs per allinearsi alle dimensioni del LUN del blocco esistenti.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">Le LUN NetApp memorizzano dati in blocchi fisici da 4KB KB, ottenendo otto blocchi logici da 512 byte.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Se non si impostano le stesse dimensioni del blocco, l'i/o non verrà allineato correttamente con i blocchi fisici e potrebbe scrivere in due unità diverse in un gruppo RAID, con conseguente latenza.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">È importante allineare l'i/o per semplificare le operazioni di lettura/scrittura. Tuttavia, quando l'i/o inizia ad un blocco logico che non si trova all'inizio di un blocco fisico, l'i/o è disallineato. Le operazioni di i/o sono allineate solo quando iniziano presso un blocco logico, il primo blocco logico in un blocco fisico.</block>
  <block id="282155126a94a0702cfd80daf38d4362" category="doc">Panoramica della configurazione</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parametri</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Valori</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_buffer_pool_instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Per impostare i parametri descritti in questa sezione, è necessario modificarli nel file di configurazione MySQL (my.cnf). Le Best practice di NetApp sono il risultato di test eseguiti internamente.</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">La containerizzazione dei database MySQL sta diventando sempre più diffusa.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">La gestione di container a basso livello viene quasi sempre eseguita con Docker. Le piattaforme di gestione dei container come OpenShift e Kubernetes semplificano ulteriormente la gestione di ambienti container di grandi dimensioni. I vantaggi della containerizzazione includono una riduzione dei costi, poiché non è necessario acquistare una licenza per un hypervisor. Inoltre, i container consentono l'esecuzione di più database isolati l'uno dall'altro, condividendo lo stesso kernel e sistema operativo sottostanti. È possibile eseguire il provisioning dei container in microsecondi.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Documentazione di Astra Trident</block>
  <block id="d4f640fe6950a1baff001f5601c7fbd7" category="paragraph">NetApp offre Astra Trident per fornire funzionalità di gestione avanzate dello storage. Ad esempio, Astra Trident consente a un container creato in Kubernetes di eseguire automaticamente il provisioning dello storage nel Tier appropriato, applicare policy di esportazione, impostare policy di copia Snapshot di NetApp e persino clonare un container in un altro. Per ulteriori informazioni, consultare <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">Struttura dei file MySQL</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Struttura dei file</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB funge da livello intermedio tra lo storage e il server MySQL, e memorizza i dati nelle unità.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">Errore: Immagine grafica non trovata</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">I/o MySQL è suddiviso in due tipi:</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">I/o di file casuali</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">I/o di file sequenziale</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">I file di dati vengono letti e sovrascritti in modo casuale, con conseguente aumento degli IOPS. Pertanto, si consiglia di utilizzare l'unità SSD.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">I file di log di ripristino e i file di log binari sono registri transazionali. Vengono scritti in sequenza, così potrai ottenere buone performance sul disco HDD con cache in scrittura. Al momento del ripristino si verifica una lettura sequenziale, che raramente causa problemi di prestazioni, poiché le dimensioni dei file di registro sono in genere inferiori ai file di dati e le letture sequenziali sono più veloci delle letture casuali (che si verificano sui file di dati).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">Il buffer double-write è una caratteristica speciale di InnoDB. InnoDB prima scrive le pagine svuotate nel buffer di doppia scrittura e poi scrive le pagine nelle posizioni corrette sui file di dati. Questo processo impedisce il danneggiamento della pagina. Senza il buffer di scrittura doppia, la pagina potrebbe danneggiarsi se si verifica un'interruzione dell'alimentazione durante il processo di scrittura su unità. La scrittura nel buffer double-write è sequenziale, pertanto è altamente ottimizzato per gli HDD. Al momento del ripristino vengono eseguite letture sequenziali.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Poiché la NVRAM ONTAP fornisce già la protezione in scrittura, non è necessario il doppio buffer in scrittura. MySQL ha un parametro,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, per disattivare il buffer di doppia scrittura. Questa funzione può migliorare notevolmente le prestazioni.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">Il buffer insert è anche una caratteristica speciale di InnoDB. Se i blocchi di indice secondari non univoci non sono in memoria, InnoDB inserisce le voci nel buffer di inserimento per evitare operazioni di i/o casuali. Periodicamente, il buffer di inserimento viene Unito agli alberi di indice secondari nel database. Il buffer di inserimento riduce il numero di operazioni di i/o unendo le richieste di i/o allo stesso blocco; le operazioni di i/o casuali possono essere sequenziali. Anche il buffer di inserimento è altamente ottimizzato per gli HDD. Durante le normali operazioni, vengono eseguite operazioni di scrittura e lettura sequenziali.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">I segmenti di annullamento sono orientati all'i/o casuale. Per garantire la concorrenza multi-versione (MVCC), InnoDB deve registrare le vecchie immagini nei segmenti di annullamento. La lettura delle immagini precedenti dai segmenti di annullamento richiede letture casuali. Se si esegue una transazione lunga con letture ripetibili (come mysqldump, una singola transazione) o si esegue una query lunga, è possibile che si verifichino letture casuali. Pertanto, in questo caso è preferibile memorizzare i segmenti di annullamento negli SSD. Se si eseguono solo transazioni o query brevi, le letture casuali non costituiscono un problema.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp consiglia* il seguente layout di progettazione dello storage a causa delle caratteristiche i/o di InnoDB.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Un unico volume per memorizzare i file di MySQL orientati ai/o casuali e sequenziali</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Un altro volume per memorizzare i file di MySQL orientati a i/o puramente sequenziali</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Questo layout aiuta inoltre a progettare politiche e strategie di protezione dei dati.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">È possibile disattivare questo parametro con<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> per i benchmark o quando siete più preoccupati per le prestazioni superiori che l'integrità dei dati o possibili guasti. InnoDB utilizza una tecnica di scaricamento file chiamata double-write. Prima di scrivere le pagine nei file di dati, InnoDB le scrive in un'area contigua denominata buffer double-write. Una volta completata la scrittura e lo scarico nel buffer di doppia scrittura, InnoDB scrive le pagine nelle posizioni corrette nel file di dati. Se il sistema operativo o un processo mysqld si blocca durante la scrittura di una pagina, InnoDB può in seguito trovare una buona copia della pagina dal buffer di doppia scrittura durante il recupero del crash.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp recommended* disabilitare il buffer double-write. La NVRAM ONTAP svolge la stessa funzione. Il doppio buffering danneggia inutilmente le prestazioni.</block>
  <block id="dd5a2a602f713562e0f9f0fd8385660e" category="doc">MySQL su NFS</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">La documentazione MySQL consiglia di utilizzare NFSv4 per le implementazioni NAS.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">Dimensioni del trasferimento di NFS ONTAP</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">Per impostazione predefinita, ONTAP limiterà le dimensioni di i/o NFS a 64K. I/o casuali con un database MySQL utilizzano blocchi di dimensioni molto inferiori, che sono ben al di sotto del massimo di 64K KB. L'io a blocchi di grandi dimensioni è solitamente parallelizzato, quindi anche il massimo di 64K KB non costituisce un limite.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Ci sono alcuni carichi di lavoro in cui il massimo di 64K crea un limite. In particolare, le operazioni single-threaded, come le operazioni di backup della scansione completa del piano d'esame, verranno eseguite in modo più rapido ed efficiente se il database è in grado di eseguire un numero di io inferiore ma maggiore. La dimensione ottimale di gestione io per ONTAP con carichi di lavoro del database è 256K. Le opzioni di montaggio NFS elencate per i sistemi operativi specifici elencati di seguito sono state aggiornate da 64K a 256K di conseguenza.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Non diminuire mai la dimensione di trasferimento massima consentita su ONTAP al di sotto del valore rsize/wsize dei filesystem NFS attualmente montati. In alcuni sistemi operativi, ciò può causare blocchi o addirittura danni ai dati. Ad esempio, se i client NFS sono attualmente impostati su un valore rsize/wsize di 65536, la dimensione massima di trasferimento ONTAP potrebbe essere regolata tra 65536 e 1048576 senza alcun effetto perché i client stessi sono limitati. La riduzione della dimensione massima di trasferimento inferiore a 65536 GB può danneggiare la disponibilità o i dati.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp consiglia*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Impostazione della seguente impostazione NFSv4 fstab (/etc/fstab):</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">Un problema comune con NFSv3 è stato il blocco dei file di registro InnoDB dopo un'interruzione dell'alimentazione. Questo problema è stato risolto utilizzando i file di registro Time o Switching. Tuttavia, NFSv4 ha operazioni di blocco e tiene traccia dei file aperti e delle delegazioni.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP è la base per la gestione dei dati e la protezione dei dati per molte applicazioni aziendali e tecnologie di database. Le pagine seguenti contengono indicazioni sulle Best practice e le procedure di implementazione per ONTAP e le applicazioni e l'infrastruttura aziendali.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Protezione dei dati di Microsoft SQL Server</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Database open-source</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB e MySQL su ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL su ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Database Oracle</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle su ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Data Protection Oracle</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Migrazione Oracle</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">Soluzioni SAP</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA con AFF e FC</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA con AFF e NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Volumi virtuali (vVol) con ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware Site Recovery Manager con ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Applicazioni aziendali</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA e AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Impostazioni</block>
  <block id="c476a4701643b158f9f5d57bcc91951d" category="sidebar">Tecnologia Snapshot</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="sidebar">Carichi di lavoro</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Istanza condivisa contro istanza dedicata</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Configurazione della memoria</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">File tempdb</block>
  <block id="6fb6843bd9a214011969c02729c7d671" category="sidebar">Considerazioni sullo storage</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Sicurezza dei dati</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Limiti di capacità</block>
  <block id="4d2caccc34711835f6ff99da411ac04e" category="sidebar">Macchine virtuali per lo storage</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Failover e switchover</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Dimensioni dei blocchi di dati e ripristino</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">Oracle RAC</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Configurazione dell'host</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux con ASMlib e AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Interfacce logiche</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Configurazione Ethernet</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">Configurazione FC SAN</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">Striping LVM</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Configurazione</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (DNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">Leasing e blocchi di NFS</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">Caching di NFS</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">Utilità di recupero ASM</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Policy di tiering</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Invio di dati a un archivio di oggetti</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Recupero dei dati dall'archivio oggetti in corso</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Strategie di tiering</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">File interi</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">File parziali</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Selezionare file</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Disponibilità dei dati</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Integrità dei dati</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Backup online basati su snapshot</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Backup ottimizzati per le snapshot di storage</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Architettura fisica</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Architettura logica</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="3f23f85f537c810b6eca3c767c3ff00c" category="sidebar">Failover di Oracle</block>
  <block id="5783cab279142a801ff0fd0a03b607d5" category="sidebar">Istanza singola su MetroCluster</block>
  <block id="ea98d1b4d8c0f4b9e705df8dcdf77730" category="sidebar">Istanza singola su SM-BC</block>
  <block id="39520db4a78ddf352897eac9b11c5890" category="sidebar">Oracle RAC su SM-BC</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Scenari di errore</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migrazione dei database Oracle</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Procedure</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Copia dei dati host</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Importazione LUN esterne</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Completamento</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Conversione del protocollo</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Note aggiuntive</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Ottimizzazione delle prestazioni e benchmarking</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Blocchi NFS obsoleti</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Storage unificato</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Tool di virtualizzazione</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Gestione basata su policy di Virtual Volume e storage</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Cloning</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">QoS</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Gestione basata su criteri di storage</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Impostazioni consigliate</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Distribuzione dello storage vVol</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Sicurezza dei prodotti</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">Plug-in SnapCenter per VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Containerizzazione</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">Il provider ONTAP Tools VASA si occupa della gestione degli igroup FCP e iSCSI, nonché dei sottosistemi NVMe in ONTAP in base agli iniziatori rilevati degli host ESXi gestiti. Tuttavia, non si integra con gli switch Fibre Channel per gestire lo zoning. Lo zoning deve essere eseguito in base alle Best practice prima di eseguire qualsiasi provisioning. Di seguito è riportato un esempio di zoning a initiator singolo per quattro sistemi ONTAP:</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">Zoning a initiator singolo:</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Fare riferimento ai seguenti documenti per ulteriori Best practice:</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="4047245d73abc6e3ae8bf58ec063e52e" category="paragraph">Gli SCP inclusi sono adatti per la maggior parte degli usi generici, ma i requisiti potrebbero essere diversi.</block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Prendere in considerazione l'utilizzo di IOPS massimi per controllare macchine virtuali sconosciute o di test.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Per la prima volta disponibile nel provider VASA 7.1, è possibile utilizzare il massimo IOPS per limitare gli IOPS a un vVol specifico per un carico di lavoro sconosciuto, in modo da evitare impatti su altri carichi di lavoro più critici. Per ulteriori informazioni sulla gestione delle performance, vedere la Tabella 4.</block>
  <block id="bdbd10905a1446f944699405bca52654" category="paragraph">*Assicurarsi di disporre di LIF di dati sufficienti.*
Creare almeno due LIF per nodo per coppia ha. In base al carico di lavoro, potrebbe essere necessario un numero maggiore di risorse.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Fare riferimento alle altre guide alle Best practice di NetApp e VMware specifiche per il protocollo selezionato. In generale, non vi sono modifiche diverse da quelle già menzionate.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Esempio di configurazione di rete utilizzando vVol su NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">Dimensioni trasferimento NFS</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14ce62ac76fa34a51093e6bcf11a2fd1" category="paragraph">L'aspetto principale da prendere in considerazione per il backup del database è l'utilizzo della tecnologia Snapshot di NetApp. Il layout dei database e il backup coerenti con le applicazioni sono altre considerazioni fondamentali per ottenere RTO e RPO orchestrabili da NetApp SnapCenter.</block>
  <block id="2c024bdc7d0e87e8ba0f473024d45a4e" category="paragraph">La modifica delle impostazioni dei server e dei database può contribuire a migliorare e ad aumentare l'efficienza delle performance dei database.</block>
  <block id="861f074a1ecd9d1cc088d2fe81903565" category="paragraph"><block ref="861f074a1ecd9d1cc088d2fe81903565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="710e9cd79e3865d47122a799f425b31f" category="paragraph"><block ref="710e9cd79e3865d47122a799f425b31f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5e31e9b7075c2926dba10053509346b" category="paragraph">L'efficienza dello storage è una combinazione di RAID, provisioning (layout e utilizzo generali), mirroring e altre tecnologie di protezione dei dati. Tecnologie NetApp come le copie Snapshot, il thin provisioning e FlexClone consentono di creare vantaggi in termini di costi ottimizzando lo storage esistente nell'infrastruttura e posticipando o evitando le spese future per lo storage. Più si utilizzano queste tecnologie insieme, maggiore sarà il risparmio.</block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25cec91f17a8619119f76c8adbace583" category="paragraph">Vedere anche la discussione sull'allineamento dei blocchi di compressione nella sezione <block ref="0faffd62be034c86d531acfee84d252e" category="inline-link-macro-rx"></block>. Qualsiasi layout allineato ai limiti del blocco di compressione 8KB è allineato ai limiti 4KB.</block>
  <block id="38ac6f4e1538397bd4f659237ec03ebf" category="paragraph"><block ref="38ac6f4e1538397bd4f659237ec03ebf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f01518e5f3b18a9ea241bc63a3475dbd" category="paragraph"><block ref="f01518e5f3b18a9ea241bc63a3475dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Panoramica sulla data Protection di Oracle</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">La migrazione su distanze più lunghe in genere richiede un approccio più creativo, ad esempio il processo di distribuzione dei log illustrato nella <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. Le reti IP a lunga distanza raramente dispongono di larghezza di banda in qualsiasi punto vicino alle velocità LAN o SAN. In un caso, NetApp ha assistito alla migrazione a lunga distanza di un database 220TB con tassi di generazione di log di archiviazione molto elevati. L'approccio scelto per il trasferimento dei dati era la spedizione giornaliera dei nastri, perché questo metodo offriva la massima larghezza di banda possibile.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">Ad esempio, la copia di un database 10TB richiede in genere circa sette ore. Se le esigenze aziendali rendono possibile un'interruzione di sette ore, la copia dei file è un'opzione semplice e sicura per la migrazione. Se cinque ore sono inaccettabili, un semplice log-processo di spedizione (vedere <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>) può essere impostato con il minimo sforzo per ridurre il tempo di cutover a circa 15 minuti. Durante questo periodo, un amministratore di database può completare il processo. Se 15 minuti sono inaccettabili, è possibile automatizzare il processo di cutover finale tramite script per ridurre il tempo di cutover a pochi minuti. È sempre possibile accelerare una migrazione, anche se ciò comporta costi di tempo e lavoro. Gli obiettivi del tempo di cutover devono basarsi su ciò che è accettabile per l'azienda.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">Uno zpool deve essere creato solo dopo i passaggi nella <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> vengono eseguite. Se la procedura non viene eseguita correttamente, le prestazioni potrebbero peggiorare notevolmente a causa dell'allineamento i/O. Per ottenere prestazioni ottimali con ONTAP è necessario allineare l'i/o a un confine di 4K su un'unità. I file system creati su uno zpool utilizzano una dimensione di blocco effettiva controllata tramite un parametro chiamato<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, che può essere visualizzato eseguendo il comando<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">La partizione è stata creata con un offset a 33 settori anziché con il valore predefinito 32. Ripetere la procedura descritta in <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. L'istogramma viene visualizzato come segue:</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">Aumentare la dimensione dei LUN</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">Aggiungere un LUN a un gruppo di volumi esistente e aumentare il volume logico contenuto</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">Un gruppo iniziatore (igroup) fa parte dell'architettura di mascheramento LUN di ONTAP. Un LUN appena creato non è accessibile a meno che non venga concesso per la prima volta l'accesso a un host. A tale scopo, creare un igroup in cui siano elencati i nomi WWN FC o iSCSI Initiator a cui è necessario concedere l'accesso. Al momento della scrittura del report, FLI era supportato solo per LUN FC. Tuttavia, la conversione in post-migrazione iSCSI è un'attività semplice, come illustrato nella <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">In questo modo, gli amministratori di database possono recuperare spazio sull'array di storage dopo l'eliminazione dei dati. ONTAP intercetta gli zero e dealloca lo spazio dal LUN. Il processo di recupero dei dati è estremamente rapido, poiché non viene scritto alcun dato all'interno del sistema di storage.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">I sistemi storage ONTAP offrono una grande flessibilità nella creazione di datastore per macchine virtuali e dischi virtuali. Sebbene vengano applicate molte Best practice ONTAP quando si utilizza VSC per il provisioning dei datastore per vSphere (elencate nella sezione <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>), ecco alcune linee guida aggiuntive da prendere in considerazione:</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">In alcuni casi, potrebbe non essere necessario un datastore. Per ottenere performance e gestibilità ottimali, evitare di utilizzare un datastore per applicazioni con i/o elevato, come database e alcune applicazioni. Si consiglia invece di prendere in considerazione file system di proprietà degli ospiti, come NFS o iSCSI, gestiti dal guest o con RDM. Per indicazioni specifiche sulle applicazioni, consulta i report tecnici NetApp relativi alla tua applicazione. Ad esempio, <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> contiene una sezione sulla virtualizzazione con informazioni utili.</block>
  <block id="3cd9527ff0ddb17e00c08bdb4cd1a776" category="paragraph">Le policy di storage delle macchine virtuali vengono utilizzate in vSphere per gestire funzionalità opzionali come Storage i/o Control o vSphere Encryption. Vengono inoltre utilizzati con vVol per applicare funzionalità di storage specifiche alla macchina virtuale. Utilizzare il tipo di storage "NetApp.Clustered.Data.ONTAP.VP.vvol" e la regola "ProfileName" per applicare un SCP specifico alle macchine virtuali attraverso l'utilizzo del criterio. Consulta link:vmware-vvol-ontap.html#Best practice[esempio di configurazione di rete con vVol su NFS v3] per un esempio con il provider VASA degli strumenti ONTAP. Le regole per lo storage "NetApp.Clustered.Data.ONTAP.VP.VASA10" devono essere utilizzate con datastore non basati su vVol.</block>
  <block id="36ad91be49fdde7d3fadeba0fb782510" category="paragraph">Una volta creata la policy di storage, è possibile utilizzarla per il provisioning di nuove macchine virtuali, come illustrato nella <block ref="d202b3fe265f968d81802fcec9f3c381" category="inline-link-macro-rx"></block>. Le linee guida per l'utilizzo delle funzionalità di gestione delle prestazioni con VASA Provider 7,2 sono illustrate nella <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block>.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">Quando<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> È attivato (impostazione predefinita), InnoDB memorizza tutti i dati due volte: Prima nel buffer di doppia scrittura e poi nei file di dati effettivi.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">Configurazione host per PostgreSQL</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">Configurazione dello storage per PostgreSQL</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">Protezione dei dati per PostgreSQL</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Configurazione del database per Microsoft SQL Server</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Configurazione dello storage per Microsoft SQL Server</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Configurazione del database per Oracle Database</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Configurazione host per database Oracle</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Configurazione di rete per Oracle Database</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Configurazione dello storage per database Oracle</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">Configurazione del database per MySQL</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">Configurazione host per MySQL</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">Configurazione dello storage per MySQL</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">Database PostgreSQL con SAN su ONTAP</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">PostgreSQL con SAN Filesystems</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">I database PostgreSQL con SAN sono generalmente ospitati su filesystem xfs, ma altri possono essere utilizzati se supportati dal fornitore del sistema operativo</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">Mentre un singolo LUN può generalmente supportare fino a 100K IOPS, i database io-intensive richiedono generalmente l'utilizzo di LVM con lo striping.</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">I database PostgreSQL possono essere ospitati su filesystem NFSv3 o NFSv4. L'opzione migliore dipende da fattori esterni al database.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">Per esempio, il comportamento di bloccaggio di NFSv4 può essere preferibile in certi ambienti raggruppati. (Vedere <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> per ulteriori informazioni)</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">In caso contrario, la funzionalità del database dovrebbe essere quasi identica, incluse le prestazioni. L'unico requisito è l'uso di<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> opzione di montaggio. Questo è necessario per garantire che i timeout software non producano errori io irreversibili.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">Se si sceglie NFSv4 come protocollo, NetApp consiglia di utilizzare NFSv4,1. Nel NFSv4,1 sono stati apportati alcuni miglioramenti funzionali al protocollo NFSv4 che migliorano la resilienza rispetto al NFSv4,0.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">Utilizzare le seguenti opzioni di montaggio per i carichi di lavoro generali del database:</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">Una volta aumentata la dimensione di trasferimento a livello ONTAP, si utilizzeranno le seguenti opzioni di montaggio:</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">NFSv3 tabelle slot TCP</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">Se NFSv3 viene usato con Linux, è fondamentale impostare correttamente le tabelle degli slot TCP.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Copie Snapshot</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">Le snapshot di storage sono repliche point-in-time dei dati di destinazione. L'implementazione di ONTAP include le funzionalità per impostare varie policy e memorizzare fino a 1024 snapshot per volume. Le Snapshot in ONTAP sono efficienti in termini di spazio. Lo spazio viene consumato solo quando viene modificato il set di dati originale. Sono anche di sola lettura. Uno snapshot può essere eliminato, ma non può essere modificato.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">In alcuni casi, le snapshot possono essere pianificate direttamente su ONTAP. In altri casi, software come SnapCenter potrebbe essere necessario per orchestrare le operazioni dell'applicazione o del sistema operativo prima di creare snapshot. Qualunque sia l'approccio migliore per i tuoi workload, un'aggressiva strategia di snapshot può garantire sicurezza dei dati tramite un accesso frequente e facilmente accessibile ai backup di ogni elemento, dalle LUN di avvio ai database mission-critical.</block>
  <block id="210c45246ad11e0b53bdb20b64266780" category="paragraph">*Nota*: Un volume flessibile ONTAP, o più semplicemente, un volume non è sinonimo di LUN. I volumi sono container di gestione per dati come file o LUN. Ad esempio, un database può essere posizionato su un set di stripe da 8 LUN, con tutti i LUN contenuti in un singolo volume.</block>
  <block id="ad590deba1cd4423ee565e822c3a91d1" category="paragraph">Per ulteriori informazioni sulle istantanee, fare clic su <block ref="211d7effcac0cb0488144c6fc8b3cb7c" category="inline-link-macro-rx"></block></block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">Snapshot a prova di manomissione</block>
  <block id="d2e783db61d20da61c761d4d473bed14" category="paragraph">A partire da ONTAP 9.12.1, le snapshot non sono solo di lettura, ma possono anche essere protette da eliminazioni accidentali o intenzionali. La funzione è denominata istantanee antimanomissione. È possibile impostare e applicare un periodo di conservazione tramite policy snapshot. Gli snapshot risultanti non possono essere eliminati fino a quando non hanno raggiunto la data di scadenza. Non sono presenti sostituzioni amministrative o del centro di supporto.</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">In questo modo, un intruso, un malintenzionato o persino un attacco ransomware non sono in grado di compromettere i backup, anche nel caso in cui abbiano accesso al sistema ONTAP stesso. Se combinato con una pianificazione degli snapshot frequente, offre una data Protection estremamente potente con un RPO molto basso.</block>
  <block id="c64db0c79e66c1c0e5b932c5d2dedfea" category="paragraph">Per ulteriori informazioni sulle istantanee antimanomissione, fare clic su <block ref="134603be635c039f9224bff191c6103c" category="inline-link-macro-rx"></block></block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">Replica SnapMirror</block>
  <block id="1bb837ddfb635c39a6c6e23d847823f9" category="paragraph">Gli snapshot possono anche essere replicati su un sistema remoto. Sono incluse le istantanee antimanomissione, in cui il periodo di conservazione viene applicato e applicato sul sistema remoto. Come risultato otterrai gli stessi vantaggi di protezione dei dati delle snapshot locali, ma i dati verranno posizionati in un secondo storage array. In questo modo si garantisce che la distruzione dell'array originale non comprometta i backup.</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">Un secondo sistema apre anche nuove opzioni per la sicurezza amministrativa. Ad esempio, alcuni clienti NetApp segregano le credenziali di autenticazione per i sistemi di storage primario e secondario. Nessun utente amministrativo singolo ha accesso a entrambi i sistemi, il che significa che un amministratore malintenzionato non può eliminare tutte le copie dei dati.</block>
  <block id="e805272dcce51c35975e830e5ee9ecaf" category="paragraph">Per ulteriori informazioni su SnapMirror, fare clic su <block ref="9abdfd5d94773cf0a996248d1d722cac" category="inline-link-macro-rx"></block></block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">Macchine virtuali di storage</block>
  <block id="d5174dd4c760ef1a826b3e5bc22215e5" category="paragraph">Un sistema di storage ONTAP appena configurato è simile a un server VMware ESX appena configurato, perché nessuno di questi può supportare gli utenti fino alla creazione di una macchina virtuale. Con ONTAP viene creata una Storage Virtual Machine (SVM) che diventa l'unità di gestione dello storage più base. Ciascuna SVM dispone di risorse di storage, configurazioni di protocolli, indirizzi IP e WWN FCP.  Questa è la base di ONTAP mult-tenancy.</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">Ad esempio, è possibile configurare una SVM per i carichi di lavoro di produzione critici e una seconda SVM su un segmento di rete diverso per le attività di sviluppo. Quindi, è possibile limitare l'accesso alla SVM di produzione a determinati amministratori, garantendo al contempo agli sviluppatori un controllo più esteso sulle risorse storage nella SVM di sviluppo. Potrebbe anche essere necessario fornire una terza SVM ai tuoi team finanziari e delle risorse umane per memorizzare dati particolarmente critici solo per gli occhi.</block>
  <block id="18519d16720b1e13890c2639657b5bf8" category="paragraph">Per ulteriori informazioni sulle SVM, fare clic su <block ref="a06a0fd566387240178b1c926e07cb7b" category="inline-link-macro-rx"></block></block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">RBAC amministrativo</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP offre un potente role-based access control (RBAC) per gli accessi amministrativi. Alcuni amministratori potrebbero aver bisogno di un accesso completo al cluster, altri invece potrebbero aver bisogno solo dell'accesso a determinate SVM. Il personale avanzato dell'helpdesk potrebbe aver bisogno di aumentare le dimensioni dei volumi. Il risultato è la possibilità di concedere agli utenti amministrativi l'accesso necessario per eseguire le proprie responsabilità lavorative, e niente di più. Inoltre, è possibile proteggere questi accessi utilizzando PKI di vari fornitori, limitare l'accesso solo alle chiavi ssh e applicare blocchi dei tentativi di accesso non riusciti.</block>
  <block id="6ae13b0198daa7d13d79a8631297e64d" category="paragraph">Per ulteriori informazioni sul controllo dell'accesso amministrativo, fare clic su <block ref="db5be08b697b5ef26e0e94da1d5f4970" category="inline-link-macro-rx"></block></block>
  <block id="671a94a08dff3cf44fad087e2346c8b0" category="section-title">Autenticazione a più fattori</block>
  <block id="c6595c32ea3c4aa315aa5c66b88b0a54" category="paragraph">ONTAP e alcuni altri prodotti NetApp supportano ora l'autenticazione a più fattori utilizzando una vasta gamma di metodi. Il risultato è un nome utente/password compromesso da solo non è un thread di sicurezza senza i dati del secondo fattore, come un FOB o un'applicazione per smartphone.</block>
  <block id="945c88a63c229c39ee73ab5592b3ef63" category="paragraph">Per ulteriori informazioni, fare clic su <block ref="03628d0cd13b6640ef56c399aa1c2070" category="inline-link-macro-rx"></block></block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">RBAC API</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">L'automazione richiede chiamate API, ma non tutti gli strumenti richiedono un accesso amministrativo completo. Per contribuire a proteggere i sistemi di automazione, RBAC è disponibile anche a livello di API. È possibile limitare gli account utente di automazione alle chiamate API richieste. Ad esempio, il software di monitoraggio non richiede l'accesso alle modifiche, ma solo l'accesso in lettura. I workflow che forniscono storage non hanno bisogno della capacità di eliminare lo storage.</block>
  <block id="97ad75902b447ba6b23cabdb10252ce8" category="paragraph">Per saperne di più, inizia <block ref="d3dd665f13f927a9546f36768f8407dd" category="inline-link-macro-rx"></block></block>
  <block id="cb93ad4589e6e6834d2627d2ef8c8456" category="section-title">Verifica multi-admin</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">L'autenticazione a più "fattori" può essere ulteriormente eseguita richiedendo l'approvazione di determinate attività da parte di due amministratori diversi, ciascuno con le proprie credenziali. Ciò include la modifica delle autorizzazioni di accesso, l'esecuzione dei comandi diagnostici e l'eliminazione dei dati.</block>
  <block id="e890d04cd745ac382688bbb307655e81" category="paragraph">Per ulteriori informazioni sulla verifica multi-admin (MAV), fare clic su <block ref="88f84d4fec0424d978600980bf11baf0" category="inline-link-macro-rx"></block></block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">Se si prevede un io sequenziale pesante, le dimensioni del trasferimento NFS possono essere aumentate come descritto nella sezione seguente.</block>
  <block id="f8fd5d7386ed935c8520d4e04b029e93" category="paragraph">Nelle sezioni seguenti vengono illustrate alcune delle impostazioni di configurazione della memoria critica.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">Questa documentazione sostituisce il report tecnico precedentemente pubblicato _TR-4590: Best practice guide for Microsoft SQL Server with ONTAP_</block>
  <block id="1f6b7ed754cfe3488cf91c21c13ec49a" category="paragraph">La protezione di un ambiente di database è un impegno multidimensionale che va oltre la gestione del database stesso. NetApp offre diverse funzioni esclusive progettate per proteggere gli aspetti dello storage dell'infrastruttura di database.</block>
  <block id="15d2f797f7375b32cb5e92538291f2af" category="list-text"><block ref="15d2f797f7375b32cb5e92538291f2af" category="inline-link-rx"></block></block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">Le guide precedenti hanno consigliato la creazione di una LIF in una località dati. Vale a dire, montare sempre un datastore utilizzando una LIF situata sul nodo che fisicamente possiede il volume. Questo non è più un requisito nelle versioni moderne di ONTAP 9. Quando possibile e se specifiche credenziali di ambito del cluster, i tool ONTAP continueranno a scegliere di bilanciare il carico tra le LIF locali dei dati, ma non è un requisito di high Availability o performance.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM funziona al meglio quando il numero di datastore e quindi di gruppi di protezione viene ridotto al minimo nei piani di ripristino. È quindi opportuno prendere in considerazione l'ottimizzazione della densità delle macchine virtuali negli ambienti protetti con SRM in cui l'RTO è fondamentale.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">Utilizza DRS (Distributed Resource Scheduler) per bilanciare il carico sui cluster ESXi protetti e di recovery. Tenere presente che se si prevede di eseguire il failback, quando si esegue una nuova protezione i cluster precedentemente protetti diventeranno i nuovi cluster di ripristino. Il DRS aiuterà a bilanciare il posizionamento in entrambe le direzioni.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">Ove possibile, evitare di utilizzare la personalizzazione IP con SRM, poiché ciò può aumentare il vostro RTO.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">A partire da SRM 8,3, è supportata la protezione delle macchine virtuali che utilizzano gli archivi dati vVol. Le pianificazioni di SnapMirror sono esposte ai criteri di storage delle macchine virtuali dal provider VASA quando la replica di vVol è attivata nel menu delle impostazioni degli strumenti di ONTAP, come mostrato nelle seguenti schermate.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">Nell'esempio riportato di seguito viene illustrata l'attivazione della replica vVol.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">A differenza dei datastore vVols precedenti, gli archivi dati vVols replicati devono essere creati dall'inizio con la replica abilitata e devono utilizzare volumi pre-creati sui sistemi ONTAP con relazioni SnapMirror. Ciò richiede la preconfigurazione di elementi come il peering dei cluster e il peering SVM. Queste attività devono essere eseguite dall'amministratore ONTAP, in quanto ciò facilita una rigorosa separazione delle responsabilità tra coloro che gestiscono i sistemi ONTAP in più siti e coloro che sono i principali responsabili delle operazioni vSphere.</block>
  <block id="e4ad04c89e34f6ca94c87cd68315b108" category="paragraph">Questo viene fornito con un nuovo requisito per conto dell'amministratore di vSphere. Poiché i volumi vengono creati al di fuori dell'ambito degli strumenti di ONTAP, non è a conoscenza delle modifiche apportate dall'amministratore di ONTAP fino al periodo di riscoperta regolarmente pianificato. Per questo motivo, è consigliabile eseguire sempre la risDiscovery ogni volta che si crea un volume o una relazione SnapMirror da utilizzare con i vVol. È sufficiente fare clic con il pulsante destro del mouse sull'host o sul cluster e selezionare NetApp ONTAP tools &gt; Update host and Storage Data (Strumenti &gt; Aggiorna dati host e archiviazione), come illustrato nella seguente schermata.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">Viene creato un gestore di array per ogni coppia di array. Con gli strumenti SRM e ONTAP, ogni accoppiamento di array viene eseguito con l'ambito di una SVM, anche se si utilizzano le credenziali del cluster. Ciò consente di segmentare i flussi di lavoro DR tra tenant in base alle SVM assegnate per la gestione. È possibile creare più array manager per un determinato cluster e possono essere asimmetrici. È possibile eseguire il fan-out o il fan-in tra diversi cluster di ONTAP 9. Ad esempio, è possibile utilizzare SVM-A e SVM-B nel cluster-1 in replica su SVM-C nel cluster-2, SVM-D nel cluster-3 o viceversa.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">Esistono diversi fattori da considerare per i gruppi di replica e il modo in cui si distribuiscono le macchine virtuali tra i volumi FlexVol. Il raggruppamento di macchine virtuali simili nello stesso volume può aumentare l'efficienza dello storage con i sistemi ONTAP meno recenti che non dispongono di una deduplica a livello di aggregato, ma il raggruppamento aumenta la dimensione del volume e riduce l'simultaneità dell'i/O. Il miglior equilibrio tra performance ed efficienza dello storage si può ottenere negli attuali sistemi ONTAP distribuendo le VM su volumi FlexVol nello stesso aggregato, sfruttando così la deduplica a livello di aggregato e ottenendo una maggiore parallelizzazione i/o su più volumi. È possibile ripristinare le macchine virtuali nei volumi insieme perché un gruppo di protezione (discusso di seguito) può contenere più gruppi di replica. Lo svantaggio di questo layout è che i blocchi potrebbero essere trasmessi più volte via cavo perché SnapMirror per i volumi non prende in considerazione la deduplica degli aggregati.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">Ad esempio, la tua azienda potrebbe disporre di un'applicazione business-critical Tier 1 che si affida a un server Microsoft SQL per il proprio database. Quindi, si decide di inserire le macchine virtuali nel gruppo di priorità 1. All'interno del gruppo di priorità 1, si inizia a pianificare l'ordine per visualizzare i servizi. Probabilmente si desidera che il controller di dominio Microsoft Windows venga avviato prima del server Microsoft SQL, che deve essere online prima del server dell'applicazione e così via. È necessario aggiungere tutte queste macchine virtuali al gruppo di priorità e quindi impostare le dipendenze perché le dipendenze si applicano solo all'interno di un determinato gruppo di priorità.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">Come Best practice, eseguire sempre un test di failover ogni volta che viene apportata una modifica alla configurazione di uno storage VM protetto. In questo modo, in caso di emergenza, è possibile verificare che Site Recovery Manager sia in grado di ripristinare i servizi entro la destinazione RTO prevista.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">SRM consente inoltre di modificare la configurazione di rete di una macchina virtuale durante il ripristino. Questa riconfigurazione include impostazioni quali indirizzi IP, indirizzi gateway e impostazioni del server DNS. È possibile specificare diverse impostazioni di rete, che vengono applicate alle singole macchine virtuali non appena vengono recuperate, nelle impostazioni della proprietà di una macchina virtuale nel piano di ripristino.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">Dopo il failback, è necessario confermare con tutti gli stakeholder che i loro servizi sono stati riportati alla normalità prima di eseguire nuovamente la funzione di protezione,</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">File di database e filegroup</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">Allineamento delle LUN</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">Numero di LUN e dimensioni LUN</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">Ridimensionamento LUN</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">Striping LVM</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO, RTO e SLA</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">Elementi di base di backup e recovery</block>
  <block id="3403aac944f3cb6e2d2c7f7d52bc44b9" category="paragraph">Con la crescita esponenziale dei dati, la gestione dei dati diventa più complessa per le aziende. Questa complessità aumenta i costi di licenza, operativi, di supporto e di manutenzione. Per ridurre il TCO complessivo, considerare il passaggio da database commerciali a open-source con storage back-end affidabile e dalle performance elevate.</block>
  <block id="dcac08882e3396bd30210108baa1641d" category="paragraph">ONTAP è una piattaforma ideale, perché ONTAP è letteralmente progettato per i database. Sono state create numerose funzionalità come le ottimizzazioni della latenza io random per la qualità del servizio avanzata fino alle funzionalità FlexClone di base per rispondere specificamente alle esigenze dei carichi di lavoro dei database.</block>
  <block id="1429a98a71e16287326edd7fc1f999fd" category="paragraph">Funzioni aggiuntive come gli aggiornamenti senza interruzioni, (inclusa la sostituzione dello storage) garantiscono la disponibilità dei database critici. Puoi anche disporre di un disaster recovery istantaneo per ambienti di grandi dimensioni tramite MetroCluster o selezionare database tramite la sincronizzazione attiva di SnapMirror.</block>
  <block id="8df3fb35ff15e02683bfb1bc7f852c93" category="paragraph">Soprattutto, ONTAP offre prestazioni senza pari con la possibilità di dimensionare la soluzione in base alle proprie esigenze specifiche. I nostri sistemi high-end possono offrire oltre 1M IOPS con latenze misurate in microsecondi, ma se ti servono solo 100K IOPS, puoi dimensionare al meglio la tua soluzione storage con un controller più piccolo che esegue ancora lo stesso sistema operativo per lo storage.</block>
  <block id="97b4cda00dd31f5be69440f48c4da149" category="summary">Configurazione del database PostgreSQL con ONTAP</block>
  <block id="c4f52498c0db572381512887d7584e53" category="summary">Database PostgreSQL e snapshot di storage</block>
  <block id="b0792163c858a7c221b236d84619b5ef" category="summary">Database PostgreSQL NFS con ONTAP</block>
  <block id="189950ed46e5e8b7e92941531a5bb88b" category="doc">Database PostgreSQL con filesystem NFS</block>
  <block id="504cd1fb60a8eb7918484270e743ae3a" category="summary">Protezione dati PostgreSQL</block>
  <block id="6cabd4dcf3582d38c441228705da3bda" category="doc">Protezione dei dati PostgreSQL</block>
  <block id="383a6a5241ecfc558b9fec1d7cff5239" category="summary">Tablespace PostgreSQL</block>
  <block id="20d0e2519b3555a0a2927c8914c17280" category="summary">Software di protezione dei dati PostgreSQL</block>
  <block id="29e2aec511a8e307ecceacbd86c22f14" category="summary">Parametri di inizializzazione PostgreSQL</block>
  <block id="55e3f073b1864d9281d074e5b23effca" category="doc">Procedure di benchmarking e ottimizzazione delle performance Oracle</block>
  <block id="035ecd1be6cacde993302b440e396bc2" category="paragraph">La maggior parte dei clienti che utilizzano database sceglie ora gli array all-flash, il che crea alcune considerazioni aggiuntive. Ad esempio, prendi in considerazione il test delle performance su un sistema AFF A900 a due nodi:</block>
  <block id="33f545d041b93838074263c0efd2e9da" category="list-text">Con un rapporto di lettura/scrittura di 80/20:1, due nodi A900 possono fornire oltre 1M IOPS di database casuali prima che la latenza attraversi anche il contrassegno 150µs. Questo ben oltre le attuali richieste di performance della maggior parte dei database è difficile prevedere il miglioramento previsto. Lo storage verrebbe ampiamente cancellato come collo di bottiglia.</block>
  <block id="0445195555faac96ebff962dbff126ea" category="summary">Parametri di configurazione MySQL</block>
  <block id="c0b7708ffcd66fd65a9d2a4801091563" category="paragraph">NetApp consiglia alcuni importanti parametri di configurazione di MySQL per ottenere prestazioni ottimali.</block>
  <block id="10eb8b7e75da1815860da31490513841" category="summary">MySQL con NFS</block>
  <block id="5249e05857621fbfae51371a73006c44" category="summary">MySQL e NFSv3 slot tables</block>
  <block id="d058f95e3a8d4b7b46802139d6b95982" category="paragraph">NFSv3 le prestazioni di Linux dipendono da un parametro chiamato<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="bf2bdc980948fb9084a63963398846b2" category="paragraph">ONTAP è una piattaforma ideale per database MySQL, perché ONTAP è letteralmente progettato per database. Sono state create numerose funzionalità come le ottimizzazioni della latenza io random per la qualità del servizio avanzata fino alle funzionalità FlexClone di base per rispondere specificamente alle esigenze dei carichi di lavoro dei database.</block>
  <block id="1b3804b7e2292e18f5e66d54f7a9fafc" category="paragraph">Soprattutto, ONTAP offre prestazioni senza pari con la possibilità di dimensionare la soluzione in base alle proprie esigenze specifiche. I nostri sistemi high-end possono offrire oltre 1M IOPS con latenze misurate in microsecondi, ma se ti servono solo 100K IOPS, puoi dimensionare correttamente la tua soluzione storage con un controller più piccolo che esegue ancora lo stesso sistema operativo per lo storage.</block>
  <block id="1339877637a3f7f59745a00e04f304fd" category="summary">MySQL e innodb_log_file_size</block>
  <block id="c1c4e722764621d56a075e42ce48d0c0" category="summary">MySQL e innodb_buffer_pool_size</block>
  <block id="ae14ab6d1e5edd0e782d8897d1721eb4" category="summary">MySQL e innodb_doublewrite</block>
  <block id="689c52e3f5db5d2dafccd7d93cf1abc4" category="summary">MySQL e innodb_Flush_log_at_trx_commi</block>
  <block id="639600080c225673dfdfa012fdbd6146" category="summary">Programmatori MySQL e io</block>
  <block id="32e3724e2b54692cbef969373fbfe040" category="doc">Programmatori i/o e MySQL</block>
  <block id="72985ac51e91797345b2437088a4362e" category="summary">MySQL con SAN</block>
  <block id="d5ef0a45fe252b03f538bfd134b168db" category="summary">MySQL e innodb_lru_Scan_Depth</block>
  <block id="df657260453f6ef228ee0ca22dd7a415" category="summary">Containerizzazione di MySQL</block>
  <block id="885b1b5a90f898c89b664ec58a42121c" category="doc">Containerizzazione MySQL</block>
  <block id="2cbac38815d492c0afc5e7d7229601df" category="doc">MySQL e InnoDB</block>
  <block id="1115aaa86f0065e0a105795d33ef4731" category="summary">Descrizione dei file MySQL</block>
  <block id="2828450fc6669c8df75f937e227996f1" category="doc">Descrittori di file MySQL</block>
  <block id="9420010a756fb6d3ddeadfa63d2170f6" category="paragraph">Per l'esecuzione, il server MySQL ha bisogno di descrittori di file, e i valori predefiniti non sono sufficienti.</block>
  <block id="62414a5a9c0e2fc12a8d028ad29164b8" category="summary">MySQL e innodb_io_Capacity</block>
  <block id="6219c45bc8c26437c0b7e1a69d4cbe58" category="summary">MySQL e innodb_Flush_Method</block>
  <block id="35d1a5d7b12999ec27f5233dccba043f" category="summary">MySQL e open_file_limits</block>
  <block id="c031febc35017c70bf3b526723756b2a" category="doc">ISCSI e NVMe/TCP</block>
  <block id="4da35d461815e71b97bda03476e89b7b" category="paragraph">Un host che utilizza iSCSI o NVMe/TCP può essere collegato direttamente a un sistema storage e funzionare normalmente. La ragione è la pedata. Le connessioni dirette a due storage controller differenti offrono due percorsi indipendenti per il flusso di dati. La perdita di percorso, porta o controller non impedisce l'utilizzo dell'altro percorso.</block>
  <block id="40715d81cea527f13cdf470773fc3a65" category="paragraph">È possibile utilizzare lo storage NFS con connessione diretta, ma con una limitazione significativa: Il failover non funzionerà senza una significativa attività di scripting, che sarà responsabilità del cliente.</block>
  <block id="d0b13bfd23c05f64222869de30f81000" category="paragraph">Il motivo per cui il failover senza interruzioni è complicato con lo storage NFS connesso direttamente è il routing che si verifica sul sistema operativo locale. Ad esempio, si supponga che un host abbia un indirizzo IP 192.168.1.1/24 e che sia collegato direttamente a un controller ONTAP con un indirizzo IP 192.168.1.50/24. Durante il failover, l'indirizzo 192.168.1.50 può eseguire il failover sull'altro controller e sarà disponibile per l'host, ma in che modo l'host rileva la sua presenza? L'indirizzo 192.168.1.1 originale esiste ancora sulla scheda di rete host che non si connette più a un sistema operativo. Il traffico destinato a 192.168.1.50 continuerebbe ad essere inviato a una porta di rete inutilizzabile.</block>
  <block id="288a0a5ebbc70fb3b968ec58d36d71ab" category="paragraph">La seconda scheda NIC del sistema operativo potrebbe essere configurata come 19 2.168.1.2 e sarebbe in grado di comunicare con l'indirizzo 192.168.1.50 non riuscito, ma le tabelle di routing locali avrebbero un valore predefinito di utilizzo di un solo indirizzo *e di un solo indirizzo* per comunicare con la subnet 192.168.1.0/24. Un amministratore di sistema potrebbe creare un framework di script che rilevi una connessione di rete non riuscita e alteri le tabelle di routing locali o che porti le interfacce verso l'alto e verso il basso. La procedura esatta dipende dal sistema operativo in uso.</block>
  <block id="d6ce8522932df7ae76aa0b963ad9ef7d" category="paragraph">In pratica, i clienti NetApp dispongono di NFS con connessione diretta, ma in genere solo per i workload in cui le pause io durante i failover sono accettabili. Quando si utilizzano i supporti rigidi, non devono verificarsi errori di i/o durante tali pause. L'io dovrebbe bloccarsi finché i servizi non vengono ripristinati, mediante failback o intervento manuale, per spostare gli indirizzi IP tra le schede NIC dell'host.</block>
  <block id="3436a7073ac9f4071820b6720a7789fc" category="section-title">Connessione diretta FC</block>
  <block id="b7981516813a09695906aa429b07f48f" category="paragraph">Non è possibile connettere direttamente un host a un sistema storage ONTAP utilizzando il protocollo FC. Il motivo è l'uso di NPIV. Il WWN che identifica una porta FC ONTAP per la rete FC utilizza un tipo di virtualizzazione chiamato NPIV. Qualsiasi dispositivo collegato a un sistema ONTAP deve essere in grado di riconoscere un WWN NPIV. Attualmente non vi sono fornitori di HBA che offrono un HBA che può essere installato in un host in grado di supportare un target NPIV.</block>
  <block id="97db606ac6781989ea3b189d7be28bf2" category="section-title">Connessione di rete diretta</block>
  <block id="d078ae9a339971900f939db9e82f253d" category="paragraph">Gli amministratori dello storage a volte preferiscono semplificare le loro infrastrutture rimuovendo gli switch di rete dalla configurazione. Questo può essere supportato in alcuni scenari.</block>
  <block id="14a07a9c146c886f1cf8b6ebd4b2b418" category="summary">Connessioni di rete dirette con ONTAP</block>
  <block id="a4e0be5abb980518338c55619fbfa4df" category="doc">Connessione diretta con reti TCP/IP e FC</block>
</blocks>