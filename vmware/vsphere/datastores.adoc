---
sidebar: sidebar 
permalink: vmware/vsphere/datastores.html 
keywords: vSphere, datastore, VMFS, FC, FCoE, NVMe/FC, iSCSI, NFS, vVols 
summary: 'Questa pagina descrive le Best practice per l"implementazione di una soluzione di storage NetApp ONTAP in un ambiente VMware vSphere.' 
---
= Datastore e protocolli
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== Datastore vSphere e funzionalità del protocollo

Per collegare VMware vSphere a datastore su un sistema con software ONTAP vengono utilizzati sette protocolli:

* FCP
* FCoE
* NVMe/FC
* NVMe/TCP
* ISCSI
* NFS v3
* NFS v4,1


FCP, FCoE, NVMe/FC, NVMe/TCP e iSCSI sono protocolli a blocchi che utilizzano il file system della macchina virtuale vSphere per memorizzare le macchine virtuali all'interno di LUN ONTAP o spazi dei nomi NVMe contenuti in un volume ONTAP FlexVol. A partire da vSphere 7.0, VMware non supporta più il software FCoE negli ambienti di produzione. NFS è un protocollo di file che inserisce le macchine virtuali in datastore (che sono semplicemente volumi ONTAP) senza la necessità di VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS possono essere utilizzati anche direttamente da un sistema operativo guest a ONTAP.

Le tabelle seguenti presentano le funzionalità tradizionali del datastore supportate da vSphere con ONTAP. Queste informazioni non si applicano agli archivi dati vVol, ma in genere si applicano a vSphere 6.x e alle versioni successive che utilizzano le versioni supportate di ONTAP. È inoltre possibile consultare https://www.vmware.com/support/pubs/["Valori massimi di configurazione VMware"^] Per release specifiche di vSphere per confermare limiti specifici.

|===
| Funzionalità | FC/FCoE | ISCSI | NVMe-of | NFS 


| Formato | VMFS o RDM (raw device mapping) | VMFS o RDM | VMFS | N/A. 


| Numero massimo di datastore o LUN | 1024 LUN per host | 1024 LUN per server | 256 namespeces per server | 256 supporti
Default NFS (NFS predefinito). MaxVolumes è 8. Utilizza i tool ONTAP per VMware vSphere per aumentare fino a 256. 


| Dimensione massima datastore | 64 TB | 64 TB | 64 TB | 100 TB di volume FlexVol o superiore con volume FlexGroup 


| Dimensione massima del file del datastore | 62 TB | 62 TB | 62 TB | 62TB con ONTAP 9.12.1P2 e versioni successive 


| Profondità ottimale della coda per LUN o file system | 64-256 | 64-256 | Negoziazione automatica | Fare riferimento a NFS.MaxQueueDefelse in https://docs.netapp.com/us-en/netapp-solutions/virtualization/vsphere_ontap_recommended_esxi_host_and_other_ontap_settings.html["Host ESXi consigliato e altre impostazioni ONTAP"^]. 
|===
La seguente tabella elenca le funzionalità supportate relative allo storage VMware.

|===
| Capacità/funzionalità | FC/FCoE | ISCSI | NVMe-of | NFS 


| VMotion | Sì | Sì | Sì | Sì 


| Storage vMotion | Sì | Sì | Sì | Sì 


| VMware ha | Sì | Sì | Sì | Sì 


| SDR (Storage Distributed Resource Scheduler) | Sì | Sì | Sì | Sì 


| Software di backup abilitato VADP (VMware vStorage API for Data Protection) | Sì | Sì | Sì | Sì 


| Microsoft Cluster Service (MSCS) o clustering di failover all'interno di una macchina virtuale | Sì | Sì* | Sì* | Non supportato 


| Tolleranza agli errori | Sì | Sì | Sì | Sì 


| Site Recovery Manager | Sì | Sì | No** | Solo V3** 


| Macchine virtuali con thin provisioning (dischi virtuali) | Sì | Sì | Sì | Sì
Si tratta dell'impostazione predefinita per tutte le macchine virtuali su NFS quando non si utilizza VAAI. 


| Multipathing nativo di VMware | Sì | Sì | Sì, utilizzando il nuovo plug-in ad alte prestazioni (HPP) | N/A. 
|===
La tabella seguente elenca le funzionalità di gestione dello storage ONTAP supportate.

|===
| Funzionalità | FC/FCoE | ISCSI | NVMe-of | NFS 


| Deduplica dei dati | Risparmi nell'array | Risparmi nell'array | Risparmi nell'array | Risparmi nel datastore 


| Thin provisioning | Datastore o RDM | Datastore o RDM | Datastore | Datastore 


| Ridimensiona datastore | Crescere solo | Crescere solo | Crescere solo | Crescita, crescita automatica e riduzione 


| Plug-in SnapCenter per applicazioni Windows e Linux (in guest) | Sì | Sì | No | Sì 


| Monitoraggio e configurazione dell'host con gli strumenti ONTAP per VMware vSphere | Sì | Sì | No | Sì 


| Provisioning con gli strumenti ONTAP per VMware vSphere | Sì | Sì | No | Sì 
|===
La tabella seguente elenca le funzionalità di backup supportate.

|===
| Funzionalità | FC/FCoE | ISCSI | NVMe-of | NFS 


| Istantanee di ONTAP | Sì | Sì | Sì | Sì 


| SRM supportato da backup replicati | Sì | Sì | No** | Solo V3** 


| Volume SnapMirror | Sì | Sì | Sì | Sì 


| Accesso all'immagine VMDK | Software di backup abilitato per VADP | Software di backup abilitato per VADP | Software di backup abilitato per VADP | Software di backup abilitato VADP, vSphere Client e il browser datastore di vSphere Web Client 


| Accesso a livello di file VMDK | Software di backup abilitato VADP, solo Windows | Software di backup abilitato VADP, solo Windows | Software di backup abilitato VADP, solo Windows | Software di backup abilitato VADP e applicazioni di terze parti 


| Granularità NDMP | Datastore | Datastore | Datastore | Datastore o macchina virtuale 
|===
*NetApp consiglia di utilizzare iSCSI in-guest per cluster Microsoft piuttosto che VMDK abilitati per il multi-writer in un datastore VMFS. Questo approccio è completamente supportato da Microsoft e VMware, offre grande flessibilità con ONTAP (SnapMirror per sistemi ONTAP on-premise o nel cloud), è facile da configurare e automatizzare e può essere protetto con SnapCenter. VSphere 7 aggiunge una nuova opzione VMDK in cluster. Si tratta di un'operazione diversa dai VMDK abilitati per il multi-writer, che richiede un datastore presentato tramite il protocollo FC che ha attivato il supporto VMDK in cluster. Sono previste altre restrizioni. Vedere VMware https://docs.vmware.com/en/VMware-vSphere/7.0/vsphere-esxi-vcenter-server-70-setup-wsfc.pdf["Configurazione per il clustering di failover di Windows Server"^] documentazione per le linee guida di configurazione.

**I datastore che utilizzano NVMe-of e NFS v4.1 richiedono la replica vSphere. La replica basata su array non è supportata da SRM.



== Selezione di un protocollo di storage

I sistemi che eseguono il software ONTAP supportano tutti i principali protocolli di storage, in modo che i clienti possano scegliere ciò che meglio si adatta al proprio ambiente, a seconda dell'infrastruttura di rete esistente e pianificata e delle competenze dello staff. I test di NetApp hanno generalmente mostrato poca differenza tra i protocolli eseguiti a velocità di linea simili, pertanto è meglio concentrarsi sull'infrastruttura di rete e sulle funzionalità del personale rispetto alle performance del protocollo raw.

I seguenti fattori potrebbero essere utili per valutare una scelta di protocollo:

* *Ambiente attuale del cliente.* sebbene i team IT siano generalmente esperti nella gestione dell'infrastruttura IP Ethernet, non tutti sono esperti nella gestione di un fabric SAN FC. Tuttavia, l'utilizzo di una rete IP generica non progettata per il traffico di storage potrebbe non funzionare bene. Prendi in considerazione l'infrastruttura di rete in uso, gli eventuali miglioramenti pianificati e le competenze e la disponibilità del personale per gestirli.
* *Facilità di configurazione.* oltre alla configurazione iniziale del fabric FC (switch e cablaggio aggiuntivi, zoning e verifica dell'interoperabilità di HBA e firmware), i protocolli a blocchi richiedono anche la creazione e la mappatura di LUN e il rilevamento e la formattazione da parte del sistema operativo guest. Una volta creati ed esportati, i volumi NFS vengono montati dall'host ESXi e pronti all'uso. NFS non dispone di specifiche qualifiche hardware o firmware da gestire.
* *Facilità di gestione.* con i protocolli SAN, se è necessario più spazio, sono necessari diversi passaggi, tra cui la crescita di un LUN, la ricerca di nuove dimensioni e la crescita del file system). Sebbene sia possibile aumentare un LUN, non è possibile ridurre le dimensioni di un LUN e il ripristino dello spazio inutilizzato può richiedere ulteriore impegno. NFS consente un facile dimensionamento in alto o in basso e questo ridimensionamento può essere automatizzato dal sistema storage. LA SAN offre la bonifica dello spazio attraverso i comandi TRIM/UNMAP del sistema operativo guest, consentendo di restituire spazio dai file cancellati all'array. Questo tipo di recupero dello spazio è più difficile con gli archivi dati NFS.
* *Trasparenza dello spazio di storage.* l'utilizzo dello storage è in genere più semplice da visualizzare negli ambienti NFS perché il thin provisioning restituisce immediatamente risparmi. Allo stesso modo, i risparmi di deduplica e clonazione sono immediatamente disponibili per altre macchine virtuali nello stesso datastore o per altri volumi di sistemi storage. La densità delle macchine virtuali è in genere maggiore anche in un datastore NFS, che può migliorare i risparmi della deduplica e ridurre i costi di gestione grazie a un numero inferiore di datastore da gestire.




== Layout del datastore

I sistemi storage ONTAP offrono una grande flessibilità nella creazione di datastore per macchine virtuali e dischi virtuali. Sebbene vengano applicate molte Best practice ONTAP quando si utilizza VSC per il provisioning dei datastore per vSphere (elencate nella sezione link:settings.html["Host ESXi consigliato e altre impostazioni ONTAP"]), ecco alcune linee guida aggiuntive da prendere in considerazione:

* L'implementazione di vSphere con datastore NFS di ONTAP offre un'implementazione facile da gestire e dalle performance elevate che offre rapporti VM-datastore che non possono essere ottenuti con protocolli di storage basati su blocchi. Questa architettura può comportare un aumento di dieci volte della densità degli archivi dati con una conseguente riduzione del numero di archivi dati. Anche se un datastore più grande può trarre beneficio dall'efficienza dello storage e offrire vantaggi operativi, è consigliabile utilizzare almeno quattro datastore (volumi FlexVol) per memorizzare le macchine virtuali su un singolo controller ONTAP per ottenere le massime prestazioni dalle risorse hardware. Questo approccio consente inoltre di stabilire datastore con policy di recovery diverse. Alcuni possono essere sottoposti a backup o replicati più frequentemente rispetto ad altri in base alle esigenze aziendali. I volumi FlexGroup non richiedono più datastore per le performance, in quanto sono scalabili in base alla progettazione.
* NetApp consiglia di utilizzare i volumi FlexVol per la maggior parte dei datastore NFS. A partire da ONTAP 9,8, l'utilizzo dei volumi FlexGroup è supportato anche come datastore e generalmente è consigliato per alcuni casi d'utilizzo. Gli altri container di storage ONTAP, come i qtree, non sono generalmente consigliati, in quanto al momento non sono supportati dai tool ONTAP per VMware vSphere o dal plug-in NetApp SnapCenter per VMware vSphere. Ciò detto, implementare datastore come qtree multiple in un singolo volume potrebbe essere utile per ambienti altamente automatizzati, che possono trarre beneficio da quote a livello di datastore o cloni dei file delle macchine virtuali.
* Una buona dimensione per un datastore di volumi FlexVol è di circa 4TB - 8TB. Queste dimensioni rappresentano un buon punto di equilibrio per le performance, la facilità di gestione e la protezione dei dati. Inizia in piccolo (ad esempio, 4 TB) e fai crescere il datastore in base alle necessità (fino a un massimo di 100 TB). I datastore più piccoli sono più veloci da ripristinare dal backup o dopo un disastro e possono essere spostati rapidamente nel cluster. Prendere in considerazione l'utilizzo della funzione di dimensionamento automatico di ONTAP per aumentare e ridurre automaticamente il volume in base alle modifiche dello spazio utilizzato. Per impostazione predefinita, i tool ONTAP per il provisioning guidato degli archivi dati VMware vSphere utilizzano la dimensione automatica per i nuovi archivi dati. È possibile personalizzare ulteriormente le soglie di aumento e riduzione e le dimensioni massime e minime con System Manager o la riga di comando.
* In alternativa, gli archivi dati VMFS possono essere configurati con LUN accessibili da FC, iSCSI o FCoE. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. Gli archivi di dati VMFS possono avere dimensioni fino a 64 TB e sono costituiti da un massimo di 32 LUN da 2 TB (VMFS 3) o un singolo LUN da 64 TB (VMFS 5). La dimensione massima del LUN ONTAP è 16 TB sulla maggior parte dei sistemi e 128 TB sui sistemi all-SAN-array. Pertanto, è possibile creare un datastore VMFS 5 di dimensioni massime sulla maggior parte dei sistemi ONTAP utilizzando quattro LUN da 16 TB. Sebbene i carichi di lavoro con i/o elevati possano offrire un vantaggio in termini di performance con più LUN (con sistemi FAS o AFF high-end), questo vantaggio è compensato dalla complessità di gestione aggiunta per creare, gestire e proteggere le LUN degli archivi dati e dall'aumento del rischio di disponibilità. In genere, NetApp consiglia di utilizzare un singolo LUN di grandi dimensioni per ciascun datastore e solo se è necessario andare oltre un datastore da 16 TB. Come per NFS, puoi utilizzare più datastore (volumi) per massimizzare le performance su un singolo controller ONTAP.
* I sistemi operativi guest precedenti necessitavano di un allineamento con il sistema storage per ottenere le migliori performance ed efficienza dello storage. Tuttavia, i moderni sistemi operativi supportati dai vendor dei distributori Microsoft e Linux come Red Hat non richiedono più modifiche per allineare la partizione del file system con i blocchi del sistema storage sottostante in un ambiente virtuale. Se si utilizza un sistema operativo precedente che potrebbe richiedere l'allineamento, cercare gli articoli nella Knowledge base del supporto NetApp utilizzando "allineamento delle macchine virtuali" o richiedere una copia di TR-3747 a un contatto commerciale o partner di NetApp.
* Evitare l'uso di utilità di deframmentazione all'interno del sistema operativo guest, poiché ciò non offre vantaggi in termini di prestazioni e influisce sull'efficienza dello storage e sull'utilizzo dello spazio snapshot. È inoltre consigliabile disattivare l'indicizzazione della ricerca nel sistema operativo guest per i desktop virtuali.
* ONTAP ha guidato il settore con innovative funzionalità di efficienza dello storage, che ti consentono di sfruttare al massimo lo spazio su disco utilizzabile. I sistemi AFF aumentano ulteriormente questa efficienza con la deduplica e la compressione inline predefinite. I dati vengono deduplicati in tutti i volumi in un aggregato, quindi non è più necessario raggruppare sistemi operativi simili e applicazioni simili in un singolo datastore per massimizzare i risparmi.
* In alcuni casi, potrebbe non essere necessario un datastore. Per ottenere performance e gestibilità ottimali, evitare di utilizzare un datastore per applicazioni con i/o elevato, come database e alcune applicazioni. Si consiglia invece di prendere in considerazione file system di proprietà degli ospiti, come NFS o iSCSI, gestiti dal guest o con RDM. Per indicazioni specifiche sulle applicazioni, consulta i report tecnici NetApp relativi alla tua applicazione. Ad esempio, link:/oracle/overview.html["Database Oracle su ONTAP"] contiene una sezione sulla virtualizzazione con informazioni utili.
* I dischi di prima classe (o dischi virtuali migliorati) consentono dischi gestiti da vCenter indipendenti da una macchina virtuale con vSphere 6.5 e versioni successive. Anche se gestiti principalmente da API, possono essere utili con vVol, soprattutto se gestiti da OpenStack o Kubernetes tools. Sono supportati da ONTAP e dai tool ONTAP per VMware vSphere.




== Migrazione di datastore e macchine virtuali

Quando si esegue la migrazione delle macchine virtuali da un datastore esistente su un altro sistema storage a ONTAP, è necessario tenere presente alcune procedure:

* Utilizzare Storage vMotion per spostare la maggior parte delle macchine virtuali su ONTAP. Questo approccio non solo non è disgregativo per l'esecuzione di macchine virtuali, ma consente anche funzionalità di efficienza dello storage ONTAP come la deduplica inline e la compressione per elaborare i dati durante la migrazione. Prendere in considerazione l'utilizzo delle funzionalità di vCenter per selezionare più macchine virtuali dall'elenco di inventario e quindi pianificare la migrazione (utilizzare il tasto Ctrl mentre si fa clic su azioni) in un momento appropriato.
* Sebbene sia possibile pianificare con attenzione una migrazione verso datastore di destinazione appropriati, spesso è più semplice eseguire la migrazione in blocco e poi organizzarla in un secondo momento. Potresti voler utilizzare questo approccio per guidare la migrazione verso datastore diversi, se hai esigenze specifiche di data Protection, come ad esempio diverse pianificazioni Snapshot.
* La maggior parte delle macchine virtuali e del relativo storage può essere migrata durante l'esecuzione (a caldo), ma la migrazione dello storage collegato (non nel datastore) come gli ISO, i LUN o i volumi NFS da un altro sistema storage potrebbe richiedere la migrazione a freddo.
* Le macchine virtuali che richiedono una migrazione più accurata includono database e applicazioni che utilizzano lo storage collegato. In generale, considerare l'utilizzo degli strumenti dell'applicazione per gestire la migrazione. Per Oracle, prendere in considerazione l'utilizzo di strumenti Oracle come RMAN o ASM per migrare i file di database. Vedere https://www.netapp.com/us/media/tr-4534.pdf["TR-4534"^] per ulteriori informazioni. Allo stesso modo, per SQL Server, prendere in considerazione l'utilizzo di SQL Server Management Studio o di strumenti NetApp come SnapManager per SQL Server o SnapCenter.




== Strumenti ONTAP per VMware vSphere

La Best practice più importante per l'utilizzo di vSphere con i sistemi che eseguono il software ONTAP consiste nell'installare e utilizzare i tool ONTAP per il plug-in di VMware vSphere (precedentemente noto come console di storage virtuale). Questo plug-in vCenter semplifica la gestione dello storage, migliora la disponibilità e riduce i costi di storage e l'overhead operativo, sia che si utilizzi SAN che NAS. Utilizza le Best practice per il provisioning degli archivi di dati e ottimizza le impostazioni degli host ESXi per i timeout multipath e HBA (descritti nell'Appendice B). Poiché si tratta di un plug-in vCenter, è disponibile per tutti i client web vSphere che si connettono al server vCenter.

Il plug-in consente inoltre di utilizzare altri strumenti ONTAP in ambienti vSphere. Il prodotto consente di installare il plug-in NFS per VMware VAAI, che consente l'offload delle copie in ONTAP per le operazioni di cloning delle macchine virtuali, lo space reservation per i file di dischi virtuali con thick provisioning e l'offload delle snapshot ONTAP.

Il plug-in è anche l'interfaccia di gestione di molte funzionalità del provider VASA per ONTAP, con supporto per la gestione basata su policy di storage con vVol. Una volta registrati i tool ONTAP per VMware vSphere, utilizzali per creare profili di capacità storage, mapparli allo storage e garantire la conformità dei datastore con i profili nel tempo. Il provider VASA fornisce anche un'interfaccia per creare e gestire datastore vVol.

In generale, NetApp consiglia di utilizzare i tool ONTAP per l'interfaccia di VMware vSphere all'interno di vCenter per eseguire il provisioning di datastore tradizionali e vVol per garantire il rispetto delle Best practice.



== Rete generale

La configurazione delle impostazioni di rete quando si utilizza vSphere con sistemi che eseguono il software ONTAP è semplice e simile ad altre configurazioni di rete. Ecco alcuni aspetti da considerare:

* Separare il traffico di rete dello storage dalle altre reti. È possibile ottenere una rete separata utilizzando una VLAN dedicata o switch separati per lo storage. Se la rete di storage condivide percorsi fisici come gli uplink, potrebbe essere necessario QoS o porte di uplink aggiuntive per garantire una larghezza di banda sufficiente. Non connettere gli host direttamente allo storage; utilizzare gli switch per disporre di percorsi ridondanti e consentire a VMware ha di funzionare senza alcun intervento.
* I frame jumbo possono essere utilizzati se lo si desidera e supportati dalla rete, in particolare quando si utilizza iSCSI. Se vengono utilizzati, assicurarsi che siano configurati in modo identico su tutti i dispositivi di rete, VLAN e così via nel percorso tra lo storage e l'host ESXi. In caso contrario, potrebbero verificarsi problemi di connessione o di prestazioni. La MTU deve essere impostata in modo identico anche sullo switch virtuale ESXi, sulla porta VMkernel e anche sulle porte fisiche o sui gruppi di interfacce di ciascun nodo ONTAP.
* NetApp consiglia di disattivare il controllo del flusso di rete solo sulle porte di rete del cluster all'interno di un cluster ONTAP. NetApp non fornisce altri consigli sulle Best practice per le restanti porte di rete utilizzate per il traffico dati. Attivare o disattivare secondo necessità. Vedere http://www.netapp.com/us/media/tr-4182.pdf["TR-4182"^] per ulteriori informazioni sul controllo di flusso.
* Quando gli array di storage ESXi e ONTAP sono collegati a reti di storage Ethernet, NetApp consiglia di configurare le porte Ethernet a cui questi sistemi si connettono come porte edge RSTP (Rapid Spanning Tree Protocol) o utilizzando la funzione PortFast di Cisco. NetApp consiglia di abilitare la funzione di trunk PortFast Spanning-Tree in ambienti che utilizzano la funzionalità Cisco PortFast e che dispongono di un trunking VLAN 802.1Q abilitato per il server ESXi o gli array di storage ONTAP.
* NetApp consiglia le seguenti Best practice per l'aggregazione dei collegamenti:
+
** Utilizzare switch che supportano l'aggregazione di collegamenti di porte su due chassis switch separati utilizzando un approccio a gruppi di aggregazione di collegamenti multi-chassis, ad esempio Virtual PortChannel (VPC) di Cisco.
** Disattivare LACP per le porte dello switch connesse a ESXi, a meno che non si utilizzi dvSwitch 5.1 o versioni successive con LACP configurato.
** Utilizza LACP per creare aggregati di link per sistemi di storage ONTAP con gruppi di interfacce dinamiche multimode con hash porta o IP. Fare riferimento a. https://docs.netapp.com/us-en/ontap/networking/combine_physical_ports_to_create_interface_groups.html#dynamic-multimode-interface-group["Gestione della rete"^] per ulteriori indicazioni.
** Utilizzare un criterio di raggruppamento hash IP su ESXi quando si utilizza l'aggregazione di collegamenti statici (ad esempio, EtherChannel) e vSwitch standard o l'aggregazione di collegamenti basata su LACP con gli switch distribuiti vSphere. Se non si utilizza l'aggregazione dei collegamenti, utilizzare invece "Route based on the origining virtual port ID" (percorso basato sull'ID della porta virtuale di origine).




La seguente tabella fornisce un riepilogo degli elementi di configurazione di rete e indica la posizione in cui vengono applicate le impostazioni.

|===
| Elemento | ESXi | Switch | Nodo | SVM 


| Indirizzo IP | VMkernel | No** | No** | Sì 


| Aggregazione dei collegamenti | Switch virtuale | Sì | Sì | No* 


| VLAN | Gruppi di porte VMkernel e VM | Sì | Sì | No* 


| Controllo di flusso | NIC | Sì | Sì | No* 


| Spanning tree | No | Sì | No | No 


| MTU (per frame jumbo) | Switch virtuale e porta VMkernel (9000) | Sì (impostato su max) | Sì (9000) | No* 


| Gruppi di failover | No | No | Sì (creare) | Sì (selezionare) 
|===
*Le LIF SVM si connettono a porte, gruppi di interfacce o interfacce VLAN con VLAN, MTU e altre impostazioni. Tuttavia, le impostazioni non vengono gestite a livello di SVM.

**Questi dispositivi dispongono di indirizzi IP propri per la gestione, ma non vengono utilizzati nel contesto dello storage di rete ESXi.



== SAN (FC, FCoE, NVMe/FC, iSCSI), RDM

In vSphere, esistono tre modi per utilizzare le LUN dello storage a blocchi:

* Con datastore VMFS
* Con RDM (raw device mapping)
* Come LUN accessibile e controllato da un iniziatore software da un sistema operativo guest VM


VMFS è un file system in cluster dalle performance elevate che fornisce datastore che sono pool di storage condivisi. Gli archivi dati VMFS possono essere configurati con LUN a cui si accede utilizzando spazi dei nomi FC, iSCSI, FCoE o NVMe a cui si accede dal protocollo NVMe/FC. VMFS consente l'accesso simultaneo alle LUN tradizionali da parte di ogni server ESX in un cluster. La dimensione massima del LUN ONTAP è generalmente di 16 TB; pertanto, un datastore VMFS 5 di 64 TB (vedere la prima tabella di questa sezione) viene creato utilizzando quattro LUN da 16 TB (tutti i sistemi array SAN supportano la dimensione massima del LUN VMFS di 64 TB). Poiché l'architettura LUN di ONTAP non ha una profondità di coda singola ridotta, gli archivi dati VMFS in ONTAP possono scalare in maniera relativamente semplice rispetto alle architetture di array tradizionali.

VSphere include il supporto integrato per più percorsi verso i dispositivi storage, definito NMP (Native Multipathing). NMP è in grado di rilevare il tipo di storage per i sistemi storage supportati e di configurare automaticamente lo stack NMP per supportare le funzionalità del sistema storage in uso.

Sia NMP che NetApp ONTAP supportano l'accesso ad unità logica asimmetrico (ALUA) per negoziare percorsi ottimizzati e non ottimizzati. In ONTAP, un percorso ottimizzato per ALUA segue un percorso di dati diretto, utilizzando una porta di destinazione sul nodo che ospita il LUN a cui si accede. ALUA è attivato per impostazione predefinita sia in vSphere che in ONTAP. NMP riconosce il cluster ONTAP come ALUA e utilizza il plug-in del tipo di array di storage ALUA (`VMW_SATP_ALUA`) e seleziona il plug-in di selezione del percorso round robin (`VMW_PSP_RR`).

ESXi 6 supporta fino a 256 LUN e fino a 1,024 percorsi totali verso LUN. I LUN o i percorsi che superano questi limiti non sono visti da ESXi. Supponendo il numero massimo di LUN, il limite di percorso consente quattro percorsi per LUN. In un cluster ONTAP più grande, è possibile raggiungere il limite di percorso prima del limite di LUN. Per risolvere questo limite, ONTAP supporta la mappa LUN selettiva (SLM) nella versione 8.3 e successive.

SLM limita i nodi che pubblicizzano i percorsi a una determinata LUN. È una Best practice di NetApp avere almeno una LIF per nodo per SVM e utilizzare SLM per limitare i percorsi pubblicizzati al nodo che ospita la LUN e il suo partner ha. Sebbene esistano altri percorsi, essi non vengono pubblicizzati per impostazione predefinita. È possibile modificare i percorsi pubblicizzati con gli argomenti del nodo di reporting add e remove all'interno di SLM. Tenere presente che le LUN create nelle release precedenti alla 8.3 pubblicizzano tutti i percorsi e devono essere modificate solo per pubblicizzare i percorsi alla coppia ha di hosting. Per ulteriori informazioni su SLM, vedere la sezione 5.9 di http://www.netapp.com/us/media/tr-4080.pdf["TR-4080"^]. Il precedente metodo di portset può essere utilizzato anche per ridurre ulteriormente i percorsi disponibili per un LUN. I portset aiutano a ridurre il numero di percorsi visibili attraverso i quali gli iniziatori in un igroup possono vedere le LUN.

* SLM è attivato per impostazione predefinita. A meno che non si utilizzino portset, non è necessaria alcuna configurazione aggiuntiva.
* Per i LUN creati prima di Data ONTAP 8.3, applicare manualmente SLM eseguendo `lun mapping remove-reporting-nodes` Comando per rimuovere i nodi di reporting del LUN e limitare l'accesso del LUN al nodo proprietario del LUN e al partner ha.


I protocolli a blocchi (iSCSI, FC e FCoE) accedono alle LUN utilizzando ID LUN e numeri di serie, insieme a nomi univoci. FC e FCoE utilizzano nomi in tutto il mondo (WWNN e WWPN), mentre iSCSI utilizza nomi iSCSI qualificati (IQN). Il percorso delle LUN all'interno dello storage è privo di significato per i protocolli a blocchi e non viene presentato in alcun punto del protocollo. Pertanto, un volume che contiene solo LUN non deve essere montato internamente e non è necessario un percorso di giunzione per i volumi che contengono LUN utilizzati negli archivi dati. Il sottosistema NVMe in ONTAP funziona in modo simile.

Altre Best practice da prendere in considerazione:

* Assicurarsi che venga creata un'interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP per garantire la massima disponibilità e mobilità. La Best practice PER LE SAN ONTAP consiste nell'utilizzare due porte fisiche e LIF per nodo, una per ciascun fabric. ALUA viene utilizzato per analizzare i percorsi e identificare i percorsi attivi ottimizzati (diretti) rispetto ai percorsi attivi non ottimizzati. ALUA viene utilizzato per FC, FCoE e iSCSI.
* Per le reti iSCSI, utilizzare più interfacce di rete VMkernel su diverse subnet di rete con raggruppamento NIC quando sono presenti più switch virtuali. È inoltre possibile utilizzare più NIC fisiche collegate a più switch fisici per fornire ha e un throughput maggiore. La figura seguente mostra un esempio di connettività multipath. In ONTAP, configurare un gruppo di interfacce single-mode per il failover con due o più collegamenti connessi a due o più switch oppure utilizzare LACP o un'altra tecnologia di aggregazione dei collegamenti con gruppi di interfacce multimodali per fornire ha e i vantaggi dell'aggregazione dei collegamenti.
* Se il protocollo CHAP (Challenge-Handshake Authentication Protocol) viene utilizzato in ESXi per l'autenticazione di destinazione, deve essere configurato anche in ONTAP utilizzando la CLI (`vserver iscsi security create`) O con System Manager (modificare Initiator Security in Storage > SVM > SVM Settings > Protocols > iSCSI).
* Utilizza i tool ONTAP per VMware vSphere per creare e gestire LUN e igroups. Il plug-in determina automaticamente le WWPN dei server e crea gli igroups appropriati. Inoltre, configura i LUN in base alle Best practice e li associa agli igroups corretti.
* Utilizzare con cautela gli RDM poiché possono essere più difficili da gestire e utilizzano anche percorsi limitati come descritto in precedenza. I LUN ONTAP supportano entrambi https://kb.vmware.com/s/article/2009226["modalità di compatibilità fisica e virtuale"^] RDM.
* Per ulteriori informazioni sull'utilizzo di NVMe/FC con vSphere 7.0, consulta questo articolo https://docs.netapp.com/us-en/ontap-sanhost/nvme_esxi_7.html["Guida alla configurazione degli host NVMe/FC di ONTAP"^] e. http://www.netapp.com/us/media/tr-4684.pdf["TR-4684"^]La figura seguente mostra la connettività multipath da un host vSphere a un LUN ONTAP.


image:vsphere_ontap_image2.png["Errore: Immagine grafica mancante"]



== NFS

VSphere consente ai clienti di utilizzare array NFS di livello Enterprise per fornire l'accesso simultaneo agli archivi dati a tutti i nodi di un cluster ESXi. Come indicato nella sezione datastore, l'utilizzo di NFS con vSphere offre alcuni vantaggi in termini di facilità d'uso e visibilità dell'efficienza dello storage.

Quando si utilizza ONTAP NFS con vSphere, si consiglia di seguire le seguenti Best practice:

* Utilizzare una singola interfaccia logica (LIF) per ogni SVM su ciascun nodo del cluster ONTAP. Le raccomandazioni precedenti di un LIF per datastore non sono più necessarie. Benché l'accesso diretto (LIF e datastore sullo stesso nodo) sia migliore, non preoccuparti dell'accesso indiretto perché l'effetto sulle performance è generalmente minimo (microsecondi).
* VMware supporta NFSv3 da VMware Infrastructure 3. VSphere 6.0 ha aggiunto il supporto per NFSv4.1, che abilita alcune funzionalità avanzate come la sicurezza Kerberos. Dove NFSv3 utilizza il blocco lato client, NFSv4.1 utilizza il blocco lato server. Anche se un volume ONTAP può essere esportato attraverso entrambi i protocolli, ESXi può essere montato solo attraverso un protocollo. Questo montaggio di protocollo singolo non impedisce ad altri host ESXi di montare lo stesso datastore attraverso una versione diversa. Assicurarsi di specificare la versione del protocollo da utilizzare durante il montaggio in modo che tutti gli host utilizzino la stessa versione e, di conseguenza, lo stesso stile di blocco. Non mischiare versioni NFS tra gli host. Se possibile, utilizzare i profili host per verificare la conformità.
+
** Poiché non esiste alcuna conversione automatica del datastore tra NFSv3 e NFSv4.1, creare un nuovo datastore NFSv4.1 e utilizzare Storage vMotion per migrare le macchine virtuali nel nuovo datastore.
** Fare riferimento alle note della tabella di interoperabilità NFS v4.1 nella https://mysupport.netapp.com/matrix/["Tool NetApp Interoperability Matrix"^] Per i livelli di patch ESXi specifici richiesti per il supporto.


* Le policy di esportazione NFS vengono utilizzate per controllare l'accesso da parte degli host vSphere. È possibile utilizzare un criterio con più volumi (datastore). Con NFSv3, ESXi utilizza lo stile di sicurezza sys (UNIX) e richiede l'opzione di montaggio root per eseguire le macchine virtuali. In ONTAP, questa opzione viene definita superutente e, quando viene utilizzata l'opzione superutente, non è necessario specificare l'ID utente anonimo. Tenere presente che le regole dei criteri di esportazione con valori diversi per `-anon` e. `-allow-suid` Può causare problemi di rilevamento SVM con gli strumenti ONTAP. Ecco un esempio di politica:
+
** Access Protocol (protocollo di accesso): Nfs3
** Specifiche di corrispondenza del client: 192.168.42.21
** Regola di accesso RO: SIS
** RW Access Rule (regola di accesso RW): SIS
** UID anonimo
** Superutente: SIS


* Se si utilizza il plug-in NetApp NFS per VMware VAAI, il protocollo deve essere impostato su `nfs` quando viene creata o modificata la regola dei criteri di esportazione. Il protocollo NFSv4 è necessario per l'offload delle copie VAAI e per specificare il protocollo come `nfs` Include automaticamente le versioni NFSv3 e NFSv4.
* I volumi del datastore NFS vengono svincoli dal volume root di SVM; pertanto, ESXi deve anche avere accesso al volume root per navigare e montare i volumi del datastore. La policy di esportazione per il volume root e per qualsiasi altro volume in cui la giunzione del volume del datastore è nidificata deve includere una regola o regole per i server ESXi che concedono loro l'accesso in sola lettura. Ecco un esempio di policy per il volume root, utilizzando anche il plug-in VAAI:
+
** Access Protocol: nfs (che include sia nfs3 che nfs4)
** Specifiche di corrispondenza del client: 192.168.42.21
** Regola di accesso RO: SIS
** RW Access Rule: Never (miglior sicurezza per il volume root)
** UID anonimo
** Superutente: SYS (richiesto anche per il volume root con VAAI)


* Utilizza i tool ONTAP per VMware vSphere (la Best practice più importante):
+
** Utilizza i tool ONTAP per VMware vSphere per eseguire il provisioning degli archivi dati, poiché semplifica automaticamente la gestione delle policy di esportazione.
** Quando si creano datastore per cluster VMware con il plug-in, selezionare il cluster anziché un singolo server ESX. Questa opzione attiva il montaggio automatico del datastore su tutti gli host del cluster.
** Utilizzare la funzione di montaggio del plug-in per applicare i datastore esistenti ai nuovi server.
** Quando non si utilizzano gli strumenti ONTAP per VMware vSphere, utilizzare una singola policy di esportazione per tutti i server o per ciascun cluster di server in cui è necessario un controllo aggiuntivo degli accessi.


* Sebbene ONTAP offra una struttura flessibile dello spazio dei nomi dei volumi per organizzare i volumi in un albero utilizzando le giunzioni, questo approccio non ha alcun valore per vSphere. Crea una directory per ogni VM nella directory principale dell'archivio dati, indipendentemente dalla gerarchia dello spazio dei nomi dello storage. Pertanto, la Best practice consiste nel montare semplicemente il percorso di giunzione per i volumi per vSphere nel volume root della SVM, che è il modo in cui i tool ONTAP per VMware vSphere prevedono il provisioning dei datastore. La mancanza di percorsi di giunzione nidificati significa anche che nessun volume dipende da un volume diverso dal volume root e che la sua eliminazione o la sua eliminazione, anche intenzionalmente, non influisce sul percorso verso altri volumi.
* Una dimensione del blocco di 4K è adatta per le partizioni NTFS negli archivi dati NFS. La figura seguente mostra la connettività da un host vSphere a un datastore NFS ONTAP.


image:vsphere_ontap_image3.png["Errore: Immagine grafica mancante"]

La seguente tabella elenca le versioni di NFS e le funzionalità supportate.

|===
| Funzionalità di vSphere | NFSv3 | NFSv4,1 


| VMotion e Storage vMotion | Sì | Sì 


| Alta disponibilità | Sì | Sì 


| Tolleranza agli errori | Sì | Sì 


| DRS | Sì | Sì 


| Profili host | Sì | Sì 


| DRS dello storage | Sì | No 


| Controllo i/o dello storage | Sì | No 


| SRM | Sì | No 


| Volumi virtuali | Sì | No 


| Accelerazione hardware (VAAI) | Sì | Sì 


| Autenticazione Kerberos | No | Sì (ottimizzato con vSphere 6.5 e versioni successive per supportare AES, krb5i) 


| Supporto multipathing | No | No 
|===


== Volumi FlexGroup

ONTAP 9,8 aggiunge il supporto per datastore di volumi FlexGroup in vSphere, oltre al supporto dei tool ONTAP per VMware vSphere e del plug-in SnapCenter per VMware vSphere. FlexGroup semplifica la creazione di datastore di grandi dimensioni e crea automaticamente una serie di volumi costituenti per ottenere le massime performance da un sistema ONTAP. Utilizza FlexGroup con vSphere se desideri un singolo datastore vSphere scalabile con la potenza di un cluster ONTAP completo o se disponi di carichi di lavoro di cloning molto grandi che possono sfruttare il nuovo meccanismo di cloning di FlexGroup.

Oltre ai test di sistema estesi con carichi di lavoro vSphere, ONTAP 9.8 aggiunge anche un nuovo meccanismo di offload delle copie per gli archivi dati FlexGroup. Questo utilizza un motore di copia aggiornato che utilizza i primi cloni per popolare una cache locale in ogni volume costituente. La cache locale viene quindi utilizzata per creare rapidamente istanze dei cloni delle macchine virtuali on-demand.

Considerare il seguente scenario:

* Hai creato un nuovo FlexGroup con 8 componenti
* Il timeout della cache per il nuovo FlexGroup è impostato su 160 minuti


In questo scenario, i primi 8 cloni da completare saranno copie complete, non cloni di file locali. Qualsiasi clonazione aggiuntiva di tale macchina virtuale prima della scadenza del timeout di 160 secondi utilizzerà il motore di clonazione file all'interno di ciascun componente in modo round-robin per creare copie quasi immediate distribuite uniformemente tra i volumi costituenti.

Ogni nuovo processo di clonazione che un volume riceve ripristina il timeout. Se un volume costituente nel FlexGroup di esempio non riceve una richiesta di clone prima del timeout, la cache di quella particolare VM verrà cancellata e il volume dovrà essere popolato di nuovo. Inoltre, se l'origine del clone originale cambia (ad esempio, è stato aggiornato il modello), la cache locale di ciascun componente verrà invalidata per evitare conflitti. La cache è regolabile e può essere impostata in base alle esigenze dell'ambiente.

In ambienti in cui non è possibile sfruttare al meglio la cache FlexGroup, ma è comunque necessario un rapido cloning cross-volume, prendere in considerazione l'utilizzo di vVol. Il cloning tra volumi con vVol è molto più rapido rispetto ai datastore tradizionali, senza fare affidamento su una cache.

Per ulteriori informazioni sull'utilizzo di FlexGroup con VAAI, fare riferimento a questo articolo della KB: https://kb.netapp.com/?title=onprem%2Fontap%2Fdm%2FVAAI%2FVAAI%3A_How_does_caching_work_with_FlexGroups%253F["VAAI: Come funziona il caching con i volumi FlexGroup?"^]

ONTAP 9,8 aggiunge inoltre nuove metriche di performance basate su file (IOPS, throughput e latenza) per i file di volumi FlexGroup. Queste metriche possono essere visualizzate nei tool ONTAP per la dashboard e i report delle macchine virtuali di VMware vSphere. Il plug-in ONTAP Tools per VMware vSphere consente inoltre di impostare le regole di qualità del servizio (QoS) utilizzando una combinazione di IOPS massimo e/o minimo. Questi possono essere impostati su tutte le macchine virtuali in un datastore o singolarmente per macchine virtuali specifiche.

Ecco alcune Best practice aggiuntive sviluppate da NetApp:

* Utilizzare le impostazioni predefinite per il provisioning dei volumi FlexGroup. Mentre i tool ONTAP per VMware vSphere sono consigliati perché creano e montano il FlexGroup all'interno di vSphere, è possibile utilizzare Gestione di sistema ONTAP o la riga di comando per esigenze speciali. Anche in questo caso, utilizzare le impostazioni predefinite, ad esempio il numero di membri costituenti per nodo, poiché questo è ciò che è stato più accuratamente testato con vSphere. Detto questo, le impostazioni non predefinite, come la modifica del numero o del posizionamento dei componenti, sono ancora pienamente supportate.
* Durante il dimensionamento di un datastore basato su FlexGroup, ricorda che FlexGroup è composto da diversi volumi FlexVol più piccoli che creano un namespace più grande. Pertanto, quando si utilizza un FlexGroup con otto componenti, assicurarsi di dimensionare il datastore in modo che sia almeno 8x volte superiore alle dimensioni della macchina virtuale più grande. Ad esempio, se nell'ambiente si dispone di una macchina virtuale da 6 TB, dimensionare il datastore FlexGroup non inferiore a 48 TB.
* Consentire a FlexGroup di gestire lo spazio del datastore. Il dimensionamento automatico e il dimensionamento elastico sono stati testati con datastore vSphere. Nel caso in cui il datastore si avvicini alla capacità massima, utilizzare i tool ONTAP per VMware vSphere o un altro tool per ridimensionare il volume FlexGroup. FlexGroup mantiene la capacità e gli inode bilanciati tra i componenti, assegnando la priorità ai file all'interno di una cartella (VM) sullo stesso costituente, se la capacità lo consente.
* VMware e NetApp attualmente non supportano un approccio di rete multipath comune. Per NFSv4.1, NetApp supporta pNFS, mentre VMware supporta il trunking di sessione. NFSv3 non supporta percorsi fisici multipli per un volume. Per FlexGroup con ONTAP 9,8, si consiglia di lasciare che gli strumenti ONTAP per VMware vSphere creino FlexGroup, ma poi è necessario smontarlo e rimontarlo utilizzando il DNS round robin per distribuire il carico nel cluster. Gli strumenti ONTAP usano una sola LIF per il montaggio di datastore. Dopo aver rimontato il datastore, è possibile utilizzare strumenti ONTAP per monitorarlo e gestirlo.
* Il supporto del datastore FlexGroup vSphere è stato testato fino a 1500 macchine virtuali con la release 9.8.
* Utilizzare il plug-in NFS per VMware VAAI per l'offload delle copie. Si noti che mentre il cloning è migliorato all'interno di un datastore FlexGroup, come menzionato in precedenza, ONTAP non offre significativi vantaggi in termini di performance rispetto alla copia dell'host ESXi quando si copiano le macchine virtuali tra volumi FlexVol e/o FlexGroup. Prendi in considerazione, pertanto, i workload di cloning al momento di decidere di utilizzare VAAI o FlexGroup. La modifica del numero di volumi costituenti è un modo per ottimizzare il cloning basato su FlexGroup. Come per l'ottimizzazione del timeout della cache.
* Utilizza gli strumenti ONTAP per VMware vSphere 9.8 per monitorare le performance delle macchine virtuali FlexGroup utilizzando metriche ONTAP (report dashboard e macchine virtuali) e per gestire la qualità del servizio su singole macchine virtuali. Queste metriche non sono attualmente disponibili tramite i comandi o le API ONTAP.
* QoS (IOPS max/min) può essere impostato su singole macchine virtuali o su tutte le macchine virtuali in un datastore in quel momento. L'impostazione della QoS su tutte le macchine virtuali sostituisce le impostazioni separate per ogni macchina virtuale. Le impostazioni non si estendono alle macchine virtuali nuove o migrate in futuro; impostare la QoS sulle nuove macchine virtuali o riapplicare la QoS a tutte le macchine virtuali nel datastore. Né le policy di FlexGroup QoS seguono la macchina virtuale se viene migrata su un altro datastore. Questo contrasta con i vVol, che possono mantenere le proprie impostazioni di policy QoS se migrano in un altro datastore.
* Il plug-in SnapCenter per VMware vSphere versione 4,4 e successive supporta il backup e recovery delle macchine virtuali in un datastore FlexGroup nel sistema storage primario. SCV 4,6 aggiunge il supporto di SnapMirror per datastore basati su FlexGroup.

